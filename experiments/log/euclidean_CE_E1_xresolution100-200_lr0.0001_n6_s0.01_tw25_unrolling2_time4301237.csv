Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.01_tw25_unrolling2_time4301237.tar
Number of parameters: 1031651.0
Epoch 0
Starting epoch 0...
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01
Node: 01 (pos: 0.010): 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01
Node: 02 (pos: 0.020): 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01
Node: 03 (pos: 0.030): 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01
Node: 04 (pos: 0.040): 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01
Node: 05 (pos: 0.051): 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01
-
Node: 07 (pos: 0.071): 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01
Node: 08 (pos: 0.081): 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01
Node: 09 (pos: 0.091): 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01
Node: 10 (pos: 0.101): 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01
Node: 11 (pos: 0.111): 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01
Node: 12 (pos: 0.121): 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01
Node: 58 (pos: 0.586): 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01
Node: 59 (pos: 0.596): 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01
Node: 60 (pos: 0.606): 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01
Node: 61 (pos: 0.616): 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01
Node: 50 (pos: 0.505): 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01
-
Node: 51 (pos: 0.515): 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01, 7.74858e-01
Node: 52 (pos: 0.525): 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01, 8.49380e-01
Node: 53 (pos: 0.535): 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01, 9.12263e-01
Node: 54 (pos: 0.545): 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01, 9.60009e-01
Node: 55 (pos: 0.556): 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01, 9.89849e-01
Node: 62 (pos: 0.626): 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01, 6.92595e-01
=========================================================================================================
Training Loss (progress: 0.00), 1.3274213372331831, [0.011444595414190583, 0.021642129611806574, 0.020514969812489386, 0.01960512965165723, 0.020068802071516224, 0.019434454103798633]
Training Loss (progress: 0.08), 0.24304678365887253, [0.014776240437627142, 0.008859805873319438, 0.0008777666612104607, 0.0032997082767750457, 0.01569952710017367, 0.02247634819232059]
Training Loss (progress: 0.16), 0.17183831486728846, [0.0109402032757968, 0.010745661769867312, 0.0007806075189536076, 0.003705891440940046, 0.01891475316696571, 0.026445516120448927]
Training Loss (progress: 0.24), 0.15529807999456746, [0.008236725664551256, 0.011771076298151224, 0.0007595366721338825, 0.004333830175829605, 0.02056836717738294, 0.02999600754932947]
Training Loss (progress: 0.32), 0.14548879438827322, [0.007038164931575889, 0.01278824248052845, 0.0007140889846726436, 0.0044712447334566315, 0.02086837449274881, 0.032383646402242915]
Training Loss (progress: 0.40), 0.12753184005357862, [0.0062798269126032, 0.01276670100384181, 0.0007299490373695068, 0.004008665505132397, 0.020761912549151586, 0.0337408830732575]
Training Loss (progress: 0.48), 0.12767963294713428, [0.005440922073473938, 0.013293934667275263, 0.0007568130636700639, 0.0038972110581818264, 0.020678415244562657, 0.03480937707819168]
Training Loss (progress: 0.56), 0.12472111553727226, [0.004942857244718114, 0.012991808042318819, 0.0007052212982871152, 0.00365661344155365, 0.020228739240554176, 0.034566881486051665]
Training Loss (progress: 0.64), 0.10742319477969667, [0.004591532070890065, 0.012447448644852338, 0.0007750440078399443, 0.0034769257701597186, 0.019705307308919884, 0.03428758352203734]
Training Loss (progress: 0.72), 0.10087042446123963, [0.004527930474131505, 0.012144247931165371, 0.0007714563305187927, 0.0033662807177113462, 0.01931730633798918, 0.0337882147113431]
Training Loss (progress: 0.80), 0.10825057218017359, [0.00446592300784063, 0.012521873114013265, 0.00081795506280077, 0.003214791228941464, 0.018512171700979935, 0.03363337777879162]
Training Loss (progress: 0.88), 0.1110338960652477, [0.004386544719394543, 0.012059982354193222, 0.0008153229384142993, 0.003149526656508981, 0.01756785547768701, 0.03292484355236327]
Training Loss (progress: 0.96), 0.09692486353962766, [0.0040422725298775745, 0.012117840352496217, 0.0007801685316067429, 0.002925793463033265, 0.017083174726069267, 0.032826996257747765]
Evaluation on validation dataset:
Step 25, mean loss 0.07141720836754256
Step 50, mean loss 0.06498971820843283
Step 75, mean loss 0.07630176505275518
Step 100, mean loss 0.22380029252970138
Step 125, mean loss 0.16111179206078408
Step 150, mean loss 0.13422291234492043
Step 175, mean loss 0.230440790130088
Step 200, mean loss 0.3944079065636329
Step 225, mean loss 0.43544114099976683
Unrolled forward losses 12.643079198133117
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.92615e-01, 7.29515e-01, 1.20149e-02, 2.86063e-01, 8.04737e-01, 8.92613e-01
Node: 01 (pos: 0.010): 5.22436e-01, 8.03313e-01, 4.63952e-02, 4.19318e-01, 8.59967e-01, 9.24141e-01
Node: 02 (pos: 0.020): 6.59996e-01, 8.69213e-01, 1.40134e-01, 5.73360e-01, 9.07963e-01, 9.50764e-01
Node: 03 (pos: 0.030): 7.91575e-01, 9.24184e-01, 3.31078e-01, 7.31334e-01, 9.47138e-01, 9.71999e-01
Node: 04 (pos: 0.040): 9.01333e-01, 9.65565e-01, 6.11837e-01, 8.70176e-01, 9.76151e-01, 9.87457e-01
Node: 05 (pos: 0.051): 9.74364e-01, 9.91278e-01, 8.84421e-01, 9.65832e-01, 9.93984e-01, 9.96849e-01
-
Node: 07 (pos: 0.071): 9.74364e-01, 9.91278e-01, 8.84421e-01, 9.65832e-01, 9.93984e-01, 9.96849e-01
Node: 08 (pos: 0.081): 9.01333e-01, 9.65565e-01, 6.11837e-01, 8.70176e-01, 9.76151e-01, 9.87457e-01
Node: 09 (pos: 0.091): 7.91575e-01, 9.24184e-01, 3.31078e-01, 7.31334e-01, 9.47138e-01, 9.71999e-01
Node: 10 (pos: 0.101): 6.59996e-01, 8.69213e-01, 1.40134e-01, 5.73360e-01, 9.07963e-01, 9.50764e-01
Node: 11 (pos: 0.111): 5.22436e-01, 8.03313e-01, 4.63952e-02, 4.19318e-01, 8.59967e-01, 9.24141e-01
Node: 12 (pos: 0.121): 3.92615e-01, 7.29515e-01, 1.20149e-02, 2.86063e-01, 8.04737e-01, 8.92613e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.74364e-01, 9.91278e-01, 8.84421e-01, 9.65832e-01, 9.93984e-01, 9.96849e-01
Node: 58 (pos: 0.586): 9.01333e-01, 9.65565e-01, 6.11837e-01, 8.70176e-01, 9.76151e-01, 9.87457e-01
Node: 59 (pos: 0.596): 7.91575e-01, 9.24184e-01, 3.31078e-01, 7.31334e-01, 9.47138e-01, 9.71999e-01
Node: 60 (pos: 0.606): 6.59996e-01, 8.69213e-01, 1.40134e-01, 5.73360e-01, 9.07963e-01, 9.50764e-01
Node: 61 (pos: 0.616): 5.22436e-01, 8.03313e-01, 4.63952e-02, 4.19318e-01, 8.59967e-01, 9.24141e-01
Node: 50 (pos: 0.505): 3.92615e-01, 7.29515e-01, 1.20149e-02, 2.86063e-01, 8.04737e-01, 8.92613e-01
-
Node: 51 (pos: 0.515): 5.22436e-01, 8.03313e-01, 4.63952e-02, 4.19318e-01, 8.59967e-01, 9.24141e-01
Node: 52 (pos: 0.525): 6.59996e-01, 8.69213e-01, 1.40134e-01, 5.73360e-01, 9.07963e-01, 9.50764e-01
Node: 53 (pos: 0.535): 7.91575e-01, 9.24184e-01, 3.31078e-01, 7.31334e-01, 9.47138e-01, 9.71999e-01
Node: 54 (pos: 0.545): 9.01333e-01, 9.65565e-01, 6.11837e-01, 8.70176e-01, 9.76151e-01, 9.87457e-01
Node: 55 (pos: 0.556): 9.74364e-01, 9.91278e-01, 8.84421e-01, 9.65832e-01, 9.93984e-01, 9.96849e-01
Node: 62 (pos: 0.626): 3.92615e-01, 7.29515e-01, 1.20149e-02, 2.86063e-01, 8.04737e-01, 8.92613e-01
=========================================================================================================
