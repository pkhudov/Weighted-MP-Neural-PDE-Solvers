Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar
Number of parameters: 1031657.0
Saved initial model at models/init5191451.pt
Epoch 0
Starting epoch 0...
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Training Loss (progress: 0.00), 1.3711551022234794, [0.003431897164211928, 0.011362394200511453, 0.011391181984451569, 0.011193692217938362, 0.010278595017173903, 0.011280988672296991], [1.00633071837968, 1.0149662374963362, 1.0149895745523392, 1.0152789751377855, 1.0141081553667006, 1.0145955817718733]
Training Loss (progress: 0.08), 0.247033241485019, [0.003633571512441848, 0.0007467438421822259, 0.002651355752140579, 0.0005424635883193393, 0.0020084323969632415, 0.011747942572555571], [1.0103969457059476, 1.0321789183114487, 1.035119295847536, 1.039904278392696, 1.032014644002681, 1.0393321228033277]
Training Loss (progress: 0.16), 0.1947447217043868, [0.0032240342549296266, 0.0007185779480244723, 0.0030107187424065793, 0.0005643333698038243, 0.0025382323375935825, 0.014809200143672038], [1.008620287160639, 1.0373611140206882, 1.0419761929875446, 1.0523570783320406, 1.0383010491031768, 1.047688298784358]
Training Loss (progress: 0.24), 0.16294684172860002, [0.003285700813686535, 0.000815309209194282, 0.0031133036147597214, 0.0005287977131441145, 0.002612254340313202, 0.018819124446994753], [1.0062606824613283, 1.0403146611202683, 1.048907282809666, 1.0632923044113978, 1.0432494028709465, 1.0545518410969705]
Training Loss (progress: 0.32), 0.14473410748287813, [0.003208559803665994, 0.0008552708258211362, 0.0028807738009395136, 0.000462550158894019, 0.002693754597999273, 0.02188730134768328], [1.003822949537553, 1.0426026575418765, 1.0560559384641424, 1.0697917420686607, 1.0471656414638808, 1.059693338284968]
Training Loss (progress: 0.40), 0.13473472463109581, [0.0032849624584146593, 0.0008511016246707506, 0.0031208820220552844, 0.0004988110023573201, 0.0026505223095843054, 0.025427666111373166], [1.0014646296235756, 1.0435303359844479, 1.0619140282700041, 1.0757926994116933, 1.0507594757395393, 1.0650284545607658]
Training Loss (progress: 0.48), 0.1299964808689126, [0.0032804698632058153, 0.0008566289708529087, 0.0028948725402975824, 0.000565698530452345, 0.0028136645481749295, 0.027528984281979425], [0.9988841338843737, 1.0448777373738274, 1.067069963368859, 1.0808133865103489, 1.0542930645438215, 1.0684442244186776]
Training Loss (progress: 0.56), 0.1200029579943282, [0.0032075895355958613, 0.0008594544506837455, 0.003041636718556299, 0.0005999090260886695, 0.0025354151422583137, 0.030297666447804374], [0.9965499441824548, 1.0459175304709507, 1.0725852973071208, 1.0853153765584387, 1.0581534571424815, 1.0723077842350475]
Training Loss (progress: 0.64), 0.11015952954337431, [0.0033190431947587094, 0.0008501023936964847, 0.003079153685021296, 0.0005640066897339646, 0.0027161073206183536, 0.03300721935909123], [0.9942174165176844, 1.0477769319513024, 1.0774368114347648, 1.089285630229468, 1.0623954151591188, 1.075869507543879]
Training Loss (progress: 0.72), 0.11077055063081644, [0.0031429092128738003, 0.0008204855480129236, 0.0031951545884094275, 0.0005570034660748438, 0.002695359186201925, 0.03568057295523122], [0.9917279290059441, 1.050017444642675, 1.0820238011372654, 1.0920727985558731, 1.0656702987330584, 1.0792505673625659]
Training Loss (progress: 0.80), 0.10782793760935779, [0.0031097070819562436, 0.0008360202455123029, 0.003269316713198377, 0.0005679173119821269, 0.0026779143455776, 0.03800742842853233], [0.9890408634627643, 1.0506777824383502, 1.0870411694982811, 1.095411277840577, 1.069069633008072, 1.0818881897356325]
Training Loss (progress: 0.88), 0.10023642635634845, [0.0032229445420093993, 0.0009014360978461594, 0.0033112057128139374, 0.0005993043995378034, 0.0024994388770049007, 0.04045296245988306], [0.9861979581808736, 1.0517318071832769, 1.091166328489632, 1.0972334778758432, 1.072257713462287, 1.08472008198986]
Training Loss (progress: 0.96), 0.09978392097609506, [0.0033234635944542523, 0.000883128839050468, 0.003455592347499408, 0.0006547734704155875, 0.0026125865895239788, 0.04279761920383635], [0.9835727305141359, 1.0530388582224406, 1.0950403687148222, 1.0980957089795866, 1.0751935050038448, 1.087518116112964]
Evaluation on validation dataset:
Step 25, mean loss 0.08292028522093538
Step 50, mean loss 0.07993403811562198
Step 75, mean loss 0.10588710861142478
Step 100, mean loss 0.2704654508948099
Step 125, mean loss 0.23488263857580605
Step 150, mean loss 0.2252027051273059
Step 175, mean loss 0.40944074891659316
Step 200, mean loss 0.5017237319391517
Step 225, mean loss 0.5443783639151559
Unrolled forward losses 13.198162170899693
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.15272e-01, 2.07855e-02, 3.51657e-01, 1.91231e-03, 2.50934e-01, 1.00173e+00
Node: 01 (pos: 0.010): 4.46163e-01, 6.89738e-02, 4.97797e-01, 1.33286e-02, 3.91574e-01, 1.02746e+00
Node: 02 (pos: 0.020): 5.92763e-01, 1.84032e-01, 6.61518e-01, 6.52677e-02, 5.63548e-01, 1.04900e+00
Node: 03 (pos: 0.030): 7.39349e-01, 3.94812e-01, 8.25258e-01, 2.24542e-01, 7.48016e-01, 1.06607e+00
Node: 04 (pos: 0.040): 8.65761e-01, 6.81040e-01, 9.66485e-01, 5.42728e-01, 9.15700e-01, 1.07842e+00
Node: 05 (pos: 0.051): 9.51760e-01, 9.44589e-01, 1.06257e+00, 9.21623e-01, 1.03385e+00, 1.08591e+00
-
Node: 07 (pos: 0.071): 9.51760e-01, 9.44589e-01, 1.06257e+00, 9.21623e-01, 1.03385e+00, 1.08591e+00
Node: 08 (pos: 0.081): 8.65761e-01, 6.81040e-01, 9.66485e-01, 5.42728e-01, 9.15700e-01, 1.07842e+00
Node: 09 (pos: 0.091): 7.39349e-01, 3.94812e-01, 8.25258e-01, 2.24542e-01, 7.48016e-01, 1.06607e+00
Node: 10 (pos: 0.101): 5.92763e-01, 1.84032e-01, 6.61518e-01, 6.52677e-02, 5.63548e-01, 1.04900e+00
Node: 11 (pos: 0.111): 4.46163e-01, 6.89738e-02, 4.97797e-01, 1.33286e-02, 3.91574e-01, 1.02746e+00
Node: 12 (pos: 0.121): 3.15272e-01, 2.07855e-02, 3.51657e-01, 1.91231e-03, 2.50934e-01, 1.00173e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.51760e-01, 9.44589e-01, 1.06257e+00, 9.21623e-01, 1.03385e+00, 1.08591e+00
Node: 58 (pos: 0.586): 8.65761e-01, 6.81040e-01, 9.66485e-01, 5.42728e-01, 9.15700e-01, 1.07842e+00
Node: 59 (pos: 0.596): 7.39349e-01, 3.94812e-01, 8.25258e-01, 2.24542e-01, 7.48016e-01, 1.06607e+00
Node: 60 (pos: 0.606): 5.92763e-01, 1.84032e-01, 6.61518e-01, 6.52677e-02, 5.63548e-01, 1.04900e+00
Node: 61 (pos: 0.616): 4.46163e-01, 6.89738e-02, 4.97797e-01, 1.33286e-02, 3.91574e-01, 1.02746e+00
Node: 50 (pos: 0.505): 3.15272e-01, 2.07855e-02, 3.51657e-01, 1.91231e-03, 2.50934e-01, 1.00173e+00
-
Node: 51 (pos: 0.515): 4.46163e-01, 6.89738e-02, 4.97797e-01, 1.33286e-02, 3.91574e-01, 1.02746e+00
Node: 52 (pos: 0.525): 5.92763e-01, 1.84032e-01, 6.61518e-01, 6.52677e-02, 5.63548e-01, 1.04900e+00
Node: 53 (pos: 0.535): 7.39349e-01, 3.94812e-01, 8.25258e-01, 2.24542e-01, 7.48016e-01, 1.06607e+00
Node: 54 (pos: 0.545): 8.65761e-01, 6.81040e-01, 9.66485e-01, 5.42728e-01, 9.15700e-01, 1.07842e+00
Node: 55 (pos: 0.556): 9.51760e-01, 9.44589e-01, 1.06257e+00, 9.21623e-01, 1.03385e+00, 1.08591e+00
Node: 62 (pos: 0.626): 3.15272e-01, 2.07855e-02, 3.51657e-01, 1.91231e-03, 2.50934e-01, 1.00173e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.06904548880142572
Step 50, mean loss 0.06872256809690197
Step 75, mean loss 0.11600566890020972
Step 100, mean loss 0.13840825510737848
Step 125, mean loss 0.34455640442509994
Step 150, mean loss 0.2340443440960204
Step 175, mean loss 0.40876833686119174
Step 200, mean loss 0.3584579711480973
Step 225, mean loss 0.3054035505171611
Unrolled forward losses 13.651815993432638
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.268063086051734, [0.003277768113170751, 0.0008922036792252777, 0.0027495041545475612, 0.0006795333731363164, 0.0028966306551379767, 0.04516017198818486], [0.981972946865969, 1.0533763454680225, 1.0962101057998472, 1.099154741101808, 1.076883709689133, 1.0890716899907655]
Training Loss (progress: 0.08), 0.18849660040357574, [0.00365256373927556, 0.0007974085940284619, 0.0036018171210707613, 0.0005642917708611549, 0.0028673718909064984, 0.05205100666234529], [0.9797303463040182, 1.0547461333373465, 1.0984298402014971, 1.0989847848174081, 1.0785587423078162, 1.0924195907460355]
Training Loss (progress: 0.16), 0.19819680747541274, [0.004075405071659716, 0.000776598052352714, 0.004290768148261154, 0.0006994299880196818, 0.00287178593737384, 0.05793548325377328], [0.9775003001274397, 1.0538233933249397, 1.1004739250372024, 1.0989019972244372, 1.0815263022941435, 1.095693250582171]
Training Loss (progress: 0.24), 0.1877146011483918, [0.004416799545376366, 0.0009348701739075675, 0.004485933235044488, 0.0005641868710263181, 0.003102102925450441, 0.06398001347513396], [0.9750537026763682, 1.0536180854883623, 1.1038445771035468, 1.0992619777902504, 1.0849453484750762, 1.0994942142067377]
Training Loss (progress: 0.32), 0.1642046738530306, [0.004512273139675312, 0.0008987860410209152, 0.004450843284176138, 0.0006445987104418408, 0.0031584235180625274, 0.06962187654419986], [0.9726441057271559, 1.0548103196788965, 1.1065195737582756, 1.0986884758187303, 1.086893931774179, 1.1024810817246593]
Training Loss (progress: 0.40), 0.20729075132484212, [0.00460645438779132, 0.0008462314823607049, 0.004536792872677407, 0.0006479628019855817, 0.002903217199039115, 0.07477835507270325], [0.9707098148763436, 1.0540709971201523, 1.1097026381033201, 1.098122528200922, 1.0893054420189576, 1.1054678342932733]
Training Loss (progress: 0.48), 0.17895038509939867, [0.004901217795606076, 0.0009647270465396622, 0.004872679047475525, 0.0006298749209727665, 0.0033353881387483907, 0.0793579921833124], [0.9690861440143959, 1.0548960493919843, 1.1114499521247545, 1.0970810577674543, 1.091546757019774, 1.1075114346467778]
Training Loss (progress: 0.56), 0.16620195309549468, [0.004604351563282414, 0.0008716566661265858, 0.005074088558485802, 0.0005743364571634089, 0.0031360809579426044, 0.082945532521961], [0.9672619482844088, 1.0544257840921984, 1.1135825449405194, 1.0958099522130031, 1.0939543269676435, 1.1089602473079843]
Training Loss (progress: 0.64), 0.16416963124444328, [0.005122683894257852, 0.0009799896552814306, 0.005613163306213372, 0.0006450690491276734, 0.0031190537594018913, 0.0868950558982043], [0.9665335673297013, 1.0548593022790833, 1.1159745561846064, 1.0951144447352257, 1.096711301414979, 1.110990243792259]
Training Loss (progress: 0.72), 0.1855542913537931, [0.005040590231035291, 0.000979002837933436, 0.005523982463652994, 0.0005801814153938468, 0.0033939474835513136, 0.09124605960272694], [0.9652003156624532, 1.0545589742265418, 1.1182686487245235, 1.0944238634365508, 1.0990089821535078, 1.1132378092910942]
Training Loss (progress: 0.80), 0.1717146364929493, [0.005022532620009231, 0.0011126580654389636, 0.005755412973898036, 0.0006903841232637237, 0.0031706338120687442, 0.09397209951661104], [0.9632844257841552, 1.0537776818873859, 1.1199297166202287, 1.0930770400464422, 1.100568336080597, 1.1140963178000176]
Training Loss (progress: 0.88), 0.15187488068653043, [0.005290586319098017, 0.0009337190221882549, 0.005854531704161523, 0.0006772544954238485, 0.0032306448056911197, 0.09684142074210898], [0.9621719530026286, 1.0545360547954041, 1.1220478192973755, 1.092339318710063, 1.1038431954438517, 1.115348253700248]
Training Loss (progress: 0.96), 0.15728352105779436, [0.005718540282710822, 0.0008801104554386957, 0.006259001967115375, 0.000688661415048556, 0.0033765124444328416, 0.10012859445006936], [0.9606550980445786, 1.0537064303706711, 1.1240173248599263, 1.0919590545425297, 1.1071004121223909, 1.1174116171133537]
Evaluation on validation dataset:
Step 25, mean loss 0.09066492906024723
Step 50, mean loss 0.05854584519697578
Step 75, mean loss 0.07143748500972963
Step 100, mean loss 0.08272004273808563
Step 125, mean loss 0.13346028609174904
Step 150, mean loss 0.10758867146415745
Step 175, mean loss 0.17539178726249105
Step 200, mean loss 0.3671793581141895
Step 225, mean loss 0.33220520791388664
Unrolled forward losses 4.184302638881504
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.77567e-01, 1.19135e-02, 5.94111e-01, 8.99683e-03, 3.56650e-01, 1.07793e+00
Node: 01 (pos: 0.010): 5.91045e-01, 4.68640e-02, 7.21929e-01, 3.89739e-02, 5.04283e-01, 1.08995e+00
Node: 02 (pos: 0.020): 7.03677e-01, 1.43712e-01, 8.46709e-01, 1.29329e-01, 6.69507e-01, 1.09988e+00
Node: 03 (pos: 0.030): 8.05920e-01, 3.43560e-01, 9.58490e-01, 3.28746e-01, 8.34612e-01, 1.10767e+00
Node: 04 (pos: 0.040): 8.87925e-01, 6.40274e-01, 1.04726e+00, 6.40121e-01, 9.76928e-01, 1.11327e+00
Node: 05 (pos: 0.051): 9.41081e-01, 9.30216e-01, 1.10442e+00, 9.54780e-01, 1.07372e+00, 1.11664e+00
-
Node: 07 (pos: 0.071): 9.41081e-01, 9.30216e-01, 1.10442e+00, 9.54780e-01, 1.07372e+00, 1.11664e+00
Node: 08 (pos: 0.081): 8.87925e-01, 6.40274e-01, 1.04726e+00, 6.40121e-01, 9.76928e-01, 1.11327e+00
Node: 09 (pos: 0.091): 8.05920e-01, 3.43560e-01, 9.58490e-01, 3.28746e-01, 8.34612e-01, 1.10767e+00
Node: 10 (pos: 0.101): 7.03677e-01, 1.43712e-01, 8.46709e-01, 1.29329e-01, 6.69507e-01, 1.09988e+00
Node: 11 (pos: 0.111): 5.91045e-01, 4.68640e-02, 7.21929e-01, 3.89739e-02, 5.04283e-01, 1.08995e+00
Node: 12 (pos: 0.121): 4.77567e-01, 1.19135e-02, 5.94111e-01, 8.99683e-03, 3.56650e-01, 1.07793e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.41081e-01, 9.30216e-01, 1.10442e+00, 9.54780e-01, 1.07372e+00, 1.11664e+00
Node: 58 (pos: 0.586): 8.87925e-01, 6.40274e-01, 1.04726e+00, 6.40121e-01, 9.76928e-01, 1.11327e+00
Node: 59 (pos: 0.596): 8.05920e-01, 3.43560e-01, 9.58490e-01, 3.28746e-01, 8.34612e-01, 1.10767e+00
Node: 60 (pos: 0.606): 7.03677e-01, 1.43712e-01, 8.46709e-01, 1.29329e-01, 6.69507e-01, 1.09988e+00
Node: 61 (pos: 0.616): 5.91045e-01, 4.68640e-02, 7.21929e-01, 3.89739e-02, 5.04283e-01, 1.08995e+00
Node: 50 (pos: 0.505): 4.77567e-01, 1.19135e-02, 5.94111e-01, 8.99683e-03, 3.56650e-01, 1.07793e+00
-
Node: 51 (pos: 0.515): 5.91045e-01, 4.68640e-02, 7.21929e-01, 3.89739e-02, 5.04283e-01, 1.08995e+00
Node: 52 (pos: 0.525): 7.03677e-01, 1.43712e-01, 8.46709e-01, 1.29329e-01, 6.69507e-01, 1.09988e+00
Node: 53 (pos: 0.535): 8.05920e-01, 3.43560e-01, 9.58490e-01, 3.28746e-01, 8.34612e-01, 1.10767e+00
Node: 54 (pos: 0.545): 8.87925e-01, 6.40274e-01, 1.04726e+00, 6.40121e-01, 9.76928e-01, 1.11327e+00
Node: 55 (pos: 0.556): 9.41081e-01, 9.30216e-01, 1.10442e+00, 9.54780e-01, 1.07372e+00, 1.11664e+00
Node: 62 (pos: 0.626): 4.77567e-01, 1.19135e-02, 5.94111e-01, 8.99683e-03, 3.56650e-01, 1.07793e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.07213101553526635
Step 50, mean loss 0.04261566599389998
Step 75, mean loss 0.07150673503417768
Step 100, mean loss 0.06753236449679413
Step 125, mean loss 0.1683601114476013
Step 150, mean loss 0.11412890814992052
Step 175, mean loss 0.19551802461669548
Step 200, mean loss 0.24838933061430624
Step 225, mean loss 0.16817716033727076
Unrolled forward losses 3.490898645793765
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.22455068249745455, [0.005428964464285279, 0.0009096225560078983, 0.005782990052933796, 0.0007176660096522595, 0.0032843232781531177, 0.10138804011427152], [0.959531295402674, 1.0535972371804256, 1.1239835850345845, 1.0907994658449975, 1.1082176505899344, 1.1178725120097859]
Training Loss (progress: 0.08), 0.22421842836888278, [0.0056473110771639535, 0.0009258653859408855, 0.006242478213380914, 0.0007027729462229194, 0.0032304444156576193, 0.10387001523927411], [0.9595305438359514, 1.0534730768940015, 1.1261272112464693, 1.0913000474560244, 1.1088211216808517, 1.1197137047423056]
Training Loss (progress: 0.16), 0.20857717811411328, [0.005569147104076494, 0.0010497745569032237, 0.006465054340042799, 0.0007750724125147224, 0.003344945897082812, 0.10558572930575075], [0.9592375916333595, 1.053599403003027, 1.1270134229747117, 1.0906238770691856, 1.109925834534843, 1.1210110515250176]
Training Loss (progress: 0.24), 0.20511086702514109, [0.005618694115504369, 0.0009549226697962687, 0.006916186031300412, 0.0007096901272108816, 0.0033487765939359065, 0.10749330015421357], [0.9592291071757273, 1.0541071197558658, 1.1291872721616036, 1.090475809683908, 1.1112501518742863, 1.122311428565022]
Training Loss (progress: 0.32), 0.21630900067583264, [0.005635327170332976, 0.0009628821920274413, 0.006849830378279106, 0.0007450201141987756, 0.003323089063538566, 0.10851271968770014], [0.9585151019391611, 1.0541417770849453, 1.129768037622862, 1.0902244531871788, 1.1119572386058085, 1.1231375111347077]
Training Loss (progress: 0.40), 0.22158620168678436, [0.005966196981858278, 0.0009551114379325252, 0.007081464843959371, 0.0007084744826977569, 0.0033704149665939346, 0.11017353359783345], [0.9585780187922432, 1.0537614937587612, 1.1308013102645154, 1.0899516077802187, 1.112709437803282, 1.1243296875450512]
Training Loss (progress: 0.48), 0.22944962616029518, [0.005820432994713948, 0.0009137750302387752, 0.007178006087711243, 0.0007524842120839676, 0.0033137293484938614, 0.11180248198626355], [0.9580588407699767, 1.0535798154308815, 1.1311391318540163, 1.0895310199715575, 1.1132525511563995, 1.1253946105404609]
Training Loss (progress: 0.56), 0.21053470235014138, [0.005833385409699711, 0.0009672768617778293, 0.0074509913450160285, 0.0006779161666902858, 0.0033673198643435456, 0.11311361829955027], [0.9574640063719392, 1.0537699329412076, 1.1328967776279821, 1.0891771350583284, 1.1141781426223376, 1.1263212171677783]
Training Loss (progress: 0.64), 0.21244844016411338, [0.0057857298330795046, 0.0009964248176170983, 0.007919124843151559, 0.000679995427231619, 0.0033157159841128575, 0.11450436650068273], [0.957312418133903, 1.0540161034492646, 1.1341094059225227, 1.0889918532527278, 1.1153864093920933, 1.1271891106944834]
Training Loss (progress: 0.72), 0.23195435781131366, [0.006046867887343555, 0.0008776384836265518, 0.007919169453540847, 0.0007037803703217326, 0.0033330842590111242, 0.11582129176365205], [0.9571862449298685, 1.053823445782046, 1.1346584971898293, 1.0886312961500926, 1.116247006079054, 1.1280330308291462]
Training Loss (progress: 0.80), 0.199978808991588, [0.0060114903855241295, 0.0010204787086878586, 0.007921731421793855, 0.0006833049687069981, 0.003370775498995229, 0.11766821512941482], [0.9567267669703395, 1.0547868930187476, 1.1353102470896064, 1.0882330638891213, 1.1172951208163933, 1.1293439693435223]
Training Loss (progress: 0.88), 0.18388076345629462, [0.0058318255900005654, 0.0009371654455838857, 0.008252815401541316, 0.0007148599545074936, 0.0034057921521206064, 0.11896066554479798], [0.9560516922079005, 1.054642719075006, 1.1366232139617487, 1.0881711314889342, 1.117912827418941, 1.1300570071131828]
Training Loss (progress: 0.96), 0.2050544785689435, [0.005908400776322126, 0.0009720812891656999, 0.007914778920264915, 0.0006706742035407579, 0.003438208077504067, 0.12022446041643045], [0.955524978160457, 1.05501825643511, 1.137567855991093, 1.0880518145836293, 1.1189742446517306, 1.1310440979127978]
Evaluation on validation dataset:
Step 25, mean loss 0.08266101081222366
Step 50, mean loss 0.04059437532752472
Step 75, mean loss 0.06370381269859207
Step 100, mean loss 0.07310024192975081
Step 125, mean loss 0.10113338838771377
Step 150, mean loss 0.08805658867546723
Step 175, mean loss 0.13041577226475592
Step 200, mean loss 0.3496383180228154
Step 225, mean loss 0.27486199080592827
Unrolled forward losses 2.921483357990264
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.18886e-01, 2.28843e-02, 7.39329e-01, 1.22567e-02, 3.79228e-01, 1.09735e+00
Node: 01 (pos: 0.010): 6.25262e-01, 7.37693e-02, 8.43535e-01, 4.82666e-02, 5.27894e-01, 1.10759e+00
Node: 02 (pos: 0.020): 7.28327e-01, 1.92215e-01, 9.39628e-01, 1.48146e-01, 6.91950e-01, 1.11604e+00
Node: 03 (pos: 0.030): 8.20098e-01, 4.04832e-01, 1.02187e+00, 3.54404e-01, 8.54055e-01, 1.12265e+00
Node: 04 (pos: 0.040): 8.92646e-01, 6.89187e-01, 1.08499e+00, 6.60812e-01, 9.92611e-01, 1.12740e+00
Node: 05 (pos: 0.051): 9.39220e-01, 9.48362e-01, 1.12472e+00, 9.60340e-01, 1.08631e+00, 1.13026e+00
-
Node: 07 (pos: 0.071): 9.39220e-01, 9.48362e-01, 1.12472e+00, 9.60340e-01, 1.08631e+00, 1.13026e+00
Node: 08 (pos: 0.081): 8.92646e-01, 6.89187e-01, 1.08499e+00, 6.60812e-01, 9.92611e-01, 1.12740e+00
Node: 09 (pos: 0.091): 8.20098e-01, 4.04832e-01, 1.02187e+00, 3.54404e-01, 8.54055e-01, 1.12265e+00
Node: 10 (pos: 0.101): 7.28327e-01, 1.92215e-01, 9.39628e-01, 1.48146e-01, 6.91950e-01, 1.11604e+00
Node: 11 (pos: 0.111): 6.25262e-01, 7.37693e-02, 8.43535e-01, 4.82666e-02, 5.27894e-01, 1.10759e+00
Node: 12 (pos: 0.121): 5.18886e-01, 2.28843e-02, 7.39329e-01, 1.22567e-02, 3.79228e-01, 1.09735e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.39220e-01, 9.48362e-01, 1.12472e+00, 9.60340e-01, 1.08631e+00, 1.13026e+00
Node: 58 (pos: 0.586): 8.92646e-01, 6.89187e-01, 1.08499e+00, 6.60812e-01, 9.92611e-01, 1.12740e+00
Node: 59 (pos: 0.596): 8.20098e-01, 4.04832e-01, 1.02187e+00, 3.54404e-01, 8.54055e-01, 1.12265e+00
Node: 60 (pos: 0.606): 7.28327e-01, 1.92215e-01, 9.39628e-01, 1.48146e-01, 6.91950e-01, 1.11604e+00
Node: 61 (pos: 0.616): 6.25262e-01, 7.37693e-02, 8.43535e-01, 4.82666e-02, 5.27894e-01, 1.10759e+00
Node: 50 (pos: 0.505): 5.18886e-01, 2.28843e-02, 7.39329e-01, 1.22567e-02, 3.79228e-01, 1.09735e+00
-
Node: 51 (pos: 0.515): 6.25262e-01, 7.37693e-02, 8.43535e-01, 4.82666e-02, 5.27894e-01, 1.10759e+00
Node: 52 (pos: 0.525): 7.28327e-01, 1.92215e-01, 9.39628e-01, 1.48146e-01, 6.91950e-01, 1.11604e+00
Node: 53 (pos: 0.535): 8.20098e-01, 4.04832e-01, 1.02187e+00, 3.54404e-01, 8.54055e-01, 1.12265e+00
Node: 54 (pos: 0.545): 8.92646e-01, 6.89187e-01, 1.08499e+00, 6.60812e-01, 9.92611e-01, 1.12740e+00
Node: 55 (pos: 0.556): 9.39220e-01, 9.48362e-01, 1.12472e+00, 9.60340e-01, 1.08631e+00, 1.13026e+00
Node: 62 (pos: 0.626): 5.18886e-01, 2.28843e-02, 7.39329e-01, 1.22567e-02, 3.79228e-01, 1.09735e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.07017602327153341
Step 50, mean loss 0.0304766226120892
Step 75, mean loss 0.05852758361893959
Step 100, mean loss 0.060301288408996845
Step 125, mean loss 0.1337050204790298
Step 150, mean loss 0.10390651610702747
Step 175, mean loss 0.13277634535525473
Step 200, mean loss 0.17073768279177334
Step 225, mean loss 0.15421743486549694
Unrolled forward losses 2.501930027568425
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.19752006540529737, [0.006084516765109579, 0.0009390181426699122, 0.008586006890107745, 0.0007463464369421702, 0.003257047337422274, 0.12073227137441382], [0.9553672976701807, 1.054706965560687, 1.138288253804017, 1.0877338311650977, 1.1193409223390935, 1.1310667752464638]
Training Loss (progress: 0.08), 0.19460433711971903, [0.006003972948949571, 0.0009707032616838756, 0.008675917660276864, 0.0006768555992291216, 0.003252908861752396, 0.12226147349634009], [0.9544854825072692, 1.0548624069541135, 1.1386755416809275, 1.087400263478938, 1.120147241932768, 1.1323237875510146]
Training Loss (progress: 0.16), 0.19712063784455336, [0.006084520327915513, 0.0009350775403468146, 0.00861377235314902, 0.0006823280454396487, 0.003276012645867632, 0.1232973370374178], [0.9540701147437638, 1.0551515480147762, 1.1398617598573528, 1.0871382327529924, 1.1214575297574183, 1.1331006754155815]
Training Loss (progress: 0.24), 0.2266637452432641, [0.005993780487559263, 0.0010177058919974519, 0.00873593612456744, 0.0007161740587490283, 0.0032759284154000325, 0.1242144462395874], [0.9536176924890192, 1.0550712006942027, 1.1405333738743555, 1.0865948628691562, 1.122281269211885, 1.1334907280214144]
Training Loss (progress: 0.32), 0.20000264973440934, [0.006055270250196771, 0.0009132136223151767, 0.009068785213509923, 0.0008109127665747042, 0.0033324090952800284, 0.12543907528111023], [0.9529742724586937, 1.0549417576923767, 1.1412699073897075, 1.086379592383817, 1.1233042333279526, 1.1345313947643292]
Training Loss (progress: 0.40), 0.1881001007433518, [0.006141744643631781, 0.0009499462471562666, 0.009366263566371389, 0.0006901427596570562, 0.003335780720123816, 0.1269488500017722], [0.9521942467309416, 1.0551407846945668, 1.142191245835371, 1.086175325317178, 1.1241484619821578, 1.1354278745853608]
Training Loss (progress: 0.48), 0.19276900348509385, [0.0061842723622926666, 0.001001445188608875, 0.009826999843421693, 0.0007209382204836865, 0.003389556516654261, 0.12827880599686398], [0.9519819203241213, 1.0549916892330098, 1.1433816302810562, 1.0856069269239255, 1.1246926295134287, 1.1361074915027751]
Training Loss (progress: 0.56), 0.20134196421178682, [0.006221394502046142, 0.0009635490825820362, 0.009575651348773539, 0.0006401228455585272, 0.003383707518947047, 0.12955735313242908], [0.9513656375641094, 1.054727223233836, 1.144124861188008, 1.0854462357922612, 1.1255824108471528, 1.1367853545327178]
Training Loss (progress: 0.64), 0.17999876666772902, [0.006280536072499841, 0.0009728892298755154, 0.009750521006531912, 0.0007538866171612285, 0.0033774360748770357, 0.1309053537620201], [0.9509454982528057, 1.0551379783693002, 1.1451378705650967, 1.085053033378702, 1.1263917927358875, 1.1379261490346821]
Training Loss (progress: 0.72), 0.18353868201881315, [0.005992967311602546, 0.000949975781948834, 0.009361395102554756, 0.000766014033202041, 0.0032860638013382103, 0.1320755222561325], [0.9498112176960647, 1.0546399442782648, 1.1455047776439002, 1.0846934426266397, 1.1269803099122973, 1.1383954332325976]
Training Loss (progress: 0.80), 0.17161758301687513, [0.006137186933523663, 0.0009755338003092964, 0.010273920023119377, 0.0007888665680873747, 0.0033499753559774175, 0.13346770439723996], [0.9492278760801933, 1.0552198214372464, 1.146736634963244, 1.0843311816072423, 1.1281272119249952, 1.1392668054938329]
Training Loss (progress: 0.88), 0.19073565132823583, [0.006152914775880797, 0.000903128532298776, 0.010325158899903757, 0.0007267154841420289, 0.0032690512118999752, 0.13443432862498358], [0.9485880563881558, 1.0554589384288964, 1.147593432216781, 1.083832944889476, 1.1287983787268046, 1.1397653455622059]
Training Loss (progress: 0.96), 0.17245227046873166, [0.006134535970999026, 0.0009379861370201788, 0.010264173228137498, 0.0007825407415881975, 0.0032245489788174926, 0.13557908615281633], [0.9480770102516667, 1.0553603315817746, 1.1478408165392282, 1.083387717170972, 1.1290099591800542, 1.1405320366369625]
Evaluation on validation dataset:
Step 25, mean loss 0.05596417117769992
Step 50, mean loss 0.03503853455364451
Step 75, mean loss 0.046305286762660304
Step 100, mean loss 0.0567414866771571
Step 125, mean loss 0.07399210931135307
Step 150, mean loss 0.06270207921102354
Step 175, mean loss 0.09434707170046641
Step 200, mean loss 0.25894827502064977
Step 225, mean loss 0.20347453856069828
Unrolled forward losses 2.68042520706525
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.24626e-01, 1.87650e-02, 8.01071e-01, 6.60512e-03, 3.71569e-01, 1.11082e+00
Node: 01 (pos: 0.010): 6.28537e-01, 6.42847e-02, 8.94193e-01, 3.13822e-02, 5.21906e-01, 1.12001e+00
Node: 02 (pos: 0.020): 7.28690e-01, 1.76051e-01, 9.78380e-01, 1.12313e-01, 6.89156e-01, 1.12758e+00
Node: 03 (pos: 0.030): 8.17495e-01, 3.85424e-01, 1.04930e+00, 3.02778e-01, 8.55491e-01, 1.13350e+00
Node: 04 (pos: 0.040): 8.87480e-01, 6.74544e-01, 1.10309e+00, 6.14840e-01, 9.98355e-01, 1.13775e+00
Node: 05 (pos: 0.051): 9.32315e-01, 9.43743e-01, 1.13667e+00, 9.40469e-01, 1.09528e+00, 1.14031e+00
-
Node: 07 (pos: 0.071): 9.32315e-01, 9.43743e-01, 1.13667e+00, 9.40469e-01, 1.09528e+00, 1.14031e+00
Node: 08 (pos: 0.081): 8.87480e-01, 6.74544e-01, 1.10309e+00, 6.14840e-01, 9.98355e-01, 1.13775e+00
Node: 09 (pos: 0.091): 8.17495e-01, 3.85424e-01, 1.04930e+00, 3.02778e-01, 8.55491e-01, 1.13350e+00
Node: 10 (pos: 0.101): 7.28690e-01, 1.76051e-01, 9.78380e-01, 1.12313e-01, 6.89156e-01, 1.12758e+00
Node: 11 (pos: 0.111): 6.28537e-01, 6.42847e-02, 8.94193e-01, 3.13822e-02, 5.21906e-01, 1.12001e+00
Node: 12 (pos: 0.121): 5.24626e-01, 1.87650e-02, 8.01071e-01, 6.60512e-03, 3.71569e-01, 1.11082e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.32315e-01, 9.43743e-01, 1.13667e+00, 9.40469e-01, 1.09528e+00, 1.14031e+00
Node: 58 (pos: 0.586): 8.87480e-01, 6.74544e-01, 1.10309e+00, 6.14840e-01, 9.98355e-01, 1.13775e+00
Node: 59 (pos: 0.596): 8.17495e-01, 3.85424e-01, 1.04930e+00, 3.02778e-01, 8.55491e-01, 1.13350e+00
Node: 60 (pos: 0.606): 7.28690e-01, 1.76051e-01, 9.78380e-01, 1.12313e-01, 6.89156e-01, 1.12758e+00
Node: 61 (pos: 0.616): 6.28537e-01, 6.42847e-02, 8.94193e-01, 3.13822e-02, 5.21906e-01, 1.12001e+00
Node: 50 (pos: 0.505): 5.24626e-01, 1.87650e-02, 8.01071e-01, 6.60512e-03, 3.71569e-01, 1.11082e+00
-
Node: 51 (pos: 0.515): 6.28537e-01, 6.42847e-02, 8.94193e-01, 3.13822e-02, 5.21906e-01, 1.12001e+00
Node: 52 (pos: 0.525): 7.28690e-01, 1.76051e-01, 9.78380e-01, 1.12313e-01, 6.89156e-01, 1.12758e+00
Node: 53 (pos: 0.535): 8.17495e-01, 3.85424e-01, 1.04930e+00, 3.02778e-01, 8.55491e-01, 1.13350e+00
Node: 54 (pos: 0.545): 8.87480e-01, 6.74544e-01, 1.10309e+00, 6.14840e-01, 9.98355e-01, 1.13775e+00
Node: 55 (pos: 0.556): 9.32315e-01, 9.43743e-01, 1.13667e+00, 9.40469e-01, 1.09528e+00, 1.14031e+00
Node: 62 (pos: 0.626): 5.24626e-01, 1.87650e-02, 8.01071e-01, 6.60512e-03, 3.71569e-01, 1.11082e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.04669758113711785
Step 50, mean loss 0.026031767420596097
Step 75, mean loss 0.04006583267219055
Step 100, mean loss 0.0390912653583552
Step 125, mean loss 0.06605742794696876
Step 150, mean loss 0.06798241372585506
Step 175, mean loss 0.10752449809649817
Step 200, mean loss 0.13781400480710299
Step 225, mean loss 0.11526077676219931
Unrolled forward losses 2.249004255528181
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.17678754609950284, [0.0061762664072187844, 0.001000561854337847, 0.010208840087470448, 0.0007416268870142197, 0.0033170016235871433, 0.1363715643043041], [0.9476361616620956, 1.0553265887250085, 1.1479975231964779, 1.083511349858077, 1.1296221557103816, 1.141164471758993]
Training Loss (progress: 0.08), 0.17452918165075962, [0.006194565735619809, 0.0009688394743124236, 0.01059243812856443, 0.0007297580940588014, 0.0033405324819222888, 0.13769145769640675], [0.9466892229927744, 1.0552076618709667, 1.1489485963387573, 1.0830217843116607, 1.1300854340366506, 1.1420352956673778]
Training Loss (progress: 0.16), 0.18974368077525514, [0.006356643146946179, 0.0010380165689189698, 0.010787395793494498, 0.0007431485312829786, 0.003407330234759872, 0.13861220709140679], [0.9461524318572139, 1.0551513704342435, 1.1501173850302429, 1.0827480972765073, 1.1313289703526224, 1.1425183826310756]
Training Loss (progress: 0.24), 0.16529868293921893, [0.00631211343142972, 0.0009814957331467226, 0.01067487097597986, 0.0007366299741755381, 0.0033330290862841473, 0.13980867242004494], [0.9456192967720358, 1.0551514373301547, 1.1506612673905476, 1.082469407250499, 1.1319904039439048, 1.1433201944759552]
Training Loss (progress: 0.32), 0.17027673730323756, [0.006470398585274915, 0.000977911492386692, 0.0112666340614022, 0.0007645421759926437, 0.003339380728515789, 0.14068067909791188], [0.9448419576926206, 1.0549303943256516, 1.1521939165049353, 1.081872978847676, 1.1326312908470189, 1.1439270308491498]
Training Loss (progress: 0.40), 0.1874042778820916, [0.006438944606084416, 0.0009570701858246385, 0.011362816243262405, 0.0007011682335105627, 0.0032657861475928274, 0.14164201561487666], [0.9441448526759063, 1.0551193257603346, 1.1528570069523314, 1.0814634974285087, 1.1331331179212576, 1.144446340574653]
Training Loss (progress: 0.48), 0.1890578672343571, [0.006375146100930179, 0.0010694849657772352, 0.011226480745344778, 0.0007132643057337975, 0.003312862489192356, 0.14296264655112068], [0.9434839706232127, 1.0550752500438314, 1.152945381189967, 1.0811193813035644, 1.1340528431152603, 1.1451295378762714]
Training Loss (progress: 0.56), 0.1686797848474801, [0.006507916133686464, 0.0009268574175853319, 0.011682103262545441, 0.0008011777571405486, 0.003295512376832191, 0.14407392085533066], [0.9429157408199779, 1.0555102287629583, 1.1541863053146095, 1.0805111711947906, 1.1343650796603904, 1.1457591604971282]
Training Loss (progress: 0.64), 0.15600316980910167, [0.006412194933057477, 0.001021233635856759, 0.011677580163179825, 0.0007543130672039787, 0.003334841600267952, 0.1452692424352676], [0.9418900573218538, 1.0551202183391388, 1.1547028036770748, 1.0801602393812908, 1.1349909065107833, 1.1463988557445894]
Training Loss (progress: 0.72), 0.18243355011886594, [0.006415089098671163, 0.0009092835744285531, 0.011554941589971328, 0.000780242095775319, 0.0033582883020429615, 0.14640526554615643], [0.9414285691141554, 1.055244203391552, 1.1552453514961571, 1.0798085522052716, 1.1357207579970356, 1.147155943706172]
Training Loss (progress: 0.80), 0.1713516516717984, [0.006442108161303312, 0.001064099328248715, 0.012147391408914405, 0.0007203288158124151, 0.0033914807370805495, 0.14732725314945544], [0.9405974120325055, 1.055148190386778, 1.156166194223718, 1.0795605458342268, 1.1366064679531278, 1.1477861199363077]
Training Loss (progress: 0.88), 0.15331582344191627, [0.006358213128523267, 0.0009368696585250149, 0.01224601703228257, 0.0007656663598748779, 0.003262829437765538, 0.14868682756825424], [0.9397927388719876, 1.0553068012748028, 1.1570132608719577, 1.0788897700994635, 1.1373155315003138, 1.1482843154363094]
Training Loss (progress: 0.96), 0.17224825781059225, [0.006635461395996697, 0.0009814908625583013, 0.012770501726364764, 0.0007807436786736363, 0.00338127300075467, 0.14963737060534693], [0.9392753048244072, 1.054846713607016, 1.1576113707856848, 1.0785758886129566, 1.1381992364275355, 1.149086466306506]
Evaluation on validation dataset:
Step 25, mean loss 0.05463103105972645
Step 50, mean loss 0.03040899061739761
Step 75, mean loss 0.040838089203266786
Step 100, mean loss 0.053885558359937066
Step 125, mean loss 0.07886474981712933
Step 150, mean loss 0.06490989663738372
Step 175, mean loss 0.08555115321040518
Step 200, mean loss 0.26531780134411254
Step 225, mean loss 0.22034314807336386
Unrolled forward losses 2.464190061878262
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.32860e-01, 2.59853e-02, 8.63954e-01, 5.63021e-03, 3.96793e-01, 1.12164e+00
Node: 01 (pos: 0.010): 6.33537e-01, 8.05798e-02, 9.44832e-01, 2.80470e-02, 5.47566e-01, 1.13004e+00
Node: 02 (pos: 0.020): 7.29904e-01, 2.03405e-01, 1.01660e+00, 1.04341e-01, 7.12652e-01, 1.13697e+00
Node: 03 (pos: 0.030): 8.14881e-01, 4.17958e-01, 1.07618e+00, 2.89887e-01, 8.74757e-01, 1.14239e+00
Node: 04 (pos: 0.040): 8.81572e-01, 6.99102e-01, 1.12085e+00, 6.01466e-01, 1.01267e+00, 1.14627e+00
Node: 05 (pos: 0.051): 9.24178e-01, 9.51887e-01, 1.14855e+00, 9.31966e-01, 1.10564e+00, 1.14861e+00
-
Node: 07 (pos: 0.071): 9.24178e-01, 9.51887e-01, 1.14855e+00, 9.31966e-01, 1.10564e+00, 1.14861e+00
Node: 08 (pos: 0.081): 8.81572e-01, 6.99102e-01, 1.12085e+00, 6.01466e-01, 1.01267e+00, 1.14627e+00
Node: 09 (pos: 0.091): 8.14881e-01, 4.17958e-01, 1.07618e+00, 2.89887e-01, 8.74757e-01, 1.14239e+00
Node: 10 (pos: 0.101): 7.29904e-01, 2.03405e-01, 1.01660e+00, 1.04341e-01, 7.12652e-01, 1.13697e+00
Node: 11 (pos: 0.111): 6.33537e-01, 8.05798e-02, 9.44832e-01, 2.80470e-02, 5.47566e-01, 1.13004e+00
Node: 12 (pos: 0.121): 5.32860e-01, 2.59853e-02, 8.63954e-01, 5.63021e-03, 3.96793e-01, 1.12164e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.24178e-01, 9.51887e-01, 1.14855e+00, 9.31966e-01, 1.10564e+00, 1.14861e+00
Node: 58 (pos: 0.586): 8.81572e-01, 6.99102e-01, 1.12085e+00, 6.01466e-01, 1.01267e+00, 1.14627e+00
Node: 59 (pos: 0.596): 8.14881e-01, 4.17958e-01, 1.07618e+00, 2.89887e-01, 8.74757e-01, 1.14239e+00
Node: 60 (pos: 0.606): 7.29904e-01, 2.03405e-01, 1.01660e+00, 1.04341e-01, 7.12652e-01, 1.13697e+00
Node: 61 (pos: 0.616): 6.33537e-01, 8.05798e-02, 9.44832e-01, 2.80470e-02, 5.47566e-01, 1.13004e+00
Node: 50 (pos: 0.505): 5.32860e-01, 2.59853e-02, 8.63954e-01, 5.63021e-03, 3.96793e-01, 1.12164e+00
-
Node: 51 (pos: 0.515): 6.33537e-01, 8.05798e-02, 9.44832e-01, 2.80470e-02, 5.47566e-01, 1.13004e+00
Node: 52 (pos: 0.525): 7.29904e-01, 2.03405e-01, 1.01660e+00, 1.04341e-01, 7.12652e-01, 1.13697e+00
Node: 53 (pos: 0.535): 8.14881e-01, 4.17958e-01, 1.07618e+00, 2.89887e-01, 8.74757e-01, 1.14239e+00
Node: 54 (pos: 0.545): 8.81572e-01, 6.99102e-01, 1.12085e+00, 6.01466e-01, 1.01267e+00, 1.14627e+00
Node: 55 (pos: 0.556): 9.24178e-01, 9.51887e-01, 1.14855e+00, 9.31966e-01, 1.10564e+00, 1.14861e+00
Node: 62 (pos: 0.626): 5.32860e-01, 2.59853e-02, 8.63954e-01, 5.63021e-03, 3.96793e-01, 1.12164e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.04524343231236028
Step 50, mean loss 0.021894738768900468
Step 75, mean loss 0.038780326542552264
Step 100, mean loss 0.039629183620411436
Step 125, mean loss 0.061192708563279526
Step 150, mean loss 0.054917877727052436
Step 175, mean loss 0.09725558589382582
Step 200, mean loss 0.12011993455932943
Step 225, mean loss 0.11209742797090906
Unrolled forward losses 2.0648764442436303
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.15419373596780742, [0.006542364439148037, 0.0009941599484698856, 0.012683756692355965, 0.0007123501048733054, 0.003409379878835284, 0.15039939548830816], [0.9388950563869953, 1.0550237419664137, 1.1581431914551759, 1.0784184221294688, 1.1384064418867494, 1.149526124506861]
Training Loss (progress: 0.08), 0.16177971134655514, [0.006529019332909224, 0.0009932562194897888, 0.012664208447733551, 0.0006754283899785972, 0.003397574455935533, 0.1510111196786599], [0.9388571715023383, 1.0551113441779532, 1.1584988903966675, 1.0782577769480655, 1.1388573162790614, 1.1502698534327018]
Training Loss (progress: 0.16), 0.15206916201354365, [0.00647976609507566, 0.0010545029976036103, 0.012779775643734791, 0.0007922234235034734, 0.0034211449387706837, 0.15144619991723907], [0.938684077419673, 1.0550414746640868, 1.1592968324777073, 1.0782407280244273, 1.1394593657759704, 1.1507473298958246]
Training Loss (progress: 0.24), 0.12790327737649326, [0.006514864605074851, 0.0010382781416281859, 0.012894147246747832, 0.0007415127565793321, 0.003301061229010923, 0.1518988930354568], [0.9386654298331231, 1.0552628450950263, 1.1596925447014617, 1.0781301012730102, 1.1396688072867038, 1.1512188018465856]
Training Loss (progress: 0.32), 0.1496621495587926, [0.006502790246488507, 0.0010484832141729565, 0.012999812768498849, 0.0007295136382179369, 0.0033003877487774976, 0.15249252924886605], [0.9385316160893155, 1.0552883634129155, 1.160383769651533, 1.0780571744461576, 1.1400535445257014, 1.151883688993161]
Training Loss (progress: 0.40), 0.15040476465633584, [0.006508313672778303, 0.0010394829141902235, 0.013051421788758193, 0.0007262694916745346, 0.0033174939815891025, 0.15305894938167383], [0.9385292925547083, 1.055281773290383, 1.1608476097354543, 1.0779568526048666, 1.1406514625578958, 1.1524058378903805]
Training Loss (progress: 0.48), 0.14052744643705922, [0.006507509592255531, 0.0010061344700078953, 0.01311001451425678, 0.0007457381895176979, 0.003348074746688432, 0.15361696288251175], [0.9384053045501246, 1.0553579755631233, 1.1614216923787597, 1.0778491058027584, 1.1413062254792197, 1.1530463660999852]
Training Loss (progress: 0.56), 0.12241586658683998, [0.006413088549772599, 0.0010258624142207488, 0.013060230584542108, 0.0007521157594685943, 0.0033789243848878015, 0.1540788244338978], [0.9381746911791843, 1.0555437176304536, 1.1617701315185913, 1.0777535389453616, 1.1419364143927988, 1.1534486118108034]
Training Loss (progress: 0.64), 0.14939938290356752, [0.006420268033489118, 0.0010121254117853049, 0.013051495542107164, 0.0007272569237740673, 0.0032868859994710955, 0.15449897153388245], [0.9380237838065202, 1.0556859002971044, 1.1622649155830358, 1.0776940524046326, 1.1423822475029006, 1.1538117399019039]
Training Loss (progress: 0.72), 0.14886579969062036, [0.006472862997376702, 0.0010532808580478632, 0.013307643332365879, 0.000747599048847672, 0.0032819170310659255, 0.15518765102829707], [0.9380696046385844, 1.0558787637305918, 1.1627968508377238, 1.0775650785254147, 1.1427410703628622, 1.1544026262007079]
Training Loss (progress: 0.80), 0.12988211033443164, [0.006350998631609752, 0.0010063757467314337, 0.013437569265184196, 0.0007856073276908083, 0.0032844222769063025, 0.15565292138618853], [0.9377270551127604, 1.0559018181455346, 1.1632177354006314, 1.0775065582724692, 1.1435175777480466, 1.1549187393517775]
Training Loss (progress: 0.88), 0.14906284079007195, [0.006406927951497009, 0.0010544422171755875, 0.013495924261035174, 0.0007408994582919154, 0.0032835507880866893, 0.15608014446048998], [0.9376970320082193, 1.0559627515610148, 1.1637779317363177, 1.077323764684951, 1.1437245921462484, 1.1553765002252856]
Training Loss (progress: 0.96), 0.12291379361617763, [0.006432647670877082, 0.0010012899447809657, 0.013264097609469144, 0.0007684454825937216, 0.0033322251666715623, 0.156594655303281], [0.9375947297493599, 1.0561466956615517, 1.1638649485590602, 1.077195085700112, 1.1442517597386235, 1.1557792971104872]
Evaluation on validation dataset:
Step 25, mean loss 0.059419836403397014
Step 50, mean loss 0.036530185326331274
Step 75, mean loss 0.03876863754308858
Step 100, mean loss 0.04533210638206792
Step 125, mean loss 0.06323897128947806
Step 150, mean loss 0.056789159029980066
Step 175, mean loss 0.07555139527590787
Step 200, mean loss 0.21368609200569766
Step 225, mean loss 0.1638072420625573
Unrolled forward losses 2.689209498594567
Unrolled forward base losses 2.565701273852575
Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.15274461992053517, [0.0063368651640029715, 0.0009979538653686112, 0.013406913178959645, 0.0007457848522182939, 0.003341080956711885, 0.15691714290568695], [0.937427259865016, 1.0559399790590287, 1.1641767362445714, 1.0770286304091128, 1.1444191129141978, 1.1560774712202548]
Training Loss (progress: 0.08), 0.13831883779129703, [0.006301678005605463, 0.0009694315704915117, 0.013295117335354174, 0.0007404842098551154, 0.0032793568166287375, 0.15741529694102935], [0.9372274923803207, 1.0561500056986535, 1.1645389881782562, 1.0768801803301944, 1.1449673480494607, 1.1565798122317152]
Training Loss (progress: 0.16), 0.14079159709414774, [0.006454707388388822, 0.0010630826026882757, 0.013427152602398903, 0.0007709122941390563, 0.003321860527194513, 0.15791183383428148], [0.9372189306203247, 1.056157767557793, 1.1651042752413276, 1.076787407713312, 1.1455041164627306, 1.1571312813652535]
Training Loss (progress: 0.24), 0.13610679640072954, [0.006392424667276828, 0.0010998118477629547, 0.013622300755728125, 0.0007424848411765956, 0.0032146644977452815, 0.1584250074759534], [0.9369058687217121, 1.0563892871741225, 1.1656417313176277, 1.0767189632056702, 1.1456323292953003, 1.1576177986651697]
Training Loss (progress: 0.32), 0.15294799055785502, [0.00634839739232387, 0.0010381749696320366, 0.01366166441406787, 0.0007277202587421045, 0.0032056433165812545, 0.15858134453702277], [0.9366944688760296, 1.0564286354656887, 1.165974561516171, 1.0765023444168633, 1.1461660412948902, 1.157816859283545]
Training Loss (progress: 0.40), 0.1447481910704055, [0.006369714389430576, 0.0010464745023133861, 0.013906666840003239, 0.0007299546559841337, 0.003263416564997181, 0.159167900692547], [0.9365449981826002, 1.0565266468620034, 1.1666529019604788, 1.0764635274562917, 1.146691526203661, 1.158323796451984]
Training Loss (progress: 0.48), 0.14412149899897167, [0.006381845160946519, 0.0010113421963526997, 0.013864104865349268, 0.0008025161476571727, 0.003229094982297571, 0.15976647136883482], [0.9365313546789948, 1.0566155188470794, 1.1669616590325496, 1.0764778234073846, 1.147121965654097, 1.1589151768172252]
Training Loss (progress: 0.56), 0.13678572481363394, [0.0063002048432704745, 0.000986127274741989, 0.013978598767142044, 0.0007331259328223651, 0.0033032021753257933, 0.160148898517785], [0.9364362874244446, 1.0567375509680488, 1.167635707996169, 1.076435820641787, 1.1477321844465942, 1.159327336897043]
Training Loss (progress: 0.64), 0.14569461659253774, [0.006319816317130655, 0.0010574115368091716, 0.014176395739666383, 0.000759028968553989, 0.0033114261930120093, 0.16065275946103513], [0.9362151370883952, 1.0568334592053583, 1.1678755141113153, 1.0763250924397252, 1.1481634274724388, 1.1597186657309129]
Training Loss (progress: 0.72), 0.13464011390593017, [0.006342557283388529, 0.0010768282883854225, 0.014221786499820182, 0.00076479422763122, 0.003242419854143397, 0.16101637985157072], [0.9360543469634484, 1.0569962166519566, 1.168564769537898, 1.0761089378594264, 1.148492102986676, 1.1600585438399313]
Training Loss (progress: 0.80), 0.13566048534132882, [0.006376120945754435, 0.0010019686446705819, 0.014143828507061208, 0.0007319150431828426, 0.0033137519334941533, 0.16143653316683063], [0.9359267143115512, 1.0571019607640828, 1.1687314753648355, 1.0759186876286015, 1.14886690599352, 1.1604213846303162]
Training Loss (progress: 0.88), 0.12511259784891843, [0.006326610317722881, 0.0009918908267438245, 0.014223946397637969, 0.0007618928296756816, 0.0033117476880140267, 0.16193979928151878], [0.9356580120644472, 1.0570832666247245, 1.1691676309558996, 1.0759287854602944, 1.1493260824281557, 1.1609346939155034]
Training Loss (progress: 0.96), 0.1362854763672852, [0.00638356212472283, 0.0010511552877338077, 0.014328301380421586, 0.00075176665991132, 0.0032298937594582335, 0.16243613225161535], [0.9355355592358803, 1.0572458433756646, 1.169697593755673, 1.0757618752963871, 1.1496207584978206, 1.161392246794522]
Evaluation on validation dataset:
Step 25, mean loss 0.03346203407557965
Step 50, mean loss 0.02340492000007689
Step 75, mean loss 0.03224862603289198
Step 100, mean loss 0.03705311791161517
Step 125, mean loss 0.05113313371937808
Step 150, mean loss 0.048375071215465165
Step 175, mean loss 0.06453302210979517
Step 200, mean loss 0.20557368126285167
Step 225, mean loss 0.15344358396455002
Unrolled forward losses 1.9305152279726137
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.25669e-01, 3.02884e-02, 9.06399e-01, 9.17419e-03, 3.77038e-01, 1.13561e+00
Node: 01 (pos: 0.010): 6.26908e-01, 8.96832e-02, 9.79889e-01, 3.93359e-02, 5.30092e-01, 1.14347e+00
Node: 02 (pos: 0.020): 7.24082e-01, 2.17987e-01, 1.04443e+00, 1.29438e-01, 7.00510e-01, 1.14995e+00
Node: 03 (pos: 0.030): 8.09962e-01, 4.34944e-01, 1.09755e+00, 3.26876e-01, 8.70110e-01, 1.15501e+00
Node: 04 (pos: 0.040): 8.77472e-01, 7.12397e-01, 1.13714e+00, 6.33515e-01, 1.01585e+00, 1.15864e+00
Node: 05 (pos: 0.051): 9.20650e-01, 9.57844e-01, 1.16157e+00, 9.42281e-01, 1.11477e+00, 1.16082e+00
-
Node: 07 (pos: 0.071): 9.20650e-01, 9.57844e-01, 1.16157e+00, 9.42281e-01, 1.11477e+00, 1.16082e+00
Node: 08 (pos: 0.081): 8.77472e-01, 7.12397e-01, 1.13714e+00, 6.33515e-01, 1.01585e+00, 1.15864e+00
Node: 09 (pos: 0.091): 8.09962e-01, 4.34944e-01, 1.09755e+00, 3.26876e-01, 8.70110e-01, 1.15501e+00
Node: 10 (pos: 0.101): 7.24082e-01, 2.17987e-01, 1.04443e+00, 1.29438e-01, 7.00510e-01, 1.14995e+00
Node: 11 (pos: 0.111): 6.26908e-01, 8.96832e-02, 9.79889e-01, 3.93359e-02, 5.30092e-01, 1.14347e+00
Node: 12 (pos: 0.121): 5.25669e-01, 3.02884e-02, 9.06399e-01, 9.17419e-03, 3.77038e-01, 1.13561e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.20650e-01, 9.57844e-01, 1.16157e+00, 9.42281e-01, 1.11477e+00, 1.16082e+00
Node: 58 (pos: 0.586): 8.77472e-01, 7.12397e-01, 1.13714e+00, 6.33515e-01, 1.01585e+00, 1.15864e+00
Node: 59 (pos: 0.596): 8.09962e-01, 4.34944e-01, 1.09755e+00, 3.26876e-01, 8.70110e-01, 1.15501e+00
Node: 60 (pos: 0.606): 7.24082e-01, 2.17987e-01, 1.04443e+00, 1.29438e-01, 7.00510e-01, 1.14995e+00
Node: 61 (pos: 0.616): 6.26908e-01, 8.96832e-02, 9.79889e-01, 3.93359e-02, 5.30092e-01, 1.14347e+00
Node: 50 (pos: 0.505): 5.25669e-01, 3.02884e-02, 9.06399e-01, 9.17419e-03, 3.77038e-01, 1.13561e+00
-
Node: 51 (pos: 0.515): 6.26908e-01, 8.96832e-02, 9.79889e-01, 3.93359e-02, 5.30092e-01, 1.14347e+00
Node: 52 (pos: 0.525): 7.24082e-01, 2.17987e-01, 1.04443e+00, 1.29438e-01, 7.00510e-01, 1.14995e+00
Node: 53 (pos: 0.535): 8.09962e-01, 4.34944e-01, 1.09755e+00, 3.26876e-01, 8.70110e-01, 1.15501e+00
Node: 54 (pos: 0.545): 8.77472e-01, 7.12397e-01, 1.13714e+00, 6.33515e-01, 1.01585e+00, 1.15864e+00
Node: 55 (pos: 0.556): 9.20650e-01, 9.57844e-01, 1.16157e+00, 9.42281e-01, 1.11477e+00, 1.16082e+00
Node: 62 (pos: 0.626): 5.25669e-01, 3.02884e-02, 9.06399e-01, 9.17419e-03, 3.77038e-01, 1.13561e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.028074529664992742
Step 50, mean loss 0.016140003393711105
Step 75, mean loss 0.026187103545854542
Step 100, mean loss 0.028877866111005124
Step 125, mean loss 0.045764202243248155
Step 150, mean loss 0.047393077774964425
Step 175, mean loss 0.07423658465084466
Step 200, mean loss 0.11576617403460279
Step 225, mean loss 0.0932973591818221
Unrolled forward losses 1.5879068351837198
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.13074721171304532, [0.006336360072836431, 0.0010423821314075258, 0.014318959550403866, 0.0007418307331217065, 0.003297898867692013, 0.1625832505611532], [0.9354904650151883, 1.0572016970923281, 1.1697574744492492, 1.0755938480823886, 1.1498311362821132, 1.1615184263559173]
Training Loss (progress: 0.08), 0.1231771204344102, [0.006337183946117307, 0.0010234067048559316, 0.014727044830806673, 0.0007640633002393471, 0.0032652359445815454, 0.16308456699005844], [0.9352968028040637, 1.0574246527348143, 1.1704027647635735, 1.0753863250605926, 1.1502597467592304, 1.1620022648474397]
Training Loss (progress: 0.16), 0.15537772057347415, [0.00633324150180573, 0.0010175717226143612, 0.014769523723944829, 0.0007720183392280578, 0.003206736107537308, 0.16356780849243993], [0.9350742988571614, 1.0571914838519358, 1.1706337662329631, 1.0754201951264661, 1.15059982902491, 1.162458740886135]
Training Loss (progress: 0.24), 0.13478116758941794, [0.006303567076145477, 0.0010143323653466825, 0.014902771835765882, 0.000784493742091046, 0.0033124006084065023, 0.16398150058794003], [0.9348678621346614, 1.0572659052001256, 1.1709737559286777, 1.075473683638255, 1.1510268421885375, 1.1628655808465036]
Training Loss (progress: 0.32), 0.12404393256314598, [0.006407687878792212, 0.001030195084688722, 0.01487918284673046, 0.0007734454463163446, 0.0032829890903151807, 0.16428203881799552], [0.934843840064381, 1.0574590451828902, 1.171342276087593, 1.0752507489807661, 1.1516662233007435, 1.1632122234638245]
Training Loss (progress: 0.40), 0.12680999898285683, [0.006391694093551908, 0.001034626428215192, 0.015114390475394585, 0.0007601034348856078, 0.0032542323638925716, 0.16472104474696136], [0.9347032446613083, 1.057536376225604, 1.1717857132195428, 1.0750282866264897, 1.151969028613986, 1.1636278110771856]
Training Loss (progress: 0.48), 0.1264989560898451, [0.006300837792807588, 0.0010952216755453954, 0.015254150271052631, 0.0007324274635631331, 0.003281840290048253, 0.16516384349211155], [0.9344808521371832, 1.057644064304956, 1.172347199494805, 1.0748463066167708, 1.1522873328383578, 1.1639748271331645]
Training Loss (progress: 0.56), 0.12859070242366433, [0.0063280740920730934, 0.0010325099576538454, 0.015241242076142579, 0.0007531322192590404, 0.003274164004346962, 0.16548957404384523], [0.9343041585339243, 1.0577535980295776, 1.1727860169753517, 1.0747287588456567, 1.1525422912294934, 1.1643870793261504]
Training Loss (progress: 0.64), 0.12890368946480027, [0.006344005748840451, 0.001023941091521752, 0.015365680195513627, 0.00075236900305624, 0.003217796421112215, 0.1658423654825586], [0.9341610828283501, 1.0577399324037593, 1.1730692672863183, 1.0746085972647896, 1.153187903658127, 1.1647253939746847]
Training Loss (progress: 0.72), 0.12069700645231357, [0.006351896316545476, 0.0010124241943309928, 0.015476310979411713, 0.000774967004616151, 0.0033047424967708287, 0.16625129192290672], [0.9340719504986772, 1.0578601787307926, 1.1732959853784088, 1.0744935963601132, 1.1536396774244801, 1.1650875984429094]
Training Loss (progress: 0.80), 0.12246239217821685, [0.006236311414943189, 0.0010370652479676432, 0.015624968335340538, 0.0007650572318166361, 0.003272286165056171, 0.16675720486391443], [0.9336736494229438, 1.057909737324775, 1.1738646020044292, 1.0744396189485932, 1.1539785683244068, 1.1656623272722513]
Training Loss (progress: 0.88), 0.1326904020568303, [0.006262875939796904, 0.0010131350013938753, 0.01573423090556339, 0.0007671338389465076, 0.003222434861723847, 0.1670851007975259], [0.9335866411866994, 1.0579424982366938, 1.1741919653687531, 1.074240988747858, 1.1542191752021278, 1.1659810001878745]
Training Loss (progress: 0.96), 0.13733015329633105, [0.006298622473562096, 0.0010455539630082307, 0.01560682465722144, 0.0007868531445103233, 0.0032247719032041473, 0.1674231712514375], [0.9334061912240733, 1.0580117517356626, 1.1745043033253297, 1.0741700366528144, 1.1548178021239501, 1.166423913612611]
Evaluation on validation dataset:
Step 25, mean loss 0.03470115934168543
Step 50, mean loss 0.01904049872429875
Step 75, mean loss 0.028483778662790955
Step 100, mean loss 0.03241282648143146
Step 125, mean loss 0.04828850421617179
Step 150, mean loss 0.04179316368498104
Step 175, mean loss 0.06346587919482352
Step 200, mean loss 0.1961028083144963
Step 225, mean loss 0.15909072757678666
Unrolled forward losses 1.7924762834555432
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.16496e-01, 3.16847e-02, 9.31168e-01, 9.57416e-03, 3.73499e-01, 1.14128e+00
Node: 01 (pos: 0.010): 6.18824e-01, 9.25570e-02, 9.99676e-01, 4.05015e-02, 5.27362e-01, 1.14895e+00
Node: 02 (pos: 0.020): 7.17456e-01, 2.22496e-01, 1.05946e+00, 1.31812e-01, 6.99340e-01, 1.15527e+00
Node: 03 (pos: 0.030): 8.04915e-01, 4.40137e-01, 1.10842e+00, 3.30032e-01, 8.71020e-01, 1.16020e+00
Node: 04 (pos: 0.040): 8.73841e-01, 7.16482e-01, 1.14477e+00, 6.35725e-01, 1.01889e+00, 1.16374e+00
Node: 05 (pos: 0.051): 9.17998e-01, 9.59790e-01, 1.16715e+00, 9.42101e-01, 1.11941e+00, 1.16587e+00
-
Node: 07 (pos: 0.071): 9.17998e-01, 9.59790e-01, 1.16715e+00, 9.42101e-01, 1.11941e+00, 1.16587e+00
Node: 08 (pos: 0.081): 8.73841e-01, 7.16482e-01, 1.14477e+00, 6.35725e-01, 1.01889e+00, 1.16374e+00
Node: 09 (pos: 0.091): 8.04915e-01, 4.40137e-01, 1.10842e+00, 3.30032e-01, 8.71020e-01, 1.16020e+00
Node: 10 (pos: 0.101): 7.17456e-01, 2.22496e-01, 1.05946e+00, 1.31812e-01, 6.99340e-01, 1.15527e+00
Node: 11 (pos: 0.111): 6.18824e-01, 9.25570e-02, 9.99676e-01, 4.05015e-02, 5.27362e-01, 1.14895e+00
Node: 12 (pos: 0.121): 5.16496e-01, 3.16847e-02, 9.31168e-01, 9.57416e-03, 3.73499e-01, 1.14128e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.17998e-01, 9.59790e-01, 1.16715e+00, 9.42101e-01, 1.11941e+00, 1.16587e+00
Node: 58 (pos: 0.586): 8.73841e-01, 7.16482e-01, 1.14477e+00, 6.35725e-01, 1.01889e+00, 1.16374e+00
Node: 59 (pos: 0.596): 8.04915e-01, 4.40137e-01, 1.10842e+00, 3.30032e-01, 8.71020e-01, 1.16020e+00
Node: 60 (pos: 0.606): 7.17456e-01, 2.22496e-01, 1.05946e+00, 1.31812e-01, 6.99340e-01, 1.15527e+00
Node: 61 (pos: 0.616): 6.18824e-01, 9.25570e-02, 9.99676e-01, 4.05015e-02, 5.27362e-01, 1.14895e+00
Node: 50 (pos: 0.505): 5.16496e-01, 3.16847e-02, 9.31168e-01, 9.57416e-03, 3.73499e-01, 1.14128e+00
-
Node: 51 (pos: 0.515): 6.18824e-01, 9.25570e-02, 9.99676e-01, 4.05015e-02, 5.27362e-01, 1.14895e+00
Node: 52 (pos: 0.525): 7.17456e-01, 2.22496e-01, 1.05946e+00, 1.31812e-01, 6.99340e-01, 1.15527e+00
Node: 53 (pos: 0.535): 8.04915e-01, 4.40137e-01, 1.10842e+00, 3.30032e-01, 8.71020e-01, 1.16020e+00
Node: 54 (pos: 0.545): 8.73841e-01, 7.16482e-01, 1.14477e+00, 6.35725e-01, 1.01889e+00, 1.16374e+00
Node: 55 (pos: 0.556): 9.17998e-01, 9.59790e-01, 1.16715e+00, 9.42101e-01, 1.11941e+00, 1.16587e+00
Node: 62 (pos: 0.626): 5.16496e-01, 3.16847e-02, 9.31168e-01, 9.57416e-03, 3.73499e-01, 1.14128e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.029897884686473815
Step 50, mean loss 0.012482892572071457
Step 75, mean loss 0.023057682661367887
Step 100, mean loss 0.026207292025917223
Step 125, mean loss 0.04468415162637457
Step 150, mean loss 0.041284133480725946
Step 175, mean loss 0.06582534181986317
Step 200, mean loss 0.10183959394086692
Step 225, mean loss 0.07954661784012886
Unrolled forward losses 1.5406404131002112
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.13093239855555794, [0.0062839314357535925, 0.0010118666230973326, 0.01571844387982473, 0.0007871210608511905, 0.0031950071415915242, 0.16748199461202726], [0.9332957394246989, 1.0579859129300495, 1.1745875184325651, 1.0740132407206453, 1.1549291153765593, 1.166512190246009]
Training Loss (progress: 0.08), 0.14008587446669907, [0.006313097752950096, 0.0010492080745147345, 0.01581332973480244, 0.00074564214271945, 0.0032138683420566837, 0.1681011795609634], [0.9330954285067877, 1.0581135026282518, 1.1751270780277332, 1.0739340222666016, 1.1553254032449516, 1.1671387740806958]
Training Loss (progress: 0.16), 0.1271456174404643, [0.006271017276811459, 0.00105536423832742, 0.015998676572566064, 0.0007550199519627094, 0.003199426385202548, 0.16832438523634263], [0.9327630998546314, 1.0582571482590648, 1.1756907713864444, 1.0739194984275229, 1.155807046590056, 1.167386744560348]
Training Loss (progress: 0.24), 0.13981942176718912, [0.006298241890867611, 0.0010498400792258837, 0.01611163083804985, 0.0007880152219205372, 0.003169477102709429, 0.1687873211848712], [0.932615019543953, 1.0583406259003134, 1.1759852036793288, 1.0736173032921705, 1.1563258241955465, 1.167818360789132]
Training Loss (progress: 0.32), 0.14598634184343173, [0.006299066519716509, 0.0010131887509754337, 0.01619975823336539, 0.000757266030955573, 0.0031960400889339763, 0.16934896902149005], [0.9324035798716477, 1.058505324406997, 1.1763400499880672, 1.073447880794121, 1.1567333124965382, 1.1682745036912625]
Training Loss (progress: 0.40), 0.12564511177031207, [0.0063546491728235, 0.0010405095224363316, 0.016056978959698105, 0.0007400879734134908, 0.0032493495301715884, 0.16971294996093175], [0.9323694581250735, 1.0583144998880945, 1.1765875226337321, 1.0733716962405944, 1.1571668874739798, 1.1685944979975391]
Training Loss (progress: 0.48), 0.13372563227151466, [0.006404323667820552, 0.0010173841001693091, 0.016405481011968308, 0.0007584861659650913, 0.003273931657905432, 0.1700922684938777], [0.9320481053652766, 1.0584041886526752, 1.1769551653055002, 1.0730641833998416, 1.1573895910576786, 1.169078025059863]
Training Loss (progress: 0.56), 0.14062002288887893, [0.0063276013397610435, 0.0010133315582399422, 0.016494493799440686, 0.0007618008166404658, 0.0032493579190867278, 0.1704783646042788], [0.931894671881918, 1.0584576003291433, 1.1772912708756909, 1.0730099788213268, 1.157679136687224, 1.169354158570856]
Training Loss (progress: 0.64), 0.12514197135697203, [0.006339147454970831, 0.0010040901881339201, 0.016704500302526428, 0.0007684223824674244, 0.0032452993175812097, 0.17102241819403402], [0.9318051221158395, 1.0586516520488356, 1.1775969315963726, 1.0729294263609415, 1.1581306182193571, 1.1699924254093526]
Training Loss (progress: 0.72), 0.1218633099301319, [0.006328253915527742, 0.0010488473367145324, 0.016858427820512147, 0.000786370189379024, 0.0032029558186594392, 0.17113520335235824], [0.9315908958332215, 1.059076905043516, 1.1780649107603904, 1.0728786601295397, 1.1584024612288943, 1.1701742069008612]
Training Loss (progress: 0.80), 0.11895331304204768, [0.006308555492121629, 0.0009995454662702335, 0.0170276807667291, 0.0008143432666746872, 0.0032396047511446583, 0.17163428762000782], [0.9313637310571191, 1.058909054333425, 1.1784428960329214, 1.0726440942372204, 1.1588413642890054, 1.170550466785944]
Training Loss (progress: 0.88), 0.12820854406194032, [0.006296721791345795, 0.0010626044054406975, 0.016949271521607447, 0.0008079792185496384, 0.0032181750509678855, 0.17203913686398664], [0.9311079360595139, 1.0588641122851234, 1.1786103597700903, 1.0725932915724952, 1.1593280707202636, 1.1709628468633075]
Training Loss (progress: 0.96), 0.12246910950357683, [0.00630398310411667, 0.0010410771445552513, 0.016956563986334924, 0.0007710746390702811, 0.0032475118329124133, 0.172336859828608], [0.9309364898301145, 1.0588558050630186, 1.1789260327018802, 1.0724377128920832, 1.159675880194089, 1.1712743803717385]
Evaluation on validation dataset:
Step 25, mean loss 0.03409297032571716
Step 50, mean loss 0.02060752578462159
Step 75, mean loss 0.029822461376848713
Step 100, mean loss 0.035965647011451524
Step 125, mean loss 0.04805101906696982
Step 150, mean loss 0.04408131151031666
Step 175, mean loss 0.060711873659335475
Step 200, mean loss 0.20838559751053318
Step 225, mean loss 0.14625824911257396
Unrolled forward losses 1.9928724925459202
Unrolled forward base losses 2.565701273852575
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.13500215238029722, [0.006198967130607186, 0.0010301477716378156, 0.016968368078093314, 0.0007794483367413535, 0.0031922552876622766, 0.1726990070148455], [0.9306746208035902, 1.058904171873501, 1.179084223031936, 1.0724440748186337, 1.1596557857638965, 1.1715436311825804]
Training Loss (progress: 0.08), 0.11917022190255468, [0.006366092304137247, 0.0010347073085025655, 0.017149544275867352, 0.0007717256570364715, 0.003215107954617002, 0.17298909224777287], [0.9307339401370968, 1.0591589981884884, 1.1794125237205997, 1.072228180822461, 1.160085008257306, 1.1718351876663757]
Training Loss (progress: 0.16), 0.12429955851665356, [0.006307257981536645, 0.0010116071639164849, 0.017162118416183637, 0.0007886970257276494, 0.0032518444210994793, 0.173699916413114], [0.930462463878923, 1.0590853716612387, 1.1796278060074903, 1.0720941787530336, 1.1604233996152482, 1.1724715485912658]
Training Loss (progress: 0.24), 0.12486068264688388, [0.006266260686555846, 0.00105085100577904, 0.01747598130383113, 0.0007974531890443653, 0.0032413421995485326, 0.17411143164400641], [0.9302741769177124, 1.0593016389443122, 1.180208735543591, 1.072033881504048, 1.160808473839424, 1.1728351838172049]
Training Loss (progress: 0.32), 0.12645745902787572, [0.00624752979496514, 0.0010314747652842304, 0.01757180955594524, 0.0007985417582327359, 0.003264980291309333, 0.1745377963924443], [0.9300476671197265, 1.059319433388703, 1.1803791303266686, 1.0719217511374088, 1.1611764303887024, 1.1731899933352605]
Training Loss (progress: 0.40), 0.13887438871649888, [0.006239584135485865, 0.0010465583459744671, 0.017583296232684148, 0.0008017532810763817, 0.0032621462682921936, 0.17492678150085555], [0.9298700527726871, 1.0591100226026688, 1.1806615049006974, 1.0717778133869942, 1.1615577669505472, 1.1735814706057706]
Training Loss (progress: 0.48), 0.1307282118556342, [0.006348114660541984, 0.0010449937506217056, 0.017866031380325928, 0.0007920757859003431, 0.003214376270176339, 0.1753726469018723], [0.9297368206702851, 1.0590491370542958, 1.180963071845624, 1.0716343292907147, 1.1616356320623866, 1.1738041124773522]
Training Loss (progress: 0.56), 0.13093348546272568, [0.0062808779133329, 0.0010081383534328834, 0.017918571194040514, 0.0007475105009029397, 0.0032519158427934394, 0.17584647386781382], [0.9294350336671855, 1.0593170861127454, 1.1811183685357936, 1.071477049343385, 1.1619959907066357, 1.1742600765627256]
Training Loss (progress: 0.64), 0.13040472320322646, [0.006290182113081485, 0.0010392145827057067, 0.018262264505560625, 0.0007729041571256786, 0.003208599992961446, 0.17610337050470842], [0.9292193227748294, 1.0590886768074323, 1.181634759494048, 1.0713099363414613, 1.1622955239504178, 1.1744648210368906]
Training Loss (progress: 0.72), 0.13304544375643312, [0.00626081493498631, 0.0010175042050588913, 0.01854299252810536, 0.0007617052436596057, 0.0032213476927994535, 0.176406166902574], [0.9289703719951458, 1.0594255227154448, 1.1821554207273504, 1.0711720122023969, 1.1630164518869255, 1.1747532184323763]
Training Loss (progress: 0.80), 0.10953698918920707, [0.006240660120059071, 0.0010562192504955257, 0.018487619740865206, 0.0007942207037556289, 0.0032532145461876484, 0.1768392914146054], [0.9287294000263522, 1.0593773227335885, 1.1821200454955334, 1.0709725367249097, 1.163266400676292, 1.1750850625043556]
Training Loss (progress: 0.88), 0.12504040132234703, [0.006221880421085727, 0.0010269132129719387, 0.018654452686840125, 0.0007812568750601886, 0.003260686268445738, 0.17733680201735524], [0.9285507334122834, 1.0595550943466052, 1.1823682014270733, 1.070843124681562, 1.1636730480085904, 1.1755531337020404]
Training Loss (progress: 0.96), 0.12786941503924384, [0.006276812372699077, 0.0010411778553046601, 0.01883742193980793, 0.0007833736523438178, 0.0032829174341927024, 0.17779527505856133], [0.9284119388941803, 1.059769110068616, 1.182730741536896, 1.0708800429076086, 1.1640347907212099, 1.1759185634203921]
Evaluation on validation dataset:
Step 25, mean loss 0.03148485481993079
Step 50, mean loss 0.01770569301428869
Step 75, mean loss 0.025927758702663763
Step 100, mean loss 0.027843932991552862
Step 125, mean loss 0.0355583008508996
Step 150, mean loss 0.03786314178085917
Step 175, mean loss 0.05740078858320362
Step 200, mean loss 0.17700996741142708
Step 225, mean loss 0.1371573468886448
Unrolled forward losses 1.5743930897777814
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.15124e-01, 2.89226e-02, 9.73979e-01, 1.08179e-02, 3.77307e-01, 1.15217e+00
Node: 01 (pos: 0.010): 6.16663e-01, 8.69179e-02, 1.03355e+00, 4.40448e-02, 5.32356e-01, 1.15945e+00
Node: 02 (pos: 0.020): 7.14459e-01, 2.13843e-01, 1.08498e+00, 1.38925e-01, 7.05547e-01, 1.16545e+00
Node: 03 (pos: 0.030): 8.01125e-01, 4.30720e-01, 1.12675e+00, 3.39473e-01, 8.78348e-01, 1.17013e+00
Node: 04 (pos: 0.040): 8.69394e-01, 7.10246e-01, 1.15757e+00, 6.42637e-01, 1.02713e+00, 1.17349e+00
Node: 05 (pos: 0.051): 9.13117e-01, 9.58821e-01, 1.17646e+00, 9.42456e-01, 1.12823e+00, 1.17550e+00
-
Node: 07 (pos: 0.071): 9.13117e-01, 9.58821e-01, 1.17646e+00, 9.42456e-01, 1.12823e+00, 1.17550e+00
Node: 08 (pos: 0.081): 8.69394e-01, 7.10246e-01, 1.15757e+00, 6.42637e-01, 1.02713e+00, 1.17349e+00
Node: 09 (pos: 0.091): 8.01125e-01, 4.30720e-01, 1.12675e+00, 3.39473e-01, 8.78348e-01, 1.17013e+00
Node: 10 (pos: 0.101): 7.14459e-01, 2.13843e-01, 1.08498e+00, 1.38925e-01, 7.05547e-01, 1.16545e+00
Node: 11 (pos: 0.111): 6.16663e-01, 8.69179e-02, 1.03355e+00, 4.40448e-02, 5.32356e-01, 1.15945e+00
Node: 12 (pos: 0.121): 5.15124e-01, 2.89226e-02, 9.73979e-01, 1.08179e-02, 3.77307e-01, 1.15217e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.13117e-01, 9.58821e-01, 1.17646e+00, 9.42456e-01, 1.12823e+00, 1.17550e+00
Node: 58 (pos: 0.586): 8.69394e-01, 7.10246e-01, 1.15757e+00, 6.42637e-01, 1.02713e+00, 1.17349e+00
Node: 59 (pos: 0.596): 8.01125e-01, 4.30720e-01, 1.12675e+00, 3.39473e-01, 8.78348e-01, 1.17013e+00
Node: 60 (pos: 0.606): 7.14459e-01, 2.13843e-01, 1.08498e+00, 1.38925e-01, 7.05547e-01, 1.16545e+00
Node: 61 (pos: 0.616): 6.16663e-01, 8.69179e-02, 1.03355e+00, 4.40448e-02, 5.32356e-01, 1.15945e+00
Node: 50 (pos: 0.505): 5.15124e-01, 2.89226e-02, 9.73979e-01, 1.08179e-02, 3.77307e-01, 1.15217e+00
-
Node: 51 (pos: 0.515): 6.16663e-01, 8.69179e-02, 1.03355e+00, 4.40448e-02, 5.32356e-01, 1.15945e+00
Node: 52 (pos: 0.525): 7.14459e-01, 2.13843e-01, 1.08498e+00, 1.38925e-01, 7.05547e-01, 1.16545e+00
Node: 53 (pos: 0.535): 8.01125e-01, 4.30720e-01, 1.12675e+00, 3.39473e-01, 8.78348e-01, 1.17013e+00
Node: 54 (pos: 0.545): 8.69394e-01, 7.10246e-01, 1.15757e+00, 6.42637e-01, 1.02713e+00, 1.17349e+00
Node: 55 (pos: 0.556): 9.13117e-01, 9.58821e-01, 1.17646e+00, 9.42456e-01, 1.12823e+00, 1.17550e+00
Node: 62 (pos: 0.626): 5.15124e-01, 2.89226e-02, 9.73979e-01, 1.08179e-02, 3.77307e-01, 1.15217e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.025814832804992627
Step 50, mean loss 0.011129097272250789
Step 75, mean loss 0.01979807303207362
Step 100, mean loss 0.02248139815989398
Step 125, mean loss 0.03653800876609849
Step 150, mean loss 0.03812661641172935
Step 175, mean loss 0.060289943076477906
Step 200, mean loss 0.0983943002236036
Step 225, mean loss 0.0721129468752602
Unrolled forward losses 1.336804842683938
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00), 0.12161322640011041, [0.006272546528993864, 0.0010191509897327245, 0.018938890327865, 0.0008037358494524788, 0.003252551534501422, 0.17811289301853822], [0.9282367575400127, 1.0597798236348144, 1.1828720051867356, 1.070788119081102, 1.16411277138185, 1.1761743524604484]
Training Loss (progress: 0.08), 0.12199962437022184, [0.006311486201879844, 0.0010468364599811831, 0.01913008044939793, 0.0007847103853016816, 0.0032573413130903197, 0.17831656350107528], [0.9282586888750326, 1.0597989438971533, 1.1831857088431967, 1.0707568017638207, 1.1643179747032415, 1.1764000119153109]
Training Loss (progress: 0.16), 0.11905245657501454, [0.0062824296825820195, 0.0010444813338506235, 0.01925857237899243, 0.0007863104793472436, 0.0032711613506473166, 0.17844142682121195], [0.928217345445666, 1.0599685685346842, 1.1834861663796994, 1.0707452277719252, 1.1645017576026722, 1.1765782346133271]
Training Loss (progress: 0.24), 0.12316298988595129, [0.006295881768696223, 0.001008663881310223, 0.0191955419254925, 0.000790260069181542, 0.0032541024731938943, 0.17870611917564214], [0.9282174350817435, 1.060025498501253, 1.183639028955096, 1.0706643555363473, 1.1645828454321026, 1.1768922668252682]
Training Loss (progress: 0.32), 0.11545160629907303, [0.006289218182401935, 0.0010450753784035898, 0.01938327875823436, 0.0007718544548692839, 0.0032594256047020556, 0.17885091523122396], [0.928157931258696, 1.060128824730444, 1.1840886546278153, 1.0707266078379916, 1.164868368983674, 1.1770948092784372]
Training Loss (progress: 0.40), 0.12018075297206367, [0.006293415385917068, 0.001036031267528389, 0.019337677687277732, 0.0008062739085193696, 0.0032778329663647925, 0.17913156184278434], [0.9280810600867682, 1.0601288210891449, 1.1841928352718674, 1.0706202732913204, 1.1650654966605627, 1.1774422181044089]
Training Loss (progress: 0.48), 0.11659572407108763, [0.006276792688103147, 0.0010384297038975097, 0.01939516927854433, 0.000773448337355707, 0.0032409694795496593, 0.1792026382199592], [0.9280542702718375, 1.0602926455835677, 1.1843341595253432, 1.0706078681891205, 1.1652742569791077, 1.177566465152375]
Training Loss (progress: 0.56), 0.1202723293351328, [0.006241724189586184, 0.0010470441196304787, 0.019549627724450874, 0.0007894737289141666, 0.0032621943567179524, 0.1793655900158267], [0.927990939412834, 1.0603615324401874, 1.1846550097318922, 1.0706597806164886, 1.1656235872646235, 1.1777486812762266]
Training Loss (progress: 0.64), 0.11883441487169473, [0.006291233315258257, 0.0010457235425712498, 0.019485491146130813, 0.0007705891489902497, 0.0032608042497483235, 0.1795423826447946], [0.9280363017099734, 1.060421895594023, 1.1847721589863922, 1.0705472459236174, 1.1658823504845774, 1.1779483606142158]
Training Loss (progress: 0.72), 0.12854931374733014, [0.006261265963219476, 0.0010307986514457846, 0.019521009045325947, 0.0008042996536822242, 0.0032518316845117803, 0.17977128964848452], [0.9279418854899024, 1.0605123901773474, 1.1849353140745291, 1.0704944942593444, 1.1660653145386803, 1.1782487982348577]
Training Loss (progress: 0.80), 0.11593308796232717, [0.006282384169247684, 0.001037246557224529, 0.019581805549259097, 0.0007807888084204234, 0.0032294552544439824, 0.1799294234906971], [0.927885468632124, 1.0605177955204506, 1.1851213553070306, 1.0705215509669481, 1.166226988266237, 1.1784621231916155]
Training Loss (progress: 0.88), 0.11722233141560359, [0.00626623939760145, 0.0010255326744549184, 0.019705775799906924, 0.0007973333434801878, 0.003256406027966148, 0.18013600960144927], [0.9278373399027608, 1.0605149468979904, 1.1854177754243138, 1.0704490627383292, 1.166464595621404, 1.1787246709920605]
Training Loss (progress: 0.96), 0.10862263836923373, [0.0062521315291837, 0.0010515196746877756, 0.019692096413116398, 0.000786857940258109, 0.0032618121934113774, 0.18035286025245004], [0.9277934478646271, 1.060687946426097, 1.1856161820538378, 1.0704600373055493, 1.166691586355339, 1.1789516640330604]
Evaluation on validation dataset:
Step 25, mean loss 0.025348811438428806
Step 50, mean loss 0.017400771731589257
Step 75, mean loss 0.026100349402480585
Step 100, mean loss 0.02736168101270932
Step 125, mean loss 0.037608993483858225
Step 150, mean loss 0.03737182607892783
Step 175, mean loss 0.057388606746726495
Step 200, mean loss 0.18069881858080597
Step 225, mean loss 0.1401684703614517
Unrolled forward losses 1.6457210621302325
Unrolled forward base losses 2.565701273852575
Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00), 0.126068758812978, [0.006301306683887154, 0.001024530519530552, 0.019692837160603924, 0.0007916540336610606, 0.00322725999903671, 0.18045252168157566], [0.9278349242984073, 1.060710426248373, 1.1856709891509347, 1.0704342779921643, 1.1667472950907558, 1.179059380623826]
Training Loss (progress: 0.08), 0.11871228020561687, [0.006307826824773391, 0.001039581487756212, 0.019792199771999905, 0.000785062701620579, 0.0032581719449346533, 0.18060135128764077], [0.9277677892782599, 1.0607516986210428, 1.1858991737542024, 1.0704046316805114, 1.1670371328368114, 1.1792587063068107]
Training Loss (progress: 0.16), 0.111089127088081, [0.006254103394156816, 0.0010466008053112478, 0.019779626839979934, 0.0007935265890167479, 0.003200701277306893, 0.1808247391276452], [0.9277311185733976, 1.0608392246881364, 1.1860440144944433, 1.0703621267322054, 1.167123676071343, 1.1794765323966625]
Training Loss (progress: 0.24), 0.10939286322960373, [0.006261854813908201, 0.0010259582392419086, 0.019889010329576122, 0.0008069269219282922, 0.0032168934650485094, 0.18100259556692688], [0.9276646489030693, 1.060847595652329, 1.1862348531968243, 1.0703476455319296, 1.1672903871684666, 1.1796932509603528]
Training Loss (progress: 0.32), 0.11237460504841003, [0.006254730051963648, 0.0010351075674890852, 0.019872283496058206, 0.0007791544994131749, 0.0032323860343877837, 0.18125491226226387], [0.9276417299057582, 1.0609217133215094, 1.1864146981053107, 1.0702925563375332, 1.1676056043603043, 1.179984683290057]
Training Loss (progress: 0.40), 0.1261699370941589, [0.006214611106354796, 0.001044648266943862, 0.019995839641913656, 0.0007908210475943871, 0.0032421350637157438, 0.18149817844480276], [0.9275712891288355, 1.060999522534344, 1.1866839305954424, 1.070312238040788, 1.1677912354470499, 1.180287912045681]
Training Loss (progress: 0.48), 0.10426598823440257, [0.006201516501602272, 0.001045385608378857, 0.020004604619882068, 0.0007894114047540235, 0.0032217833457003076, 0.18166029761506786], [0.9274821794894391, 1.0610211103935718, 1.1867856277949005, 1.0703040322858266, 1.16792140696779, 1.1804655214777655]
Training Loss (progress: 0.56), 0.11001371488618963, [0.006235971875889351, 0.0010455017659850043, 0.020155864071646427, 0.0007915014456715145, 0.0032542853095883163, 0.18191805065137784], [0.9274527038664973, 1.0610582922027207, 1.1870252164243025, 1.070281984090728, 1.1681712070708292, 1.180766165859492]
Training Loss (progress: 0.64), 0.10986259370829056, [0.006249488727394035, 0.0010498665714533206, 0.02015358279055166, 0.0007914967455749477, 0.0032324358931250193, 0.18210732820671838], [0.927368793392407, 1.0611822959467863, 1.187229305250674, 1.070227845187259, 1.168230877313336, 1.1809974190421155]
Training Loss (progress: 0.72), 0.10478398692237059, [0.006233451312048627, 0.0010349220351241032, 0.020343161929313427, 0.0008021253038533515, 0.0032479098338430053, 0.18234960529358243], [0.9272806595711615, 1.061100346478513, 1.1875278382411352, 1.070265461060708, 1.1684512869652253, 1.1812700194976786]
Training Loss (progress: 0.80), 0.11739548016897153, [0.006219867345050012, 0.0010244198139518505, 0.020293302189287515, 0.0008249244778070323, 0.0032667441077379954, 0.18254596773166248], [0.9272908722070953, 1.0612548742211483, 1.187575502533765, 1.0702064006584142, 1.1687041325653638, 1.181442865620704]
Training Loss (progress: 0.88), 0.10195679684016733, [0.006259931059023893, 0.0010309162885852226, 0.020358015780678945, 0.0007832608572154052, 0.003250808310073609, 0.18263592590801753], [0.9273349874068668, 1.0612962434554967, 1.1877074059758455, 1.0701661818924992, 1.1689032869870517, 1.1815478564826458]
Training Loss (progress: 0.96), 0.12345366645590256, [0.006282725672707385, 0.0010281921701220215, 0.020449159804731696, 0.0008025519192407818, 0.0032685242978447385, 0.18277664227287307], [0.9272206081597052, 1.0614042239020132, 1.1879025068846047, 1.0700937925948923, 1.1690665599412626, 1.1817419220771104]
Evaluation on validation dataset:
Step 25, mean loss 0.022410863429398506
Step 50, mean loss 0.01567451266093372
Step 75, mean loss 0.02447249954919942
Step 100, mean loss 0.026754750679247527
Step 125, mean loss 0.03909380325226819
Step 150, mean loss 0.03686681394035918
Step 175, mean loss 0.055940373568302434
Step 200, mean loss 0.17560023950378978
Step 225, mean loss 0.12997682129831542
Unrolled forward losses 1.564901111665804
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.15599e-01, 3.21333e-02, 9.92703e-01, 9.03042e-03, 3.78694e-01, 1.15836e+00
Node: 01 (pos: 0.010): 6.16852e-01, 9.35574e-02, 1.04869e+00, 3.88452e-02, 5.34432e-01, 1.16549e+00
Node: 02 (pos: 0.020): 7.14318e-01, 2.24293e-01, 1.09683e+00, 1.28163e-01, 7.08428e-01, 1.17136e+00
Node: 03 (pos: 0.030): 8.00654e-01, 4.42758e-01, 1.13580e+00, 3.24325e-01, 8.82061e-01, 1.17594e+00
Node: 04 (pos: 0.040): 8.68640e-01, 7.19667e-01, 1.16449e+00, 6.29497e-01, 1.03157e+00, 1.17923e+00
Node: 05 (pos: 0.051): 9.12172e-01, 9.63187e-01, 1.18204e+00, 9.37135e-01, 1.13319e+00, 1.18120e+00
-
Node: 07 (pos: 0.071): 9.12172e-01, 9.63187e-01, 1.18204e+00, 9.37135e-01, 1.13319e+00, 1.18120e+00
Node: 08 (pos: 0.081): 8.68640e-01, 7.19667e-01, 1.16449e+00, 6.29497e-01, 1.03157e+00, 1.17923e+00
Node: 09 (pos: 0.091): 8.00654e-01, 4.42758e-01, 1.13580e+00, 3.24325e-01, 8.82061e-01, 1.17594e+00
Node: 10 (pos: 0.101): 7.14318e-01, 2.24293e-01, 1.09683e+00, 1.28163e-01, 7.08428e-01, 1.17136e+00
Node: 11 (pos: 0.111): 6.16852e-01, 9.35574e-02, 1.04869e+00, 3.88452e-02, 5.34432e-01, 1.16549e+00
Node: 12 (pos: 0.121): 5.15599e-01, 3.21333e-02, 9.92703e-01, 9.03042e-03, 3.78694e-01, 1.15836e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.12172e-01, 9.63187e-01, 1.18204e+00, 9.37135e-01, 1.13319e+00, 1.18120e+00
Node: 58 (pos: 0.586): 8.68640e-01, 7.19667e-01, 1.16449e+00, 6.29497e-01, 1.03157e+00, 1.17923e+00
Node: 59 (pos: 0.596): 8.00654e-01, 4.42758e-01, 1.13580e+00, 3.24325e-01, 8.82061e-01, 1.17594e+00
Node: 60 (pos: 0.606): 7.14318e-01, 2.24293e-01, 1.09683e+00, 1.28163e-01, 7.08428e-01, 1.17136e+00
Node: 61 (pos: 0.616): 6.16852e-01, 9.35574e-02, 1.04869e+00, 3.88452e-02, 5.34432e-01, 1.16549e+00
Node: 50 (pos: 0.505): 5.15599e-01, 3.21333e-02, 9.92703e-01, 9.03042e-03, 3.78694e-01, 1.15836e+00
-
Node: 51 (pos: 0.515): 6.16852e-01, 9.35574e-02, 1.04869e+00, 3.88452e-02, 5.34432e-01, 1.16549e+00
Node: 52 (pos: 0.525): 7.14318e-01, 2.24293e-01, 1.09683e+00, 1.28163e-01, 7.08428e-01, 1.17136e+00
Node: 53 (pos: 0.535): 8.00654e-01, 4.42758e-01, 1.13580e+00, 3.24325e-01, 8.82061e-01, 1.17594e+00
Node: 54 (pos: 0.545): 8.68640e-01, 7.19667e-01, 1.16449e+00, 6.29497e-01, 1.03157e+00, 1.17923e+00
Node: 55 (pos: 0.556): 9.12172e-01, 9.63187e-01, 1.18204e+00, 9.37135e-01, 1.13319e+00, 1.18120e+00
Node: 62 (pos: 0.626): 5.15599e-01, 3.21333e-02, 9.92703e-01, 9.03042e-03, 3.78694e-01, 1.15836e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.019341836857086698
Step 50, mean loss 0.010428888775309737
Step 75, mean loss 0.01825626798460997
Step 100, mean loss 0.021221773643289983
Step 125, mean loss 0.03597637659300834
Step 150, mean loss 0.035291200590013824
Step 175, mean loss 0.056715972263709495
Step 200, mean loss 0.09998522123225984
Step 225, mean loss 0.07248146433207024
Unrolled forward losses 1.3018994254588314
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00), 0.11446143426217625, [0.006255160651929765, 0.0010454561305667017, 0.020506798562665463, 0.0007823542878780215, 0.003262394262181811, 0.18292628412123063], [0.927157578915129, 1.0615126455327302, 1.1879982453513083, 1.0700640819732774, 1.1692104339048814, 1.18190391336175]
Training Loss (progress: 0.08), 0.11692747073882587, [0.006263061063701914, 0.0010589528330838096, 0.020514702409898677, 0.000799473373167769, 0.003224428988325123, 0.18307483110462358], [0.9270831557753564, 1.0615189825438984, 1.1882264189005822, 1.0700633251331795, 1.1692713401487087, 1.1820740772653935]
Training Loss (progress: 0.16), 0.12455172273913619, [0.006251739099745675, 0.0010394628664292924, 0.020598813337987756, 0.0007861939075010125, 0.0032366136884474585, 0.18319881772481078], [0.9270629204447947, 1.061583989176712, 1.1884674150668708, 1.0700934872895227, 1.1694778681693903, 1.1822150603305837]
Training Loss (progress: 0.24), 0.11867356192457633, [0.006246128492554729, 0.0010529130516103574, 0.02060681102673023, 0.0008136956944918057, 0.0032410773550373313, 0.18342925074502167], [0.9270515992135665, 1.0617096017029546, 1.1885405497756922, 1.0700379131100086, 1.1697340843178714, 1.182452558379968]
Training Loss (progress: 0.32), 0.11917540212728248, [0.0062689856495745, 0.00103124323219669, 0.020568083633633664, 0.0008034864813539571, 0.003240658826127686, 0.18359201444713202], [0.9270407471328769, 1.0618118322969017, 1.188708639248743, 1.0700541487456476, 1.1698968327698749, 1.1826584802358167]
Training Loss (progress: 0.40), 0.10457285835116142, [0.006192141940346493, 0.0010549253060588282, 0.020619362575261015, 0.0007899143378108216, 0.0032425284927066265, 0.18376767479283887], [0.9269321730278107, 1.0618199976848055, 1.188878948776623, 1.069965288351199, 1.170021234113585, 1.1828646183256404]
Training Loss (progress: 0.48), 0.11147547638097996, [0.00618781482518828, 0.0010421986710344297, 0.02061005350731389, 0.0007861488994043721, 0.00324304363500786, 0.18386460135609914], [0.9268435631501628, 1.0619357522600925, 1.18904309058793, 1.0698796881692456, 1.1702057897448221, 1.183039564870278]
Training Loss (progress: 0.56), 0.11811747984458328, [0.006218798546737635, 0.0010269207209609183, 0.020811583176917017, 0.0007932265996110494, 0.003263537814910138, 0.18410299913609882], [0.9267639512059092, 1.0619252108847819, 1.1892693874916143, 1.06984791197022, 1.1703998572216117, 1.1832856662957136]
Training Loss (progress: 0.64), 0.10690348568609293, [0.006248532879211407, 0.0010371208946495924, 0.020958116160348532, 0.0007875183631607875, 0.0032552947419189774, 0.18423416914185275], [0.926754304256498, 1.062108419857055, 1.1894881742337906, 1.0697911739704316, 1.1704656069273425, 1.1834375351381936]
Training Loss (progress: 0.72), 0.10981707279339932, [0.006240676849309993, 0.001051841519480225, 0.02095417678279837, 0.0007898517681862395, 0.003269132848140523, 0.18439243492267926], [0.9266671846417677, 1.062153006641943, 1.1896398594361597, 1.0697176026128001, 1.1707414835458876, 1.183678979420689]
Training Loss (progress: 0.80), 0.11325580979991215, [0.006232777264560244, 0.0010473530365152873, 0.021055337518903244, 0.0008077368987761663, 0.003246632660163527, 0.1845838129865979], [0.9266037004955329, 1.062231954398757, 1.189803142571019, 1.0696590199285647, 1.1708946602404684, 1.18386585993609]
Training Loss (progress: 0.88), 0.10914031172895967, [0.006238632158737444, 0.0010190289851011432, 0.02115698544911153, 0.0008049645094563328, 0.003231995425512585, 0.18472831044400975], [0.9265266423564722, 1.0622764309647232, 1.1900044683505748, 1.0695826265897326, 1.171123074514897, 1.1840262759789306]
Training Loss (progress: 0.96), 0.107228728336292, [0.006243907302333214, 0.0010452652879086564, 0.021234684379458458, 0.0007986610556414255, 0.003256977903269321, 0.18496742665788934], [0.9264751325960596, 1.0623414082674363, 1.1901171033004307, 1.0695752508217637, 1.171210677767554, 1.1842801634557558]
Evaluation on validation dataset:
Step 25, mean loss 0.02443732717818147
Step 50, mean loss 0.017142235155202912
Step 75, mean loss 0.02627635938657885
Step 100, mean loss 0.027929569520937805
Step 125, mean loss 0.03279012808363768
Step 150, mean loss 0.035935865732712576
Step 175, mean loss 0.05317715443763282
Step 200, mean loss 0.16891979321624606
Step 225, mean loss 0.13861540276655474
Unrolled forward losses 1.6067916073222879
Unrolled forward base losses 2.565701273852575
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00), 0.11687613479813418, [0.006247915486291857, 0.001058899102552845, 0.021281413646871892, 0.000799677825774564, 0.003249198248441194, 0.18504187725651036], [0.92647905877615, 1.0624504511164492, 1.1902156794343899, 1.0695966017274374, 1.1713086922690765, 1.1843640277810317]
Training Loss (progress: 0.08), 0.12087283064921377, [0.006217226444638164, 0.0010193782165733192, 0.021387605905361876, 0.0007970304350427452, 0.0032224280105302683, 0.18511892013374798], [0.9263849854479684, 1.06244953718105, 1.1904698716767919, 1.0695600118943631, 1.1713851956854666, 1.1845076972608524]
Training Loss (progress: 0.16), 0.11469894700659561, [0.006259445036719807, 0.001035993051518128, 0.021433937823241354, 0.0008106054854198735, 0.0032157913191422824, 0.1853565278961119], [0.9263617761290944, 1.062552072706858, 1.1905661675238894, 1.0694976918177934, 1.1715832051761366, 1.1847583271552815]
Training Loss (progress: 0.24), 0.12214055015979133, [0.00624435404339812, 0.0010374592964288163, 0.021430922349650782, 0.0008027998548496308, 0.0032456921689353077, 0.1855398283555491], [0.9263107814703652, 1.062588636750176, 1.1907225220083446, 1.0694356661382338, 1.171770969159043, 1.184920134064745]
Training Loss (progress: 0.32), 0.10864762088978049, [0.0062286185185349415, 0.0010354607398274116, 0.021503277363999894, 0.0007846278000414752, 0.003232588560964327, 0.18565393441348182], [0.9262233498442075, 1.0626280575517184, 1.1908652000765196, 1.069389833211626, 1.1720025681382, 1.1850717326726616]
Training Loss (progress: 0.40), 0.1205414853510301, [0.006229020303890271, 0.0010618653648836619, 0.0214538165961942, 0.0007841607203094832, 0.0032353175080028196, 0.18583279362135313], [0.9261708665614381, 1.0626590884647502, 1.1909503373507502, 1.0693680085510313, 1.172082146049064, 1.1852439570462938]
Training Loss (progress: 0.48), 0.11062900062790612, [0.006230195426569297, 0.0010250624780663497, 0.02155089401232086, 0.000795652575357722, 0.003247231064023371, 0.1860113957638885], [0.9260733273106203, 1.0627267351741072, 1.1911196021863815, 1.0692919746244423, 1.17224840531068, 1.1855089122778604]
Training Loss (progress: 0.56), 0.1034656895796951, [0.006250471416648289, 0.0010476644189894978, 0.021626626367446347, 0.0007852778973066501, 0.003244592923330341, 0.18610498447229276], [0.9261099234015883, 1.062878252401672, 1.1912526119839109, 1.0692858040705393, 1.1724517681929583, 1.1856547537754651]
Training Loss (progress: 0.64), 0.11203402771052821, [0.006204161357258648, 0.0010546976744445567, 0.021672213631261945, 0.0008030758701886734, 0.0032204014445695837, 0.18628912654422963], [0.9259348356801232, 1.062972238540339, 1.1914878264615008, 1.0692503544082006, 1.1726028662525516, 1.1858187995934528]
Training Loss (progress: 0.72), 0.11555852915198535, [0.006185600970650696, 0.0010362082229313492, 0.021774988371556322, 0.0007897103455004783, 0.003244623101199396, 0.1865106981051348], [0.9258997380301566, 1.0629357867969056, 1.1916938439319047, 1.0692369559993118, 1.1727683337642427, 1.1860366945668612]
Training Loss (progress: 0.80), 0.10896192981320531, [0.006213543301316132, 0.0010266532314159404, 0.021779876686488696, 0.0007895203983279647, 0.0032511002853565065, 0.18666578258689742], [0.925864081525743, 1.063003199421586, 1.191847649205498, 1.0692260761419037, 1.1729524001008678, 1.1861943539825943]
Training Loss (progress: 0.88), 0.12569043177416267, [0.006239908219743281, 0.0010426946898042578, 0.02194586027956865, 0.0007992071220575337, 0.003236224788457563, 0.18681610732705106], [0.9258204933086209, 1.0631164018724142, 1.192124727996711, 1.06910797556293, 1.1731217642573457, 1.1864049543607407]
Training Loss (progress: 0.96), 0.10509072062504075, [0.006185526748071319, 0.0010395048014782856, 0.0219321831937434, 0.0008125898401779774, 0.003259785716675566, 0.1869782637111721], [0.9257459917038708, 1.0631515289826476, 1.1921954227459741, 1.0691137765987648, 1.1733854737910254, 1.186612115071929]
Evaluation on validation dataset:
Step 25, mean loss 0.024497106212417588
Step 50, mean loss 0.015430345990209465
Step 75, mean loss 0.02499325210470383
Step 100, mean loss 0.025631595598279128
Step 125, mean loss 0.03500409071761126
Step 150, mean loss 0.03513822817063266
Step 175, mean loss 0.05442868875969658
Step 200, mean loss 0.16359994870542777
Step 225, mean loss 0.13735708326270715
Unrolled forward losses 1.4744682817164136
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.12495e-01, 3.22659e-02, 1.00865e+00, 1.05164e-02, 3.78669e-01, 1.16363e+00
Node: 01 (pos: 0.010): 6.13974e-01, 9.38726e-02, 1.06153e+00, 4.31679e-02, 5.34991e-01, 1.17063e+00
Node: 02 (pos: 0.020): 7.11779e-01, 2.24909e-01, 1.10686e+00, 1.37071e-01, 7.09814e-01, 1.17639e+00
Node: 03 (pos: 0.030): 7.98499e-01, 4.43762e-01, 1.14345e+00, 3.36686e-01, 8.84411e-01, 1.18089e+00
Node: 04 (pos: 0.040): 8.66839e-01, 7.21051e-01, 1.17032e+00, 6.39728e-01, 1.03485e+00, 1.18412e+00
Node: 05 (pos: 0.051): 9.10619e-01, 9.64841e-01, 1.18675e+00, 9.40280e-01, 1.13712e+00, 1.18605e+00
-
Node: 07 (pos: 0.071): 9.10619e-01, 9.64841e-01, 1.18675e+00, 9.40280e-01, 1.13712e+00, 1.18605e+00
Node: 08 (pos: 0.081): 8.66839e-01, 7.21051e-01, 1.17032e+00, 6.39728e-01, 1.03485e+00, 1.18412e+00
Node: 09 (pos: 0.091): 7.98499e-01, 4.43762e-01, 1.14345e+00, 3.36686e-01, 8.84411e-01, 1.18089e+00
Node: 10 (pos: 0.101): 7.11779e-01, 2.24909e-01, 1.10686e+00, 1.37071e-01, 7.09814e-01, 1.17639e+00
Node: 11 (pos: 0.111): 6.13974e-01, 9.38726e-02, 1.06153e+00, 4.31679e-02, 5.34991e-01, 1.17063e+00
Node: 12 (pos: 0.121): 5.12495e-01, 3.22659e-02, 1.00865e+00, 1.05164e-02, 3.78669e-01, 1.16363e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.10619e-01, 9.64841e-01, 1.18675e+00, 9.40280e-01, 1.13712e+00, 1.18605e+00
Node: 58 (pos: 0.586): 8.66839e-01, 7.21051e-01, 1.17032e+00, 6.39728e-01, 1.03485e+00, 1.18412e+00
Node: 59 (pos: 0.596): 7.98499e-01, 4.43762e-01, 1.14345e+00, 3.36686e-01, 8.84411e-01, 1.18089e+00
Node: 60 (pos: 0.606): 7.11779e-01, 2.24909e-01, 1.10686e+00, 1.37071e-01, 7.09814e-01, 1.17639e+00
Node: 61 (pos: 0.616): 6.13974e-01, 9.38726e-02, 1.06153e+00, 4.31679e-02, 5.34991e-01, 1.17063e+00
Node: 50 (pos: 0.505): 5.12495e-01, 3.22659e-02, 1.00865e+00, 1.05164e-02, 3.78669e-01, 1.16363e+00
-
Node: 51 (pos: 0.515): 6.13974e-01, 9.38726e-02, 1.06153e+00, 4.31679e-02, 5.34991e-01, 1.17063e+00
Node: 52 (pos: 0.525): 7.11779e-01, 2.24909e-01, 1.10686e+00, 1.37071e-01, 7.09814e-01, 1.17639e+00
Node: 53 (pos: 0.535): 7.98499e-01, 4.43762e-01, 1.14345e+00, 3.36686e-01, 8.84411e-01, 1.18089e+00
Node: 54 (pos: 0.545): 8.66839e-01, 7.21051e-01, 1.17032e+00, 6.39728e-01, 1.03485e+00, 1.18412e+00
Node: 55 (pos: 0.556): 9.10619e-01, 9.64841e-01, 1.18675e+00, 9.40280e-01, 1.13712e+00, 1.18605e+00
Node: 62 (pos: 0.626): 5.12495e-01, 3.22659e-02, 1.00865e+00, 1.05164e-02, 3.78669e-01, 1.16363e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.02157603450827276
Step 50, mean loss 0.01025439264509333
Step 75, mean loss 0.016694609470687835
Step 100, mean loss 0.021173563313066517
Step 125, mean loss 0.03222496038953811
Step 150, mean loss 0.03704379301393995
Step 175, mean loss 0.0535922950726538
Step 200, mean loss 0.09360795808451174
Step 225, mean loss 0.0705088450690124
Unrolled forward losses 1.3246281717593793
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00), 0.11211593274289863, [0.006206628512907661, 0.001061006642284327, 0.021989727669818944, 0.0008031194962226755, 0.003245548165495796, 0.18710606892855844], [0.9257091528706245, 1.0632552634540258, 1.1923003228922748, 1.0690977570841476, 1.173435865333021, 1.186728165088567]
Training Loss (progress: 0.08), 0.10315051919202566, [0.006197706607346664, 0.0010526107373431876, 0.02206540302605615, 0.0008003344197258863, 0.003231520787621, 0.18730467012452437], [0.9256498241898184, 1.0631612547379192, 1.1925005073273869, 1.069069886937835, 1.1735941484773027, 1.186960847592057]
Training Loss (progress: 0.16), 0.12424645323112055, [0.006225051629959213, 0.0010370821959626538, 0.02225938226985023, 0.0008025153429076344, 0.003230974937460593, 0.1873418102024072], [0.9256682089200038, 1.06329542482699, 1.1928049422566924, 1.068988815074447, 1.173747370669845, 1.1870449333245399]
Training Loss (progress: 0.24), 0.10772207597075688, [0.006236329920158572, 0.001034144275129249, 0.02220278201596354, 0.00079381905633668, 0.003249304480327747, 0.18751383852804931], [0.925627113209102, 1.0634116507566669, 1.1928757257134637, 1.0689817790589335, 1.1739521369266066, 1.1872035174145037]
Training Loss (progress: 0.32), 0.11557793307556626, [0.006223035911997212, 0.0010463679273049061, 0.022306474122791405, 0.0007941078613003927, 0.003285299073042281, 0.18775398800075163], [0.925495122251509, 1.0634687739245237, 1.1930143467445846, 1.0688555211792252, 1.1740636512042386, 1.187504447190064]
Training Loss (progress: 0.40), 0.1131496852421357, [0.006219246608340271, 0.0010706354544619578, 0.022235647894659184, 0.0008013633434810662, 0.003262614626359254, 0.18789413052787426], [0.9254983882484122, 1.0635889226831514, 1.1930833130289602, 1.068895151762488, 1.1741824857760583, 1.1876458379963692]
Training Loss (progress: 0.48), 0.11564032567225556, [0.00619447234795737, 0.0010565128345385241, 0.02240337395207632, 0.0008072480590159348, 0.0032491446346283627, 0.18804659865759465], [0.9254201876757807, 1.0636235529208349, 1.1933402016642747, 1.068844388847145, 1.1743943100605205, 1.1878141017567418]
Training Loss (progress: 0.56), 0.1067925286430022, [0.006195390524283464, 0.001035562674722411, 0.022424177592651636, 0.0008096832009875057, 0.0032672507074720516, 0.18828492085046625], [0.9253454767031812, 1.0636147851802968, 1.1934614999704454, 1.0688330170881253, 1.1745932693723484, 1.1880500636794973]
Training Loss (progress: 0.64), 0.09918326789894868, [0.006223702772446313, 0.001049694860283483, 0.022495835780853922, 0.0008061504764488502, 0.0032422045839189265, 0.18846000644218844], [0.9253969680900409, 1.0637349443917425, 1.1936449574135295, 1.0687998855637655, 1.1746500425686652, 1.1881927609416523]
Training Loss (progress: 0.72), 0.10483746395346903, [0.006161631947240221, 0.0010536106977135028, 0.02251286466784182, 0.0008015741869197373, 0.003226501790203566, 0.1885464414170112], [0.9252263612427897, 1.0638161832386739, 1.1937616270968765, 1.0687156329788183, 1.174768528559542, 1.1883222599670773]
Training Loss (progress: 0.80), 0.11457634946951017, [0.006193718599592345, 0.001055025318659291, 0.022779513761874183, 0.0007946153502412653, 0.003231197217190103, 0.1887052788678563], [0.9251915577297521, 1.0639662063041966, 1.194154936525424, 1.0686780330948566, 1.175117647620594, 1.1885260902642034]
Training Loss (progress: 0.88), 0.10803644996821225, [0.006188303432353894, 0.001063397348768246, 0.022803695891335022, 0.0007904766584686055, 0.0032401438890399996, 0.1888625048741036], [0.9251041172918633, 1.0639091369472113, 1.194190133133681, 1.0686530949137842, 1.1752831100734233, 1.1886790443318092]
Training Loss (progress: 0.96), 0.11418643978465773, [0.0061913770552835, 0.0010484347188978204, 0.022901326864204215, 0.0007978001184251335, 0.0032364580175059583, 0.1891011392306734], [0.9250224783847416, 1.063900943459025, 1.1943130029467377, 1.0686451996558055, 1.1754785533618561, 1.1889398439198435]
Evaluation on validation dataset:
Step 25, mean loss 0.021493833264243718
Step 50, mean loss 0.014795913701457143
Step 75, mean loss 0.024702873915818338
Step 100, mean loss 0.02537598978557895
Step 125, mean loss 0.033292505972168915
Step 150, mean loss 0.03791430898797038
Step 175, mean loss 0.052821446283294424
Step 200, mean loss 0.1625694402356227
Step 225, mean loss 0.1420551623074714
Unrolled forward losses 1.4807013275694527
Unrolled forward base losses 2.565701273852575
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00), 0.10614316645133598, [0.0062337681386268814, 0.0010314458158870493, 0.022899094409523355, 0.0008014628785860013, 0.0032558114136507998, 0.18923287154301238], [0.9250729004544432, 1.0639485147817007, 1.194420668561874, 1.0686176817461996, 1.175560570862467, 1.1890466100702262]
Training Loss (progress: 0.08), 0.10467576266876064, [0.006200911565288784, 0.0010444006736292759, 0.022968025700818153, 0.0008126393532805893, 0.0032227125925866386, 0.1892658542096328], [0.9250361675404495, 1.0639761294481676, 1.1945475597323307, 1.0686338724011992, 1.1756563651820577, 1.189125970078927]
Training Loss (progress: 0.16), 0.10379554098319838, [0.0062195681392321475, 0.001062903312898951, 0.02301790349481336, 0.0007890420313039544, 0.003225482982090109, 0.1893296458012328], [0.9250654195658496, 1.064019229086474, 1.194641075963404, 1.0686330667693813, 1.17576295957566, 1.1892284901104018]
Training Loss (progress: 0.24), 0.10949204137622615, [0.00620414012078876, 0.001064610066554448, 0.023102317836969612, 0.0008066162983232914, 0.0032484353241890793, 0.18942693774630023], [0.9250428321384639, 1.0640484231819254, 1.1947876412153913, 1.0686258958645578, 1.175880726559045, 1.1893301960375033]
Training Loss (progress: 0.32), 0.10108108610900708, [0.006190229196710192, 0.00104498285025796, 0.023078726797272468, 0.0008088440060012325, 0.0032519782366613155, 0.18949433672550237], [0.9250096974096603, 1.064113343851148, 1.1948185317737343, 1.068649088472443, 1.1759309959737967, 1.1894029213974486]
Training Loss (progress: 0.40), 0.10757511841231858, [0.00617664139787138, 0.0010356282669498028, 0.023159216584213466, 0.0008074696747392861, 0.0032328454848115458, 0.18956548338818213], [0.9249693600796616, 1.0641269968899765, 1.1949647351085455, 1.0685970233808337, 1.175978554737263, 1.189517112309842]
Training Loss (progress: 0.48), 0.10529121245271665, [0.0061647162520702395, 0.001044798597868602, 0.023179626834528167, 0.0008117081159541078, 0.0032466724124213292, 0.18962626510091812], [0.9249405150551002, 1.0641205514915373, 1.1949948676987965, 1.0685677373594649, 1.1761138083787313, 1.1896175939988267]
Training Loss (progress: 0.56), 0.10390985876474898, [0.00619215318786714, 0.0010314679104396081, 0.02315946850178962, 0.0008017521589966029, 0.0032467480298745124, 0.1897046474807788], [0.9249710235487162, 1.0642101724517181, 1.1950637380194908, 1.0685350395484092, 1.1761645402966348, 1.1897262003896512]
Training Loss (progress: 0.64), 0.11062288803251512, [0.006207339164795611, 0.0010407440962367054, 0.023270527527595463, 0.0007977980397519614, 0.0032575538914624766, 0.18979337241793265], [0.9249496040005949, 1.0642604894838, 1.195196042979682, 1.0685358655052668, 1.1762835561631546, 1.1898461970444247]
Training Loss (progress: 0.72), 0.10267607714715897, [0.006196611636722202, 0.0010358370722715845, 0.02323410892863241, 0.0007945655280742525, 0.003255419031047915, 0.18987206875705523], [0.9249200855115418, 1.0642557042968233, 1.1952133852964577, 1.0685177851542826, 1.1763236974911913, 1.1899281910887405]
Training Loss (progress: 0.80), 0.10976770334198681, [0.006181532457069424, 0.0010475284514929381, 0.02324370613178285, 0.0008142606683071168, 0.0032605094251986814, 0.1899747598493056], [0.9249039551681975, 1.0643134754845642, 1.1953482330709442, 1.0685070312929408, 1.1764213336785716, 1.190044600687113]
Training Loss (progress: 0.88), 0.11126929488059102, [0.0061899191418714515, 0.0010526727485948046, 0.02326007490611197, 0.0008067055517163717, 0.0032546178452051524, 0.19009391943672446], [0.9249100736251004, 1.0643202064796828, 1.195416635264492, 1.0685098083156637, 1.1765052829404843, 1.1901685303342833]
Training Loss (progress: 0.96), 0.10890610636755725, [0.006181768773202277, 0.0010548240817403725, 0.023328466931629935, 0.0007980307459427091, 0.003251914932958522, 0.1901512749683822], [0.9248708549505253, 1.0643340913677262, 1.1955549694264478, 1.0685096796887652, 1.1765894545752473, 1.1902446124288923]
Evaluation on validation dataset:
Step 25, mean loss 0.022090445169502614
Step 50, mean loss 0.015455470590455416
Step 75, mean loss 0.023353470106393447
Step 100, mean loss 0.025183736931971984
Step 125, mean loss 0.03259509809088077
Step 150, mean loss 0.0343313546202848
Step 175, mean loss 0.04880321417581013
Step 200, mean loss 0.16288872387004472
Step 225, mean loss 0.13617882155875222
Unrolled forward losses 1.5347276695819358
Unrolled forward base losses 2.565701273852575
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00), 0.11540679776867259, [0.006183916809729295, 0.001036801631671644, 0.023303510793298024, 0.0008049882346009467, 0.003236357930200431, 0.19014814109860045], [0.9248843250191355, 1.064381757168848, 1.1955693206852822, 1.0685140360455176, 1.1765838577564516, 1.1902620158927506]
Training Loss (progress: 0.08), 0.11931990444159198, [0.0062050762307809745, 0.0010572455304306634, 0.023315748945310584, 0.0008077052018525226, 0.003241127302308498, 0.190247808925424], [0.9248967278442944, 1.064416059132763, 1.195627277588305, 1.0684661469513554, 1.176728965342146, 1.1904049723711723]
Training Loss (progress: 0.16), 0.10016563632889956, [0.006174021991754218, 0.0010626629193175477, 0.023355123732761968, 0.0008037251219395701, 0.0032340439634840614, 0.19026805512137596], [0.9248231111578422, 1.0644243472048995, 1.1957522471802788, 1.0684706082222866, 1.1767993406972899, 1.1904336505629305]
Training Loss (progress: 0.24), 0.1090434413224117, [0.006180960938410959, 0.001057971750915409, 0.02340831021620333, 0.0008047134232659945, 0.0032280830870869076, 0.1903543886794841], [0.9248366677210995, 1.0644919631938752, 1.1958390928150295, 1.0684621235024456, 1.1768503867495899, 1.1905395030541923]
Training Loss (progress: 0.32), 0.1126819737150097, [0.006186242060396167, 0.001044814840028969, 0.023431396726999763, 0.0007954281911354394, 0.0032354445124337275, 0.1904165683683404], [0.9248104469097331, 1.0645483907766746, 1.1959293389788015, 1.0684205956526773, 1.1769250910976101, 1.1906317893970637]
Training Loss (progress: 0.40), 0.10865067812509557, [0.006204521936872307, 0.0010540618299888348, 0.02348652931390584, 0.0008047750738357148, 0.0032403673716445707, 0.19051568343351585], [0.9248086109373642, 1.0645498008035628, 1.1959949187163337, 1.0683956087608457, 1.1770085140466537, 1.1907328090048348]
Training Loss (progress: 0.48), 0.09889142975357507, [0.006165108164183005, 0.001052142274220299, 0.023504245864294702, 0.0008037042046122839, 0.003228020467868138, 0.19058445357847667], [0.9247534356642694, 1.064587500344905, 1.1961134912160254, 1.0683602236887269, 1.1770994716172074, 1.1908339616449988]
Training Loss (progress: 0.56), 0.10595489850028182, [0.00619097165857865, 0.0010577527431825605, 0.02357588949827819, 0.0008066288365268121, 0.003220147911131742, 0.19067975588913041], [0.9247731642199746, 1.0646333168358513, 1.1962081856834013, 1.0684002261500527, 1.1771492708726436, 1.1909496474222356]
Training Loss (progress: 0.64), 0.09719938241900407, [0.006166434464339248, 0.0010493051102613777, 0.023607630205644933, 0.0008202750100319877, 0.003246682961781722, 0.19072809234098756], [0.9247423567039232, 1.0647008211220352, 1.196305779887662, 1.0683978978872073, 1.1772822190498191, 1.1910145149512756]
Training Loss (progress: 0.72), 0.10387779602421082, [0.0061678347541889444, 0.0010459974808554766, 0.023587270813043685, 0.0008046026141152301, 0.0032311197988876337, 0.1908133288347876], [0.9247327363990102, 1.0647647428657694, 1.1963149075679338, 1.0683529917088666, 1.1773205770224708, 1.1911208847976165]
Training Loss (progress: 0.80), 0.09377230106554503, [0.006145143115942816, 0.001030264376753441, 0.02364862562800976, 0.0008143699217658686, 0.0032393138055343096, 0.19087639683300983], [0.9247024074168886, 1.0647808233587532, 1.1963911031466907, 1.0683819052343921, 1.1774174638153294, 1.1912039064240263]
Training Loss (progress: 0.88), 0.10683461171569124, [0.006143345389378477, 0.0010478911418544336, 0.023655814534657663, 0.0008106164377881202, 0.003228490591747007, 0.19097179700973327], [0.924703669223269, 1.0647777690018434, 1.1964678175653065, 1.0683705746310233, 1.1774761865203214, 1.191309033746975]
Training Loss (progress: 0.96), 0.10494736094843421, [0.0061390128008614545, 0.0010470338947235814, 0.02368271834193084, 0.0008014352889372211, 0.003233435788136411, 0.19106099729839487], [0.9246783096017682, 1.0647993264774605, 1.1965609685549317, 1.0683492404259087, 1.177621591476352, 1.1914164712457684]
Evaluation on validation dataset:
Step 25, mean loss 0.0200390224494431
Step 50, mean loss 0.014150750397663323
Step 75, mean loss 0.023047733645513727
Step 100, mean loss 0.02393525109453843
Step 125, mean loss 0.03189031874897354
Step 150, mean loss 0.03276358700046582
Step 175, mean loss 0.04938765201700997
Step 200, mean loss 0.1573496663535428
Step 225, mean loss 0.13813015546703805
Unrolled forward losses 1.4156210916149714
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.08690e-01, 3.24388e-02, 1.02460e+00, 1.10882e-02, 3.79122e-01, 1.16875e+00
Node: 01 (pos: 0.010): 6.10604e-01, 9.42640e-02, 1.07434e+00, 4.47751e-02, 5.36028e-01, 1.17564e+00
Node: 02 (pos: 0.020): 7.09001e-01, 2.25629e-01, 1.11684e+00, 1.40280e-01, 7.11621e-01, 1.18130e+00
Node: 03 (pos: 0.030): 7.96369e-01, 4.44846e-01, 1.15105e+00, 3.40991e-01, 8.87080e-01, 1.18573e+00
Node: 04 (pos: 0.040): 8.65292e-01, 7.22423e-01, 1.17612e+00, 6.43097e-01, 1.03832e+00, 1.18890e+00
Node: 05 (pos: 0.051): 9.09477e-01, 9.66365e-01, 1.19143e+00, 9.41015e-01, 1.14117e+00, 1.19080e+00
-
Node: 07 (pos: 0.071): 9.09477e-01, 9.66365e-01, 1.19143e+00, 9.41015e-01, 1.14117e+00, 1.19080e+00
Node: 08 (pos: 0.081): 8.65292e-01, 7.22423e-01, 1.17612e+00, 6.43097e-01, 1.03832e+00, 1.18890e+00
Node: 09 (pos: 0.091): 7.96369e-01, 4.44846e-01, 1.15105e+00, 3.40991e-01, 8.87080e-01, 1.18573e+00
Node: 10 (pos: 0.101): 7.09001e-01, 2.25629e-01, 1.11684e+00, 1.40280e-01, 7.11621e-01, 1.18130e+00
Node: 11 (pos: 0.111): 6.10604e-01, 9.42640e-02, 1.07434e+00, 4.47751e-02, 5.36028e-01, 1.17564e+00
Node: 12 (pos: 0.121): 5.08690e-01, 3.24388e-02, 1.02460e+00, 1.10882e-02, 3.79122e-01, 1.16875e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.09477e-01, 9.66365e-01, 1.19143e+00, 9.41015e-01, 1.14117e+00, 1.19080e+00
Node: 58 (pos: 0.586): 8.65292e-01, 7.22423e-01, 1.17612e+00, 6.43097e-01, 1.03832e+00, 1.18890e+00
Node: 59 (pos: 0.596): 7.96369e-01, 4.44846e-01, 1.15105e+00, 3.40991e-01, 8.87080e-01, 1.18573e+00
Node: 60 (pos: 0.606): 7.09001e-01, 2.25629e-01, 1.11684e+00, 1.40280e-01, 7.11621e-01, 1.18130e+00
Node: 61 (pos: 0.616): 6.10604e-01, 9.42640e-02, 1.07434e+00, 4.47751e-02, 5.36028e-01, 1.17564e+00
Node: 50 (pos: 0.505): 5.08690e-01, 3.24388e-02, 1.02460e+00, 1.10882e-02, 3.79122e-01, 1.16875e+00
-
Node: 51 (pos: 0.515): 6.10604e-01, 9.42640e-02, 1.07434e+00, 4.47751e-02, 5.36028e-01, 1.17564e+00
Node: 52 (pos: 0.525): 7.09001e-01, 2.25629e-01, 1.11684e+00, 1.40280e-01, 7.11621e-01, 1.18130e+00
Node: 53 (pos: 0.535): 7.96369e-01, 4.44846e-01, 1.15105e+00, 3.40991e-01, 8.87080e-01, 1.18573e+00
Node: 54 (pos: 0.545): 8.65292e-01, 7.22423e-01, 1.17612e+00, 6.43097e-01, 1.03832e+00, 1.18890e+00
Node: 55 (pos: 0.556): 9.09477e-01, 9.66365e-01, 1.19143e+00, 9.41015e-01, 1.14117e+00, 1.19080e+00
Node: 62 (pos: 0.626): 5.08690e-01, 3.24388e-02, 1.02460e+00, 1.10882e-02, 3.79122e-01, 1.16875e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.01716110887184219
Step 50, mean loss 0.00903464485109601
Step 75, mean loss 0.01571844525268443
Step 100, mean loss 0.01934698827555853
Step 125, mean loss 0.0314669313613557
Step 150, mean loss 0.03453399446474494
Step 175, mean loss 0.050939159163631245
Step 200, mean loss 0.0909571225020796
Step 225, mean loss 0.06740003435972827
Unrolled forward losses 1.2651076158732826
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time5191451.tar

Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00), 0.10028662571774018, [0.006154044188328193, 0.0010492114243491203, 0.02368682985758684, 0.000804870215891125, 0.0032321792944095436, 0.1910823463589178], [0.9246970165343131, 1.064781093273785, 1.196583684627769, 1.0683387518370777, 1.1776766194100308, 1.1914599719272057]
Training Loss (progress: 0.08), 0.09238785918020555, [0.006129247949061464, 0.0010451602128662152, 0.023682765814351806, 0.0008111072901272755, 0.0032281109039250565, 0.1911650456124106], [0.9246298000618881, 1.0648615328448388, 1.1965950195031096, 1.068376426323267, 1.1777492771787648, 1.1915557765861957]
Training Loss (progress: 0.16), 0.11638853041697463, [0.0061356522679797895, 0.0010493536416256149, 0.023718370334912267, 0.0007993497255445493, 0.0032473482645588264, 0.19123256625968205], [0.9246502794482693, 1.0649324959160738, 1.1967170307250448, 1.0683696108299738, 1.1777949310574216, 1.1916409295302728]
Training Loss (progress: 0.24), 0.10548510284395352, [0.006150948912114094, 0.0010518176054355199, 0.02370474973770318, 0.0008038911320924299, 0.0032313950892141918, 0.19130123686815256], [0.9246165867188203, 1.0649592203447211, 1.1967813580372677, 1.0683483373407883, 1.177915970530743, 1.1917510821482304]
Training Loss (progress: 0.32), 0.11144089147167015, [0.006151878523575192, 0.0010477831584631671, 0.023754295382275675, 0.0008050630397089036, 0.0032148044284207246, 0.1913899572530668], [0.9246303575004442, 1.064999586253476, 1.1968853901597443, 1.0683625092504685, 1.1779805837235613, 1.1918342748487212]
Training Loss (progress: 0.40), 0.10730680937223258, [0.006168382560950642, 0.0010613386155277683, 0.02380047053379061, 0.0008039796148526795, 0.003219405457056539, 0.19142475363477507], [0.9246158595013009, 1.065030641240139, 1.1969862953008705, 1.0683405016260294, 1.178120660859505, 1.191919422462041]
Training Loss (progress: 0.48), 0.10808372890712341, [0.006174682558230009, 0.0010388638588278, 0.023812776992803444, 0.0008000318871253431, 0.003223625808841848, 0.19151453181204608], [0.9246064188611836, 1.0650448290517447, 1.1970472201647646, 1.068348486615371, 1.1782364468000865, 1.192014027589653]
Training Loss (progress: 0.56), 0.0999384826916072, [0.006150479736283474, 0.0010620795241396781, 0.023851107971067133, 0.0008088827326197772, 0.003218410723500424, 0.191594165636318], [0.9245645648535471, 1.0651046261045825, 1.1971605734399042, 1.0683179351801042, 1.1782380509428148, 1.1921054345169086]
Training Loss (progress: 0.64), 0.0995964196620134, [0.006158846636423755, 0.0010549725940955496, 0.0238697383292969, 0.0008142573890920682, 0.0032235992636512824, 0.1916520387433305], [0.9245481166506928, 1.0651106933496413, 1.1972273710003767, 1.0683124959584718, 1.178295471665735, 1.192183343125835]
Training Loss (progress: 0.72), 0.10642176413000344, [0.006154304550876139, 0.0010598824210846568, 0.023994318325846836, 0.0008085850271481048, 0.003226962222833858, 0.19175594429709888], [0.9245270725898596, 1.0651384897911136, 1.1973727758789876, 1.0683250634655381, 1.1784040583150974, 1.1923125998476156]
Training Loss (progress: 0.80), 0.10225526227396085, [0.006168187948312105, 0.0010512535896332674, 0.02397921260514087, 0.0008172967952313749, 0.003226729409367431, 0.19178674387579195], [0.9245256182143261, 1.0651630907060232, 1.1974075862918272, 1.0682955313883506, 1.178461766290382, 1.1923729702994286]
Training Loss (progress: 0.88), 0.10032106393951397, [0.006134504943385529, 0.001057056089899879, 0.024044803494525372, 0.0007921906649530321, 0.0032327007959081925, 0.19190204383609707], [0.9244754398548602, 1.0651868107238565, 1.1974721801107846, 1.0682968425104438, 1.1785271043358885, 1.192487350753833]
Training Loss (progress: 0.96), 0.10771502094617758, [0.0061465181049950215, 0.0010528062974236578, 0.02413293636097071, 0.0008106990704626263, 0.0032250419799766963, 0.19197982751331027], [0.9244457206039645, 1.0651803470376922, 1.197598603445765, 1.0682771309078816, 1.1786163257092706, 1.192590180826161]
Evaluation on validation dataset:
Step 25, mean loss 0.01901080357413775
Step 50, mean loss 0.01403648669362462
Step 75, mean loss 0.022936637009725508
Step 100, mean loss 0.025270696652317574
Step 125, mean loss 0.03127699895306686
Step 150, mean loss 0.03318011875552362
Step 175, mean loss 0.05097699355386881
Step 200, mean loss 0.1605052137118355
Step 225, mean loss 0.13971594524603131
Unrolled forward losses 1.4492058066379911
Unrolled forward base losses 2.565701273852575
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00), 0.1093739011348612, [0.00618267779876711, 0.0010521058563652483, 0.024105037169980987, 0.000795044884374179, 0.003235899477012799, 0.1920332005773637], [0.924492311578152, 1.0652610876444395, 1.1976284079094657, 1.0682607605289152, 1.1786954423546323, 1.192636850785945]
Training Loss (progress: 0.08), 0.10129239535388192, [0.006154926645846614, 0.0010440884329907143, 0.02416751303179666, 0.0008014279285243237, 0.003226485629698164, 0.19208924528796711], [0.9244260936782203, 1.0652790114109816, 1.1977156541378358, 1.0682508690173897, 1.1787679400540136, 1.1927226157894821]
Training Loss (progress: 0.16), 0.10387502167198573, [0.006169146535877517, 0.0010542237938790289, 0.02419045444704247, 0.0007973354744520442, 0.0032424740539561234, 0.1921096826299025], [0.9244241303524507, 1.065304313080762, 1.1977997894659416, 1.068240653197087, 1.1788605084922246, 1.192767271788405]
Training Loss (progress: 0.24), 0.10143084528216595, [0.006157056543484049, 0.0010625141184050777, 0.024241991565973807, 0.0008000735322906115, 0.0032292258349126417, 0.19217123532671104], [0.9243992791347772, 1.06529398982565, 1.1978900755352175, 1.0682339562336096, 1.1789542570483897, 1.1928586080825905]
Training Loss (progress: 0.32), 0.11091792540809636, [0.006144900172435479, 0.0010591398850886677, 0.024280081826936223, 0.0008128484410198444, 0.003237542216632629, 0.19220591185743713], [0.9243973446471121, 1.0653168114393972, 1.197962235965086, 1.068219940839294, 1.179004733363303, 1.192899168426216]
Training Loss (progress: 0.40), 0.09680382172948339, [0.006132253709226648, 0.0010522857134930824, 0.024315528161355265, 0.0007992366434103938, 0.0032261915731107275, 0.19227741438703005], [0.9243659620991217, 1.0653572742750452, 1.1980611718248961, 1.0682233108939774, 1.1790592523666794, 1.192983958159422]
Training Loss (progress: 0.48), 0.10151399990322563, [0.00615845513785277, 0.0010569130314903572, 0.02431546465246612, 0.0008046200768491095, 0.0032352601987922325, 0.19235389239553347], [0.9243633141364764, 1.065380311526706, 1.198127451160679, 1.0682100991812182, 1.1791151427321278, 1.1931002178860766]
Training Loss (progress: 0.56), 0.10462389389051818, [0.0061307063353082305, 0.001058194642548431, 0.02434409984612462, 0.0008046856409763419, 0.0032324256542082255, 0.19243120301557648], [0.9243160984053785, 1.065392612186457, 1.198201721249127, 1.0682062394521703, 1.1792118753846732, 1.1931774746810044]
Training Loss (progress: 0.64), 0.1042438136945601, [0.006149946408393773, 0.0010619547875890287, 0.024337059779776495, 0.0008054220027857709, 0.0032430495604576794, 0.19252231571349274], [0.9243505980161889, 1.0654867874651, 1.1982731118325547, 1.0681921779202923, 1.1792849468108706, 1.193286666705443]
Training Loss (progress: 0.72), 0.10789898316441353, [0.0061496062938388545, 0.001056480278378152, 0.024357059275402992, 0.000809912445061457, 0.003216880258152402, 0.19259038706009254], [0.9243142904317294, 1.0655177088472283, 1.1983502342485326, 1.0681832352737846, 1.1793179503123392, 1.1933825472196953]
Training Loss (progress: 0.80), 0.10437103442902922, [0.006133509824813027, 0.0010583773782650789, 0.02440966306819459, 0.000808999676333664, 0.003229855416480809, 0.1926548751264544], [0.9242753501583989, 1.0655547057828327, 1.1984459729204147, 1.0681703832456284, 1.1794204327439144, 1.1934793938303665]
Training Loss (progress: 0.88), 0.10363618751289529, [0.006162031550438832, 0.0010533894988348095, 0.024414002187974963, 0.0008120565300972622, 0.00324291066516672, 0.19273561179960202], [0.9242842746168364, 1.0656060906372224, 1.1985200168794288, 1.0681501934439162, 1.1795288764497007, 1.1935845346878258]
Training Loss (progress: 0.96), 0.1026063023290314, [0.006159659120329392, 0.0010480426161494504, 0.024444743331091902, 0.0008111423292086655, 0.003234246299794196, 0.19283430609844035], [0.9242635525303728, 1.0656619251443156, 1.19861610945467, 1.0681374128145147, 1.179597214700796, 1.193726362965653]
Evaluation on validation dataset:
Step 25, mean loss 0.020386912783191255
Step 50, mean loss 0.013947782326120902
Step 75, mean loss 0.021908977074763445
Step 100, mean loss 0.0245958236705956
Step 125, mean loss 0.03253843865958417
Step 150, mean loss 0.034571522399222426
Step 175, mean loss 0.04915731630059914
Step 200, mean loss 0.1619028079040339
Step 225, mean loss 0.13846414951469585
Unrolled forward losses 1.4736466001905546
Unrolled forward base losses 2.565701273852575
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00), 0.10742746028590253, [0.006158189689725505, 0.0010588678519375925, 0.024499260657643677, 0.0008221246440817145, 0.0032335514837358095, 0.19287289939307148], [0.9242615448851658, 1.0656859002618648, 1.1987163907072764, 1.0681427416724307, 1.179641008143441, 1.1937705719104321]
Training Loss (progress: 0.08), 0.09963393764767367, [0.006197045012534095, 0.001046510299559706, 0.024536465806448853, 0.0008000778691136358, 0.003242019109636285, 0.19292649171591694], [0.9242831849165384, 1.0656979385178385, 1.1987544623360396, 1.0681054723513992, 1.179685826392502, 1.193828857515491]
Training Loss (progress: 0.16), 0.10511184102136627, [0.00615980640450399, 0.0010649955877788124, 0.024585547089599098, 0.00080732228732394, 0.003227074391666115, 0.1930116956820427], [0.9242121402286148, 1.0657167140532733, 1.1988473009522813, 1.0681018592793334, 1.1797977484347588, 1.1939322008919875]
Training Loss (progress: 0.24), 0.10113264698959465, [0.00618114553597161, 0.0010609162922166396, 0.02452829301718282, 0.0008048681878289883, 0.0032133043165942787, 0.1930725225685944], [0.924197947015026, 1.0657093593353988, 1.1988035011912952, 1.0680979348703763, 1.1798379831952808, 1.1939981427481365]
Training Loss (progress: 0.32), 0.10211641919315213, [0.0061454355215353395, 0.001052927725328278, 0.024646111863718994, 0.00081624501793711, 0.0032235359409095317, 0.19314432011054888], [0.9241534769531534, 1.0657351297689432, 1.1989580477864494, 1.0681005469977842, 1.179973940925046, 1.1941110602880587]
Training Loss (progress: 0.40), 0.10262015368211641, [0.00613515515357899, 0.0010538234697831772, 0.024667434102506103, 0.0008076202883991481, 0.0032263218722853554, 0.19319467276876803], [0.9241518570932462, 1.0658028930122292, 1.1990553452088717, 1.0680787174816815, 1.1800476852481463, 1.1941695440414282]
Training Loss (progress: 0.48), 0.10538021270398039, [0.0061620143048995105, 0.0010589194109049066, 0.024683612474290278, 0.000799377838605591, 0.0032295036989645, 0.19326367552795456], [0.9241341102399708, 1.0657402642286289, 1.1991189607259918, 1.0680641214431132, 1.1800755955274822, 1.1942407275981577]
Training Loss (progress: 0.56), 0.11236151083284569, [0.006144422568875697, 0.0010446772929885624, 0.024717142554692262, 0.0008229408288629405, 0.0032126584545342624, 0.19333378231792472], [0.9241030034258161, 1.065829785739497, 1.199198476416455, 1.0680399403061536, 1.180154405236576, 1.1943215719853975]
Training Loss (progress: 0.64), 0.10089812352842611, [0.0061586277215412545, 0.0010591056913635442, 0.024784660738830015, 0.0008192799749303204, 0.0032369133064148146, 0.19342222250322977], [0.9241064637735776, 1.0658870495149948, 1.1993055028657904, 1.0680134095572318, 1.180243118592934, 1.194439685818413]
Training Loss (progress: 0.72), 0.10949216041381853, [0.006165689833167621, 0.001060094941612549, 0.02483466075287037, 0.0008098217996555356, 0.003230901351221224, 0.19349829631027612], [0.924085738383565, 1.0659150264701778, 1.1994068236890842, 1.0679802904373976, 1.180296800018065, 1.1945320503685266]
Training Loss (progress: 0.80), 0.11443350531758939, [0.006183395135434578, 0.001046640926038719, 0.024842708796722048, 0.0008120782349921983, 0.0032366744341352834, 0.1935992196622002], [0.924125514935252, 1.0659931246326908, 1.1995370682385664, 1.0679802293169132, 1.1804026487588186, 1.194653498816665]
Training Loss (progress: 0.88), 0.10626789977308626, [0.006170165286540768, 0.0010416428953972767, 0.024849093446594857, 0.0008003685684651878, 0.0032319303744280424, 0.19364387018220244], [0.9240978616305587, 1.0660138255579217, 1.1995263727486467, 1.0679791867205282, 1.180488754045582, 1.1947017558365243]
Training Loss (progress: 0.96), 0.10758970754326129, [0.006164728008383605, 0.0010508547368129446, 0.024905958814015142, 0.0008080678146735723, 0.003219047226762638, 0.19371462485600063], [0.9240534651334531, 1.0660525095116025, 1.1996545040922968, 1.0679644362200387, 1.1805614131181268, 1.1947909346387169]
Evaluation on validation dataset:
Step 25, mean loss 0.019116013744206677
Step 50, mean loss 0.013523661414957814
Step 75, mean loss 0.02215922775488264
Step 100, mean loss 0.025406503661959103
Step 125, mean loss 0.030091367206736455
Step 150, mean loss 0.033291878238330984
Step 175, mean loss 0.048864274286694445
Step 200, mean loss 0.15532964285852388
Step 225, mean loss 0.13519641577326896
Unrolled forward losses 1.445591162603486
Unrolled forward base losses 2.565701273852575
Test loss: 1.2651076158732826
