Training on dataset data/CE_train_E2.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar
Beta parameter added to the GNN solver
Number of parameters: 1033789.0
Saved initial model at models/init69325.pt
Epoch 0
Starting epoch 0...
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Training Loss (progress: 0.00), 1.178639628856799, [0.00543249901414295, 0.010608943151370407, 0.010511418688283302, 0.010747707473771842, 0.010499719244795345, 0.011091269125451504], [1.0073093727007447, 1.0135379947523853, 1.0132479134965482, 1.0145817668145753, 1.0137044963710058, 1.0141715745750515]
Training Loss (progress: 0.08), 0.20292323347658883, [0.00498359266049653, 0.0005967218620317116, 0.0017482513918204642, 0.005345392641705091, 0.009542447043903593, 0.019605544863095167], [1.0109847852019633, 1.032432519596316, 1.0298987246872517, 1.0315848410071304, 1.0330301835413616, 1.0408412271427139]
Training Loss (progress: 0.16), 0.15523103790016654, [0.004783684524843741, 0.0005935363381292196, 0.0015115101062463255, 0.005582416012315173, 0.009928802968198857, 0.02266984995796567], [1.0090461510879183, 1.0365110334772056, 1.0332013320221145, 1.0347589705008704, 1.0391037874613758, 1.0485623463930693]
Training Loss (progress: 0.24), 0.13652646406508176, [0.004639191585780119, 0.0005161441649528315, 0.0014771030605793883, 0.006348929088203655, 0.009959460057706381, 0.024645484248435708], [1.0069133358168751, 1.0395935827137124, 1.0360280306484484, 1.0374214385104756, 1.0440731215161703, 1.0528783174537724]
Training Loss (progress: 0.32), 0.12756751245680784, [0.004270897639527514, 0.0005413267139937435, 0.0016767085591929266, 0.0066706171538647215, 0.008997003103451334, 0.026145071732258825], [1.0048435890775504, 1.0418397276709648, 1.0388999036155615, 1.0393180913999964, 1.0481539048651431, 1.0560471576551955]
Training Loss (progress: 0.40), 0.11408520100967745, [0.0039682471093965, 0.0005836171372509279, 0.0015191189452122141, 0.006848486671003854, 0.00869655227963383, 0.028069752363783628], [1.0026752950647189, 1.0440192227272242, 1.0424928961444266, 1.0411142548089776, 1.0527888965332832, 1.0588725861153259]
Training Loss (progress: 0.48), 0.10939940331917171, [0.003590032847930683, 0.0005198462241022764, 0.0014689553537161697, 0.006398022264248532, 0.008398240481356702, 0.030115561035487185], [1.000372175507961, 1.0460362816607376, 1.0465580462429487, 1.0424646703110818, 1.0572626299270227, 1.0613892977836794]
Training Loss (progress: 0.56), 0.10559855709203848, [0.003341433325141847, 0.0005730458180880917, 0.0014105028043294165, 0.006453479579656898, 0.008196984421052095, 0.032217953928356996], [0.9981539888084893, 1.0489915235867406, 1.0493808451799056, 1.0437852418890274, 1.0613864314196233, 1.0636012670002912]
Training Loss (progress: 0.64), 0.09809141553361082, [0.00324199907253823, 0.000541037908066541, 0.0013144843824392416, 0.0065823767093351, 0.007901075962026823, 0.033710771597520665], [0.9953674359714145, 1.0508614231192681, 1.0518510819863784, 1.0451197883496448, 1.0656528920271713, 1.0652662113257656]
Training Loss (progress: 0.72), 0.0934401523675268, [0.003021191939797971, 0.0005475279324146884, 0.0014501773845414863, 0.00635281987155629, 0.007934553798076753, 0.035344731816222566], [0.9928605202022254, 1.052103369386549, 1.0554212549182738, 1.0463117732017173, 1.0704979600811233, 1.0669573465081486]
Training Loss (progress: 0.80), 0.09814174521930413, [0.0030689519818192933, 0.000549947680090644, 0.0014982817730775603, 0.006334863095254723, 0.007725245551960123, 0.03717959470456598], [0.9903323173397366, 1.053288794306927, 1.057215042281254, 1.047642515838644, 1.0743403619791705, 1.0687571225887094]
Training Loss (progress: 0.88), 0.08394885818291803, [0.0027456593959456466, 0.0005211145776424658, 0.001441979731751983, 0.00594350643816983, 0.007874881197030578, 0.038551505899006376], [0.9882720139170277, 1.0541433401622198, 1.0593147329504435, 1.0487054957268303, 1.077732269208107, 1.069913285550996]
Training Loss (progress: 0.96), 0.08544464582159421, [0.0028616793798173805, 0.0005171252470214309, 0.0014919195776413854, 0.005997275698431022, 0.0076409950682494975, 0.03918096981600554], [0.9849373751406959, 1.055209485638483, 1.061586688724502, 1.0501064827368356, 1.0812156344673554, 1.0709187573938654]
Evaluation on validation dataset:
Step 25, mean loss 0.07312041772397292
Step 50, mean loss 0.061142335056441385
Step 75, mean loss 0.06279149047575891
Step 100, mean loss 0.0711569475687904
Step 125, mean loss 0.0860135892656991
Step 150, mean loss 0.09250051876679954
Step 175, mean loss 0.10559820050270433
Step 200, mean loss 0.11952388667756247
Step 225, mean loss 0.14937318457358495
Unrolled forward losses 19.901683920378034
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.74079e-01, 1.09326e-03, 6.82276e-02, 5.90442e-01, 6.68861e-01, 9.78992e-01
Node: 01 (pos: 0.010): 4.05007e-01, 8.92521e-03, 1.57867e-01, 7.04113e-01, 7.75060e-01, 1.00657e+00
Node: 02 (pos: 0.020): 5.57461e-01, 4.97408e-02, 3.13602e-01, 8.13215e-01, 8.74376e-01, 1.02971e+00
Node: 03 (pos: 0.030): 7.14716e-01, 1.89238e-01, 5.34842e-01, 9.09630e-01, 9.60339e-01, 1.04808e+00
Node: 04 (pos: 0.040): 8.53529e-01, 4.91480e-01, 7.83124e-01, 9.85421e-01, 1.02687e+00, 1.06140e+00
Node: 05 (pos: 0.051): 9.49443e-01, 8.71373e-01, 9.84449e-01, 1.03389e+00, 1.06898e+00, 1.06947e+00
-
Node: 07 (pos: 0.071): 9.49443e-01, 8.71373e-01, 9.84449e-01, 1.03389e+00, 1.06898e+00, 1.06947e+00
Node: 08 (pos: 0.081): 8.53529e-01, 4.91480e-01, 7.83124e-01, 9.85421e-01, 1.02687e+00, 1.06140e+00
Node: 09 (pos: 0.091): 7.14716e-01, 1.89238e-01, 5.34842e-01, 9.09630e-01, 9.60339e-01, 1.04808e+00
Node: 10 (pos: 0.101): 5.57461e-01, 4.97408e-02, 3.13602e-01, 8.13215e-01, 8.74376e-01, 1.02971e+00
Node: 11 (pos: 0.111): 4.05007e-01, 8.92521e-03, 1.57867e-01, 7.04113e-01, 7.75060e-01, 1.00657e+00
Node: 12 (pos: 0.121): 2.74079e-01, 1.09326e-03, 6.82276e-02, 5.90442e-01, 6.68861e-01, 9.78992e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.49443e-01, 8.71373e-01, 9.84449e-01, 1.03389e+00, 1.06898e+00, 1.06947e+00
Node: 58 (pos: 0.586): 8.53529e-01, 4.91480e-01, 7.83124e-01, 9.85421e-01, 1.02687e+00, 1.06140e+00
Node: 59 (pos: 0.596): 7.14716e-01, 1.89238e-01, 5.34842e-01, 9.09630e-01, 9.60339e-01, 1.04808e+00
Node: 60 (pos: 0.606): 5.57461e-01, 4.97408e-02, 3.13602e-01, 8.13215e-01, 8.74376e-01, 1.02971e+00
Node: 61 (pos: 0.616): 4.05007e-01, 8.92521e-03, 1.57867e-01, 7.04113e-01, 7.75060e-01, 1.00657e+00
Node: 50 (pos: 0.505): 2.74079e-01, 1.09326e-03, 6.82276e-02, 5.90442e-01, 6.68861e-01, 9.78992e-01
-
Node: 51 (pos: 0.515): 4.05007e-01, 8.92521e-03, 1.57867e-01, 7.04113e-01, 7.75060e-01, 1.00657e+00
Node: 52 (pos: 0.525): 5.57461e-01, 4.97408e-02, 3.13602e-01, 8.13215e-01, 8.74376e-01, 1.02971e+00
Node: 53 (pos: 0.535): 7.14716e-01, 1.89238e-01, 5.34842e-01, 9.09630e-01, 9.60339e-01, 1.04808e+00
Node: 54 (pos: 0.545): 8.53529e-01, 4.91480e-01, 7.83124e-01, 9.85421e-01, 1.02687e+00, 1.06140e+00
Node: 55 (pos: 0.556): 9.49443e-01, 8.71373e-01, 9.84449e-01, 1.03389e+00, 1.06898e+00, 1.06947e+00
Node: 62 (pos: 0.626): 2.74079e-01, 1.09326e-03, 6.82276e-02, 5.90442e-01, 6.68861e-01, 9.78992e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.06677602060895696
Step 50, mean loss 0.059658472025223445
Step 75, mean loss 0.06975614122321214
Step 100, mean loss 0.08577927070890717
Step 125, mean loss 0.10312642900909152
Step 150, mean loss 0.14311102222021074
Step 175, mean loss 0.15866394118637422
Step 200, mean loss 0.1710035156126431
Step 225, mean loss 0.2120083425809905
Unrolled forward losses 16.9381231294008
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.19137041223198095, [0.0030685243497022225, 0.0005869668912664958, 0.0015286818435039846, 0.0064614805856321456, 0.007691179252475424, 0.040691984497670475], [0.9840384168144481, 1.054726054650484, 1.0623960640945125, 1.0504521543826733, 1.0834365054855108, 1.0722573428000324]
Training Loss (progress: 0.08), 0.19006539316377546, [0.0032171850357116715, 0.0006905509922124007, 0.0016871663372995424, 0.00822770321834074, 0.009833132965879277, 0.04573878139003432], [0.9820565637620683, 1.0535337190178613, 1.0615941359806682, 1.0527939217776703, 1.0867624387880275, 1.0749562259271779]
Training Loss (progress: 0.16), 0.18837225580104847, [0.003186431092539538, 0.0005734071988422154, 0.0014953699073289612, 0.008286183102088581, 0.011252637047682623, 0.050030748311126444], [0.979964087766112, 1.0525563031938157, 1.0633095147859115, 1.053814710080631, 1.0904308308346877, 1.0777432719992102]
Training Loss (progress: 0.24), 0.18868985332572136, [0.00394624422250113, 0.0006751152493057164, 0.0020916118754707525, 0.010127597296992795, 0.012327503772212072, 0.05409625104877498], [0.9791096474068867, 1.0516288792546653, 1.0655365430772235, 1.0563394039163672, 1.093527515828716, 1.0796089802320896]
Training Loss (progress: 0.32), 0.18233421607288552, [0.003648546969673677, 0.0005782954193105613, 0.0018325927299684662, 0.010869460243911036, 0.014119478331563368, 0.058390942213567255], [0.9771144950119053, 1.0503659762074309, 1.0648623185294084, 1.0568035850680801, 1.096238930756188, 1.081899003575329]
Training Loss (progress: 0.40), 0.16225084931563533, [0.0038472360710041687, 0.0006823556449610856, 0.0016570201506376629, 0.010672157099952955, 0.014475471323668058, 0.0612573739782925], [0.9751724011900297, 1.04904508549431, 1.0654962199926015, 1.0574731698649213, 1.0977870603682898, 1.0835127403708726]
Training Loss (progress: 0.48), 0.1767322101723766, [0.0038666019101060343, 0.0006768429884646654, 0.001987664959040669, 0.011659395660621148, 0.01589333989991654, 0.06495462293675802], [0.9733202333540857, 1.0476709490867564, 1.066649820352286, 1.0585654343420592, 1.101411876354957, 1.0852239745955985]
Training Loss (progress: 0.56), 0.14484471712887428, [0.0039466020376977395, 0.0007601285018493453, 0.0018506044131129979, 0.011278276495874689, 0.015697008819546162, 0.06763478218208496], [0.9719266431613846, 1.0467711015613599, 1.068089630984995, 1.0588550039720066, 1.1025567732431123, 1.0860760191454593]
Training Loss (progress: 0.64), 0.1865355458215952, [0.003883848485470939, 0.0006842496396475302, 0.0019063644298657587, 0.011963053264757783, 0.01721953145193581, 0.07127381928553951], [0.9695778759872465, 1.0451358981842898, 1.0690350038520384, 1.06027210545589, 1.1049407232422443, 1.087553424989284]
Training Loss (progress: 0.72), 0.1562533619599277, [0.003930925497692389, 0.0008688817969216832, 0.0020733398190757543, 0.012231242495046918, 0.01645847808474727, 0.0741083343221613], [0.9668846394533834, 1.043217418750569, 1.0703099237384828, 1.0613473396236215, 1.1057059688706408, 1.0886945422706102]
Training Loss (progress: 0.80), 0.16016221625248506, [0.0037837058102837408, 0.0008203586275176496, 0.0019642189351935383, 0.013090402075859276, 0.017174880613188635, 0.07699986705028629], [0.9655539308430576, 1.0422313612625642, 1.0706337504255368, 1.0626907717243097, 1.1074455247193442, 1.089848150334353]
Training Loss (progress: 0.88), 0.15853515967755025, [0.0038325356398744713, 0.0006468591223235817, 0.0019129839354883706, 0.013547155557559016, 0.018119234716386688, 0.07975207767207693], [0.9628624986138046, 1.039903150239791, 1.0711477777311211, 1.0633886526855467, 1.1097985488828883, 1.0910220271033308]
Training Loss (progress: 0.96), 0.14684806872448655, [0.00398439022251295, 0.0006836340550293157, 0.0017931081911546634, 0.01432766665914459, 0.018882901647073114, 0.08253744440731058], [0.9607968632255921, 1.0385818303406598, 1.0722814046547233, 1.0643502328481833, 1.1121917052383032, 1.0923604842295378]
Evaluation on validation dataset:
Step 25, mean loss 0.06864095668746849
Step 50, mean loss 0.035957302405878466
Step 75, mean loss 0.04254219844921766
Step 100, mean loss 0.05487930465154156
Step 125, mean loss 0.0652308264429167
Step 150, mean loss 0.08456554125719729
Step 175, mean loss 0.094666762663776
Step 200, mean loss 0.12285815199315984
Step 225, mean loss 0.14653779331664507
Unrolled forward losses 3.1442393859529956
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.04626e-01, 4.69187e-03, 1.46855e-01, 8.33168e-01, 9.19588e-01, 1.04603e+00
Node: 01 (pos: 0.010): 5.26997e-01, 2.44193e-02, 2.69625e-01, 8.98142e-01, 9.74812e-01, 1.06013e+00
Node: 02 (pos: 0.020): 6.54181e-01, 9.41607e-02, 4.43257e-01, 9.55054e-01, 1.02245e+00, 1.07181e+00
Node: 03 (pos: 0.030): 7.73969e-01, 2.69001e-01, 6.52490e-01, 1.00180e+00, 1.06111e+00, 1.08098e+00
Node: 04 (pos: 0.040): 8.72739e-01, 5.69356e-01, 8.60033e-01, 1.03659e+00, 1.08962e+00, 1.08758e+00
Node: 05 (pos: 0.051): 9.37953e-01, 8.92818e-01, 1.01503e+00, 1.05803e+00, 1.10708e+00, 1.09155e+00
-
Node: 07 (pos: 0.071): 9.37953e-01, 8.92818e-01, 1.01503e+00, 1.05803e+00, 1.10708e+00, 1.09155e+00
Node: 08 (pos: 0.081): 8.72739e-01, 5.69356e-01, 8.60033e-01, 1.03659e+00, 1.08962e+00, 1.08758e+00
Node: 09 (pos: 0.091): 7.73969e-01, 2.69001e-01, 6.52490e-01, 1.00180e+00, 1.06111e+00, 1.08098e+00
Node: 10 (pos: 0.101): 6.54181e-01, 9.41607e-02, 4.43257e-01, 9.55054e-01, 1.02245e+00, 1.07181e+00
Node: 11 (pos: 0.111): 5.26997e-01, 2.44193e-02, 2.69625e-01, 8.98142e-01, 9.74812e-01, 1.06013e+00
Node: 12 (pos: 0.121): 4.04626e-01, 4.69187e-03, 1.46855e-01, 8.33168e-01, 9.19588e-01, 1.04603e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.37953e-01, 8.92818e-01, 1.01503e+00, 1.05803e+00, 1.10708e+00, 1.09155e+00
Node: 58 (pos: 0.586): 8.72739e-01, 5.69356e-01, 8.60033e-01, 1.03659e+00, 1.08962e+00, 1.08758e+00
Node: 59 (pos: 0.596): 7.73969e-01, 2.69001e-01, 6.52490e-01, 1.00180e+00, 1.06111e+00, 1.08098e+00
Node: 60 (pos: 0.606): 6.54181e-01, 9.41607e-02, 4.43257e-01, 9.55054e-01, 1.02245e+00, 1.07181e+00
Node: 61 (pos: 0.616): 5.26997e-01, 2.44193e-02, 2.69625e-01, 8.98142e-01, 9.74812e-01, 1.06013e+00
Node: 50 (pos: 0.505): 4.04626e-01, 4.69187e-03, 1.46855e-01, 8.33168e-01, 9.19588e-01, 1.04603e+00
-
Node: 51 (pos: 0.515): 5.26997e-01, 2.44193e-02, 2.69625e-01, 8.98142e-01, 9.74812e-01, 1.06013e+00
Node: 52 (pos: 0.525): 6.54181e-01, 9.41607e-02, 4.43257e-01, 9.55054e-01, 1.02245e+00, 1.07181e+00
Node: 53 (pos: 0.535): 7.73969e-01, 2.69001e-01, 6.52490e-01, 1.00180e+00, 1.06111e+00, 1.08098e+00
Node: 54 (pos: 0.545): 8.72739e-01, 5.69356e-01, 8.60033e-01, 1.03659e+00, 1.08962e+00, 1.08758e+00
Node: 55 (pos: 0.556): 9.37953e-01, 8.92818e-01, 1.01503e+00, 1.05803e+00, 1.10708e+00, 1.09155e+00
Node: 62 (pos: 0.626): 4.04626e-01, 4.69187e-03, 1.46855e-01, 8.33168e-01, 9.19588e-01, 1.04603e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.06745834338002626
Step 50, mean loss 0.03750040969481404
Step 75, mean loss 0.045047992753704566
Step 100, mean loss 0.05912949183864981
Step 125, mean loss 0.0716305020086904
Step 150, mean loss 0.11103958073845963
Step 175, mean loss 0.12309293070926115
Step 200, mean loss 0.16305332836146458
Step 225, mean loss 0.18806958167982965
Unrolled forward losses 3.646391057506553
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.2332917644398384, [0.004208724249620041, 0.0007417193644592377, 0.0018460773018960683, 0.015041177352395426, 0.01918069949758867, 0.08399172061473545], [0.9606623549401354, 1.0373057440935394, 1.0727444231796852, 1.065222309179527, 1.1128734592247223, 1.0930240303608032]
Training Loss (progress: 0.08), 0.19087009608313826, [0.0040366846449725186, 0.0005979827093603971, 0.0018122265669354694, 0.015511601232775845, 0.020114366046035743, 0.0856907739478833], [0.960730526974689, 1.0366853042016915, 1.0737501430809062, 1.065871332049267, 1.1148640237049532, 1.0943747530389527]
Training Loss (progress: 0.16), 0.2109674363566487, [0.004036593284492036, 0.0006424648927321002, 0.002056686477673014, 0.016788246060667044, 0.020662930070523913, 0.08713997830903666], [0.9608283565201722, 1.036343066409997, 1.0746276662003544, 1.0677150341635977, 1.1161865532851252, 1.0953332695984594]
Training Loss (progress: 0.24), 0.17180112032779377, [0.0039632359818934735, 0.0006551284206770442, 0.0018282799884903882, 0.01723098444892997, 0.02064086448243972, 0.08858471118691083], [0.9606365439945417, 1.0354851052872662, 1.0751426874654628, 1.0688037437538198, 1.1172195019832962, 1.096316346589605]
Training Loss (progress: 0.32), 0.194799941642836, [0.0038999401591680908, 0.000714259532508481, 0.0019842440640781235, 0.017562573872915842, 0.02135240262588093, 0.08964231057443608], [0.9605087732341581, 1.0346849691146929, 1.0765684328514764, 1.0698505408421208, 1.1190837577303798, 1.0968385653321253]
Training Loss (progress: 0.40), 0.2114293134332445, [0.003972148202812426, 0.0006622239071268597, 0.00197418610735685, 0.018697742300891683, 0.02184939348297806, 0.09117968458423113], [0.9604148262552834, 1.0342081912574836, 1.0764009876495757, 1.0710896391682336, 1.1200138070595895, 1.0978223728842698]
Training Loss (progress: 0.48), 0.2147013419272527, [0.003993588087876397, 0.0006996704289713468, 0.0020088622414412578, 0.019217408620271315, 0.022651546824196227, 0.09250036149782537], [0.9603898833171947, 1.0338997537511838, 1.0776764195335973, 1.0724281723128524, 1.1214472873151637, 1.0984831186202246]
Training Loss (progress: 0.56), 0.18091187087302918, [0.003949690893247676, 0.0006571078747822259, 0.002063140830212668, 0.02052039193029451, 0.02314715621352272, 0.09328166883789547], [0.960285780310338, 1.0331525743982986, 1.078208850194149, 1.0739073863787594, 1.1227905564997953, 1.0988940640653793]
Training Loss (progress: 0.64), 0.20872591275687705, [0.003849190916206809, 0.0006309306823304771, 0.0018675861641425104, 0.02082455227803669, 0.023547299080020935, 0.09448773936655014], [0.9599287441537036, 1.0326662440165557, 1.0790542913398207, 1.07457447091258, 1.124206859146317, 1.0995889983785816]
Training Loss (progress: 0.72), 0.17056262330767516, [0.0037929658857237974, 0.0007298414389202422, 0.001872274342574566, 0.02169536786125745, 0.023826805659574322, 0.09527253503268876], [0.9600318466353291, 1.0320086020534676, 1.0802056312906514, 1.0760421172867451, 1.125242099449313, 1.0998833340097365]
Training Loss (progress: 0.80), 0.1978000911016028, [0.003853630561442895, 0.0008386314576227758, 0.00199644236796405, 0.022723899270269538, 0.02445244305055012, 0.09655651002339652], [0.9598862878092297, 1.0316768325554584, 1.0811327002535513, 1.0775630714139512, 1.126764871610378, 1.1008398221587565]
Training Loss (progress: 0.88), 0.19789198113778986, [0.003966611895393086, 0.0006956211779896615, 0.0019412770294469498, 0.023117102256237698, 0.024870590054794892, 0.09727910880714569], [0.9594786712929384, 1.0308242754530321, 1.081855438255893, 1.0786871864275245, 1.1277849494456056, 1.1010931152047119]
Training Loss (progress: 0.96), 0.18942312961091373, [0.003682997222798724, 0.0007367508882226313, 0.0019515595131081298, 0.024260733910498673, 0.025299262379226903, 0.09788605394500603], [0.9591018631384034, 1.0300775924941812, 1.0824508627195488, 1.0801482190579683, 1.1288745679854202, 1.1013447528053362]
Evaluation on validation dataset:
Step 25, mean loss 0.06604692604973375
Step 50, mean loss 0.023770970004527287
Step 75, mean loss 0.030293411549000324
Step 100, mean loss 0.036446348767384715
Step 125, mean loss 0.04777639591486808
Step 150, mean loss 0.054842399486489446
Step 175, mean loss 0.07446794108080257
Step 200, mean loss 0.09640815619112685
Step 225, mean loss 0.11882582781101207
Unrolled forward losses 2.329321136362136
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.60876e-01, 7.26517e-03, 1.60272e-01, 9.26781e-01, 9.78392e-01, 1.06075e+00
Node: 01 (pos: 0.010): 4.86485e-01, 3.30115e-02, 2.87281e-01, 9.71139e-01, 1.02225e+00, 1.07296e+00
Node: 02 (pos: 0.020): 6.21151e-01, 1.13908e-01, 4.63102e-01, 1.00901e+00, 1.05959e+00, 1.08305e+00
Node: 03 (pos: 0.030): 7.51175e-01, 2.98478e-01, 6.71372e-01, 1.03948e+00, 1.08957e+00, 1.09097e+00
Node: 04 (pos: 0.040): 8.60402e-01, 5.93935e-01, 8.75323e-01, 1.06180e+00, 1.11151e+00, 1.09665e+00
Node: 05 (pos: 0.051): 9.33420e-01, 8.97502e-01, 1.02634e+00, 1.07543e+00, 1.12488e+00, 1.10008e+00
-
Node: 07 (pos: 0.071): 9.33420e-01, 8.97502e-01, 1.02634e+00, 1.07543e+00, 1.12488e+00, 1.10008e+00
Node: 08 (pos: 0.081): 8.60402e-01, 5.93935e-01, 8.75323e-01, 1.06180e+00, 1.11151e+00, 1.09665e+00
Node: 09 (pos: 0.091): 7.51175e-01, 2.98478e-01, 6.71372e-01, 1.03948e+00, 1.08957e+00, 1.09097e+00
Node: 10 (pos: 0.101): 6.21151e-01, 1.13908e-01, 4.63102e-01, 1.00901e+00, 1.05959e+00, 1.08305e+00
Node: 11 (pos: 0.111): 4.86485e-01, 3.30115e-02, 2.87281e-01, 9.71139e-01, 1.02225e+00, 1.07296e+00
Node: 12 (pos: 0.121): 3.60876e-01, 7.26517e-03, 1.60272e-01, 9.26781e-01, 9.78392e-01, 1.06075e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.33420e-01, 8.97502e-01, 1.02634e+00, 1.07543e+00, 1.12488e+00, 1.10008e+00
Node: 58 (pos: 0.586): 8.60402e-01, 5.93935e-01, 8.75323e-01, 1.06180e+00, 1.11151e+00, 1.09665e+00
Node: 59 (pos: 0.596): 7.51175e-01, 2.98478e-01, 6.71372e-01, 1.03948e+00, 1.08957e+00, 1.09097e+00
Node: 60 (pos: 0.606): 6.21151e-01, 1.13908e-01, 4.63102e-01, 1.00901e+00, 1.05959e+00, 1.08305e+00
Node: 61 (pos: 0.616): 4.86485e-01, 3.30115e-02, 2.87281e-01, 9.71139e-01, 1.02225e+00, 1.07296e+00
Node: 50 (pos: 0.505): 3.60876e-01, 7.26517e-03, 1.60272e-01, 9.26781e-01, 9.78392e-01, 1.06075e+00
-
Node: 51 (pos: 0.515): 4.86485e-01, 3.30115e-02, 2.87281e-01, 9.71139e-01, 1.02225e+00, 1.07296e+00
Node: 52 (pos: 0.525): 6.21151e-01, 1.13908e-01, 4.63102e-01, 1.00901e+00, 1.05959e+00, 1.08305e+00
Node: 53 (pos: 0.535): 7.51175e-01, 2.98478e-01, 6.71372e-01, 1.03948e+00, 1.08957e+00, 1.09097e+00
Node: 54 (pos: 0.545): 8.60402e-01, 5.93935e-01, 8.75323e-01, 1.06180e+00, 1.11151e+00, 1.09665e+00
Node: 55 (pos: 0.556): 9.33420e-01, 8.97502e-01, 1.02634e+00, 1.07543e+00, 1.12488e+00, 1.10008e+00
Node: 62 (pos: 0.626): 3.60876e-01, 7.26517e-03, 1.60272e-01, 9.26781e-01, 9.78392e-01, 1.06075e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.061055167600277085
Step 50, mean loss 0.025478416233465445
Step 75, mean loss 0.03290187986874318
Step 100, mean loss 0.04291205831858526
Step 125, mean loss 0.04934160857279002
Step 150, mean loss 0.0879550146246306
Step 175, mean loss 0.09813132804256422
Step 200, mean loss 0.11926513976970338
Step 225, mean loss 0.14111831701053196
Unrolled forward losses 2.58496542531425
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.17044260632845432, [0.0038376734454579177, 0.0006910648814400815, 0.0018863663858367332, 0.024430781099884002, 0.025584361940878816, 0.09836606127069107], [0.9590438955277141, 1.0299113663271333, 1.082349941768092, 1.0805218836497248, 1.129422217686455, 1.101491736349967]
Training Loss (progress: 0.08), 0.18366198953888244, [0.0036835982539280086, 0.0006527038604921649, 0.0018740097143492682, 0.02483197023722588, 0.026055172367506867, 0.09917347716942299], [0.9586010993650182, 1.0290396945011921, 1.0837728020884927, 1.0812808141720547, 1.1308927039659429, 1.1017608193685822]
Training Loss (progress: 0.16), 0.1810051169353921, [0.003705672464051542, 0.0007238750448645132, 0.0019936061581440428, 0.025624596547037776, 0.02632333801894715, 0.09980645429296144], [0.95818781113921, 1.0284329694367214, 1.0840967975633655, 1.0826545793284783, 1.1317485622193917, 1.102008536207885]
Training Loss (progress: 0.24), 0.18324050294352623, [0.0037243705830194676, 0.0007281126402689872, 0.0020116236273174026, 0.02669180496312998, 0.026687877904280108, 0.10047896714969215], [0.9581399032844327, 1.0280027558172065, 1.084714252049965, 1.0844370463749673, 1.1329443136173103, 1.1023400870639257]
Training Loss (progress: 0.32), 0.16981140050227472, [0.003927440470730946, 0.0008694388959661885, 0.0019900908910506967, 0.027472642684245454, 0.026914664462981498, 0.10134330631796311], [0.9576346799009452, 1.0276736191609095, 1.0851012252849939, 1.085490777224181, 1.1339046127103902, 1.102745010796612]
Training Loss (progress: 0.40), 0.16163116449192688, [0.0037015312556987565, 0.0007637117722589848, 0.002022763879962129, 0.02821852123895117, 0.027830496758571566, 0.10187205685666954], [0.9569004703452597, 1.0267574993125863, 1.0853469876422612, 1.0865070964963999, 1.135116659200949, 1.1028844795616508]
Training Loss (progress: 0.48), 0.16269991747409498, [0.0038001117796754727, 0.0007169049507691986, 0.001863348739301095, 0.02936412634750576, 0.02752350842949949, 0.10294225040298807], [0.9565235227634079, 1.0261301379448258, 1.0861639977668325, 1.0880957882561593, 1.13598649281751, 1.1035839642567062]
Training Loss (progress: 0.56), 0.1838746767442661, [0.003609159953764014, 0.0007177858326487375, 0.0019378820919217447, 0.030092679405479716, 0.02823237767107585, 0.10339757994104444], [0.9561538958487353, 1.025636927686123, 1.0871320113378673, 1.0892105473960763, 1.1372465440754351, 1.1037501957687932]
Training Loss (progress: 0.64), 0.1773075283683329, [0.0037657792685246248, 0.0007560195095107096, 0.001970627326287639, 0.031127833517855672, 0.028925574516987945, 0.10422120522105212], [0.9556852506968561, 1.025275885294088, 1.08691863962773, 1.0906623200089973, 1.138359533064006, 1.1041881333662982]
Training Loss (progress: 0.72), 0.17284143755774556, [0.0037678961550735215, 0.0007183319308560896, 0.002042027638760551, 0.03153131859338589, 0.029433027508912326, 0.10481036716177015], [0.9553458936214001, 1.024483397355511, 1.0877459647322854, 1.0911406520683193, 1.1398102836675772, 1.1044314660844874]
Training Loss (progress: 0.80), 0.144197355239802, [0.003637812961072235, 0.0008004825582870982, 0.002039495680381936, 0.03227493629291572, 0.029276727170003094, 0.10537386457772355], [0.9548473802244763, 1.0236257834088365, 1.0879892868249696, 1.0922903996219329, 1.1401395161183279, 1.1044931204781612]
Training Loss (progress: 0.88), 0.15620133869143088, [0.0037732463960139045, 0.0007968972617810933, 0.001964781910951334, 0.03344260978735178, 0.029942522675509425, 0.1060917604342372], [0.9541741514451088, 1.0233464888235608, 1.088695584713292, 1.093454643623811, 1.1418754321299371, 1.1049651915473966]
Training Loss (progress: 0.96), 0.1419551672617215, [0.0035619530277517307, 0.0007102877331547718, 0.0019017687891304666, 0.033904365545840996, 0.029993058209873864, 0.10664745503281019], [0.9537504599618177, 1.022714364560882, 1.0893898415373553, 1.0946381826687648, 1.1426618688116341, 1.1050106148818775]
Evaluation on validation dataset:
Step 25, mean loss 0.054452584015594746
Step 50, mean loss 0.018934291244482142
Step 75, mean loss 0.023671966913526882
Step 100, mean loss 0.029632897679708944
Step 125, mean loss 0.0401957078070078
Step 150, mean loss 0.04545191228305867
Step 175, mean loss 0.055263764729847946
Step 200, mean loss 0.07078191379968321
Step 225, mean loss 0.08923558158111625
Unrolled forward losses 1.770836873984893
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.58806e-01, 4.74821e-03, 1.64463e-01, 9.82557e-01, 1.01300e+00, 1.06793e+00
Node: 01 (pos: 0.010): 4.83715e-01, 2.45149e-02, 2.93064e-01, 1.01557e+00, 1.05119e+00, 1.07920e+00
Node: 02 (pos: 0.020): 6.17635e-01, 9.39104e-02, 4.70154e-01, 1.04341e+00, 1.08350e+00, 1.08851e+00
Node: 03 (pos: 0.030): 7.46943e-01, 2.66918e-01, 6.79047e-01, 1.06558e+00, 1.10932e+00, 1.09581e+00
Node: 04 (pos: 0.040): 8.55570e-01, 5.62890e-01, 8.82964e-01, 1.08171e+00, 1.12814e+00, 1.10105e+00
Node: 05 (pos: 0.051): 9.28189e-01, 8.80748e-01, 1.03364e+00, 1.09151e+00, 1.13958e+00, 1.10421e+00
-
Node: 07 (pos: 0.071): 9.28189e-01, 8.80748e-01, 1.03364e+00, 1.09151e+00, 1.13958e+00, 1.10421e+00
Node: 08 (pos: 0.081): 8.55570e-01, 5.62890e-01, 8.82964e-01, 1.08171e+00, 1.12814e+00, 1.10105e+00
Node: 09 (pos: 0.091): 7.46943e-01, 2.66918e-01, 6.79047e-01, 1.06558e+00, 1.10932e+00, 1.09581e+00
Node: 10 (pos: 0.101): 6.17635e-01, 9.39104e-02, 4.70154e-01, 1.04341e+00, 1.08350e+00, 1.08851e+00
Node: 11 (pos: 0.111): 4.83715e-01, 2.45149e-02, 2.93064e-01, 1.01557e+00, 1.05119e+00, 1.07920e+00
Node: 12 (pos: 0.121): 3.58806e-01, 4.74821e-03, 1.64463e-01, 9.82557e-01, 1.01300e+00, 1.06793e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.28189e-01, 8.80748e-01, 1.03364e+00, 1.09151e+00, 1.13958e+00, 1.10421e+00
Node: 58 (pos: 0.586): 8.55570e-01, 5.62890e-01, 8.82964e-01, 1.08171e+00, 1.12814e+00, 1.10105e+00
Node: 59 (pos: 0.596): 7.46943e-01, 2.66918e-01, 6.79047e-01, 1.06558e+00, 1.10932e+00, 1.09581e+00
Node: 60 (pos: 0.606): 6.17635e-01, 9.39104e-02, 4.70154e-01, 1.04341e+00, 1.08350e+00, 1.08851e+00
Node: 61 (pos: 0.616): 4.83715e-01, 2.45149e-02, 2.93064e-01, 1.01557e+00, 1.05119e+00, 1.07920e+00
Node: 50 (pos: 0.505): 3.58806e-01, 4.74821e-03, 1.64463e-01, 9.82557e-01, 1.01300e+00, 1.06793e+00
-
Node: 51 (pos: 0.515): 4.83715e-01, 2.45149e-02, 2.93064e-01, 1.01557e+00, 1.05119e+00, 1.07920e+00
Node: 52 (pos: 0.525): 6.17635e-01, 9.39104e-02, 4.70154e-01, 1.04341e+00, 1.08350e+00, 1.08851e+00
Node: 53 (pos: 0.535): 7.46943e-01, 2.66918e-01, 6.79047e-01, 1.06558e+00, 1.10932e+00, 1.09581e+00
Node: 54 (pos: 0.545): 8.55570e-01, 5.62890e-01, 8.82964e-01, 1.08171e+00, 1.12814e+00, 1.10105e+00
Node: 55 (pos: 0.556): 9.28189e-01, 8.80748e-01, 1.03364e+00, 1.09151e+00, 1.13958e+00, 1.10421e+00
Node: 62 (pos: 0.626): 3.58806e-01, 4.74821e-03, 1.64463e-01, 9.82557e-01, 1.01300e+00, 1.06793e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.0504073471107783
Step 50, mean loss 0.01898657544901826
Step 75, mean loss 0.02299973960440869
Step 100, mean loss 0.032256120547225375
Step 125, mean loss 0.036506550270832626
Step 150, mean loss 0.0627314361180003
Step 175, mean loss 0.07242423619023768
Step 200, mean loss 0.09305955794239479
Step 225, mean loss 0.11932150626612545
Unrolled forward losses 1.9424920985074197
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.1651138075138184, [0.0036736311758250517, 0.0006329085424131476, 0.0019105498276976017, 0.034188984044206006, 0.030111448278699264, 0.10714757318878824], [0.9535761914503311, 1.0226031756597147, 1.0897258701632102, 1.0949456007618286, 1.1434498733855112, 1.1054785139573695]
Training Loss (progress: 0.08), 0.151821430451875, [0.0036056576622439905, 0.0007561966636324025, 0.0019263288088279093, 0.03502962311503044, 0.03037111252158903, 0.10762947861875423], [0.953172910926415, 1.0223999416528633, 1.0902225340933012, 1.0963980140870753, 1.144574495870158, 1.1056688466046416]
Training Loss (progress: 0.16), 0.1498483186835301, [0.0037236617388684136, 0.0007527418793723071, 0.0019946141235579035, 0.035488174407161656, 0.03082688683755917, 0.10827087075312393], [0.9528617370071253, 1.0219197976271592, 1.0907256113621506, 1.0971436193685085, 1.145649145803276, 1.1058740068473858]
Training Loss (progress: 0.24), 0.16820273089289572, [0.003561859127143056, 0.0008036723790362485, 0.0019437026243815196, 0.03641418491196034, 0.030985770427263675, 0.10842755278956102], [0.9520315344783523, 1.0208739050667437, 1.0906921000880305, 1.0980820365033377, 1.1464286435352211, 1.1059093579643273]
Training Loss (progress: 0.32), 0.16762825357377428, [0.0036283822978565683, 0.0007874998560224468, 0.0018980177481100083, 0.03748521608013507, 0.03159064625160623, 0.10907328733313679], [0.9517019566130044, 1.0201029425687094, 1.0907670376791205, 1.0993238582089477, 1.1475072240246853, 1.1060404075670405]
Training Loss (progress: 0.40), 0.16556877884050183, [0.0035824131316172644, 0.0007764572809517568, 0.001952149363023802, 0.038452083913642944, 0.03200693390953974, 0.109734997255526], [0.9512462028044887, 1.0195532404434164, 1.0918193438027295, 1.100624173534104, 1.148756024381175, 1.1062232596087962]
Training Loss (progress: 0.48), 0.16472087447438077, [0.003618675200131468, 0.0007472799250274368, 0.002004697689089972, 0.039485541979791046, 0.032805739201593284, 0.11074599638211557], [0.9506590810677698, 1.019124112607826, 1.0919642664614302, 1.1019289717981937, 1.1502395560010346, 1.1067877863522837]
Training Loss (progress: 0.56), 0.17374975444018043, [0.003557735519267679, 0.0006993601241993989, 0.0020006329109006453, 0.04061333370913093, 0.03276409449017432, 0.11115342355223251], [0.9499660967503336, 1.0181987777296515, 1.0921311023659301, 1.103686290636737, 1.1508029665620625, 1.10685472549328]
Training Loss (progress: 0.64), 0.15211516261471297, [0.003625487897377577, 0.0008532201533881302, 0.001977003876973256, 0.04154572839717745, 0.03320173246671413, 0.11159307207873126], [0.9492908583426036, 1.0174756454942577, 1.092326084336748, 1.1049215968066264, 1.1515580345363907, 1.1069598990550793]
Training Loss (progress: 0.72), 0.1517505903334476, [0.003787956354394775, 0.0007084771604401007, 0.001942012663868387, 0.04202192610941077, 0.033699334247030026, 0.11219435588891331], [0.9486464827983664, 1.0172581270136427, 1.092414613871872, 1.105567004597012, 1.1524400919599265, 1.106955101056676]
Training Loss (progress: 0.80), 0.15849965342299502, [0.0037255099924643504, 0.0006411715216461223, 0.001985719280321421, 0.0429979400431383, 0.0340118130181856, 0.11265450456944893], [0.948399610761917, 1.0163105545349778, 1.092496452777676, 1.106801015161418, 1.1535294065564743, 1.1071667226527946]
Training Loss (progress: 0.88), 0.15768327683433933, [0.003482500406746139, 0.0007776713163619716, 0.001990684950728093, 0.04349978441815695, 0.03397168194766393, 0.1129439232132705], [0.9477732428592376, 1.0161244591491678, 1.0928370387467599, 1.1073544518675429, 1.1541232806522816, 1.1072666650900118]
Training Loss (progress: 0.96), 0.1658240207193916, [0.0036605687293249038, 0.0006499753957595102, 0.0018996073426621471, 0.044840455326292675, 0.03417188476018426, 0.11349129489109089], [0.9473540973677477, 1.0156344249262081, 1.0927444631382544, 1.1086900908173873, 1.1549458464499156, 1.1073991752201018]
Evaluation on validation dataset:
Step 25, mean loss 0.043619698665663204
Step 50, mean loss 0.016959135614087344
Step 75, mean loss 0.02318774100987473
Step 100, mean loss 0.03456089091728132
Step 125, mean loss 0.044454761121488065
Step 150, mean loss 0.05288096730382198
Step 175, mean loss 0.06267446331979862
Step 200, mean loss 0.07307026803988179
Step 225, mean loss 0.09207205911188573
Unrolled forward losses 1.843273709443827
Unrolled forward base losses 1.1720234445357585
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.124197492830405, [0.0035887643548688074, 0.0006960406642152144, 0.0019557660203756164, 0.04535895423211644, 0.034074629762768004, 0.11358501723720758], [0.9470293907893269, 1.0151499622150317, 1.092718758868142, 1.109366108712167, 1.1550994640632315, 1.1073868063517278]
Training Loss (progress: 0.08), 0.12273700520342755, [0.0035917383675107373, 0.0007508174373525871, 0.0019161374087078977, 0.045909206489450016, 0.034502056942986845, 0.1139530854868385], [0.9471487538702775, 1.0149000648477147, 1.0932903598740245, 1.1101117844308668, 1.1562657928614124, 1.1077743199254855]
Training Loss (progress: 0.16), 0.12189771782271755, [0.003538249120027199, 0.0007440462284868517, 0.001932224787788761, 0.04620110383014785, 0.034818473427113895, 0.1143724350244894], [0.9471373856006223, 1.0147050465935021, 1.0936877183729983, 1.1109326169474307, 1.157005993859748, 1.1082438472987064]
Training Loss (progress: 0.24), 0.12217804579842008, [0.0034928943103574076, 0.0007526748450526637, 0.0019508525142905655, 0.046824130015636053, 0.0352532304472508, 0.11462018830361093], [0.9469724879505855, 1.0145576490136954, 1.094096458883922, 1.1118321902364008, 1.1579883571393677, 1.1086593729016307]
Training Loss (progress: 0.32), 0.13360668414044646, [0.003528584640258094, 0.0007183545519739507, 0.0019387872190872874, 0.047369291323942346, 0.035378485128442896, 0.11489571556779901], [0.946962212802327, 1.0143914875169007, 1.0943146127017496, 1.1126747986405412, 1.158600374847075, 1.1089613517385901]
Training Loss (progress: 0.40), 0.13108649707394707, [0.0035830550208101933, 0.0007744932060924816, 0.0019974003102743608, 0.04799383413479621, 0.03578002762662449, 0.11509892337920098], [0.9470099903165718, 1.0142442611483038, 1.0945450868092408, 1.1133349781126738, 1.1593529643519427, 1.1090853885456717]
Training Loss (progress: 0.48), 0.13365490335660363, [0.0035481651808022107, 0.0007385541777280842, 0.0019770763032328836, 0.04868584350423746, 0.035847435131900446, 0.1153808923315353], [0.9469407471679684, 1.0138977882968896, 1.0948070712162254, 1.1144265704234255, 1.1600697682972723, 1.109441308258105]
Training Loss (progress: 0.56), 0.12360133939627566, [0.0035211083023616078, 0.0007549930571142576, 0.0019362821529023983, 0.04932240620286239, 0.03625368072415565, 0.11555248895032505], [0.946775341630441, 1.0137454312512346, 1.095167588089263, 1.1151689078853597, 1.1607506716322709, 1.1097026200340747]
Training Loss (progress: 0.64), 0.13490761049063218, [0.003498472437515871, 0.0008051196172994018, 0.0020200690130016334, 0.049642561612199515, 0.036562818287932564, 0.11572395073718642], [0.9467978779753968, 1.0135146534208914, 1.0956399424639365, 1.1160128092384527, 1.1616340932001943, 1.1098138971792382]
Training Loss (progress: 0.72), 0.13895813082166755, [0.003407990667825773, 0.0007353429056407671, 0.0019306783810718407, 0.05007197936460971, 0.036576586945849046, 0.11593404826657418], [0.9466073201618624, 1.0133742012971427, 1.0958040095450179, 1.1166395515533707, 1.1621109634208262, 1.1100248852128831]
Training Loss (progress: 0.80), 0.12805345090289452, [0.003482653957130546, 0.0007460450367696549, 0.0019757033864978004, 0.050533912517916384, 0.03663612099820424, 0.11609995096513569], [0.9465844121401716, 1.0132086250171037, 1.0962956653061415, 1.1173610381852834, 1.1627383287204807, 1.110241813554766]
Training Loss (progress: 0.88), 0.13429368287243323, [0.003515358891254218, 0.0007534995883813223, 0.0019538157149450366, 0.05114308519574079, 0.03734716379760427, 0.11628244836847436], [0.9464859168904289, 1.0129932739922518, 1.0963974784434098, 1.1182033000654006, 1.163750564942905, 1.110481399891124]
Training Loss (progress: 0.96), 0.12664156988667474, [0.003510300788236456, 0.0007584772617712952, 0.0019792599006158546, 0.05177222276424178, 0.037264577333030964, 0.11647230529339826], [0.9463965173085362, 1.0128516777891656, 1.0966029129668697, 1.1190173271154422, 1.1640576928986666, 1.110572379303029]
Evaluation on validation dataset:
Step 25, mean loss 0.031987637414722284
Step 50, mean loss 0.0125804993701741
Step 75, mean loss 0.017786046332613673
Step 100, mean loss 0.02377894204148491
Step 125, mean loss 0.03166723583254384
Step 150, mean loss 0.039806899157333556
Step 175, mean loss 0.04936358935433218
Step 200, mean loss 0.06261762217102015
Step 225, mean loss 0.08033691101511248
Unrolled forward losses 1.57433885711447
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.30079e-01, 7.97854e-03, 1.69955e-01, 1.04264e+00, 1.05546e+00, 1.07619e+00
Node: 01 (pos: 0.010): 4.55392e-01, 3.50497e-02, 3.00439e-01, 1.06546e+00, 1.08761e+00, 1.08660e+00
Node: 02 (pos: 0.020): 5.92573e-01, 1.17647e-01, 4.78842e-01, 1.08450e+00, 1.11464e+00, 1.09520e+00
Node: 03 (pos: 0.030): 7.27252e-01, 3.01725e-01, 6.88084e-01, 1.09954e+00, 1.13613e+00, 1.10193e+00
Node: 04 (pos: 0.040): 8.41814e-01, 5.91256e-01, 8.91468e-01, 1.11041e+00, 1.15173e+00, 1.10676e+00
Node: 05 (pos: 0.051): 9.19041e-01, 8.85266e-01, 1.04132e+00, 1.11699e+00, 1.16119e+00, 1.10967e+00
-
Node: 07 (pos: 0.071): 9.19041e-01, 8.85266e-01, 1.04132e+00, 1.11699e+00, 1.16119e+00, 1.10967e+00
Node: 08 (pos: 0.081): 8.41814e-01, 5.91256e-01, 8.91468e-01, 1.11041e+00, 1.15173e+00, 1.10676e+00
Node: 09 (pos: 0.091): 7.27252e-01, 3.01725e-01, 6.88084e-01, 1.09954e+00, 1.13613e+00, 1.10193e+00
Node: 10 (pos: 0.101): 5.92573e-01, 1.17647e-01, 4.78842e-01, 1.08450e+00, 1.11464e+00, 1.09520e+00
Node: 11 (pos: 0.111): 4.55392e-01, 3.50497e-02, 3.00439e-01, 1.06546e+00, 1.08761e+00, 1.08660e+00
Node: 12 (pos: 0.121): 3.30079e-01, 7.97854e-03, 1.69955e-01, 1.04264e+00, 1.05546e+00, 1.07619e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.19041e-01, 8.85266e-01, 1.04132e+00, 1.11699e+00, 1.16119e+00, 1.10967e+00
Node: 58 (pos: 0.586): 8.41814e-01, 5.91256e-01, 8.91468e-01, 1.11041e+00, 1.15173e+00, 1.10676e+00
Node: 59 (pos: 0.596): 7.27252e-01, 3.01725e-01, 6.88084e-01, 1.09954e+00, 1.13613e+00, 1.10193e+00
Node: 60 (pos: 0.606): 5.92573e-01, 1.17647e-01, 4.78842e-01, 1.08450e+00, 1.11464e+00, 1.09520e+00
Node: 61 (pos: 0.616): 4.55392e-01, 3.50497e-02, 3.00439e-01, 1.06546e+00, 1.08761e+00, 1.08660e+00
Node: 50 (pos: 0.505): 3.30079e-01, 7.97854e-03, 1.69955e-01, 1.04264e+00, 1.05546e+00, 1.07619e+00
-
Node: 51 (pos: 0.515): 4.55392e-01, 3.50497e-02, 3.00439e-01, 1.06546e+00, 1.08761e+00, 1.08660e+00
Node: 52 (pos: 0.525): 5.92573e-01, 1.17647e-01, 4.78842e-01, 1.08450e+00, 1.11464e+00, 1.09520e+00
Node: 53 (pos: 0.535): 7.27252e-01, 3.01725e-01, 6.88084e-01, 1.09954e+00, 1.13613e+00, 1.10193e+00
Node: 54 (pos: 0.545): 8.41814e-01, 5.91256e-01, 8.91468e-01, 1.11041e+00, 1.15173e+00, 1.10676e+00
Node: 55 (pos: 0.556): 9.19041e-01, 8.85266e-01, 1.04132e+00, 1.11699e+00, 1.16119e+00, 1.10967e+00
Node: 62 (pos: 0.626): 3.30079e-01, 7.97854e-03, 1.69955e-01, 1.04264e+00, 1.05546e+00, 1.07619e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.03048566249582349
Step 50, mean loss 0.01345656277034227
Step 75, mean loss 0.01661072679220901
Step 100, mean loss 0.024889597855872275
Step 125, mean loss 0.02992040753950984
Step 150, mean loss 0.05329420930776108
Step 175, mean loss 0.06500080242895788
Step 200, mean loss 0.07622582094307487
Step 225, mean loss 0.10658658482443939
Unrolled forward losses 1.7387311999735038
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.13113793256134593, [0.003484794410040151, 0.000755943434340061, 0.0020033176086225093, 0.05188311830280665, 0.037384765488691934, 0.11657917997955711], [0.9462959199616048, 1.0127951537689819, 1.096714398228241, 1.1192966187043303, 1.1643300229207405, 1.110647423198597]
Training Loss (progress: 0.08), 0.13156453127791215, [0.003544597281505203, 0.0008011367254003645, 0.0019953065065065156, 0.05241563399719137, 0.037639306400998246, 0.1167523331689469], [0.946223905104176, 1.0125292921351887, 1.0968024675498962, 1.1199778018752353, 1.1649336001670758, 1.1108806394146031]
Training Loss (progress: 0.16), 0.13639433810699875, [0.003498966294615371, 0.0007491235890384183, 0.0019655872811148744, 0.052770090769490935, 0.03783934486400533, 0.11694687251085431], [0.9461876891797639, 1.0123276086650177, 1.0972035022840947, 1.120498804450741, 1.1654737344509307, 1.1110323150360406]
Training Loss (progress: 0.24), 0.12934569415501349, [0.0034517285301034813, 0.0007592075188292033, 0.0019986824702709124, 0.053330372400609824, 0.03826229433109875, 0.11728844876360002], [0.9460562991448048, 1.0120462628795528, 1.097351816859608, 1.1213008483458338, 1.1663759230158555, 1.1112920668655673]
Training Loss (progress: 0.32), 0.11963444144085918, [0.003415272936776641, 0.0007511742766231485, 0.0019841183695460496, 0.05376375399871814, 0.0385197162139496, 0.11750265098857383], [0.9460062776786132, 1.0118347718420542, 1.0974224779372013, 1.1219171207183725, 1.1669951715365245, 1.1114159818508877]
Training Loss (progress: 0.40), 0.13348346302934852, [0.0034442351631098892, 0.0007545048211786224, 0.00197611556784208, 0.05437767768422404, 0.038629587183952235, 0.11770894399011646], [0.9458513739236181, 1.0116504870572829, 1.0978082529626927, 1.1226380858134126, 1.16732869159039, 1.1115885255837656]
Training Loss (progress: 0.48), 0.12515435612043233, [0.003450047305957704, 0.0008186027069308861, 0.001982868545203863, 0.05474780664576364, 0.03848978135429353, 0.11784625378619683], [0.9456990881491748, 1.0114826246417445, 1.098014789975748, 1.123367201675773, 1.167810252842323, 1.111708952379165]
Training Loss (progress: 0.56), 0.1362125038693681, [0.0035198080130062004, 0.0007815652829109594, 0.0020339340048442203, 0.055096511424543006, 0.03895485788162241, 0.11805779404785213], [0.9457191550068941, 1.0111622692586835, 1.0981558698128162, 1.1240161419837074, 1.168725101232017, 1.1118787293144545]
Training Loss (progress: 0.64), 0.11891073986509985, [0.003401157324085527, 0.0007346020018913343, 0.001994415088525479, 0.055758888554865965, 0.03944675523901, 0.11825775518711262], [0.9456091404823109, 1.0109605283207654, 1.0983850330284426, 1.124854084619602, 1.1694184047710197, 1.1120447116663983]
Training Loss (progress: 0.72), 0.12217979975441062, [0.0033851179498612014, 0.0007954872249790781, 0.001969791533445283, 0.05632152548089833, 0.039789570778181904, 0.11834633725642961], [0.9455708503389854, 1.010960710832111, 1.0987763022936559, 1.1256465469154573, 1.17030084377526, 1.1121043191833913]
Training Loss (progress: 0.80), 0.12798363766852242, [0.003363747472935235, 0.0007737230433441536, 0.0019555289010259815, 0.05678115570791748, 0.039995250224060405, 0.11850085250793038], [0.9454165253861597, 1.0106893759223758, 1.0990328350737115, 1.1263024652793536, 1.1706791268985208, 1.1121584498746133]
Training Loss (progress: 0.88), 0.11154412890691917, [0.0034886394949749404, 0.0007388474873942113, 0.001989712994320747, 0.05717895595763177, 0.040130866408980156, 0.11878392834424402], [0.9452190942981173, 1.0106581846030622, 1.0992259537149034, 1.1269885016106869, 1.1712033078280568, 1.112408938438543]
Training Loss (progress: 0.96), 0.12751396278833074, [0.0035109547679873306, 0.0007857448372444869, 0.0019891391412949445, 0.057649897750319895, 0.04041726923068414, 0.11899146442578983], [0.9451782968784703, 1.0102808441294893, 1.0995730648153035, 1.127934505919223, 1.1718706411782693, 1.1126232694512586]
Evaluation on validation dataset:
Step 25, mean loss 0.028832819074252277
Step 50, mean loss 0.012249962051025614
Step 75, mean loss 0.01601246831112478
Step 100, mean loss 0.020425185955626375
Step 125, mean loss 0.02943952695211273
Step 150, mean loss 0.03624941725900993
Step 175, mean loss 0.044424731170466525
Step 200, mean loss 0.05364623452434257
Step 225, mean loss 0.07210717666061717
Unrolled forward losses 1.3638519504291562
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.25789e-01, 9.09735e-03, 1.72698e-01, 1.05866e+00, 1.07055e+00, 1.07883e+00
Node: 01 (pos: 0.010): 4.51078e-01, 3.83649e-02, 3.04035e-01, 1.07939e+00, 1.10059e+00, 1.08905e+00
Node: 02 (pos: 0.020): 5.88673e-01, 1.24541e-01, 4.82946e-01, 1.09665e+00, 1.12579e+00, 1.09748e+00
Node: 03 (pos: 0.030): 7.24107e-01, 3.11209e-01, 6.92170e-01, 1.11026e+00, 1.14579e+00, 1.10409e+00
Node: 04 (pos: 0.040): 8.39532e-01, 5.98620e-01, 8.95088e-01, 1.12009e+00, 1.16030e+00, 1.10883e+00
Node: 05 (pos: 0.051): 9.17441e-01, 8.86362e-01, 1.04438e+00, 1.12603e+00, 1.16909e+00, 1.11168e+00
-
Node: 07 (pos: 0.071): 9.17441e-01, 8.86362e-01, 1.04438e+00, 1.12603e+00, 1.16909e+00, 1.11168e+00
Node: 08 (pos: 0.081): 8.39532e-01, 5.98620e-01, 8.95088e-01, 1.12009e+00, 1.16030e+00, 1.10883e+00
Node: 09 (pos: 0.091): 7.24107e-01, 3.11209e-01, 6.92170e-01, 1.11026e+00, 1.14579e+00, 1.10409e+00
Node: 10 (pos: 0.101): 5.88673e-01, 1.24541e-01, 4.82946e-01, 1.09665e+00, 1.12579e+00, 1.09748e+00
Node: 11 (pos: 0.111): 4.51078e-01, 3.83649e-02, 3.04035e-01, 1.07939e+00, 1.10059e+00, 1.08905e+00
Node: 12 (pos: 0.121): 3.25789e-01, 9.09735e-03, 1.72698e-01, 1.05866e+00, 1.07055e+00, 1.07883e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.17441e-01, 8.86362e-01, 1.04438e+00, 1.12603e+00, 1.16909e+00, 1.11168e+00
Node: 58 (pos: 0.586): 8.39532e-01, 5.98620e-01, 8.95088e-01, 1.12009e+00, 1.16030e+00, 1.10883e+00
Node: 59 (pos: 0.596): 7.24107e-01, 3.11209e-01, 6.92170e-01, 1.11026e+00, 1.14579e+00, 1.10409e+00
Node: 60 (pos: 0.606): 5.88673e-01, 1.24541e-01, 4.82946e-01, 1.09665e+00, 1.12579e+00, 1.09748e+00
Node: 61 (pos: 0.616): 4.51078e-01, 3.83649e-02, 3.04035e-01, 1.07939e+00, 1.10059e+00, 1.08905e+00
Node: 50 (pos: 0.505): 3.25789e-01, 9.09735e-03, 1.72698e-01, 1.05866e+00, 1.07055e+00, 1.07883e+00
-
Node: 51 (pos: 0.515): 4.51078e-01, 3.83649e-02, 3.04035e-01, 1.07939e+00, 1.10059e+00, 1.08905e+00
Node: 52 (pos: 0.525): 5.88673e-01, 1.24541e-01, 4.82946e-01, 1.09665e+00, 1.12579e+00, 1.09748e+00
Node: 53 (pos: 0.535): 7.24107e-01, 3.11209e-01, 6.92170e-01, 1.11026e+00, 1.14579e+00, 1.10409e+00
Node: 54 (pos: 0.545): 8.39532e-01, 5.98620e-01, 8.95088e-01, 1.12009e+00, 1.16030e+00, 1.10883e+00
Node: 55 (pos: 0.556): 9.17441e-01, 8.86362e-01, 1.04438e+00, 1.12603e+00, 1.16909e+00, 1.11168e+00
Node: 62 (pos: 0.626): 3.25789e-01, 9.09735e-03, 1.72698e-01, 1.05866e+00, 1.07055e+00, 1.07883e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.028750395050735077
Step 50, mean loss 0.012937039407426843
Step 75, mean loss 0.015460158197339327
Step 100, mean loss 0.022374948954301997
Step 125, mean loss 0.026421951449463646
Step 150, mean loss 0.04670988649101332
Step 175, mean loss 0.058448968847371364
Step 200, mean loss 0.06915266000831695
Step 225, mean loss 0.09797841724928738
Unrolled forward losses 1.5759573068722355
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.12469166522540247, [0.0033674830408191667, 0.0007803552767288427, 0.0019956877187402907, 0.057863739757820144, 0.04048499817019807, 0.11901173686530689], [0.9449613162549692, 1.0101599375687857, 1.0994676110263548, 1.1279437217519592, 1.171950684941092, 1.112590937693226]
Training Loss (progress: 0.08), 0.10839519353043477, [0.0034993468436574607, 0.0007398802786951122, 0.00200083410402553, 0.058455463174046735, 0.04095996194086778, 0.11933370194417359], [0.944840782760769, 1.0100084543831505, 1.0997525624983098, 1.1286653014422439, 1.1728412749578738, 1.1129121158131199]
Training Loss (progress: 0.16), 0.12303127794463874, [0.0034653535314517355, 0.0007353945009528967, 0.0019934244939576566, 0.05892792127747878, 0.04115709506232081, 0.11940117819267292], [0.9447130285515533, 1.0099231051990498, 1.0998696188355725, 1.1294213894219787, 1.1733471156098585, 1.1129579204140816]
Training Loss (progress: 0.24), 0.12332453963414529, [0.003398022298202125, 0.0007550548627726184, 0.0019923377902460147, 0.059213100606626476, 0.041326478260711834, 0.11966024208723385], [0.944561332741582, 1.0096420023519783, 1.100090534577671, 1.129994276604469, 1.1737869487610662, 1.1131288912750716]
Training Loss (progress: 0.32), 0.12433349721102778, [0.0033877295128568858, 0.0008161284101707693, 0.001952378268193394, 0.0597284129396388, 0.041515582295074044, 0.11967282366875984], [0.9445059821625956, 1.0093467134976948, 1.1002911511733349, 1.1306011958719064, 1.1742986049920934, 1.1131074957545204]
Training Loss (progress: 0.40), 0.126589156960549, [0.0033757702232931576, 0.0007808724987995406, 0.0020439437110694896, 0.06018413625441896, 0.04172433848923556, 0.1198438044784537], [0.9442353383477341, 1.0091932137761073, 1.1004788490167765, 1.1312866248410927, 1.174930122491901, 1.1132217939949123]
Training Loss (progress: 0.48), 0.1299336384069946, [0.0033746393074485146, 0.0007740827311712991, 0.0020417042879374925, 0.06070720758809249, 0.041869353701481926, 0.12006249815032843], [0.9440658950693077, 1.0090186053255783, 1.1008176749277971, 1.1319866196826396, 1.1753364710650416, 1.1133790541503472]
Training Loss (progress: 0.56), 0.1256697277538011, [0.003506587134948945, 0.0007988515552812958, 0.001968673939926777, 0.06126688317336433, 0.0422138550550301, 0.12017839471889516], [0.9440761501391159, 1.0089602388641734, 1.1009650804809243, 1.1327063743660348, 1.176108993258107, 1.1134348718082563]
Training Loss (progress: 0.64), 0.1068981194110134, [0.003406905020652765, 0.0007904060109769297, 0.001978982732778162, 0.061895190009934965, 0.0424988939208473, 0.12057197629330554], [0.9440299759370842, 1.00882267738031, 1.1012004675216363, 1.1335760185842294, 1.1767509198731618, 1.1137035053467237]
Training Loss (progress: 0.72), 0.120138087908729, [0.0033788697015132638, 0.0007783951064892643, 0.001964741275177542, 0.06239602448216657, 0.04263037533274003, 0.12058732141644486], [0.9437334894436754, 1.0086570221785622, 1.1013203934539566, 1.1342029938103788, 1.1772271534000023, 1.1136833019869858]
Training Loss (progress: 0.80), 0.11139571548144671, [0.003330733264864964, 0.000728111970428467, 0.0019495578779322271, 0.06251621142792653, 0.04280997586694599, 0.12074585025543863], [0.9435747095410592, 1.0084208957695349, 1.1014021802917333, 1.1345492170825522, 1.1778585356299611, 1.1138552165843445]
Training Loss (progress: 0.88), 0.11717039567175229, [0.0034056875585224524, 0.0007777017034714549, 0.002030224880691407, 0.06302154526450209, 0.04305356217855404, 0.12092869044039135], [0.9434475772109493, 1.008148220882293, 1.1016159036260604, 1.1350972329459816, 1.1783759884299816, 1.1140062260312098]
Training Loss (progress: 0.96), 0.1228687519336786, [0.003382008371941122, 0.0007284171066166166, 0.001971176122967344, 0.06358920952131072, 0.043376297581393004, 0.12106703536609774], [0.9432000019464938, 1.0079915437491551, 1.10190063473491, 1.135847320398729, 1.1790504186732091, 1.114186134596418]
Evaluation on validation dataset:
Step 25, mean loss 0.025583157829036883
Step 50, mean loss 0.010880540631072107
Step 75, mean loss 0.016561637384321877
Step 100, mean loss 0.023200345993415677
Step 125, mean loss 0.030480645722533867
Step 150, mean loss 0.036558233346093864
Step 175, mean loss 0.042946423948128615
Step 200, mean loss 0.0568180969724102
Step 225, mean loss 0.07562842839903211
Unrolled forward losses 1.3107003858345352
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.14551e-01, 1.06133e-02, 1.79569e-01, 1.07280e+00, 1.08381e+00, 1.08101e+00
Node: 01 (pos: 0.010): 4.39951e-01, 4.26685e-02, 3.12591e-01, 1.09180e+00, 1.11216e+00, 1.09107e+00
Node: 02 (pos: 0.020): 5.78928e-01, 1.33198e-01, 4.91982e-01, 1.10760e+00, 1.13590e+00, 1.09936e+00
Node: 03 (pos: 0.030): 7.16722e-01, 3.22867e-01, 7.00084e-01, 1.12004e+00, 1.15471e+00, 1.10586e+00
Node: 04 (pos: 0.040): 8.34803e-01, 6.07695e-01, 9.00698e-01, 1.12902e+00, 1.16835e+00, 1.11052e+00
Node: 05 (pos: 0.051): 9.14795e-01, 8.88142e-01, 1.04770e+00, 1.13444e+00, 1.17660e+00, 1.11333e+00
-
Node: 07 (pos: 0.071): 9.14795e-01, 8.88142e-01, 1.04770e+00, 1.13444e+00, 1.17660e+00, 1.11333e+00
Node: 08 (pos: 0.081): 8.34803e-01, 6.07695e-01, 9.00698e-01, 1.12902e+00, 1.16835e+00, 1.11052e+00
Node: 09 (pos: 0.091): 7.16722e-01, 3.22867e-01, 7.00084e-01, 1.12004e+00, 1.15471e+00, 1.10586e+00
Node: 10 (pos: 0.101): 5.78928e-01, 1.33198e-01, 4.91982e-01, 1.10760e+00, 1.13590e+00, 1.09936e+00
Node: 11 (pos: 0.111): 4.39951e-01, 4.26685e-02, 3.12591e-01, 1.09180e+00, 1.11216e+00, 1.09107e+00
Node: 12 (pos: 0.121): 3.14551e-01, 1.06133e-02, 1.79569e-01, 1.07280e+00, 1.08381e+00, 1.08101e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.14795e-01, 8.88142e-01, 1.04770e+00, 1.13444e+00, 1.17660e+00, 1.11333e+00
Node: 58 (pos: 0.586): 8.34803e-01, 6.07695e-01, 9.00698e-01, 1.12902e+00, 1.16835e+00, 1.11052e+00
Node: 59 (pos: 0.596): 7.16722e-01, 3.22867e-01, 7.00084e-01, 1.12004e+00, 1.15471e+00, 1.10586e+00
Node: 60 (pos: 0.606): 5.78928e-01, 1.33198e-01, 4.91982e-01, 1.10760e+00, 1.13590e+00, 1.09936e+00
Node: 61 (pos: 0.616): 4.39951e-01, 4.26685e-02, 3.12591e-01, 1.09180e+00, 1.11216e+00, 1.09107e+00
Node: 50 (pos: 0.505): 3.14551e-01, 1.06133e-02, 1.79569e-01, 1.07280e+00, 1.08381e+00, 1.08101e+00
-
Node: 51 (pos: 0.515): 4.39951e-01, 4.26685e-02, 3.12591e-01, 1.09180e+00, 1.11216e+00, 1.09107e+00
Node: 52 (pos: 0.525): 5.78928e-01, 1.33198e-01, 4.91982e-01, 1.10760e+00, 1.13590e+00, 1.09936e+00
Node: 53 (pos: 0.535): 7.16722e-01, 3.22867e-01, 7.00084e-01, 1.12004e+00, 1.15471e+00, 1.10586e+00
Node: 54 (pos: 0.545): 8.34803e-01, 6.07695e-01, 9.00698e-01, 1.12902e+00, 1.16835e+00, 1.11052e+00
Node: 55 (pos: 0.556): 9.14795e-01, 8.88142e-01, 1.04770e+00, 1.13444e+00, 1.17660e+00, 1.11333e+00
Node: 62 (pos: 0.626): 3.14551e-01, 1.06133e-02, 1.79569e-01, 1.07280e+00, 1.08381e+00, 1.08101e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.025067689638772928
Step 50, mean loss 0.011249008814475919
Step 75, mean loss 0.016079750332837428
Step 100, mean loss 0.022630431933402362
Step 125, mean loss 0.027805149362769885
Step 150, mean loss 0.04717564716432992
Step 175, mean loss 0.060205152057920513
Step 200, mean loss 0.0762666666007312
Step 225, mean loss 0.09872754353461692
Unrolled forward losses 1.5208637427796932
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.11002256483178559, [0.003416301941235206, 0.0007461147478569347, 0.0020170213872853517, 0.06398082680845282, 0.043465213227647514, 0.12122327326624639], [0.9431650501453359, 1.007858497353424, 1.1019260129543422, 1.1363251012396405, 1.1793596244206608, 1.1142889091597976]
Training Loss (progress: 0.08), 0.12135540386323504, [0.003418948148346769, 0.0007802365723878722, 0.001967449071313793, 0.06439312919964092, 0.04379116623023202, 0.1213578216225888], [0.9431015118665954, 1.0076892379009204, 1.102035116627866, 1.1369752693064785, 1.179996750332868, 1.114339853328831]
Training Loss (progress: 0.16), 0.12316690422128877, [0.003400602377963021, 0.0007825143124156923, 0.001957204536075035, 0.0647929905898735, 0.04400315647741701, 0.1214489330926563], [0.9428239529728669, 1.0076511853000492, 1.1022551646959096, 1.1377033581841807, 1.1807722084900736, 1.1144361810859786]
Training Loss (progress: 0.24), 0.11699515757974907, [0.0033764667849042985, 0.0007879155513576747, 0.001985231956751769, 0.06551444551420132, 0.04412435639084213, 0.12168280849835457], [0.9427755567806767, 1.0074561015651848, 1.102493252708057, 1.1386190521137676, 1.1813466670149684, 1.1146027654885924]
Training Loss (progress: 0.32), 0.13010457794027855, [0.0033834486760662423, 0.0007792408457111968, 0.001984419067770142, 0.06583754125887259, 0.0444567564237301, 0.12192474269432253], [0.9426208040607863, 1.0071652710784205, 1.1026701431429053, 1.1390208132466648, 1.1817232573003424, 1.1147338799688604]
Training Loss (progress: 0.40), 0.11769916449798073, [0.0033879466364478052, 0.0007491224793086762, 0.0019392209975260231, 0.06618516706203081, 0.0446614943502069, 0.12201942783041453], [0.9424440434156643, 1.0069265340841633, 1.102706838552212, 1.139439586714266, 1.182193471978604, 1.1147310070971501]
Training Loss (progress: 0.48), 0.10703000841941414, [0.0033852945514466783, 0.0007537291338035705, 0.001988930115927785, 0.06677800219157494, 0.04480945194068579, 0.12224901361680686], [0.942271246898926, 1.0067013575309072, 1.1029022842495684, 1.1401689380359745, 1.18266184935528, 1.1149050669255167]
Training Loss (progress: 0.56), 0.1071060165331443, [0.0033388149130130535, 0.0007709138097762652, 0.001999754797048642, 0.06723253844514218, 0.04509294882489713, 0.12240526872453458], [0.942142171085351, 1.0065739356520083, 1.1031999149695204, 1.1408376454718454, 1.1834535887649267, 1.115045711791106]
Training Loss (progress: 0.64), 0.12016339676883875, [0.0033702340983894547, 0.0007663386054661514, 0.0019143997724211487, 0.0677129895071455, 0.04524448897105386, 0.12256186193614398], [0.9421173131811191, 1.0064062173653041, 1.1033216558796586, 1.1414902578226598, 1.1839747626977806, 1.115083497074001]
Training Loss (progress: 0.72), 0.12174525393751938, [0.0033665970783383465, 0.0007608660309410222, 0.0020233014114049213, 0.06824761530780771, 0.04548293465869416, 0.1228339157586538], [0.9419958514332734, 1.0062451815821338, 1.1034123652840182, 1.1422116959712907, 1.1844715551459708, 1.1152560979178925]
Training Loss (progress: 0.80), 0.11590862741108351, [0.0033234253347608806, 0.0007364440261883718, 0.0019449758347799108, 0.06875709320140237, 0.045718073494782366, 0.12288166220050169], [0.9418113254482346, 1.0060287061987672, 1.103730628082879, 1.1428432251624936, 1.1851115363089209, 1.1152367142865351]
Training Loss (progress: 0.88), 0.11550083991991557, [0.00337387687489506, 0.0007799509210026654, 0.0020064967372662172, 0.06932882856743042, 0.04570965266369279, 0.12311320996560311], [0.9417413920740694, 1.0059884280443716, 1.104079481421385, 1.143520406690156, 1.1854345086556777, 1.1154462652379977]
Training Loss (progress: 0.96), 0.11749105373012399, [0.0033394502644046925, 0.0007833362172368504, 0.0020042964164824054, 0.06961493446470252, 0.04578628198241245, 0.12322596244143506], [0.9416475746152229, 1.0056886775783138, 1.10434556138952, 1.1439359989590006, 1.1860906340344952, 1.1155099847634051]
Evaluation on validation dataset:
Step 25, mean loss 0.023918796333490953
Step 50, mean loss 0.011204741732502736
Step 75, mean loss 0.016530052008685382
Step 100, mean loss 0.02188637284768856
Step 125, mean loss 0.028261654211404832
Step 150, mean loss 0.03794933508316587
Step 175, mean loss 0.046408504527622914
Step 200, mean loss 0.055903355611507125
Step 225, mean loss 0.0716344796148086
Unrolled forward losses 1.4419155945263018
Unrolled forward base losses 1.1720234445357585
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.11841251194518967, [0.003320205760507684, 0.0007598579444780263, 0.0019758575998598863, 0.06997697742474426, 0.045869564210912456, 0.12324492472754837], [0.9414709242975632, 1.0054931608511097, 1.104309107842351, 1.1444231786027104, 1.1861609472856054, 1.1155280177186684]
Training Loss (progress: 0.08), 0.11642494831411752, [0.003316788013234667, 0.0008102158082265559, 0.002001584425816836, 0.07038894187683463, 0.0463774064829296, 0.1235143143419741], [0.9412371872065884, 1.0053644752286564, 1.1044243223234123, 1.1449052719999506, 1.1870004466904565, 1.1156889351312476]
Training Loss (progress: 0.16), 0.12212569919653765, [0.0033784113613683966, 0.0007616181814977345, 0.001971763089214247, 0.07091648136755034, 0.04661062674364518, 0.12363183690890725], [0.9411988720865057, 1.0053629423036399, 1.1047335471729918, 1.1457712732979168, 1.1875380973192058, 1.1157064924884528]
Training Loss (progress: 0.24), 0.10987259548468184, [0.0033815644471920695, 0.0007958268478911824, 0.001970361288890216, 0.0713185321664218, 0.04666705068756285, 0.12372310054542918], [0.9410357397256641, 1.005081197739852, 1.1049029592621222, 1.1461641395744206, 1.1879014670168548, 1.115761503437821]
Training Loss (progress: 0.32), 0.11524864840858144, [0.003330487026216631, 0.0007627870000390914, 0.00195220866496598, 0.07190341923428974, 0.04682163195225875, 0.12389599215613982], [0.9407873718052291, 1.0048960106616054, 1.1052214255836383, 1.1469828146301764, 1.1882560132316706, 1.1158416086281058]
Training Loss (progress: 0.40), 0.1138872059340836, [0.0033505028737297444, 0.0007711118150254468, 0.001998817172876062, 0.07245018472830764, 0.04725723538553832, 0.12412932691861049], [0.9405704744913883, 1.0047220284056348, 1.1054977945745221, 1.1477929923249, 1.1890476321621413, 1.1159811114387954]
Training Loss (progress: 0.48), 0.11868316534977244, [0.0033161454043931474, 0.0007818601675452832, 0.001948611308920813, 0.0727931036163811, 0.047471855983420144, 0.12422387065418829], [0.9404923583955827, 1.0045294625451788, 1.1056093745288231, 1.1479345218388122, 1.1895649527728296, 1.1160038782727]
Training Loss (progress: 0.56), 0.11455018638869237, [0.0033765751686936924, 0.000788623544188256, 0.0020163502228219142, 0.07323726734666072, 0.047405270271385705, 0.12437183859887616], [0.9402855536864108, 1.0044098688273126, 1.10549405519384, 1.1485147199069567, 1.1895784574123809, 1.1160173807850962]
Training Loss (progress: 0.64), 0.12461908158361261, [0.0033764972078962276, 0.0007666555314318573, 0.0020153624078754068, 0.07401517430790153, 0.04773507936972993, 0.12456561946691515], [0.9401516224085288, 1.0041239647164333, 1.1057362095808219, 1.1493458995034267, 1.1904070124249135, 1.116205643567162]
Training Loss (progress: 0.72), 0.11124382817166216, [0.003410948692583592, 0.0007588668005315098, 0.001974798587921772, 0.07445647048610682, 0.04791463762685554, 0.12467978117585526], [0.9399892191396679, 1.0039838785313269, 1.105626799383684, 1.1499133668447723, 1.1909104108753095, 1.1162506360007907]
Training Loss (progress: 0.80), 0.10986322354199561, [0.0033411029035957576, 0.0007841224362724147, 0.002007349298585793, 0.07492133482112913, 0.04826410082522865, 0.12491013073846867], [0.9396736561764706, 1.0037193317862956, 1.105728151612805, 1.1504946113549956, 1.191422203931192, 1.1163380787521537]
Training Loss (progress: 0.88), 0.10218054335288156, [0.0033110956193766637, 0.0007763665554137484, 0.002000546497948026, 0.07523268472181542, 0.04844535797989886, 0.12513029357326233], [0.9395855597503624, 1.0034850538257758, 1.1060511625758864, 1.151039862195125, 1.191911244122204, 1.116471888781589]
Training Loss (progress: 0.96), 0.1023386111900128, [0.00335368754907198, 0.0007831447154255953, 0.001971662071599154, 0.07581288951564848, 0.04865255797565205, 0.12525806169903234], [0.9395204393559241, 1.0033324653915048, 1.1062506693738918, 1.1516181722238783, 1.1923254305667617, 1.116462276256282]
Evaluation on validation dataset:
Step 25, mean loss 0.02293967066070133
Step 50, mean loss 0.009667262435362627
Step 75, mean loss 0.015281796755231801
Step 100, mean loss 0.018877013088518437
Step 125, mean loss 0.02441221272831394
Step 150, mean loss 0.031181918343419733
Step 175, mean loss 0.038891028865242025
Step 200, mean loss 0.051910600468362426
Step 225, mean loss 0.07256335744982327
Unrolled forward losses 1.3217550127098994
Unrolled forward base losses 1.1720234445357585
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00), 0.10625609807695091, [0.003330742279419433, 0.0007525024974195831, 0.0019866373743385674, 0.07613789826116218, 0.04863412544758061, 0.12534569829386433], [0.9393692860957953, 1.0033592894674817, 1.1063742641933747, 1.1519928764296186, 1.1925133918114166, 1.1165481638129937]
Training Loss (progress: 0.08), 0.10282940245819362, [0.003355222052785262, 0.0008022126480301825, 0.001984767031177192, 0.07644453745147486, 0.04900258119379937, 0.12544668046574686], [0.9393937297251218, 1.0032907985795265, 1.1064503981303344, 1.1523978782249327, 1.1931418701821193, 1.1166710483966735]
Training Loss (progress: 0.16), 0.10566647301984547, [0.0033805853494389515, 0.0007781273162037413, 0.0020117644113455285, 0.07674029484166812, 0.049076317269874103, 0.12556619148914372], [0.9393484493711123, 1.0031146875631567, 1.1064920912159784, 1.152807303932889, 1.1934334762290693, 1.1168005423552054]
Training Loss (progress: 0.24), 0.10028885797949398, [0.003340515118962496, 0.0007761890253487084, 0.0020256425803393792, 0.07695174859277007, 0.04930517242628151, 0.12566842027943884], [0.9392995680457802, 1.0031694057613667, 1.1066936449428428, 1.1531307641994808, 1.193904084242023, 1.1169134738041857]
Training Loss (progress: 0.32), 0.09583060261988462, [0.0033375917766199532, 0.0007831546921745387, 0.0020118937554961247, 0.07724197039701246, 0.049423743289468115, 0.12576656301127873], [0.9392536932149228, 1.0031259591332513, 1.1067857097238212, 1.153558242907575, 1.194176823533055, 1.1170400762916493]
Training Loss (progress: 0.40), 0.10621611891674317, [0.003370734649363431, 0.0007792801711896103, 0.0020063728842080186, 0.07757464453473768, 0.049634035291991306, 0.12586060759295417], [0.9392661905405316, 1.0030166378461804, 1.1069289605993706, 1.1540139813170416, 1.1945457452127748, 1.1171555250083343]
Training Loss (progress: 0.48), 0.10555408619973516, [0.003310853839697488, 0.0007937157387511682, 0.0019992094106979726, 0.07778630426406427, 0.049705774416170634, 0.12597009972469353], [0.9391626437427043, 1.0029750429241229, 1.107099679794465, 1.1543384980647158, 1.1948213364358076, 1.1172824831532158]
Training Loss (progress: 0.56), 0.10228340049927494, [0.003389128425267756, 0.0007843036855662848, 0.0019961575965373223, 0.07797037768717521, 0.04989024869909169, 0.12603864745548463], [0.939214795223164, 1.0029365501183738, 1.1070414834996294, 1.1545651653218074, 1.195176448662635, 1.1173733997527244]
Training Loss (progress: 0.64), 0.0948059732792756, [0.003348198643347657, 0.0008066228135520466, 0.001990699973691325, 0.07828766121304556, 0.050130177033586514, 0.12616918809305896], [0.9391621766768793, 1.0028417453650034, 1.1071548507243947, 1.1549746639894007, 1.1955221951898636, 1.117471194989689]
Training Loss (progress: 0.72), 0.11002651214370238, [0.0033437323437715332, 0.00078471298747559, 0.002018329315620107, 0.07847478196005957, 0.050186540813100006, 0.1262734064744694], [0.9391767744889021, 1.0028295432991714, 1.1072969903041903, 1.1552341027747939, 1.1957321472882605, 1.1175901621592115]
Training Loss (progress: 0.80), 0.10525649609345818, [0.0033585354156999464, 0.0007659083714159796, 0.0019964268950515705, 0.0787781738995322, 0.05033296286205462, 0.12633106953825965], [0.9391344949265524, 1.0027265220953965, 1.1073998343715354, 1.1556637240123915, 1.1959865116452317, 1.1176511562563725]
Training Loss (progress: 0.88), 0.1002749544185221, [0.003328778273577554, 0.0007837470382433043, 0.002009781843008789, 0.07899485398349414, 0.05049939175124903, 0.12638034780361806], [0.9390938086393316, 1.002775870626818, 1.1075506327280498, 1.1559168803442763, 1.1962977396680994, 1.1177071479379197]
Training Loss (progress: 0.96), 0.10314926436396966, [0.0033903668180507835, 0.0007704616000821612, 0.00199486117586665, 0.07932555560818551, 0.05062031258298238, 0.12643186514930072], [0.9390693120754086, 1.0027208360863462, 1.1076850005924945, 1.1563235748903444, 1.1966841853329904, 1.117803052899693]
Evaluation on validation dataset:
Step 25, mean loss 0.020414540948021247
Step 50, mean loss 0.008315763721658587
Step 75, mean loss 0.013706964216789476
Step 100, mean loss 0.017957767931315944
Step 125, mean loss 0.023650836594645404
Step 150, mean loss 0.030212667125244844
Step 175, mean loss 0.03729152698622701
Step 200, mean loss 0.04883246054345469
Step 225, mean loss 0.06756134880743536
Unrolled forward losses 1.1932381490252777
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.17693e-01, 9.19933e-03, 1.77186e-01, 1.10421e+00, 1.11306e+00, 1.08582e+00
Node: 01 (pos: 0.010): 4.42410e-01, 3.85741e-02, 3.10208e-01, 1.11993e+00, 1.13799e+00, 1.09550e+00
Node: 02 (pos: 0.020): 5.80088e-01, 1.24637e-01, 4.90516e-01, 1.13295e+00, 1.15881e+00, 1.10349e+00
Node: 03 (pos: 0.030): 7.16167e-01, 3.10318e-01, 7.00537e-01, 1.14318e+00, 1.17526e+00, 1.10974e+00
Node: 04 (pos: 0.040): 8.32504e-01, 5.95359e-01, 9.03622e-01, 1.15054e+00, 1.18716e+00, 1.11422e+00
Node: 05 (pos: 0.051): 9.11190e-01, 8.80162e-01, 1.05274e+00, 1.15498e+00, 1.19435e+00, 1.11692e+00
-
Node: 07 (pos: 0.071): 9.11190e-01, 8.80162e-01, 1.05274e+00, 1.15498e+00, 1.19435e+00, 1.11692e+00
Node: 08 (pos: 0.081): 8.32504e-01, 5.95359e-01, 9.03622e-01, 1.15054e+00, 1.18716e+00, 1.11422e+00
Node: 09 (pos: 0.091): 7.16167e-01, 3.10318e-01, 7.00537e-01, 1.14318e+00, 1.17526e+00, 1.10974e+00
Node: 10 (pos: 0.101): 5.80088e-01, 1.24637e-01, 4.90516e-01, 1.13295e+00, 1.15881e+00, 1.10349e+00
Node: 11 (pos: 0.111): 4.42410e-01, 3.85741e-02, 3.10208e-01, 1.11993e+00, 1.13799e+00, 1.09550e+00
Node: 12 (pos: 0.121): 3.17693e-01, 9.19933e-03, 1.77186e-01, 1.10421e+00, 1.11306e+00, 1.08582e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.11190e-01, 8.80162e-01, 1.05274e+00, 1.15498e+00, 1.19435e+00, 1.11692e+00
Node: 58 (pos: 0.586): 8.32504e-01, 5.95359e-01, 9.03622e-01, 1.15054e+00, 1.18716e+00, 1.11422e+00
Node: 59 (pos: 0.596): 7.16167e-01, 3.10318e-01, 7.00537e-01, 1.14318e+00, 1.17526e+00, 1.10974e+00
Node: 60 (pos: 0.606): 5.80088e-01, 1.24637e-01, 4.90516e-01, 1.13295e+00, 1.15881e+00, 1.10349e+00
Node: 61 (pos: 0.616): 4.42410e-01, 3.85741e-02, 3.10208e-01, 1.11993e+00, 1.13799e+00, 1.09550e+00
Node: 50 (pos: 0.505): 3.17693e-01, 9.19933e-03, 1.77186e-01, 1.10421e+00, 1.11306e+00, 1.08582e+00
-
Node: 51 (pos: 0.515): 4.42410e-01, 3.85741e-02, 3.10208e-01, 1.11993e+00, 1.13799e+00, 1.09550e+00
Node: 52 (pos: 0.525): 5.80088e-01, 1.24637e-01, 4.90516e-01, 1.13295e+00, 1.15881e+00, 1.10349e+00
Node: 53 (pos: 0.535): 7.16167e-01, 3.10318e-01, 7.00537e-01, 1.14318e+00, 1.17526e+00, 1.10974e+00
Node: 54 (pos: 0.545): 8.32504e-01, 5.95359e-01, 9.03622e-01, 1.15054e+00, 1.18716e+00, 1.11422e+00
Node: 55 (pos: 0.556): 9.11190e-01, 8.80162e-01, 1.05274e+00, 1.15498e+00, 1.19435e+00, 1.11692e+00
Node: 62 (pos: 0.626): 3.17693e-01, 9.19933e-03, 1.77186e-01, 1.10421e+00, 1.11306e+00, 1.08582e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.02130311362573097
Step 50, mean loss 0.009013062249272473
Step 75, mean loss 0.01376580992093536
Step 100, mean loss 0.02038728446950408
Step 125, mean loss 0.02429506238719914
Step 150, mean loss 0.039811203296006355
Step 175, mean loss 0.055581509995566755
Step 200, mean loss 0.06242401449937125
Step 225, mean loss 0.08766834685147623
Unrolled forward losses 1.3901768043332456
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00), 0.10661937547446007, [0.003324831791345839, 0.0007815058292854572, 0.0019963042996983074, 0.07945779132868817, 0.05063777678638139, 0.1264503991581726], [0.9389852773450719, 1.0026659901145882, 1.1077391491874127, 1.1564734454060037, 1.196740250172527, 1.1178360055979324]
Training Loss (progress: 0.08), 0.10613708489993906, [0.0033423413634257673, 0.0007864520692344042, 0.002015918092641291, 0.07962512519936525, 0.05079140341850166, 0.12658862894823814], [0.9390179366827824, 1.002670690490409, 1.1079418654063322, 1.156808463848054, 1.1971339820162015, 1.117928436898377]
Training Loss (progress: 0.16), 0.11180443555081854, [0.0033100638751108473, 0.0007680143297937125, 0.0020024475633207755, 0.07991820513064087, 0.05095221373035833, 0.12666762174645851], [0.938984209275467, 1.0025721637299079, 1.1080921777731765, 1.1571684933255642, 1.1973804094170704, 1.1179907161057177]
Training Loss (progress: 0.24), 0.09037319804221017, [0.0033065112875791457, 0.0007894893664933746, 0.0020049423433477756, 0.08000069362941822, 0.05107243993958396, 0.12676648352309786], [0.9389076434420671, 1.0024844379543738, 1.1081405310271466, 1.1573707713514425, 1.1976575363980815, 1.1181126224044662]
Training Loss (progress: 0.32), 0.09906420181752006, [0.0033349362447075226, 0.0007619012623565857, 0.0020024618912460684, 0.08033754992115424, 0.05123831366699859, 0.1267839582204539], [0.9389208659770966, 1.0024184387620951, 1.1082421140000522, 1.1577257598637845, 1.1980305740901505, 1.1181497014754715]
Training Loss (progress: 0.40), 0.1010547740757717, [0.0033379848958773185, 0.0007923985078054489, 0.0019956589256444617, 0.08063432249780449, 0.05129447891751947, 0.12685706736609897], [0.9388856491989367, 1.0023435470562194, 1.1083460051743288, 1.1580826384568241, 1.1982901975137636, 1.118222700282828]
Training Loss (progress: 0.48), 0.10694785628625054, [0.003344847001084188, 0.0007778348997082729, 0.002006521672100602, 0.08088915727112446, 0.051439023691372925, 0.12701485056724748], [0.9389526527811489, 1.00228190372856, 1.1084146657871623, 1.1584862171105397, 1.1986193072562281, 1.1183625957857557]
Training Loss (progress: 0.56), 0.10451729178049451, [0.003333839657051089, 0.0007814466281622876, 0.0019767087135409834, 0.08115225751926959, 0.051646182357578195, 0.12704657336443895], [0.9389024911302337, 1.0023145144504306, 1.1085258465299561, 1.1587921959523324, 1.1989838863036493, 1.1184084026365624]
Training Loss (progress: 0.64), 0.09634778469487976, [0.0033036750598230153, 0.0007994071490570175, 0.002025853639331551, 0.08137761419470779, 0.05161640612755057, 0.1271001225774429], [0.9388619242941761, 1.0022340800304599, 1.108730555223889, 1.1591635267442422, 1.1991758507785073, 1.1184740167127567]
Training Loss (progress: 0.72), 0.10028911009061273, [0.0032537676176277106, 0.0008209575060717707, 0.002015923572083947, 0.08158784016704419, 0.05178039383371072, 0.12720474653450067], [0.9387829808920515, 1.0021980789537814, 1.108890130198406, 1.1593739569561794, 1.199445778420196, 1.1185333319515807]
Training Loss (progress: 0.80), 0.09163547374252212, [0.0032898126623304457, 0.0008131421147791037, 0.0020064390782966925, 0.08187321827021006, 0.051988041056657344, 0.12732969003703243], [0.9387127669261649, 1.002108333601488, 1.1089287427211858, 1.1596936353137812, 1.199805698201087, 1.118663309536462]
Training Loss (progress: 0.88), 0.1029347547963673, [0.003306847897240521, 0.0007835356838172046, 0.0020102057185422094, 0.08217520467967955, 0.052078393246622785, 0.12733873686387615], [0.9387022489958722, 1.0020897153676722, 1.1090270535824092, 1.1600688786563138, 1.2000400923328036, 1.118679796243935]
Training Loss (progress: 0.96), 0.10259349733135002, [0.0033609156355345364, 0.0007855192418315962, 0.002009528422564191, 0.08230725364350337, 0.05224380247459999, 0.12744489444441498], [0.9386184092437396, 1.0020869961476535, 1.1090957506782573, 1.1602943488424855, 1.2003312065450027, 1.118806066098598]
Evaluation on validation dataset:
Step 25, mean loss 0.022126807124806303
Step 50, mean loss 0.009518438445713751
Step 75, mean loss 0.01419113871856279
Step 100, mean loss 0.017461864639461172
Step 125, mean loss 0.023141554729908365
Step 150, mean loss 0.030133547076078536
Step 175, mean loss 0.036885384964376516
Step 200, mean loss 0.04743363867409691
Step 225, mean loss 0.0660797417593671
Unrolled forward losses 1.2998454135758535
Unrolled forward base losses 1.1720234445357585
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00), 0.10856421652076817, [0.0033097992489308043, 0.0007943493186666636, 0.0020239833380736208, 0.08245201371480751, 0.052262111640683236, 0.12745220646635014], [0.9386074487372724, 1.0020615251658016, 1.1091422243842057, 1.1604972266019429, 1.2003816585933484, 1.1188081200560516]
Training Loss (progress: 0.08), 0.09150696737917423, [0.0033359480521983845, 0.0007697460659463534, 0.001979838072656201, 0.08257395800607548, 0.05235473733847162, 0.12751785746022307], [0.9385517313991807, 1.0019670945323647, 1.1091714996345685, 1.1607179452217795, 1.2006693920388414, 1.11890108815645]
Training Loss (progress: 0.16), 0.09754214388419037, [0.0033369825806878893, 0.0007841705750666432, 0.002025844519234577, 0.08290352438018413, 0.05255382625564106, 0.12757839341248534], [0.9385880683796407, 1.0019334457561195, 1.1093954618865627, 1.1610805457257147, 1.2009918224963008, 1.1189776451971354]
Training Loss (progress: 0.24), 0.09554398580610667, [0.003329810612661888, 0.0007854830870342167, 0.002002377349919623, 0.0830840995601978, 0.05258715281966606, 0.12760191257864587], [0.9384948759537515, 1.001856549535469, 1.1094297681097722, 1.161331753793777, 1.2011534816231342, 1.1189950400909296]
Training Loss (progress: 0.32), 0.09494107436725967, [0.0033220847604790754, 0.0007965939634603852, 0.0020201413646254713, 0.0833796904451318, 0.05285889026543096, 0.1276701926984141], [0.9385070973100731, 1.0018261466998633, 1.1094947897126979, 1.161750551951954, 1.2015050940044163, 1.1190704237289117]
Training Loss (progress: 0.40), 0.10081210628419116, [0.003313892215353893, 0.0008024000072444842, 0.001996300076241039, 0.08358987001409471, 0.05292414551243283, 0.12769202945016808], [0.9384566011850028, 1.0018186764643704, 1.1096391873180365, 1.1620125487223878, 1.2017769780771435, 1.1191441168014435]
Training Loss (progress: 0.48), 0.10482248053751556, [0.0033470252290012477, 0.0007877880401827871, 0.0019989761074985807, 0.08387509429649762, 0.053138459634513246, 0.1278172311349705], [0.9384796840751205, 1.0016896050554747, 1.1096962603063283, 1.1623626371186833, 1.2021221955066383, 1.119251259583493]
Training Loss (progress: 0.56), 0.10221000023512931, [0.003351481828559138, 0.0007982514008782258, 0.0020213367928505555, 0.08410523188658509, 0.053216391348801226, 0.1278301897211684], [0.9385146268467216, 1.0017146001801507, 1.1097988331655841, 1.162699609102568, 1.2023882799204377, 1.119288520476688]
Training Loss (progress: 0.64), 0.09607096042956749, [0.003302741855527678, 0.0007822725784523156, 0.0019962368068728864, 0.08431158179194773, 0.053355454043328095, 0.12793832054530804], [0.9384150392831168, 1.0016329387575784, 1.109819058853422, 1.1629765702580714, 1.2025849369040793, 1.1193842533728515]
Training Loss (progress: 0.72), 0.10595923405816442, [0.003306998759223031, 0.0007821409093074867, 0.0019926851903275477, 0.08445363625551768, 0.05350034908815554, 0.12800176100204233], [0.9384022847403682, 1.001589608349583, 1.1099523597945908, 1.163182328026885, 1.2029049724832857, 1.1194302826281843]
Training Loss (progress: 0.80), 0.09506020349304631, [0.0032900095977050677, 0.0008001316601982862, 0.0020047359715665096, 0.08472738795023192, 0.05360184488471487, 0.12807188737649863], [0.9383953229053915, 1.0015703150703605, 1.1100442372111596, 1.163517243982014, 1.2031063613611823, 1.1194888816238666]
Training Loss (progress: 0.88), 0.10006040279103762, [0.0033258554319883626, 0.0008085029821117704, 0.002017452067900001, 0.08499143455430805, 0.053764202338013815, 0.12813928449165776], [0.938336948522655, 1.0014996713228292, 1.1102333439523342, 1.1638169543968273, 1.2035133178958797, 1.1195761202930739]
Training Loss (progress: 0.96), 0.09695685830348684, [0.0033055594777473174, 0.0007855293368081472, 0.00200339988201348, 0.08526258154563826, 0.053836950353801837, 0.12822785279239435], [0.9382923109826297, 1.0014459556670954, 1.110325419929226, 1.1641003065573121, 1.2036266777165316, 1.119624636017328]
Evaluation on validation dataset:
Step 25, mean loss 0.018522149813244345
Step 50, mean loss 0.008222058934805914
Step 75, mean loss 0.014168017145896196
Step 100, mean loss 0.016275614176663608
Step 125, mean loss 0.022944181942706695
Step 150, mean loss 0.029522294072393266
Step 175, mean loss 0.03747431056606158
Step 200, mean loss 0.04764582801599895
Step 225, mean loss 0.06604929335285883
Unrolled forward losses 1.2087165331960015
Unrolled forward base losses 1.1720234445357585
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00), 0.09905611336943614, [0.003263142711063166, 0.000782691687956137, 0.0019908496770391906, 0.08542957894223357, 0.0539485048095542, 0.12827914163174498], [0.938220377554909, 1.001341933925313, 1.1103424345479034, 1.164273051167144, 1.2037695983161567, 1.1196801925650026]
Training Loss (progress: 0.08), 0.09302805831694792, [0.003333597863079053, 0.0007787269698301261, 0.002009456960453412, 0.08554336222700873, 0.054112742913596246, 0.12832938689631235], [0.9382583431951383, 1.001305656227538, 1.1104485542995315, 1.1644863553212872, 1.2040208217586423, 1.1197470924449793]
Training Loss (progress: 0.16), 0.10353361163773062, [0.0033318453718350636, 0.0007881643819692805, 0.0020245618701622, 0.08580502780927901, 0.05411419768845961, 0.1283936577775389], [0.9381992085710283, 1.0012376737073978, 1.1105065739565492, 1.164795077415977, 1.2042114710982745, 1.119818662653452]
Training Loss (progress: 0.24), 0.10435958145252786, [0.0032831191214834133, 0.000783444862568012, 0.0020332517723807395, 0.08602897075575541, 0.05424962008879594, 0.1284646161567538], [0.9381116361924302, 1.0012494776230447, 1.1106240594090937, 1.1650992928398318, 1.2044992734315432, 1.1198966071921892]
Training Loss (progress: 0.32), 0.10346003371872241, [0.0032557718428301618, 0.0007967878898293402, 0.0020251385878506762, 0.08638928042456052, 0.05437671505414069, 0.12857837791740034], [0.9380455365700064, 1.001170481586964, 1.1106541143544435, 1.165495229983361, 1.2048481074934765, 1.1199799429517319]
Training Loss (progress: 0.40), 0.09437201189597537, [0.0032986779089480035, 0.0007701864013408562, 0.0020201103919117052, 0.08651648964936734, 0.054439625224154714, 0.12863798694163656], [0.938092570818512, 1.0011078841798065, 1.1107701340162133, 1.1656350694073279, 1.2050288945515246, 1.1200164223888662]
Training Loss (progress: 0.48), 0.09678819332944309, [0.0032502814719484966, 0.000786118662957122, 0.0020154571170126544, 0.08685177648078661, 0.05460601926670314, 0.12870194204606747], [0.9379933805675313, 1.0010019489034385, 1.1109383300534759, 1.1660371308650748, 1.2053303423950126, 1.1200623182714728]
Training Loss (progress: 0.56), 0.11123787120307622, [0.0033075046563448163, 0.0007715991042507362, 0.0020224812974042896, 0.08707216673905531, 0.05470176928581023, 0.1288139404433612], [0.9379782408860711, 1.000933587353829, 1.1109299411385463, 1.1663827288252515, 1.2055758472035751, 1.120149222094702]
Training Loss (progress: 0.64), 0.10760816877510232, [0.0032722852650902095, 0.0007846776483741785, 0.002012291668555718, 0.08733727136260024, 0.05489607442378703, 0.12889624866122057], [0.9378818734362926, 1.0009542811595182, 1.111096056364658, 1.1667236398563756, 1.2058689888751015, 1.1202302632500978]
Training Loss (progress: 0.72), 0.10240450256388735, [0.003286730173213475, 0.0007994703981396524, 0.0020371479734688377, 0.08763911219238973, 0.055065885876104975, 0.12894746350420738], [0.9378762621080525, 1.0009369260980128, 1.11122110559336, 1.1670887115405864, 1.2062114133038904, 1.1202726734707127]
Training Loss (progress: 0.80), 0.09676413810123283, [0.003339174457166107, 0.0007904078677482168, 0.0020291651680192746, 0.0878216905311094, 0.05509308948672383, 0.12900819808871158], [0.9379165373974022, 1.0007963710001266, 1.1113106983482046, 1.1673390781251989, 1.2063353273779762, 1.120345916266832]
Training Loss (progress: 0.88), 0.10138989608814868, [0.0032937113301246355, 0.0007929350639888328, 0.00201704053939493, 0.08801807436982928, 0.0552138411464149, 0.12908158136507106], [0.9378325935781255, 1.0007305189903417, 1.1112933696570462, 1.167568485169933, 1.2065524380897985, 1.120408588971724]
Training Loss (progress: 0.96), 0.10663295365798656, [0.003284916325699079, 0.0007887238901477693, 0.0020235254329068735, 0.08826989007953528, 0.05529055202824731, 0.12919892532543883], [0.9377973367986565, 1.0007107531186774, 1.1114688782515663, 1.167884102481666, 1.2068420192753162, 1.1204984169794656]
Evaluation on validation dataset:
Step 25, mean loss 0.023303877387214116
Step 50, mean loss 0.009202791777617961
Step 75, mean loss 0.013206049315642246
Step 100, mean loss 0.017014597512276228
Step 125, mean loss 0.021919106209441402
Step 150, mean loss 0.02862568392225433
Step 175, mean loss 0.03565447701641054
Step 200, mean loss 0.04676525494594544
Step 225, mean loss 0.06487746155614353
Unrolled forward losses 1.3053083268239685
Unrolled forward base losses 1.1720234445357585
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00), 0.09256749953671488, [0.0032884524048193376, 0.0008191160032227109, 0.0020087526899687244, 0.0883258152386179, 0.05540056502034125, 0.1291865565049516], [0.9377745975231633, 1.0006234634194786, 1.1115210591026334, 1.1679783613453758, 1.2070118485260235, 1.1204988614710554]
Training Loss (progress: 0.08), 0.09791953489001011, [0.003264502000716127, 0.0007839608026487852, 0.00203427163701265, 0.08861616893759344, 0.05553409515422153, 0.129283908789022], [0.9376997689531484, 1.0005680925775147, 1.111570317401881, 1.1683182365059868, 1.2072271941062276, 1.120598310227426]
Training Loss (progress: 0.16), 0.09462896284538364, [0.003255094260938416, 0.0008019168122832181, 0.0020117739621438964, 0.08888111126724571, 0.0555680339180026, 0.1292473123727449], [0.9376179271391849, 1.000529453805305, 1.1117160270765976, 1.1686016887205444, 1.2073962579183737, 1.1205582092514996]
Training Loss (progress: 0.24), 0.09885526126218798, [0.0032699310694222286, 0.0008033604376959252, 0.0020392691606909456, 0.0890787062416566, 0.05561838809218567, 0.12929952981373544], [0.9375715585910043, 1.000499815339481, 1.1118088292100818, 1.1688892338745207, 1.207591973726683, 1.1205973325093392]
Training Loss (progress: 0.32), 0.09579590934999116, [0.0032675979456918036, 0.0007917248380090341, 0.00200957601614092, 0.0893618982863603, 0.05566840825525415, 0.12940039400103084], [0.93751049064642, 1.000426070860416, 1.111842455153625, 1.1692137285498816, 1.2077735700719563, 1.1207191932372407]
Training Loss (progress: 0.40), 0.098374701657599, [0.0033185224437035253, 0.0007853856121919372, 0.0020031301356535653, 0.0895350392142942, 0.055829942794985245, 0.12944396032625505], [0.9374857106563527, 1.0004198247139553, 1.1119189771880036, 1.169429885804666, 1.2080521302591078, 1.1207360755821116]
Training Loss (progress: 0.48), 0.09885707205288943, [0.003261505610291654, 0.0008089772092385711, 0.0020112697274069003, 0.08970790336318313, 0.055913508897183196, 0.1295178649368477], [0.9374418393886297, 1.000443366425563, 1.111944233913227, 1.1696840617595192, 1.208232898727393, 1.1207975893568851]
Training Loss (progress: 0.56), 0.10116508123069022, [0.0032429100982911086, 0.0007874668017509585, 0.00203556538755423, 0.08995598823622372, 0.05605396709816109, 0.12955352625734354], [0.9374387599453522, 1.0003794975058984, 1.1121377967194008, 1.1699672241479486, 1.2085567527202559, 1.1208545380266062]
Training Loss (progress: 0.64), 0.09728477072673922, [0.003256936922793677, 0.0008030817750759528, 0.0020150110439653792, 0.09019147627903856, 0.056155930906711844, 0.1295959785119838], [0.9374116451624936, 1.0002995924594384, 1.1121841435406006, 1.170225410466412, 1.2088032189095952, 1.120887740160335]
Training Loss (progress: 0.72), 0.10628199672176991, [0.003295037025187497, 0.0007973367755538578, 0.0020170141194210916, 0.09044227222283667, 0.056284760974419944, 0.12969199231646475], [0.9373182230856015, 1.0002148834631985, 1.112260005153954, 1.1704877358416665, 1.20911901511828, 1.1209837951452342]
Training Loss (progress: 0.80), 0.09637765864246797, [0.0032513784258687848, 0.0008069081709081353, 0.002032973503662943, 0.09072861200644977, 0.05634424050423874, 0.12978052757827319], [0.937195931580227, 1.0002552947093561, 1.1123702848456047, 1.170858697861893, 1.2092832415338164, 1.1210643549215689]
Training Loss (progress: 0.88), 0.09923279114118103, [0.003285455024167674, 0.0007924998233588135, 0.00203635673994442, 0.09091692010401986, 0.05648739804580896, 0.12987986881862262], [0.9371615562006935, 1.0001539137498192, 1.1123695481736995, 1.171089157758864, 1.2095455105251944, 1.1211330689043888]
Training Loss (progress: 0.96), 0.09411267105317465, [0.003285059589369752, 0.0007905611250778251, 0.0020278508107512637, 0.0912578192799362, 0.056688370773188994, 0.12994651357251788], [0.9371423670755551, 1.0000208934451473, 1.1125535216860298, 1.1714892910562302, 1.209846773305769, 1.1211829180137023]
Evaluation on validation dataset:
Step 25, mean loss 0.019175540712214938
Step 50, mean loss 0.008275443415339877
Step 75, mean loss 0.012765219874878246
Step 100, mean loss 0.0160274191538151
Step 125, mean loss 0.022182016090494458
Step 150, mean loss 0.02885156800456287
Step 175, mean loss 0.035719155469264546
Step 200, mean loss 0.04563167866047753
Step 225, mean loss 0.06281961430146445
Unrolled forward losses 1.2795172805062403
Unrolled forward base losses 1.1720234445357585
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00), 0.09713104746029742, [0.0032716290943100735, 0.0007959172112118949, 0.0020416585789641705, 0.09133102268541728, 0.05679507902313379, 0.12994697456640608], [0.9372032073263978, 1.0000546997504909, 1.1125427364319032, 1.1716056637399126, 1.2100130020606994, 1.1211789717776222]
Training Loss (progress: 0.08), 0.09632802400698412, [0.003288706635209135, 0.0007979425678525852, 0.002031776588937171, 0.09144749778232068, 0.056829832129704806, 0.12998077581784093], [0.9371264443058128, 1.0000443186360826, 1.1126040662607473, 1.1717819615138818, 1.210117335817161, 1.121242782065511]
Training Loss (progress: 0.16), 0.0934415534614034, [0.0032830382313990135, 0.0008041844827090938, 0.002039916351403676, 0.091634384181522, 0.056930435679153006, 0.1300447641234851], [0.937121093087096, 1.0000210680270525, 1.1126333581069947, 1.172005130876191, 1.2102991701996286, 1.1213147356303759]
Training Loss (progress: 0.24), 0.10040556148503677, [0.0032934044753122594, 0.0008015921613391144, 0.0020378855658242886, 0.09175543154564042, 0.05696639244530162, 0.1300285916275235], [0.9371161838233202, 0.9999845356226126, 1.1127232905002342, 1.172153859453201, 1.2104016435878704, 1.1213225192777971]
Training Loss (progress: 0.32), 0.09550463933645993, [0.0032814267050442396, 0.000791298751658386, 0.0020418015458170285, 0.09183568849658275, 0.05710566613384657, 0.13007404924386826], [0.9370890470096116, 0.9999609916023924, 1.112801171785313, 1.172224689245191, 1.2106301682140925, 1.1213673638042327]
Training Loss (progress: 0.40), 0.09024690495627723, [0.003254685395791945, 0.0007965001767187767, 0.0020296591566394246, 0.09198331850956143, 0.05716015644862707, 0.1301264042037835], [0.9370875467352008, 0.9999712670870226, 1.1128328284038431, 1.1723812153624436, 1.210789167757245, 1.121426295672724]
Training Loss (progress: 0.48), 0.08905308264475303, [0.0032614011910810595, 0.000800534491257309, 0.0020508297677731195, 0.09210343269352965, 0.05720351412627063, 0.13017092446770967], [0.9370745624236737, 0.9999392865324077, 1.1129153005348464, 1.1725347201063971, 1.2108904743450521, 1.1214826393262447]
Training Loss (progress: 0.56), 0.09317233317207374, [0.003266036761114762, 0.000805676104394585, 0.0020566426432232603, 0.09226508150153673, 0.057257429958887704, 0.13020651331851818], [0.9370568288164246, 0.9999019773141451, 1.112943723308366, 1.172725408069403, 1.2110220237625282, 1.1215309898684798]
Training Loss (progress: 0.64), 0.10090163454146338, [0.003277042209859704, 0.0007950948805941329, 0.002035494633399524, 0.09239121804761585, 0.057302747795792634, 0.1302325984586276], [0.937058123940147, 0.9999055284818488, 1.1129629309238065, 1.1728640739016145, 1.2111184897294927, 1.1215541800256594]
Training Loss (progress: 0.72), 0.09578221704230284, [0.003253380808975888, 0.000807317339447293, 0.0020601891414461114, 0.09244967363499348, 0.057431282596265384, 0.13028681937089504], [0.9370298213812537, 0.999903782901896, 1.1130337197083155, 1.1729754667985923, 1.2113020976256168, 1.1216094294502892]
Training Loss (progress: 0.80), 0.09042726441172556, [0.0032736678680729808, 0.0007964478702136828, 0.0020423538777427615, 0.09254602415748157, 0.05745820143727042, 0.1303286018890845], [0.9370431095686831, 0.999884783975179, 1.113071634183922, 1.1730819550107794, 1.2113985339598636, 1.1216609129931783]
Training Loss (progress: 0.88), 0.09098568557238354, [0.0032816580299733855, 0.0007997759023571682, 0.0020519470168869885, 0.0926848756062971, 0.05753484785680869, 0.13037673620694024], [0.9370447168039931, 0.9998456943259127, 1.113102576941222, 1.1732670904485343, 1.211543992137083, 1.1217272310629893]
Training Loss (progress: 0.96), 0.09337593210382573, [0.0032775890896470663, 0.0007923943842325212, 0.0020426644362476, 0.09279178474163544, 0.05756106107722793, 0.13040430935916633], [0.9370403921558806, 0.9998745766333128, 1.1131635782565148, 1.173389761904298, 1.211664454645544, 1.121756506019738]
Evaluation on validation dataset:
Step 25, mean loss 0.016768742540578464
Step 50, mean loss 0.007592676079197174
Step 75, mean loss 0.01252057409638819
Step 100, mean loss 0.01665250434280724
Step 125, mean loss 0.022405596517356654
Step 150, mean loss 0.02867798155502729
Step 175, mean loss 0.0359733097291491
Step 200, mean loss 0.04662640873424958
Step 225, mean loss 0.06518330589552887
Unrolled forward losses 1.206045918604029
Unrolled forward base losses 1.1720234445357585
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00), 0.09672328499542372, [0.003272861296024185, 0.0008053167780020001, 0.0020531587183802726, 0.09287558294677621, 0.05758422196849492, 0.13042199635196874], [0.9370243930635799, 0.9998699764073354, 1.1131781303096229, 1.1734859303481875, 1.2116988737290035, 1.1217743212923321]
Training Loss (progress: 0.08), 0.09036389931875108, [0.003239978667800161, 0.0008028117970456149, 0.002040600627750505, 0.09299098425910379, 0.05770623478001148, 0.13044388223062847], [0.9369903666260829, 0.9998742262419196, 1.1132105169986182, 1.173633766634638, 1.2119490710121683, 1.1218080024484152]
Training Loss (progress: 0.16), 0.09010533537274423, [0.0032327089938841195, 0.0007907878349603337, 0.0020440234185884927, 0.0931049919247578, 0.057730251445809434, 0.13046320345682869], [0.9369938512078221, 0.9998433273037499, 1.1132555957543542, 1.1737767438129216, 1.2120183697493434, 1.1218504227458284]
Training Loss (progress: 0.24), 0.0866207371686325, [0.003254174638109617, 0.0008080162199915509, 0.002053359853716697, 0.09319755173249746, 0.057784745618839534, 0.13050870913086982], [0.9369975301035273, 0.9998222378696139, 1.1132962490840392, 1.1738539454455286, 1.212087830374254, 1.1218797369388156]
Training Loss (progress: 0.32), 0.09404414437878475, [0.0032508348881574037, 0.0008010291154567546, 0.0020354042321690646, 0.09333001877233811, 0.05784800087307573, 0.1305213889903054], [0.9369812181556523, 0.9997907626236996, 1.1133688495729528, 1.174036117478087, 1.212201919161582, 1.121902148387132]
Training Loss (progress: 0.40), 0.09490516967089602, [0.0032827170179028555, 0.0008179577586242982, 0.002057006498444681, 0.09346165335588898, 0.05797613470655601, 0.13055725235141977], [0.9369810785757413, 0.9997924237862205, 1.1133853022142721, 1.1741842743566981, 1.2124136021026508, 1.1219463137762826]
Training Loss (progress: 0.48), 0.09375939253073705, [0.003266595024762705, 0.0008090601533419516, 0.0020392550825929657, 0.09357133861905637, 0.058041325908993184, 0.1305857635704603], [0.9369649535640845, 0.9997770888800741, 1.1134239855556674, 1.1743543518108828, 1.2125489106441691, 1.1219828096401891]
Training Loss (progress: 0.56), 0.09311240602146784, [0.0032762981274149197, 0.0008032401785257181, 0.0020414132305897857, 0.0936130032323153, 0.05803924671799825, 0.1306385039956428], [0.9369665870256909, 0.9997479493814828, 1.1134958353267979, 1.1744283655692496, 1.2125866458455017, 1.1220450985072117]
Training Loss (progress: 0.64), 0.09982463525577076, [0.0032681072140913515, 0.0008084781923336299, 0.002049898811965847, 0.09375395766849563, 0.05818133096445528, 0.13069097459586465], [0.936962934563658, 0.9997186845330361, 1.1135093273138295, 1.1745955229503515, 1.2127967667932085, 1.1220997021462344]
Training Loss (progress: 0.72), 0.09404641927416567, [0.0032818131376883175, 0.0007913810629377166, 0.0020480274199134595, 0.09387285637099199, 0.05822890292330577, 0.1307304004087964], [0.9369379711540801, 0.9997185804880303, 1.1135266645578257, 1.1747207644879083, 1.2129011247279322, 1.12214714003782]
Training Loss (progress: 0.80), 0.09087210470344256, [0.003249707448769181, 0.0008006196581642107, 0.0020482348851485737, 0.09403399822849072, 0.05826943772239201, 0.13076144157335334], [0.9369276401620902, 0.9997179295853071, 1.1135775474988299, 1.1749119638307937, 1.2129935033344832, 1.122180327935454]
Training Loss (progress: 0.88), 0.09147384037493382, [0.003271735835558946, 0.0007970952146627622, 0.002045574292223809, 0.0941693012565924, 0.058338907092138084, 0.1308005212273433], [0.9369163955161498, 0.9996830840375389, 1.1135821458803752, 1.1750691891529865, 1.2131475927448627, 1.1222200133982876]
Training Loss (progress: 0.96), 0.09069871776430938, [0.0032705426678119867, 0.0008044601698549467, 0.002045313877390802, 0.09427101259846556, 0.0584233571255523, 0.13081347407496047], [0.9369037611588517, 0.9996308670175538, 1.113630733378278, 1.1752069381933095, 1.2132374071533814, 1.1222458160644204]
Evaluation on validation dataset:
Step 25, mean loss 0.01639627315127823
Step 50, mean loss 0.007272744473268337
Step 75, mean loss 0.012566049220752582
Step 100, mean loss 0.015960922852611737
Step 125, mean loss 0.021900168544975354
Step 150, mean loss 0.028050446993215503
Step 175, mean loss 0.035115180689281655
Step 200, mean loss 0.04614197498224476
Step 225, mean loss 0.06536929749631351
Unrolled forward losses 1.195708515571801
Unrolled forward base losses 1.1720234445357585
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00), 0.09012191969188402, [0.0032492848226593385, 0.000801575929795269, 0.0020394052900075477, 0.09432978988178217, 0.058410213862262916, 0.13079419564971356], [0.936861597031193, 0.9996277335905102, 1.1136846685457227, 1.1752886668082008, 1.2132560679993563, 1.122232455307189]
Training Loss (progress: 0.08), 0.09207245423293765, [0.003261997135348899, 0.0008009747933831462, 0.0020655206092518334, 0.0943639847385835, 0.058470702062878924, 0.130830509550167], [0.9368545662327559, 0.999605746756349, 1.1136915984740048, 1.175376357704465, 1.2133887018557095, 1.122268185882904]
Training Loss (progress: 0.16), 0.09629703600663443, [0.0032540278199228866, 0.0008060075617252036, 0.0020559778810752367, 0.09446904987540143, 0.05853982464054735, 0.1308775857090033], [0.936856565432784, 0.9995768999576751, 1.113683061643246, 1.1754847601059, 1.21353753380868, 1.1223133171230704]
Training Loss (progress: 0.24), 0.08931701903604201, [0.00327967553332569, 0.0007921254068994972, 0.002048117604351565, 0.09456327872506572, 0.05861698388434933, 0.13090667293596342], [0.9368656269970824, 0.9995687755626822, 1.1137567756916997, 1.1755944996329306, 1.213686274657639, 1.1223521093017028]
Training Loss (progress: 0.32), 0.09198366271930307, [0.0032695655393778153, 0.0008064725434182439, 0.00204019944091509, 0.09470205355047974, 0.058660417915557414, 0.1309431070041414], [0.9368269064924456, 0.9995655840647729, 1.113819914948212, 1.1757670154541986, 1.2137947595130139, 1.1224124124478017]
Training Loss (progress: 0.40), 0.09516676099941611, [0.0032381013254680693, 0.0008099083380524259, 0.0020720039696401345, 0.09479569579252602, 0.058694824338779976, 0.1309832540305241], [0.9368149829612437, 0.9995420228962352, 1.1138759222581507, 1.1758622448949358, 1.213855778157821, 1.1224582790791917]
Training Loss (progress: 0.48), 0.08185380612180815, [0.003246108506860019, 0.0008022968296813799, 0.0020559101324598957, 0.09488251148278233, 0.05875309555402942, 0.13101390046758027], [0.936822913042823, 0.9995354153575049, 1.113897382579096, 1.175986529062804, 1.2139895865540102, 1.122476782704454]
Training Loss (progress: 0.56), 0.09419176963033098, [0.003249954729687076, 0.0008118477369824321, 0.0020440388191067097, 0.09502972774602249, 0.058775736470054345, 0.13104728734993176], [0.9367938064307884, 0.9995327324893717, 1.1139456310321705, 1.1761756343477796, 1.2140969815067584, 1.1225264408082807]
Training Loss (progress: 0.64), 0.09255549417886146, [0.003241538223883395, 0.0008061175321982101, 0.0020421332535966196, 0.0951407074033575, 0.05888294514772333, 0.1310671982093155], [0.9367661870231069, 0.9995432981554558, 1.1140151238499658, 1.1763338234624598, 1.2142686924449022, 1.12255989610034]
Training Loss (progress: 0.72), 0.09453138179458756, [0.0032497117883616383, 0.0007965876347472325, 0.00204549482532617, 0.09522610709996929, 0.05893456089862917, 0.13108498831440604], [0.9367692646126765, 0.9994871807427491, 1.1140511097645152, 1.17644075291071, 1.2143506973090061, 1.1225862480843536]
Training Loss (progress: 0.80), 0.08093838056529262, [0.003255821484144468, 0.0008200488696533751, 0.0020336796908461074, 0.09536984914548965, 0.058972294830733824, 0.13111820396803797], [0.9367768398969252, 0.9995144204956702, 1.1141609478520447, 1.1765920306213107, 1.2144358612345265, 1.1226316461555066]
Training Loss (progress: 0.88), 0.09477177270950272, [0.003249625731707757, 0.0008070349547378955, 0.0020527899843796496, 0.09539658860347447, 0.05906402476919215, 0.1311462560689507], [0.9367694846287269, 0.9994900361549073, 1.114154616637808, 1.1766599906807114, 1.2146047275938572, 1.1226638036144587]
Training Loss (progress: 0.96), 0.09869554174457237, [0.0032547703575848486, 0.0008070089822670681, 0.0020532841337350814, 0.09555479456557696, 0.05910322705189372, 0.13117193113109266], [0.9367647073747741, 0.9994669795619628, 1.114183007809602, 1.1768121288386193, 1.2146825846931988, 1.1226849139077728]
Evaluation on validation dataset:
Step 25, mean loss 0.015935008048482843
Step 50, mean loss 0.0072300329045570984
Step 75, mean loss 0.012346870494917079
Step 100, mean loss 0.01607617545060962
Step 125, mean loss 0.022097606552623612
Step 150, mean loss 0.02771582773479355
Step 175, mean loss 0.0347253278120911
Step 200, mean loss 0.04587033666602762
Step 225, mean loss 0.06549029828683164
Unrolled forward losses 1.1551405301982518
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.04371e-01, 1.05217e-02, 1.85638e-01, 1.13243e+00, 1.14157e+00, 1.09173e+00
Node: 01 (pos: 0.010): 4.29125e-01, 4.23040e-02, 3.20980e-01, 1.14581e+00, 1.16345e+00, 1.10111e+00
Node: 02 (pos: 0.020): 5.68383e-01, 1.32070e-01, 5.02403e-01, 1.15688e+00, 1.18166e+00, 1.10884e+00
Node: 03 (pos: 0.030): 7.07252e-01, 3.20150e-01, 7.11848e-01, 1.16556e+00, 1.19602e+00, 1.11489e+00
Node: 04 (pos: 0.040): 8.26768e-01, 6.02605e-01, 9.13026e-01, 1.17180e+00, 1.20638e+00, 1.11924e+00
Node: 05 (pos: 0.051): 9.07966e-01, 8.80724e-01, 1.06009e+00, 1.17556e+00, 1.21264e+00, 1.12185e+00
-
Node: 07 (pos: 0.071): 9.07966e-01, 8.80724e-01, 1.06009e+00, 1.17556e+00, 1.21264e+00, 1.12185e+00
Node: 08 (pos: 0.081): 8.26768e-01, 6.02605e-01, 9.13026e-01, 1.17180e+00, 1.20638e+00, 1.11924e+00
Node: 09 (pos: 0.091): 7.07252e-01, 3.20150e-01, 7.11848e-01, 1.16556e+00, 1.19602e+00, 1.11489e+00
Node: 10 (pos: 0.101): 5.68383e-01, 1.32070e-01, 5.02403e-01, 1.15688e+00, 1.18166e+00, 1.10884e+00
Node: 11 (pos: 0.111): 4.29125e-01, 4.23040e-02, 3.20980e-01, 1.14581e+00, 1.16345e+00, 1.10111e+00
Node: 12 (pos: 0.121): 3.04371e-01, 1.05217e-02, 1.85638e-01, 1.13243e+00, 1.14157e+00, 1.09173e+00
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.07966e-01, 8.80724e-01, 1.06009e+00, 1.17556e+00, 1.21264e+00, 1.12185e+00
Node: 58 (pos: 0.586): 8.26768e-01, 6.02605e-01, 9.13026e-01, 1.17180e+00, 1.20638e+00, 1.11924e+00
Node: 59 (pos: 0.596): 7.07252e-01, 3.20150e-01, 7.11848e-01, 1.16556e+00, 1.19602e+00, 1.11489e+00
Node: 60 (pos: 0.606): 5.68383e-01, 1.32070e-01, 5.02403e-01, 1.15688e+00, 1.18166e+00, 1.10884e+00
Node: 61 (pos: 0.616): 4.29125e-01, 4.23040e-02, 3.20980e-01, 1.14581e+00, 1.16345e+00, 1.10111e+00
Node: 50 (pos: 0.505): 3.04371e-01, 1.05217e-02, 1.85638e-01, 1.13243e+00, 1.14157e+00, 1.09173e+00
-
Node: 51 (pos: 0.515): 4.29125e-01, 4.23040e-02, 3.20980e-01, 1.14581e+00, 1.16345e+00, 1.10111e+00
Node: 52 (pos: 0.525): 5.68383e-01, 1.32070e-01, 5.02403e-01, 1.15688e+00, 1.18166e+00, 1.10884e+00
Node: 53 (pos: 0.535): 7.07252e-01, 3.20150e-01, 7.11848e-01, 1.16556e+00, 1.19602e+00, 1.11489e+00
Node: 54 (pos: 0.545): 8.26768e-01, 6.02605e-01, 9.13026e-01, 1.17180e+00, 1.20638e+00, 1.11924e+00
Node: 55 (pos: 0.556): 9.07966e-01, 8.80724e-01, 1.06009e+00, 1.17556e+00, 1.21264e+00, 1.12185e+00
Node: 62 (pos: 0.626): 3.04371e-01, 1.05217e-02, 1.85638e-01, 1.13243e+00, 1.14157e+00, 1.09173e+00
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.01721634800908087
Step 50, mean loss 0.007797433135087758
Step 75, mean loss 0.01190520850085961
Step 100, mean loss 0.018282515413900156
Step 125, mean loss 0.021869997114171202
Step 150, mean loss 0.035311990089987574
Step 175, mean loss 0.05008302862998039
Step 200, mean loss 0.054635781852557345
Step 225, mean loss 0.08414095494728313
Unrolled forward losses 1.33251163562859
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time69325.tar

Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00), 0.09589645418840388, [0.003233861684053035, 0.0008049854357267772, 0.002037707165181866, 0.09554911975421515, 0.059148227947837896, 0.13121566289435765], [0.9367363558386391, 0.999503383896599, 1.1142026470316335, 1.1768070025185995, 1.2147599670699667, 1.122730559222142]
Training Loss (progress: 0.08), 0.08962111450602304, [0.003264316993220444, 0.0008101223239758837, 0.0020566099534594408, 0.09570198947370119, 0.05919137888055077, 0.13124793763585862], [0.9367336575315726, 0.9994882111466167, 1.1142566852673925, 1.1769831553074341, 1.214850276292023, 1.1227675609031902]
Training Loss (progress: 0.16), 0.0904455183248876, [0.003249902457782974, 0.0008055373403846286, 0.0020387585232794396, 0.09580593684143307, 0.0592351670622076, 0.13130242017475513], [0.9367060983510006, 0.9994853933408245, 1.1142953704757979, 1.1771100005345247, 1.2149577835493595, 1.1228303871187284]
Training Loss (progress: 0.24), 0.0858728252232351, [0.0032457353007318435, 0.0008103018571123599, 0.0020555209539025307, 0.0958980355236774, 0.059289963428539934, 0.13128498440644115], [0.9367288978169184, 0.9994346855886654, 1.1143704360638362, 1.1772503417094913, 1.215048204258967, 1.1228317110458848]
Training Loss (progress: 0.32), 0.08888383824498779, [0.0032608502792505737, 0.0008079946378355835, 0.002045580021042398, 0.0960315035122304, 0.05934112027131513, 0.13130966677340924], [0.936724658773081, 0.9994120944598986, 1.1144117767784638, 1.1774140293371604, 1.2151844386935367, 1.1228731500326785]
Training Loss (progress: 0.40), 0.09422705145776042, [0.0032384890634951646, 0.0008107965579863069, 0.0020706996569848923, 0.09614017155987653, 0.059410454845198635, 0.13134817023533618], [0.9366967301586071, 0.9994466979456486, 1.114433907682144, 1.1775366376886816, 1.2153274152624842, 1.1229261636943195]
Training Loss (progress: 0.48), 0.09012455936543859, [0.0032383824066187445, 0.0008025329999671646, 0.0020460873193994, 0.09629622148635097, 0.05948975586607876, 0.13135822854295845], [0.936701523556434, 0.9994177500946907, 1.1145035431529415, 1.1776922496730404, 1.2154306307668212, 1.1229397465627593]
Training Loss (progress: 0.56), 0.09041851087877041, [0.003268220544351163, 0.0008070244204585597, 0.0020733520408708636, 0.09640664504950343, 0.05952097735220032, 0.131424748729246], [0.9366802677532842, 0.9993939761278557, 1.1145345324958555, 1.1778289024544362, 1.215521168003716, 1.1230262070027912]
Training Loss (progress: 0.64), 0.09542362573649024, [0.0032511518438427074, 0.0008013522510644365, 0.0020592010009395554, 0.09650188471763406, 0.0596422470881669, 0.13143054587234368], [0.936676444764688, 0.9993862968964589, 1.1146115728468466, 1.177952450196109, 1.2156903241931265, 1.1230307039779293]
Training Loss (progress: 0.72), 0.0883134463512833, [0.0032600866043788115, 0.0007955132764770175, 0.0020269718134464463, 0.09659371794312716, 0.05965107149393603, 0.13148094195698432], [0.9366722406286715, 0.9993323529029904, 1.1145854340285453, 1.17805761095254, 1.2157388259264763, 1.1230755080907153]
Training Loss (progress: 0.80), 0.09486095399571892, [0.0032450150218729006, 0.0008002030534524129, 0.0020566447838539555, 0.09670464741143303, 0.059754716959389595, 0.13152240079348462], [0.9366636350014934, 0.9993068629331573, 1.1146614380391917, 1.1781787437021694, 1.2159237830893934, 1.1231090380454578]
Training Loss (progress: 0.88), 0.09656031628764018, [0.003249156985988521, 0.0008025878819248165, 0.0020401888835213096, 0.09684254742717535, 0.05978350383030355, 0.13154593476180387], [0.9366324507126353, 0.9993091094573985, 1.1147007140009444, 1.17833042316871, 1.2160376277522658, 1.1231485446672176]
Training Loss (progress: 0.96), 0.08662204511289698, [0.0032406484480310784, 0.0008049305450929838, 0.0020487388560027926, 0.09697225248094735, 0.05980843868079743, 0.13154599849599313], [0.9366130135836093, 0.999313389189432, 1.1147708460612593, 1.178456553412165, 1.216107989642224, 1.1231777734030663]
Evaluation on validation dataset:
Step 25, mean loss 0.015915253199421102
Step 50, mean loss 0.007362211385380003
Step 75, mean loss 0.012729191178325244
Step 100, mean loss 0.015477274791726843
Step 125, mean loss 0.021575277436309815
Step 150, mean loss 0.02741544544381966
Step 175, mean loss 0.03452919168602239
Step 200, mean loss 0.045490294650102014
Step 225, mean loss 0.06552064237089397
Unrolled forward losses 1.1830229422290621
Unrolled forward base losses 1.1720234445357585
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00), 0.09057004053302438, [0.003236403655410799, 0.0008078224024214161, 0.0020622957092149784, 0.09704697857051149, 0.05980276164720737, 0.1315688648418795], [0.9366205506707249, 0.9993193561075574, 1.114801390396506, 1.1785761356623559, 1.2161302970746413, 1.1231942050938657]
Training Loss (progress: 0.08), 0.08493918639308123, [0.0032212710154227104, 0.0008130222713388438, 0.002050825428570461, 0.09713930182234136, 0.05985456169573433, 0.1315970301658673], [0.9365938247380419, 0.9992822381767574, 1.114827798196486, 1.178661195996928, 1.2162419087685723, 1.123221849017334]
Training Loss (progress: 0.16), 0.09188596975323006, [0.0032575498857260873, 0.0007995108469759157, 0.002061514712313493, 0.09723533390290852, 0.05991534950111159, 0.13163096743904484], [0.9366023780723662, 0.999276316309761, 1.114916929612888, 1.1787798168919201, 1.2163876549692927, 1.1232786783387994]
Training Loss (progress: 0.24), 0.10565181445783495, [0.0032395460313735126, 0.0008088924909408318, 0.002062560788856438, 0.09731089611141915, 0.06003246526783147, 0.13167264505957724], [0.9365963833736582, 0.9992579249107004, 1.114930790864587, 1.1789289342648563, 1.216543421404317, 1.1233184982863311]
Training Loss (progress: 0.32), 0.07858928306297683, [0.003246531544957665, 0.0008101677385871826, 0.00204245236813228, 0.09742479640806734, 0.060062816828618595, 0.1316746828446825], [0.9365662873190667, 0.9992264419664991, 1.114986149243876, 1.1790631521336847, 1.216632192024695, 1.1233340234653968]
Training Loss (progress: 0.40), 0.09184864356208605, [0.0032601278462341884, 0.0008015992106939096, 0.002050090433001251, 0.09752389650474208, 0.060145480604648464, 0.13169362594799508], [0.9365809926911418, 0.999213434728585, 1.1150328219318586, 1.179207439976764, 1.216800254403843, 1.1233484250358141]
Training Loss (progress: 0.48), 0.0897704008900944, [0.003255766245755141, 0.0008059558710088965, 0.002056969870408443, 0.09763182328403558, 0.060219896443849855, 0.13173715975485475], [0.9365772558518229, 0.9992308765612867, 1.1150643884879554, 1.1793484613220742, 1.216895832677458, 1.1233920597642753]
Training Loss (progress: 0.56), 0.08700572903613699, [0.0032283452160718844, 0.0007995991305843196, 0.002065702971752124, 0.09776069587458934, 0.060258159708554825, 0.1317653799250046], [0.9365102251343541, 0.9991763180634955, 1.1151142646108043, 1.1794729287987706, 1.2169879461657849, 1.1234347408127918]
Training Loss (progress: 0.64), 0.09803345364779684, [0.00325683995093375, 0.000803074460872065, 0.0020472275632103785, 0.0978574527049607, 0.06030141720444822, 0.13180526711822435], [0.9365281236220491, 0.9992033436018869, 1.1151494462494338, 1.1795814125741484, 1.217073167305918, 1.1234725142596047]
Training Loss (progress: 0.72), 0.09263736333610892, [0.0032456224001971767, 0.0008289455159945591, 0.0020332189661156335, 0.09797733252429733, 0.060341888269399076, 0.1318311439983157], [0.9365094751814927, 0.9991874670741391, 1.1152151368298655, 1.1797108909582696, 1.2172198859238839, 1.1235171984387533]
Training Loss (progress: 0.80), 0.09601760554011556, [0.00323605246499682, 0.0008086975624421069, 0.002041470709100043, 0.098108905140285, 0.0603700358589313, 0.13185916678448392], [0.9364719625807669, 0.9991912427472998, 1.1152822916470087, 1.1798696712595242, 1.2172740525678085, 1.1235452560594408]
Training Loss (progress: 0.88), 0.0983248499944044, [0.003239300782676193, 0.0008031652943866666, 0.002051772043749801, 0.09821838564154109, 0.060432645495649945, 0.13185891586561072], [0.936473401578449, 0.9992034183386752, 1.1153367630862108, 1.180011622132978, 1.2173770092972716, 1.123556502715381]
Training Loss (progress: 0.96), 0.09260064499170133, [0.003228536634524183, 0.0008014814171778681, 0.0020532206150929502, 0.09829757098347804, 0.06050094965941405, 0.13187828451796968], [0.9364706853791154, 0.9991489607712104, 1.1153446966923604, 1.1801144771466472, 1.2174811252880882, 1.1235846339851383]
Evaluation on validation dataset:
Step 25, mean loss 0.016103983217383412
Step 50, mean loss 0.007518677980321568
Step 75, mean loss 0.012843610745573776
Step 100, mean loss 0.016144526699702996
Step 125, mean loss 0.02232507111071251
Step 150, mean loss 0.027836766295811076
Step 175, mean loss 0.03520465055002999
Step 200, mean loss 0.046057032536261325
Step 225, mean loss 0.06465292584676191
Unrolled forward losses 1.1880214600680696
Unrolled forward base losses 1.1720234445357585
Test loss: 1.33251163562859
