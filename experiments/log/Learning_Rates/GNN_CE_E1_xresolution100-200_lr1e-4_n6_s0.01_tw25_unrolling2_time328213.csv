Training on dataset data/CE_train_E1.h5
cuda:0
models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt
Number of parameters: 1031645
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00): 1.4128639875084605
Training Loss (progress: 0.08): 0.24628671439613892
Training Loss (progress: 0.16): 0.2023659786934632
Training Loss (progress: 0.24): 0.18403308089491757
Training Loss (progress: 0.32): 0.1441843028632251
Training Loss (progress: 0.40): 0.14727228879896181
Training Loss (progress: 0.48): 0.12067978094821753
Training Loss (progress: 0.56): 0.12540221461207274
Training Loss (progress: 0.64): 0.11497339948539634
Training Loss (progress: 0.72): 0.10741221146053441
Training Loss (progress: 0.80): 0.10858483117907637
Training Loss (progress: 0.88): 0.11767239302920074
Training Loss (progress: 0.96): 0.09459057947363583
Evaluation on validation dataset:
Step 25, mean loss 0.07468052746681253
Step 50, mean loss 0.09826529547881346
Step 75, mean loss 0.15079532229558157
Step 100, mean loss 0.29744026506793997
Step 125, mean loss 0.2769909894742285
Step 150, mean loss 0.24642519929040146
Step 175, mean loss 0.421753609946077
Step 200, mean loss 0.7559192528094789
Step 225, mean loss 0.5516596643005589
Unrolled forward losses 15.280849341990395
Unrolled forward base losses 2.565701273852575
Evaluation on test dataset:
Step 25, mean loss 0.06590587186250292
Step 50, mean loss 0.0828112504437748
Step 75, mean loss 0.12089475540367076
Step 100, mean loss 0.16587488688994934
Step 125, mean loss 0.36995189253368244
Step 150, mean loss 0.24738450616549207
Step 175, mean loss 0.42443693904494784
Step 200, mean loss 0.3829294975407049
Step 225, mean loss 0.31518024455933674
Unrolled forward losses 11.475906754038322
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00): 0.2430379527972296
Training Loss (progress: 0.08): 0.20593093510400604
Training Loss (progress: 0.16): 0.20713078453726913
Training Loss (progress: 0.24): 0.2076289280013766
Training Loss (progress: 0.32): 0.1961621410022141
Training Loss (progress: 0.40): 0.19516019924313144
Training Loss (progress: 0.48): 0.17197979355099843
Training Loss (progress: 0.56): 0.16947455543518186
Training Loss (progress: 0.64): 0.16879343888595266
Training Loss (progress: 0.72): 0.1655123764530816
Training Loss (progress: 0.80): 0.150596190781508
Training Loss (progress: 0.88): 0.15112595213412652
Training Loss (progress: 0.96): 0.17428944903661484
Evaluation on validation dataset:
Step 25, mean loss 0.09308214646068547
Step 50, mean loss 0.07429368809532326
Step 75, mean loss 0.08196842269870282
Step 100, mean loss 0.11173137823765918
Step 125, mean loss 0.14964334166866716
Step 150, mean loss 0.1156936315171493
Step 175, mean loss 0.20777348982535615
Step 200, mean loss 0.47834756284310553
Step 225, mean loss 0.37291171321328914
Unrolled forward losses 6.95039346930648
Unrolled forward base losses 2.565701273852575
Evaluation on test dataset:
Step 25, mean loss 0.07840743278570414
Step 50, mean loss 0.05887937121542969
Step 75, mean loss 0.07213770453794735
Step 100, mean loss 0.08025148297462267
Step 125, mean loss 0.11048073586354264
Step 150, mean loss 0.11555250673119893
Step 175, mean loss 0.18939752005270466
Step 200, mean loss 0.207563024331442
Step 225, mean loss 0.2419396263063156
Unrolled forward losses 6.226131139290718
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00): 0.21406381085770454
Training Loss (progress: 0.08): 0.20165827849039814
Training Loss (progress: 0.16): 0.21633528817805678
Training Loss (progress: 0.24): 0.20547492035076573
Training Loss (progress: 0.32): 0.2013604295394768
Training Loss (progress: 0.40): 0.21923961864409663
Training Loss (progress: 0.48): 0.20692504082864766
Training Loss (progress: 0.56): 0.2188897469844909
Training Loss (progress: 0.64): 0.18437866671336692
Training Loss (progress: 0.72): 0.18635455720963576
Training Loss (progress: 0.80): 0.1837569083794989
Training Loss (progress: 0.88): 0.19426776687871603
Training Loss (progress: 0.96): 0.2127313752691879
Evaluation on validation dataset:
Step 25, mean loss 0.07618150969275665
Step 50, mean loss 0.04083079113494717
Step 75, mean loss 0.05935403963249579
Step 100, mean loss 0.06680822201709766
Step 125, mean loss 0.08262610615276356
Step 150, mean loss 0.10392605524284429
Step 175, mean loss 0.1787891712450002
Step 200, mean loss 0.29700532691808906
Step 225, mean loss 0.24388900892157966
Unrolled forward losses 3.1129628399465177
Unrolled forward base losses 2.565701273852575
Evaluation on test dataset:
Step 25, mean loss 0.06029756754048132
Step 50, mean loss 0.031844164413022
Step 75, mean loss 0.04124815749876706
Step 100, mean loss 0.04883545700956216
Step 125, mean loss 0.07037044867325512
Step 150, mean loss 0.09481126431919687
Step 175, mean loss 0.14110683658190343
Step 200, mean loss 0.1868516074771964
Step 225, mean loss 0.14673838069824627
Unrolled forward losses 2.9639853153134617
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00): 0.19615854784469344
Training Loss (progress: 0.08): 0.1940052073004017
Training Loss (progress: 0.16): 0.18749435213037305
Training Loss (progress: 0.24): 0.1874422087818714
Training Loss (progress: 0.32): 0.20143462084239047
Training Loss (progress: 0.40): 0.192226295236498
Training Loss (progress: 0.48): 0.1794005605666455
Training Loss (progress: 0.56): 0.19065239933564904
Training Loss (progress: 0.64): 0.15897801080501262
Training Loss (progress: 0.72): 0.19754255676693866
Training Loss (progress: 0.80): 0.17924396585832478
Training Loss (progress: 0.88): 0.1719456813706931
Training Loss (progress: 0.96): 0.19888198385736203
Evaluation on validation dataset:
Step 25, mean loss 0.07132853494792804
Step 50, mean loss 0.04878416791873495
Step 75, mean loss 0.06468919686601496
Step 100, mean loss 0.08942190133194719
Step 125, mean loss 0.10895529014972676
Step 150, mean loss 0.09904284454401996
Step 175, mean loss 0.15865341459667365
Step 200, mean loss 0.3402206957735478
Step 225, mean loss 0.2344270123586789
Unrolled forward losses 3.954798621058888
Unrolled forward base losses 2.565701273852575
Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00): 0.1809924376698971
Training Loss (progress: 0.08): 0.18974433417227712
Training Loss (progress: 0.16): 0.1664310416864517
Training Loss (progress: 0.24): 0.17712867386865055
Training Loss (progress: 0.32): 0.15657514556811306
Training Loss (progress: 0.40): 0.1718667787333
Training Loss (progress: 0.48): 0.16492196396536687
Training Loss (progress: 0.56): 0.17473098912374077
Training Loss (progress: 0.64): 0.15978002041911368
Training Loss (progress: 0.72): 0.16580129558269371
Training Loss (progress: 0.80): 0.18553364810797598
Training Loss (progress: 0.88): 0.16912039007552734
Training Loss (progress: 0.96): 0.16678155265660458
Evaluation on validation dataset:
Step 25, mean loss 0.05680592895606179
Step 50, mean loss 0.02688328567067
Step 75, mean loss 0.04040950518401604
Step 100, mean loss 0.05507141262032241
Step 125, mean loss 0.06650891546355119
Step 150, mean loss 0.057638741706208946
Step 175, mean loss 0.1039863069130512
Step 200, mean loss 0.3040536332905986
Step 225, mean loss 0.19026553509721347
Unrolled forward losses 2.1071774447262857
Unrolled forward base losses 2.565701273852575
Evaluation on test dataset:
Step 25, mean loss 0.04720835407475543
Step 50, mean loss 0.021730621081339295
Step 75, mean loss 0.031823044118752
Step 100, mean loss 0.03540737504022813
Step 125, mean loss 0.05024912769143401
Step 150, mean loss 0.0649332249516854
Step 175, mean loss 0.10510864974147614
Step 200, mean loss 0.14389066974343773
Step 225, mean loss 0.1071744872422764
Unrolled forward losses 1.8564366534730614
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00): 0.14905524203504378
Training Loss (progress: 0.08): 0.13699380804016933
Training Loss (progress: 0.16): 0.1541233057561632
Training Loss (progress: 0.24): 0.15144690391622193
Training Loss (progress: 0.32): 0.14970303953479083
Training Loss (progress: 0.40): 0.13884543208515798
Training Loss (progress: 0.48): 0.12230243642840134
Training Loss (progress: 0.56): 0.14518716587539174
Training Loss (progress: 0.64): 0.13304833307987077
Training Loss (progress: 0.72): 0.1548503333046017
Training Loss (progress: 0.80): 0.13322224164412716
Training Loss (progress: 0.88): 0.14724945634305972
Training Loss (progress: 0.96): 0.13478118000454156
Evaluation on validation dataset:
Step 25, mean loss 0.0493379988135815
Step 50, mean loss 0.022060211354968075
Step 75, mean loss 0.034730040373592126
Step 100, mean loss 0.043359664416311436
Step 125, mean loss 0.04668559401045129
Step 150, mean loss 0.0498257194875026
Step 175, mean loss 0.09208407085443951
Step 200, mean loss 0.24601559757646455
Step 225, mean loss 0.19728663120809706
Unrolled forward losses 2.2409302471471486
Unrolled forward base losses 2.565701273852575
Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00): 0.13206097303914913
Training Loss (progress: 0.08): 0.1303459280055597
Training Loss (progress: 0.16): 0.14413512206146534
Training Loss (progress: 0.24): 0.1350243843049447
Training Loss (progress: 0.32): 0.12691658344441595
Training Loss (progress: 0.40): 0.12447882110316016
Training Loss (progress: 0.48): 0.13045614112628506
Training Loss (progress: 0.56): 0.13865831815498733
Training Loss (progress: 0.64): 0.13238382851085007
Training Loss (progress: 0.72): 0.14538252158388332
Training Loss (progress: 0.80): 0.13596372501035775
Training Loss (progress: 0.88): 0.13529024725072106
Training Loss (progress: 0.96): 0.1392181842035568
Evaluation on validation dataset:
Step 25, mean loss 0.04191695875626197
Step 50, mean loss 0.01998101623753377
Step 75, mean loss 0.03226330110517611
Step 100, mean loss 0.04272606201560183
Step 125, mean loss 0.046905491671546395
Step 150, mean loss 0.054750381879020815
Step 175, mean loss 0.10031207714185889
Step 200, mean loss 0.26300950210811147
Step 225, mean loss 0.18735339976349039
Unrolled forward losses 1.835603900232752
Unrolled forward base losses 2.565701273852575
Evaluation on test dataset:
Step 25, mean loss 0.03520817035375581
Step 50, mean loss 0.015410320391382785
Step 75, mean loss 0.024515057640799122
Step 100, mean loss 0.028025623894226914
Step 125, mean loss 0.03933286564990901
Step 150, mean loss 0.05051394000551357
Step 175, mean loss 0.07897254760264946
Step 200, mean loss 0.14193107609481997
Step 225, mean loss 0.09973367204161476
Unrolled forward losses 1.5937588422889297
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00): 0.1230329831729151
Training Loss (progress: 0.08): 0.12543208568789793
Training Loss (progress: 0.16): 0.12945610156518764
Training Loss (progress: 0.24): 0.12681602625546695
Training Loss (progress: 0.32): 0.1318863592641145
Training Loss (progress: 0.40): 0.13670980072453212
Training Loss (progress: 0.48): 0.1220211130927532
Training Loss (progress: 0.56): 0.12085925073753608
Training Loss (progress: 0.64): 0.13675692434054856
Training Loss (progress: 0.72): 0.11402131353577806
Training Loss (progress: 0.80): 0.14078392554124178
Training Loss (progress: 0.88): 0.12131638598005866
Training Loss (progress: 0.96): 0.13228342453565436
Evaluation on validation dataset:
Step 25, mean loss 0.04364944809002723
Step 50, mean loss 0.02099275754224354
Step 75, mean loss 0.030793431614425715
Step 100, mean loss 0.04040629532256128
Step 125, mean loss 0.0420920611221348
Step 150, mean loss 0.04616209271196284
Step 175, mean loss 0.08570219408783097
Step 200, mean loss 0.252480961729992
Step 225, mean loss 0.18065538826031363
Unrolled forward losses 1.9870907336957722
Unrolled forward base losses 2.565701273852575
Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00): 0.13282074029450058
Training Loss (progress: 0.08): 0.1357228994630985
Training Loss (progress: 0.16): 0.11879602149405283
Training Loss (progress: 0.24): 0.13608570077368518
Training Loss (progress: 0.32): 0.13176011188475428
Training Loss (progress: 0.40): 0.12682895982808687
Training Loss (progress: 0.48): 0.12708110664921346
Training Loss (progress: 0.56): 0.12554970492448986
Training Loss (progress: 0.64): 0.13262711470547697
Training Loss (progress: 0.72): 0.11896512323194444
Training Loss (progress: 0.80): 0.12626741507287512
Training Loss (progress: 0.88): 0.11874003137445571
Training Loss (progress: 0.96): 0.122564445945162
Evaluation on validation dataset:
Step 25, mean loss 0.04078927899059191
Step 50, mean loss 0.017625382729689935
Step 75, mean loss 0.030017855293917282
Step 100, mean loss 0.04211744098606891
Step 125, mean loss 0.039152173111337306
Step 150, mean loss 0.044368621376048585
Step 175, mean loss 0.0820279996006155
Step 200, mean loss 0.24869730302191698
Step 225, mean loss 0.17515794646798966
Unrolled forward losses 1.792268873977001
Unrolled forward base losses 2.565701273852575
Evaluation on test dataset:
Step 25, mean loss 0.03520161366366967
Step 50, mean loss 0.013071623558007549
Step 75, mean loss 0.02167900310958567
Step 100, mean loss 0.02480740840367155
Step 125, mean loss 0.03538089943039015
Step 150, mean loss 0.043971305799097526
Step 175, mean loss 0.07539767125889599
Step 200, mean loss 0.13220051520147283
Step 225, mean loss 0.08793458577948088
Unrolled forward losses 1.4218569499488725
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00): 0.129686002923064
Training Loss (progress: 0.08): 0.12498519068522092
Training Loss (progress: 0.16): 0.12525579343452936
Training Loss (progress: 0.24): 0.1299017374424523
Training Loss (progress: 0.32): 0.13022294985685853
Training Loss (progress: 0.40): 0.11710921288411147
Training Loss (progress: 0.48): 0.1290163151075209
Training Loss (progress: 0.56): 0.11484861102330281
Training Loss (progress: 0.64): 0.13109969108177796
Training Loss (progress: 0.72): 0.1271042115415776
Training Loss (progress: 0.80): 0.12709600774558855
Training Loss (progress: 0.88): 0.1299859208285457
Training Loss (progress: 0.96): 0.12770851009229842
Evaluation on validation dataset:
Step 25, mean loss 0.03939599549646565
Step 50, mean loss 0.018658836028251243
Step 75, mean loss 0.029319686910076963
Step 100, mean loss 0.041240832832846866
Step 125, mean loss 0.04346933023535225
Step 150, mean loss 0.04695271183806651
Step 175, mean loss 0.080353918961261
Step 200, mean loss 0.2494651475125524
Step 225, mean loss 0.17001428131122942
Unrolled forward losses 1.9209631064878283
Unrolled forward base losses 2.565701273852575
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00): 0.10500212763564482
Training Loss (progress: 0.08): 0.11416833715050402
Training Loss (progress: 0.16): 0.11800500238314053
Training Loss (progress: 0.24): 0.1142986948029785
Training Loss (progress: 0.32): 0.10822059414604918
Training Loss (progress: 0.40): 0.09978176674432698
Training Loss (progress: 0.48): 0.1217258208707423
Training Loss (progress: 0.56): 0.10637813162140743
Training Loss (progress: 0.64): 0.11673798732660416
Training Loss (progress: 0.72): 0.12092188583511969
Training Loss (progress: 0.80): 0.10498978616805062
Training Loss (progress: 0.88): 0.11333524547604192
Training Loss (progress: 0.96): 0.11427632958476872
Evaluation on validation dataset:
Step 25, mean loss 0.031886919959818974
Step 50, mean loss 0.01711704573245243
Step 75, mean loss 0.026166650276210096
Step 100, mean loss 0.033871910031346035
Step 125, mean loss 0.03628042176134725
Step 150, mean loss 0.04014551151770894
Step 175, mean loss 0.0721972678017463
Step 200, mean loss 0.2435225501523739
Step 225, mean loss 0.17048032007760813
Unrolled forward losses 1.7267783905791534
Unrolled forward base losses 2.565701273852575
Evaluation on test dataset:
Step 25, mean loss 0.026377608949175672
Step 50, mean loss 0.012380748418969845
Step 75, mean loss 0.019511776450069806
Step 100, mean loss 0.02163950660878756
Step 125, mean loss 0.03111483865959233
Step 150, mean loss 0.039729933905569295
Step 175, mean loss 0.06250932737460077
Step 200, mean loss 0.11644915077256315
Step 225, mean loss 0.07966574490145233
Unrolled forward losses 1.4647363570131064
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00): 0.11394516624199186
Training Loss (progress: 0.08): 0.11858185815110017
Training Loss (progress: 0.16): 0.11261490792053871
Training Loss (progress: 0.24): 0.1091027903810809
Training Loss (progress: 0.32): 0.10881162776949088
Training Loss (progress: 0.40): 0.10990265058156251
Training Loss (progress: 0.48): 0.11480337882919543
Training Loss (progress: 0.56): 0.11526473287622246
Training Loss (progress: 0.64): 0.1165748826056244
Training Loss (progress: 0.72): 0.10348163775767631
Training Loss (progress: 0.80): 0.11587773296310613
Training Loss (progress: 0.88): 0.10914577253632225
Training Loss (progress: 0.96): 0.11570155871558079
Evaluation on validation dataset:
Step 25, mean loss 0.030848645096420976
Step 50, mean loss 0.0166025129588123
Step 75, mean loss 0.025709492311029182
Step 100, mean loss 0.03755624766988688
Step 125, mean loss 0.034630236778451604
Step 150, mean loss 0.040199278651585305
Step 175, mean loss 0.07346706430143117
Step 200, mean loss 0.2299767817723708
Step 225, mean loss 0.17169445066077021
Unrolled forward losses 1.8076426773661656
Unrolled forward base losses 2.565701273852575
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00): 0.11772985426488626
Training Loss (progress: 0.08): 0.10962856045064621
Training Loss (progress: 0.16): 0.10970425494082378
Training Loss (progress: 0.24): 0.11117099877532519
Training Loss (progress: 0.32): 0.10516160503571782
Training Loss (progress: 0.40): 0.11530484659786151
Training Loss (progress: 0.48): 0.10083091223967991
Training Loss (progress: 0.56): 0.10988282736881229
Training Loss (progress: 0.64): 0.1100869263940191
Training Loss (progress: 0.72): 0.11172437639330804
Training Loss (progress: 0.80): 0.1034978621262195
Training Loss (progress: 0.88): 0.11560851316274286
Training Loss (progress: 0.96): 0.10860220288872698
Evaluation on validation dataset:
Step 25, mean loss 0.028069315497632096
Step 50, mean loss 0.014853114137556666
Step 75, mean loss 0.025063135566933094
Step 100, mean loss 0.0339342666145787
Step 125, mean loss 0.03661499230101642
Step 150, mean loss 0.039611781507946704
Step 175, mean loss 0.0677601010541547
Step 200, mean loss 0.24487366170119587
Step 225, mean loss 0.17939497712621638
Unrolled forward losses 1.5396495984358796
Unrolled forward base losses 2.565701273852575
Evaluation on test dataset:
Step 25, mean loss 0.023484469850322313
Step 50, mean loss 0.011495319842428797
Step 75, mean loss 0.018099573342161057
Step 100, mean loss 0.021307632902250802
Step 125, mean loss 0.030659832110946326
Step 150, mean loss 0.03860891064480272
Step 175, mean loss 0.05913892345467942
Step 200, mean loss 0.12336057724653335
Step 225, mean loss 0.07992694600377152
Unrolled forward losses 1.3936703727932338
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt

Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00): 0.1083860200107897
Training Loss (progress: 0.08): 0.12076686837881401
Training Loss (progress: 0.16): 0.108109028365165
Training Loss (progress: 0.24): 0.11966079174183639
Training Loss (progress: 0.32): 0.10654919518002319
Training Loss (progress: 0.40): 0.10209120359033537
Training Loss (progress: 0.48): 0.11468150044708143
Training Loss (progress: 0.56): 0.11842144604622998
Training Loss (progress: 0.64): 0.10673747331229487
Training Loss (progress: 0.72): 0.09954206566628394
Training Loss (progress: 0.80): 0.11198355492990188
Training Loss (progress: 0.88): 0.1125633489366702
Training Loss (progress: 0.96): 0.1026492722119314
Evaluation on validation dataset:
Step 25, mean loss 0.028770254170123355
Step 50, mean loss 0.014596582249000938
Step 75, mean loss 0.024195166541520253
Step 100, mean loss 0.03443174911337566
Step 125, mean loss 0.033548114653701167
Step 150, mean loss 0.03596343243158444
Step 175, mean loss 0.06335955430094757
Step 200, mean loss 0.23043570139403263
Step 225, mean loss 0.1761262136931116
Unrolled forward losses 1.5564962798851145
Unrolled forward base losses 2.565701273852575
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00): 0.11408883947165671
Training Loss (progress: 0.08): 0.11052734676648222
Training Loss (progress: 0.16): 0.09967060991957644
Training Loss (progress: 0.24): 0.10165280155611953
Training Loss (progress: 0.32): 0.11012640996310308
Training Loss (progress: 0.40): 0.10770918951431849
Training Loss (progress: 0.48): 0.10878395788718277
Training Loss (progress: 0.56): 0.11228216081032556
Training Loss (progress: 0.64): 0.09882114402631806
Training Loss (progress: 0.72): 0.10283978945804523
Training Loss (progress: 0.80): 0.11784179030553193
Training Loss (progress: 0.88): 0.10800015822897258
Training Loss (progress: 0.96): 0.11317756119700569
Evaluation on validation dataset:
Step 25, mean loss 0.0262074289961966
Step 50, mean loss 0.01498016166848913
Step 75, mean loss 0.024785784031408985
Step 100, mean loss 0.035538534862919226
Step 125, mean loss 0.034802857759509434
Step 150, mean loss 0.03816941156820608
Step 175, mean loss 0.0654886090224417
Step 200, mean loss 0.23718335416476047
Step 225, mean loss 0.1722235007504357
Unrolled forward losses 1.645128270038199
Unrolled forward base losses 2.565701273852575
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00): 0.1044125605744911
Training Loss (progress: 0.08): 0.10223487830755698
Training Loss (progress: 0.16): 0.09826808299897372
Training Loss (progress: 0.24): 0.10815865622271727
Training Loss (progress: 0.32): 0.10119751002847642
Training Loss (progress: 0.40): 0.10216178427741865
Training Loss (progress: 0.48): 0.10406021486896233
Training Loss (progress: 0.56): 0.10164309909060765
Training Loss (progress: 0.64): 0.11049844773163284
Training Loss (progress: 0.72): 0.10164023095760814
Training Loss (progress: 0.80): 0.10490148325771813
Training Loss (progress: 0.88): 0.10813003792121993
Training Loss (progress: 0.96): 0.10871572739676882
Evaluation on validation dataset:
Step 25, mean loss 0.02544158931768914
Step 50, mean loss 0.014338598619008127
Step 75, mean loss 0.023893523849191592
Step 100, mean loss 0.03507789767510181
Step 125, mean loss 0.033297840242750044
Step 150, mean loss 0.036423106105751855
Step 175, mean loss 0.0656042579332584
Step 200, mean loss 0.23872947097760483
Step 225, mean loss 0.17811817152434334
Unrolled forward losses 1.6562373166736108
Unrolled forward base losses 2.565701273852575
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00): 0.11225208526077038
Training Loss (progress: 0.08): 0.10542838799454994
Training Loss (progress: 0.16): 0.09077761509644508
Training Loss (progress: 0.24): 0.09772932809467247
Training Loss (progress: 0.32): 0.10150413203298334
Training Loss (progress: 0.40): 0.10147571693455484
Training Loss (progress: 0.48): 0.09977112450378162
Training Loss (progress: 0.56): 0.09253874100233625
Training Loss (progress: 0.64): 0.10063421598467875
Training Loss (progress: 0.72): 0.0981538731545254
Training Loss (progress: 0.80): 0.09876063137686061
Training Loss (progress: 0.88): 0.107675194840582
Training Loss (progress: 0.96): 0.09833207297860272
Evaluation on validation dataset:
Step 25, mean loss 0.024488844598545195
Step 50, mean loss 0.014196738908435383
Step 75, mean loss 0.023892531754691214
Step 100, mean loss 0.0329696474593254
Step 125, mean loss 0.032681131793328294
Step 150, mean loss 0.03604824823126486
Step 175, mean loss 0.06434072736043966
Step 200, mean loss 0.2332266827358795
Step 225, mean loss 0.1752526555797044
Unrolled forward losses 1.548181677442512
Unrolled forward base losses 2.565701273852575
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00): 0.10313862099976975
Training Loss (progress: 0.08): 0.09844806856747294
Training Loss (progress: 0.16): 0.09920537009791738
Training Loss (progress: 0.24): 0.10387681120978827
Training Loss (progress: 0.32): 0.10010353883820024
Training Loss (progress: 0.40): 0.11133399892444626
Training Loss (progress: 0.48): 0.11169933384556571
Training Loss (progress: 0.56): 0.10154453147496499
Training Loss (progress: 0.64): 0.10472801414945251
Training Loss (progress: 0.72): 0.11140613812748215
Training Loss (progress: 0.80): 0.09934481170333208
Training Loss (progress: 0.88): 0.1034071507851882
Training Loss (progress: 0.96): 0.10174114810890225
Evaluation on validation dataset:
Step 25, mean loss 0.025020797378901016
Step 50, mean loss 0.014903136052659057
Step 75, mean loss 0.023775324864684137
Step 100, mean loss 0.03453210959001989
Step 125, mean loss 0.03252059095523922
Step 150, mean loss 0.0355964053227516
Step 175, mean loss 0.06267363220426495
Step 200, mean loss 0.23594454100680062
Step 225, mean loss 0.17589727457550297
Unrolled forward losses 1.7437922758542161
Unrolled forward base losses 2.565701273852575
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00): 0.10333881339754138
Training Loss (progress: 0.08): 0.089744420576986
Training Loss (progress: 0.16): 0.10246410185642005
Training Loss (progress: 0.24): 0.10043492463495386
Training Loss (progress: 0.32): 0.10167904546295381
Training Loss (progress: 0.40): 0.09713162511865056
Training Loss (progress: 0.48): 0.10820755300143228
Training Loss (progress: 0.56): 0.093819597316584
Training Loss (progress: 0.64): 0.10209854673479542
Training Loss (progress: 0.72): 0.10797100300970905
Training Loss (progress: 0.80): 0.0978963042508205
Training Loss (progress: 0.88): 0.10614475569508457
Training Loss (progress: 0.96): 0.1038739731230019
Evaluation on validation dataset:
Step 25, mean loss 0.024497266069758415
Step 50, mean loss 0.013921061381530075
Step 75, mean loss 0.0240729151163736
Step 100, mean loss 0.031925691361512985
Step 125, mean loss 0.03201616742496199
Step 150, mean loss 0.035522091692095886
Step 175, mean loss 0.06417519839138003
Step 200, mean loss 0.2375592189764913
Step 225, mean loss 0.176581733199016
Unrolled forward losses 1.5641459089956875
Unrolled forward base losses 2.565701273852575
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00): 0.09950317572131318
Training Loss (progress: 0.08): 0.0976698485587381
Training Loss (progress: 0.16): 0.10538620371970368
Training Loss (progress: 0.24): 0.09495436702782865
Training Loss (progress: 0.32): 0.105076557451052
Training Loss (progress: 0.40): 0.10088773946008808
Training Loss (progress: 0.48): 0.09978711973105958
Training Loss (progress: 0.56): 0.10593118434881722
Training Loss (progress: 0.64): 0.10491533187330837
Training Loss (progress: 0.72): 0.10276450525537498
Training Loss (progress: 0.80): 0.10300151004818447
Training Loss (progress: 0.88): 0.09247768678689489
Training Loss (progress: 0.96): 0.10776485753260849
Evaluation on validation dataset:
Step 25, mean loss 0.02279857821135344
Step 50, mean loss 0.014007363369531898
Step 75, mean loss 0.023437021625523437
Step 100, mean loss 0.03297458987239515
Step 125, mean loss 0.03212066783752891
Step 150, mean loss 0.03529155498800915
Step 175, mean loss 0.06327536414009277
Step 200, mean loss 0.2372660330594702
Step 225, mean loss 0.17625577183507662
Unrolled forward losses 1.5331616702097988
Unrolled forward base losses 2.565701273852575
Evaluation on test dataset:
Step 25, mean loss 0.019143445838068845
Step 50, mean loss 0.009939708887461915
Step 75, mean loss 0.016272243856842422
Step 100, mean loss 0.019064416662936467
Step 125, mean loss 0.027680503309662784
Step 150, mean loss 0.03493828963853428
Step 175, mean loss 0.05444808876218099
Step 200, mean loss 0.1141266728693957
Step 225, mean loss 0.07678013667646291
Unrolled forward losses 1.2875091367316094
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_CE_E1_xresolution100-200_n6_s0.01_tw25_unrolling2_time328213.pt

Test loss: 1.2875091367316094
