Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.01_tw25_unrolling2_time531342.tar
Number of parameters: 1035587
Epoch 0
Starting epoch 0...
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): -6.47062e-03, -3.53849e-02, -1.66272e-01, -3.55151e-02, 7.44696e-02, 1.84902e-01
Node: 01 (pos: 0.010): -5.94631e-03, -3.39492e-02, -1.66225e-01, -3.54668e-02, 7.49381e-02, 1.82978e-01
Node: 02 (pos: 0.020): -5.41597e-03, -3.25041e-02, -1.66186e-01, -3.54260e-02, 7.54098e-02, 1.81049e-01
Node: 03 (pos: 0.030): -4.87963e-03, -3.10494e-02, -1.66156e-01, -3.53927e-02, 7.58848e-02, 1.79117e-01
Node: 04 (pos: 0.040): -4.33728e-03, -2.95852e-02, -1.66135e-01, -3.53667e-02, 7.63632e-02, 1.77181e-01
Node: 05 (pos: 0.051): -3.78894e-03, -2.81115e-02, -1.66123e-01, -3.53483e-02, 7.68450e-02, 1.75241e-01
-
Node: 07 (pos: 0.071): -3.78894e-03, -2.81115e-02, -1.66123e-01, -3.53483e-02, 7.68450e-02, 1.75241e-01
Node: 08 (pos: 0.081): -4.33728e-03, -2.95852e-02, -1.66135e-01, -3.53667e-02, 7.63632e-02, 1.77181e-01
Node: 09 (pos: 0.091): -4.87963e-03, -3.10494e-02, -1.66156e-01, -3.53927e-02, 7.58848e-02, 1.79117e-01
Node: 10 (pos: 0.101): -5.41597e-03, -3.25041e-02, -1.66186e-01, -3.54260e-02, 7.54098e-02, 1.81049e-01
Node: 11 (pos: 0.111): -5.94631e-03, -3.39492e-02, -1.66225e-01, -3.54668e-02, 7.49381e-02, 1.82978e-01
Node: 12 (pos: 0.121): -6.47062e-03, -3.53849e-02, -1.66272e-01, -3.55151e-02, 7.44696e-02, 1.84902e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 9.95822e-01, 8.82313e-01, 6.29982e-02, 8.81498e-01, 5.74318e-01, 3.27495e-02
Node: 01 (pos: 0.010): 9.96470e-01, 8.91139e-01, 6.30983e-02, 8.81800e-01, 5.70312e-01, 3.51517e-02
Node: 02 (pos: 0.020): 9.97071e-01, 8.99738e-01, 6.31798e-02, 8.82056e-01, 5.66282e-01, 3.77077e-02
Node: 03 (pos: 0.030): 9.97622e-01, 9.08095e-01, 6.32425e-02, 8.82264e-01, 5.62226e-01, 4.04253e-02
Node: 04 (pos: 0.040): 9.98121e-01, 9.16193e-01, 6.32863e-02, 8.82426e-01, 5.58146e-01, 4.33125e-02
Node: 05 (pos: 0.051): 9.98565e-01, 9.24016e-01, 6.33113e-02, 8.82541e-01, 5.54042e-01, 4.63772e-02
-
Node: 07 (pos: 0.071): 9.98565e-01, 9.24016e-01, 6.33113e-02, 8.82541e-01, 5.54042e-01, 4.63772e-02
Node: 08 (pos: 0.081): 9.98121e-01, 9.16193e-01, 6.32863e-02, 8.82426e-01, 5.58146e-01, 4.33125e-02
Node: 09 (pos: 0.091): 9.97622e-01, 9.08095e-01, 6.32425e-02, 8.82264e-01, 5.62226e-01, 4.04253e-02
Node: 10 (pos: 0.101): 9.97071e-01, 8.99738e-01, 6.31798e-02, 8.82056e-01, 5.66282e-01, 3.77077e-02
Node: 11 (pos: 0.111): 9.96470e-01, 8.91139e-01, 6.30983e-02, 8.81800e-01, 5.70312e-01, 3.51517e-02
Node: 12 (pos: 0.121): 9.95822e-01, 8.82313e-01, 6.29982e-02, 8.81498e-01, 5.74318e-01, 3.27495e-02
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): -3.78894e-03, -2.81115e-02, -1.66123e-01, -3.53483e-02, 7.68450e-02, 1.75241e-01
Node: 01 (pos: 0.010): -4.33728e-03, -2.95852e-02, -1.66135e-01, -3.53667e-02, 7.63632e-02, 1.77181e-01
Node: 02 (pos: 0.020): -4.87963e-03, -3.10494e-02, -1.66156e-01, -3.53927e-02, 7.58848e-02, 1.79117e-01
Node: 03 (pos: 0.030): -5.41597e-03, -3.25041e-02, -1.66186e-01, -3.54260e-02, 7.54098e-02, 1.81049e-01
Node: 04 (pos: 0.040): -5.94631e-03, -3.39492e-02, -1.66225e-01, -3.54668e-02, 7.49381e-02, 1.82978e-01
Node: 05 (pos: 0.051): -6.47062e-03, -3.53849e-02, -1.66272e-01, -3.55151e-02, 7.44696e-02, 1.84902e-01
-
Node: 07 (pos: 0.071): -5.94631e-03, -3.39492e-02, -1.66225e-01, -3.54668e-02, 7.49381e-02, 1.82978e-01
Node: 08 (pos: 0.081): -5.41597e-03, -3.25041e-02, -1.66186e-01, -3.54260e-02, 7.54098e-02, 1.81049e-01
Node: 09 (pos: 0.091): -4.87963e-03, -3.10494e-02, -1.66156e-01, -3.53927e-02, 7.58848e-02, 1.79117e-01
Node: 10 (pos: 0.101): -4.33728e-03, -2.95852e-02, -1.66135e-01, -3.53667e-02, 7.63632e-02, 1.77181e-01
Node: 11 (pos: 0.111): -3.78894e-03, -2.81115e-02, -1.66123e-01, -3.53483e-02, 7.68450e-02, 1.75241e-01
Node: 12 (pos: 0.121): -6.47062e-03, -3.53849e-02, -1.66272e-01, -3.55151e-02, 7.44696e-02, 1.84902e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.98565e-01, 9.24016e-01, 6.33113e-02, 8.82541e-01, 5.54042e-01, 4.63772e-02
Node: 58 (pos: 0.586): 9.98121e-01, 9.16193e-01, 6.32863e-02, 8.82426e-01, 5.58146e-01, 4.33125e-02
Node: 59 (pos: 0.596): 9.97622e-01, 9.08095e-01, 6.32425e-02, 8.82264e-01, 5.62226e-01, 4.04253e-02
Node: 60 (pos: 0.606): 9.97071e-01, 8.99738e-01, 6.31798e-02, 8.82056e-01, 5.66282e-01, 3.77077e-02
Node: 61 (pos: 0.616): 9.96470e-01, 8.91139e-01, 6.30983e-02, 8.81800e-01, 5.70312e-01, 3.51517e-02
Node: 50 (pos: 0.505): 9.95822e-01, 8.82313e-01, 6.29982e-02, 8.81498e-01, 5.74318e-01, 3.27495e-02
-
Node: 51 (pos: 0.515): 9.96470e-01, 8.91139e-01, 6.30983e-02, 8.81800e-01, 5.70312e-01, 3.51517e-02
Node: 52 (pos: 0.525): 9.97071e-01, 8.99738e-01, 6.31798e-02, 8.82056e-01, 5.66282e-01, 3.77077e-02
Node: 53 (pos: 0.535): 9.97622e-01, 9.08095e-01, 6.32425e-02, 8.82264e-01, 5.62226e-01, 4.04253e-02
Node: 54 (pos: 0.545): 9.98121e-01, 9.16193e-01, 6.32863e-02, 8.82426e-01, 5.58146e-01, 4.33125e-02
Node: 55 (pos: 0.556): 9.98565e-01, 9.24016e-01, 6.33113e-02, 8.82541e-01, 5.54042e-01, 4.63772e-02
Node: 62 (pos: 0.626): 9.95822e-01, 8.82313e-01, 6.29982e-02, 8.81498e-01, 5.74318e-01, 3.27495e-02
=========================================================================================================
Training Loss (progress: 0.00), 1.3272556261729607, -1.8928756634438204e-09, 3.472652663715096e-10, -2.9389033646070134e-09, 1.6251193722987344e-08, -1.8014438457597667e-08, -1.2577330148918474e-08, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.08), 0.25915812746637173, 2.374360939914512e-08, -9.562934108064852e-08, 1.4993624020775003e-08, -5.34115978001581e-07, 2.1238505196365414e-07, 9.471098158446163e-08, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.16), 0.2117741209457656, -5.239853932257518e-08, 6.177964203889047e-08, -2.8034777375755034e-07, -9.094536908832979e-07, 2.892471537773241e-07, 3.48616404894437e-07, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.24), 0.18172801841724517, -8.232196444812542e-08, 2.37842670099799e-07, -2.4974118458163526e-07, 2.541340646246328e-06, -1.1891430353370253e-07, 5.513713705036514e-07, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.32), 0.16497530258680151, 1.0684062598577676e-08, -2.0178767967692706e-07, 2.441675913987333e-08, -1.0613770633956344e-05, 1.1322692429439204e-06, 4.789125852241665e-07, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.40), 0.14152072233635607, -1.4811930026516394e-07, 1.0153055807999798e-07, -1.6359902807464333e-07, -1.792146217345144e-06, 2.4967287334175797e-07, 1.2959300515070617e-06, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.48), 0.13932796980968437, -3.749840175308649e-08, 5.942425678395366e-08, -1.2992270873953053e-07, -2.5647261925268396e-06, 2.1410418973868324e-07, 6.691468500630408e-07, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.56), 0.13003481344138396, -2.5510961670317473e-08, 1.1457878892888403e-07, -4.5369168472140833e-07, -2.8085228052573632e-06, 2.677723902740572e-07, 3.4009963000826055e-07, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.64), 0.11894659949343979, 1.7917564427874702e-07, -1.3445958793971358e-07, -3.4356446039114353e-07, -1.2945487406805565e-05, 1.0135488956320887e-06, 3.490447241202949e-08, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.72), 0.10459824906540605, -3.5657685033522874e-08, 4.145369691912739e-08, -5.403642103610469e-07, -3.4388937223354463e-06, 4.4743253074231924e-07, 2.341860263069517e-07, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.80), 0.11404459082916717, 1.3854392487464086e-07, -2.15356275847313e-07, 5.325236908990183e-07, -1.1541147824522999e-06, -3.111171462757627e-07, -1.2639885964873864e-06, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.88), 0.09578166266928172, 1.3988770867800107e-08, -7.016836033597824e-08, 1.1743292851964186e-07, -1.8989280062561232e-06, 1.0257580975213492e-07, 1.8047541814089105e-07, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Training Loss (progress: 0.96), 0.09628943712073956, -5.361868748289222e-08, 2.2114969734915916e-07, -1.1764834456987332e-06, -1.2897243490008162e-05, 1.4926051260575297e-06, 5.005011850990407e-07, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Evaluation on validation dataset:
