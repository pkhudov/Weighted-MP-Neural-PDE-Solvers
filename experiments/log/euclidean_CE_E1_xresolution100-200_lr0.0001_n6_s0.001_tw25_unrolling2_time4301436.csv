Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar
Number of parameters: 1031651.0
Epoch 0
Starting epoch 0...
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Training Loss (progress: 0.00), 1.2985584082024801, [0.004284835373256464, 0.009407144325250923, 0.009120045377804406, 0.008812950623420532, 0.009238498987742904, 0.009297753017869054]
Training Loss (progress: 0.08), 0.2401208178139616, [0.0057514223556628715, 0.004426820879746382, 0.0005508540659799595, 0.00141142367558114, 0.0020388161077544995, 0.0043677391218024456]
Training Loss (progress: 0.16), 0.1904316626051079, [0.004323285481588569, 0.006360519047878791, 0.0005559647730551574, 0.0016356708759964933, 0.0022945439529083065, 0.006135123980896009]
Training Loss (progress: 0.24), 0.16542843375909153, [0.004079193804291723, 0.006736325698067337, 0.0005394150933679384, 0.0018945973465533243, 0.0025142191130352255, 0.007634039956633332]
Training Loss (progress: 0.32), 0.14491647561649973, [0.003870116645291405, 0.007811908073003692, 0.0004944724688533034, 0.001992529422862822, 0.0024266230367833313, 0.008654819359738247]
Training Loss (progress: 0.40), 0.14008978775965156, [0.00384081906607499, 0.009236855054164717, 0.0005794714655162986, 0.001816583493614148, 0.0025943378570614443, 0.009367804889578814]
Training Loss (progress: 0.48), 0.12178464643872093, [0.003730179039011872, 0.00908001481117655, 0.000493063956090554, 0.002113732763142373, 0.0025465088014420545, 0.010381438541743917]
Training Loss (progress: 0.56), 0.1112456884906478, [0.003591206091978861, 0.008929394527463573, 0.000528171154496028, 0.0018841285078376577, 0.00245523425074355, 0.01121515458436281]
Training Loss (progress: 0.64), 0.11516062813969516, [0.003388283744448356, 0.00957581449415352, 0.0004517918176296187, 0.002030737436866488, 0.0022994876366940046, 0.011834777715963094]
Training Loss (progress: 0.72), 0.10314684653874932, [0.003407906558389503, 0.010707561745312347, 0.0005453668189177853, 0.0019047044740806009, 0.0024349248966296583, 0.012950365307492495]
Training Loss (progress: 0.80), 0.10356098504599909, [0.0032679306584599815, 0.010099062182435338, 0.0004993434736310275, 0.001997531486382588, 0.0023687906639518045, 0.013862982645986044]
Training Loss (progress: 0.88), 0.09607408145517805, [0.003254996276779175, 0.010626479813222865, 0.0005512502458922068, 0.0019572824132718797, 0.002395357425468382, 0.014481398336267952]
Training Loss (progress: 0.96), 0.10807142224754933, [0.003146850834727192, 0.011127751153070176, 0.0005540456842583184, 0.0018858261466257783, 0.0024226199719503782, 0.015384974304257084]
Evaluation on validation dataset:
Step 25, mean loss 0.060237526430864025
Step 50, mean loss 0.09005079542107353
Step 75, mean loss 0.14186856596838573
Step 100, mean loss 0.26605950511330845
Step 125, mean loss 0.1619721399021078
Step 150, mean loss 0.1601271003685189
Step 175, mean loss 0.25978378072967834
Step 200, mean loss 0.3801935947563212
Step 225, mean loss 0.4584682427680281
Unrolled forward losses 17.277738217794848
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.20616e-01, 7.32846e-01, 1.12121e-03, 1.45858e-01, 2.23583e-01, 7.90396e-01
Node: 01 (pos: 0.010): 4.53872e-01, 8.05859e-01, 8.93658e-03, 2.62661e-01, 3.53363e-01, 8.49296e-01
Node: 02 (pos: 0.020): 6.03167e-01, 8.70975e-01, 4.88371e-02, 4.25024e-01, 5.13880e-01, 9.00736e-01
Node: 03 (pos: 0.030): 7.52482e-01, 9.25237e-01, 1.82988e-01, 6.17992e-01, 6.87638e-01, 9.42890e-01
Node: 04 (pos: 0.040): 8.81271e-01, 9.66054e-01, 4.70097e-01, 8.07427e-01, 8.46673e-01, 9.74203e-01
Node: 05 (pos: 0.051): 9.68896e-01, 9.91403e-01, 8.28031e-01, 9.47929e-01, 9.59244e-01, 9.93487e-01
-
Node: 07 (pos: 0.071): 9.68896e-01, 9.91403e-01, 8.28031e-01, 9.47929e-01, 9.59244e-01, 9.93487e-01
Node: 08 (pos: 0.081): 8.81271e-01, 9.66054e-01, 4.70097e-01, 8.07427e-01, 8.46673e-01, 9.74203e-01
Node: 09 (pos: 0.091): 7.52482e-01, 9.25237e-01, 1.82988e-01, 6.17992e-01, 6.87638e-01, 9.42890e-01
Node: 10 (pos: 0.101): 6.03167e-01, 8.70975e-01, 4.88371e-02, 4.25024e-01, 5.13880e-01, 9.00736e-01
Node: 11 (pos: 0.111): 4.53872e-01, 8.05859e-01, 8.93658e-03, 2.62661e-01, 3.53363e-01, 8.49296e-01
Node: 12 (pos: 0.121): 3.20616e-01, 7.32846e-01, 1.12121e-03, 1.45858e-01, 2.23583e-01, 7.90396e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.68896e-01, 9.91403e-01, 8.28031e-01, 9.47929e-01, 9.59244e-01, 9.93487e-01
Node: 58 (pos: 0.586): 8.81271e-01, 9.66054e-01, 4.70097e-01, 8.07427e-01, 8.46673e-01, 9.74203e-01
Node: 59 (pos: 0.596): 7.52482e-01, 9.25237e-01, 1.82988e-01, 6.17992e-01, 6.87638e-01, 9.42890e-01
Node: 60 (pos: 0.606): 6.03167e-01, 8.70975e-01, 4.88371e-02, 4.25024e-01, 5.13880e-01, 9.00736e-01
Node: 61 (pos: 0.616): 4.53872e-01, 8.05859e-01, 8.93658e-03, 2.62661e-01, 3.53363e-01, 8.49296e-01
Node: 50 (pos: 0.505): 3.20616e-01, 7.32846e-01, 1.12121e-03, 1.45858e-01, 2.23583e-01, 7.90396e-01
-
Node: 51 (pos: 0.515): 4.53872e-01, 8.05859e-01, 8.93658e-03, 2.62661e-01, 3.53363e-01, 8.49296e-01
Node: 52 (pos: 0.525): 6.03167e-01, 8.70975e-01, 4.88371e-02, 4.25024e-01, 5.13880e-01, 9.00736e-01
Node: 53 (pos: 0.535): 7.52482e-01, 9.25237e-01, 1.82988e-01, 6.17992e-01, 6.87638e-01, 9.42890e-01
Node: 54 (pos: 0.545): 8.81271e-01, 9.66054e-01, 4.70097e-01, 8.07427e-01, 8.46673e-01, 9.74203e-01
Node: 55 (pos: 0.556): 9.68896e-01, 9.91403e-01, 8.28031e-01, 9.47929e-01, 9.59244e-01, 9.93487e-01
Node: 62 (pos: 0.626): 3.20616e-01, 7.32846e-01, 1.12121e-03, 1.45858e-01, 2.23583e-01, 7.90396e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.05275076720787435
Step 50, mean loss 0.07209949360390654
Step 75, mean loss 0.1223640324271375
Step 100, mean loss 0.11448427126017224
Step 125, mean loss 0.3168518735033588
Step 150, mean loss 0.14705728772404936
Step 175, mean loss 0.287122864605585
Step 200, mean loss 0.31029268647636804
Step 225, mean loss 0.22119595331894415
Unrolled forward losses 14.771282873346044
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.22271534421433245, [0.003253955814006331, 0.012450096959671994, 0.0005415780743506658, 0.002081111318462025, 0.002632348515111673, 0.01594124199001982]
Training Loss (progress: 0.08), 0.24095116058258226, [0.0038172049878466754, 0.014964290595062263, 0.0006411461353970175, 0.002026139134595361, 0.0026575227113057286, 0.01933980642585753]
Training Loss (progress: 0.16), 0.19616811300078274, [0.003935456493315789, 0.019563748116948675, 0.0006764688769475669, 0.002124020650773108, 0.0024799163246862583, 0.02249199070402531]
Training Loss (progress: 0.24), 0.21063509856159918, [0.004284467136659512, 0.022865723832529404, 0.0006068002608494407, 0.0022221322879390493, 0.0028305161052045464, 0.0250868820512691]
Training Loss (progress: 0.32), 0.18427413501082288, [0.004367417242366891, 0.026310247954775434, 0.0005445077834137746, 0.0021174913347447423, 0.0025035242008484985, 0.02736075107005653]
Training Loss (progress: 0.40), 0.18881285413870794, [0.0042484188633817475, 0.029107355241227047, 0.0006079441039315662, 0.002203602624333129, 0.0030937980669382744, 0.02991651730041881]
Training Loss (progress: 0.48), 0.18889927937658751, [0.004332070485988776, 0.032495741479351505, 0.0007006808610605231, 0.002055891575082832, 0.0028996476914633284, 0.032130817126148244]
Training Loss (progress: 0.56), 0.18249877085123892, [0.004209715292963967, 0.0353746459848337, 0.0006217900137859157, 0.002263903303551143, 0.0028798290355016563, 0.03429926900020588]
Training Loss (progress: 0.64), 0.17094164910744575, [0.004351231905352117, 0.03867377337894727, 0.0006141781949427292, 0.002263743428970808, 0.002914950397505277, 0.03571518071339131]
Training Loss (progress: 0.72), 0.17138191593634947, [0.0042114085823123145, 0.04147968389278175, 0.0007150616914860906, 0.0020439521652824144, 0.00315416471314801, 0.03715047341196541]
Training Loss (progress: 0.80), 0.20265938020719676, [0.004387204673162582, 0.04478288524597521, 0.0008348168079450259, 0.0020355650630975663, 0.0030140346580497506, 0.03902039707404576]
Training Loss (progress: 0.88), 0.15395415900885948, [0.004283802284074357, 0.04730669036394612, 0.0006316639433639002, 0.002266608411425987, 0.002831412624032532, 0.04051415689697718]
Training Loss (progress: 0.96), 0.1616259789558905, [0.004244242901048033, 0.050535356671461605, 0.0006813135717996624, 0.0021303423433380233, 0.0026665376794913808, 0.04181057062274091]
Evaluation on validation dataset:
Step 25, mean loss 0.12385785472993244
Step 50, mean loss 0.08951652445744782
Step 75, mean loss 0.12025998237945115
Step 100, mean loss 0.13589021587036892
Step 125, mean loss 0.17840396370871403
Step 150, mean loss 0.12914827645286686
Step 175, mean loss 0.19401073306850247
Step 200, mean loss 0.5110902248956468
Step 225, mean loss 0.38629972808073354
Unrolled forward losses 5.250904555762706
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.44764e-01, 9.30847e-01, 5.23536e-03, 1.87991e-01, 3.18246e-01, 9.16588e-01
Node: 01 (pos: 0.010): 5.69699e-01, 9.51454e-01, 2.60576e-02, 3.13277e-01, 4.51540e-01, 9.41309e-01
Node: 02 (pos: 0.020): 6.97611e-01, 9.68653e-01, 9.68721e-02, 4.75767e-01, 6.01181e-01, 9.62030e-01
Node: 03 (pos: 0.030): 8.16643e-01, 9.82244e-01, 2.68990e-01, 6.58467e-01, 7.51088e-01, 9.78461e-01
Node: 04 (pos: 0.040): 9.13910e-01, 9.92069e-01, 5.57891e-01, 8.30517e-01, 8.80545e-01, 9.90369e-01
Node: 05 (pos: 0.051): 9.77745e-01, 9.98011e-01, 8.64246e-01, 9.54635e-01, 9.68697e-01, 9.97584e-01
-
Node: 07 (pos: 0.071): 9.77745e-01, 9.98011e-01, 8.64246e-01, 9.54635e-01, 9.68697e-01, 9.97584e-01
Node: 08 (pos: 0.081): 9.13910e-01, 9.92069e-01, 5.57891e-01, 8.30517e-01, 8.80545e-01, 9.90369e-01
Node: 09 (pos: 0.091): 8.16643e-01, 9.82244e-01, 2.68990e-01, 6.58467e-01, 7.51088e-01, 9.78461e-01
Node: 10 (pos: 0.101): 6.97611e-01, 9.68653e-01, 9.68721e-02, 4.75767e-01, 6.01181e-01, 9.62030e-01
Node: 11 (pos: 0.111): 5.69699e-01, 9.51454e-01, 2.60576e-02, 3.13277e-01, 4.51540e-01, 9.41309e-01
Node: 12 (pos: 0.121): 4.44764e-01, 9.30847e-01, 5.23536e-03, 1.87991e-01, 3.18246e-01, 9.16588e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.77745e-01, 9.98011e-01, 8.64246e-01, 9.54635e-01, 9.68697e-01, 9.97584e-01
Node: 58 (pos: 0.586): 9.13910e-01, 9.92069e-01, 5.57891e-01, 8.30517e-01, 8.80545e-01, 9.90369e-01
Node: 59 (pos: 0.596): 8.16643e-01, 9.82244e-01, 2.68990e-01, 6.58467e-01, 7.51088e-01, 9.78461e-01
Node: 60 (pos: 0.606): 6.97611e-01, 9.68653e-01, 9.68721e-02, 4.75767e-01, 6.01181e-01, 9.62030e-01
Node: 61 (pos: 0.616): 5.69699e-01, 9.51454e-01, 2.60576e-02, 3.13277e-01, 4.51540e-01, 9.41309e-01
Node: 50 (pos: 0.505): 4.44764e-01, 9.30847e-01, 5.23536e-03, 1.87991e-01, 3.18246e-01, 9.16588e-01
-
Node: 51 (pos: 0.515): 5.69699e-01, 9.51454e-01, 2.60576e-02, 3.13277e-01, 4.51540e-01, 9.41309e-01
Node: 52 (pos: 0.525): 6.97611e-01, 9.68653e-01, 9.68721e-02, 4.75767e-01, 6.01181e-01, 9.62030e-01
Node: 53 (pos: 0.535): 8.16643e-01, 9.82244e-01, 2.68990e-01, 6.58467e-01, 7.51088e-01, 9.78461e-01
Node: 54 (pos: 0.545): 9.13910e-01, 9.92069e-01, 5.57891e-01, 8.30517e-01, 8.80545e-01, 9.90369e-01
Node: 55 (pos: 0.556): 9.77745e-01, 9.98011e-01, 8.64246e-01, 9.54635e-01, 9.68697e-01, 9.97584e-01
Node: 62 (pos: 0.626): 4.44764e-01, 9.30847e-01, 5.23536e-03, 1.87991e-01, 3.18246e-01, 9.16588e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.09849024640312151
Step 50, mean loss 0.06428955263701952
Step 75, mean loss 0.08345728689345247
Step 100, mean loss 0.08942890387708047
Step 125, mean loss 0.1464751664877905
Step 150, mean loss 0.12216472658600361
Step 175, mean loss 0.1760244738252163
Step 200, mean loss 0.20778184770122501
Step 225, mean loss 0.2151108272844352
Unrolled forward losses 4.452203163338076
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.24067624004999993, [0.004464627786184297, 0.0514622852990621, 0.0006342944075578257, 0.0023972592348866367, 0.003043746761989381, 0.04224205261359452]
Training Loss (progress: 0.08), 0.21556101943864908, [0.004331558978298972, 0.053429051768643626, 0.0006574500358981341, 0.0022915902126860017, 0.0032702340897867127, 0.043504472505454465]
Training Loss (progress: 0.16), 0.19541363002550743, [0.00441017290126175, 0.05509472344798474, 0.0006127476968672683, 0.0022378638859424497, 0.0030619672331880232, 0.044603339173071604]
Training Loss (progress: 0.24), 0.20454030216021996, [0.004358362549587938, 0.05630536639269242, 0.0006393198230662009, 0.0023221597070467196, 0.003194195737697002, 0.045266498259284624]
Training Loss (progress: 0.32), 0.21613541489010096, [0.0044313056981908705, 0.05833992551980546, 0.0006555443540857196, 0.0022881340732265154, 0.003068157141548417, 0.04640024945507143]
Training Loss (progress: 0.40), 0.20622196304865203, [0.004434533243194369, 0.06006517098473807, 0.0006631517906284224, 0.0021863282896796513, 0.003149297559547032, 0.047328124155665265]
Training Loss (progress: 0.48), 0.20626310432148226, [0.00449579061249227, 0.061370999041623894, 0.0006685320910901264, 0.002267873709200594, 0.0030997707001211004, 0.048294262258690136]
Training Loss (progress: 0.56), 0.22846949237915212, [0.004538187796275719, 0.06238924834932274, 0.0006311378384870137, 0.002227026944825085, 0.0029723104554836752, 0.04902217855018592]
Training Loss (progress: 0.64), 0.21967454094445663, [0.0044236531472569025, 0.0636559947144824, 0.000661979064779607, 0.002240900488069116, 0.003318839422432509, 0.04995349646745631]
Training Loss (progress: 0.72), 0.17010838288436442, [0.0044960009305481715, 0.06473770134785888, 0.0006585501589304923, 0.002177588762687938, 0.0032034843104479767, 0.050790609254692594]
Training Loss (progress: 0.80), 0.20187061127945669, [0.004538711893820679, 0.06688613083808478, 0.0006553413893612776, 0.0022988145853511744, 0.003269497763382959, 0.05157998594625969]
Training Loss (progress: 0.88), 0.19647570243201873, [0.004624254995933714, 0.06820426702446933, 0.0006495972150972001, 0.0023114331555346783, 0.0033838549653377684, 0.052454493833276494]
Training Loss (progress: 0.96), 0.19331320563301535, [0.004568962836376887, 0.06958789226753954, 0.0006120178062586766, 0.002377637301625151, 0.003396929487296687, 0.05366202819691712]
Evaluation on validation dataset:
Step 25, mean loss 0.07924189178129738
Step 50, mean loss 0.051848174140572204
Step 75, mean loss 0.059824245089945355
Step 100, mean loss 0.08117866231188178
Step 125, mean loss 0.1054515109051467
Step 150, mean loss 0.0836634736309967
Step 175, mean loss 0.11911829085697112
Step 200, mean loss 0.3115148913501343
Step 225, mean loss 0.24346129314162235
Unrolled forward losses 3.845229593806061
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.45553e-01, 9.49421e-01, 5.23386e-03, 1.98667e-01, 3.13317e-01, 9.34074e-01
Node: 01 (pos: 0.010): 5.70400e-01, 9.64598e-01, 2.60524e-02, 3.25528e-01, 4.46672e-01, 9.53743e-01
Node: 02 (pos: 0.020): 6.98160e-01, 9.77196e-01, 9.68597e-02, 4.87592e-01, 5.97025e-01, 9.70144e-01
Node: 03 (pos: 0.030): 8.17005e-01, 9.87108e-01, 2.68971e-01, 6.67624e-01, 7.48163e-01, 9.83095e-01
Node: 04 (pos: 0.040): 9.14090e-01, 9.94250e-01, 5.57874e-01, 8.35630e-01, 8.79019e-01, 9.92451e-01
Node: 05 (pos: 0.051): 9.77794e-01, 9.98559e-01, 8.64239e-01, 9.56100e-01, 9.68277e-01, 9.98107e-01
-
Node: 07 (pos: 0.071): 9.77794e-01, 9.98559e-01, 8.64239e-01, 9.56100e-01, 9.68277e-01, 9.98107e-01
Node: 08 (pos: 0.081): 9.14090e-01, 9.94250e-01, 5.57874e-01, 8.35630e-01, 8.79019e-01, 9.92451e-01
Node: 09 (pos: 0.091): 8.17005e-01, 9.87108e-01, 2.68971e-01, 6.67624e-01, 7.48163e-01, 9.83095e-01
Node: 10 (pos: 0.101): 6.98160e-01, 9.77196e-01, 9.68597e-02, 4.87592e-01, 5.97025e-01, 9.70144e-01
Node: 11 (pos: 0.111): 5.70400e-01, 9.64598e-01, 2.60524e-02, 3.25528e-01, 4.46672e-01, 9.53743e-01
Node: 12 (pos: 0.121): 4.45553e-01, 9.49421e-01, 5.23386e-03, 1.98667e-01, 3.13317e-01, 9.34074e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.77794e-01, 9.98559e-01, 8.64239e-01, 9.56100e-01, 9.68277e-01, 9.98107e-01
Node: 58 (pos: 0.586): 9.14090e-01, 9.94250e-01, 5.57874e-01, 8.35630e-01, 8.79019e-01, 9.92451e-01
Node: 59 (pos: 0.596): 8.17005e-01, 9.87108e-01, 2.68971e-01, 6.67624e-01, 7.48163e-01, 9.83095e-01
Node: 60 (pos: 0.606): 6.98160e-01, 9.77196e-01, 9.68597e-02, 4.87592e-01, 5.97025e-01, 9.70144e-01
Node: 61 (pos: 0.616): 5.70400e-01, 9.64598e-01, 2.60524e-02, 3.25528e-01, 4.46672e-01, 9.53743e-01
Node: 50 (pos: 0.505): 4.45553e-01, 9.49421e-01, 5.23386e-03, 1.98667e-01, 3.13317e-01, 9.34074e-01
-
Node: 51 (pos: 0.515): 5.70400e-01, 9.64598e-01, 2.60524e-02, 3.25528e-01, 4.46672e-01, 9.53743e-01
Node: 52 (pos: 0.525): 6.98160e-01, 9.77196e-01, 9.68597e-02, 4.87592e-01, 5.97025e-01, 9.70144e-01
Node: 53 (pos: 0.535): 8.17005e-01, 9.87108e-01, 2.68971e-01, 6.67624e-01, 7.48163e-01, 9.83095e-01
Node: 54 (pos: 0.545): 9.14090e-01, 9.94250e-01, 5.57874e-01, 8.35630e-01, 8.79019e-01, 9.92451e-01
Node: 55 (pos: 0.556): 9.77794e-01, 9.98559e-01, 8.64239e-01, 9.56100e-01, 9.68277e-01, 9.98107e-01
Node: 62 (pos: 0.626): 4.45553e-01, 9.49421e-01, 5.23386e-03, 1.98667e-01, 3.13317e-01, 9.34074e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.06083568239080429
Step 50, mean loss 0.04150268646329085
Step 75, mean loss 0.05508283411491112
Step 100, mean loss 0.06053274628319034
Step 125, mean loss 0.0942973430783684
Step 150, mean loss 0.09191926338513219
Step 175, mean loss 0.1667186390828801
Step 200, mean loss 0.16593953758715815
Step 225, mean loss 0.12271254206983243
Unrolled forward losses 3.0535023202512868
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.1914409748461298, [0.004500828739459705, 0.07104864946151777, 0.0006770902626437547, 0.002352535378531977, 0.003341906331484705, 0.053806080196471415]
Training Loss (progress: 0.08), 0.20256791615731679, [0.004603962348203689, 0.07250933028019654, 0.0006776542602383923, 0.0023184713999257083, 0.0032077472077157152, 0.054704395706509916]
Training Loss (progress: 0.16), 0.19040644854805003, [0.004366674610618327, 0.07385679902416595, 0.0006589453448570015, 0.0022153115897139354, 0.0032029107732809443, 0.055263064788216944]
Training Loss (progress: 0.24), 0.18200557611175147, [0.004391159211294366, 0.07531967716721823, 0.00062572492169979, 0.0023131151892364934, 0.003322618277197683, 0.05634373479759511]
Training Loss (progress: 0.32), 0.18628037876767664, [0.004644281277066402, 0.07646342832170996, 0.0007060537426449667, 0.002211251739323795, 0.00342541753786313, 0.057369589866788584]
Training Loss (progress: 0.40), 0.19237633255369568, [0.004584172862136266, 0.07847191158040319, 0.0006833990264022336, 0.0022963015620591555, 0.003253092043767063, 0.057759014488134114]
Training Loss (progress: 0.48), 0.20303418002346588, [0.004478705568882958, 0.07965477704742391, 0.0008795865642539346, 0.002262791483188901, 0.003368333307158944, 0.05836814628897328]
Training Loss (progress: 0.56), 0.18527498904741316, [0.004445937455661365, 0.08097263725592208, 0.0006328063110730925, 0.002296137620658156, 0.003204502096894008, 0.05930728142073272]
Training Loss (progress: 0.64), 0.19652308443137498, [0.004546228027636797, 0.08242374958205047, 0.0006312729602282515, 0.002296055046711035, 0.003071911060256672, 0.05954119422914387]
Training Loss (progress: 0.72), 0.1745274052745071, [0.004440282426710405, 0.08379004609354415, 0.0006640093730671368, 0.002236382639165074, 0.003355083556371932, 0.06019791163115272]
Training Loss (progress: 0.80), 0.19606365936646072, [0.004669985802367478, 0.08532259493467417, 0.0007100722577777979, 0.002236362293381742, 0.0033418668515273497, 0.06107172639820943]
Training Loss (progress: 0.88), 0.18214485791319796, [0.004665118991055364, 0.08687585906893945, 0.0006858138097507745, 0.0022490809276867058, 0.0033887719310975927, 0.061387186926988295]
Training Loss (progress: 0.96), 0.18590126914751803, [0.0045348276710557404, 0.0882893225883093, 0.0006487841869845183, 0.0022414280709641327, 0.0034699262914696764, 0.061986428609745584]
Evaluation on validation dataset:
Step 25, mean loss 0.08606855048351697
Step 50, mean loss 0.03679486013151089
Step 75, mean loss 0.0404203208377118
Step 100, mean loss 0.05707145350228787
Step 125, mean loss 0.073096425767517
Step 150, mean loss 0.058373183072182255
Step 175, mean loss 0.10143152556628574
Step 200, mean loss 0.29022015130029044
Step 225, mean loss 0.3080583192634798
Unrolled forward losses 2.901949896963959
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.53914e-01, 9.59568e-01, 3.78227e-03, 2.01721e-01, 3.33411e-01, 9.42888e-01
Node: 01 (pos: 0.010): 5.77813e-01, 9.71746e-01, 2.07914e-02, 3.28995e-01, 4.66376e-01, 9.59984e-01
Node: 02 (pos: 0.020): 7.03953e-01, 9.81824e-01, 8.38389e-02, 4.90909e-01, 6.13749e-01, 9.74202e-01
Node: 03 (pos: 0.030): 8.20812e-01, 9.89735e-01, 2.47992e-01, 6.70175e-01, 7.59880e-01, 9.85406e-01
Node: 04 (pos: 0.040): 9.15980e-01, 9.95425e-01, 5.38098e-01, 8.37048e-01, 8.85111e-01, 9.93487e-01
Node: 05 (pos: 0.051): 9.78299e-01, 9.98854e-01, 8.56476e-01, 9.56506e-01, 9.69950e-01, 9.98368e-01
-
Node: 07 (pos: 0.071): 9.78299e-01, 9.98854e-01, 8.56476e-01, 9.56506e-01, 9.69950e-01, 9.98368e-01
Node: 08 (pos: 0.081): 9.15980e-01, 9.95425e-01, 5.38098e-01, 8.37048e-01, 8.85111e-01, 9.93487e-01
Node: 09 (pos: 0.091): 8.20812e-01, 9.89735e-01, 2.47992e-01, 6.70175e-01, 7.59880e-01, 9.85406e-01
Node: 10 (pos: 0.101): 7.03953e-01, 9.81824e-01, 8.38389e-02, 4.90909e-01, 6.13749e-01, 9.74202e-01
Node: 11 (pos: 0.111): 5.77813e-01, 9.71746e-01, 2.07914e-02, 3.28995e-01, 4.66376e-01, 9.59984e-01
Node: 12 (pos: 0.121): 4.53914e-01, 9.59568e-01, 3.78227e-03, 2.01721e-01, 3.33411e-01, 9.42888e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.78299e-01, 9.98854e-01, 8.56476e-01, 9.56506e-01, 9.69950e-01, 9.98368e-01
Node: 58 (pos: 0.586): 9.15980e-01, 9.95425e-01, 5.38098e-01, 8.37048e-01, 8.85111e-01, 9.93487e-01
Node: 59 (pos: 0.596): 8.20812e-01, 9.89735e-01, 2.47992e-01, 6.70175e-01, 7.59880e-01, 9.85406e-01
Node: 60 (pos: 0.606): 7.03953e-01, 9.81824e-01, 8.38389e-02, 4.90909e-01, 6.13749e-01, 9.74202e-01
Node: 61 (pos: 0.616): 5.77813e-01, 9.71746e-01, 2.07914e-02, 3.28995e-01, 4.66376e-01, 9.59984e-01
Node: 50 (pos: 0.505): 4.53914e-01, 9.59568e-01, 3.78227e-03, 2.01721e-01, 3.33411e-01, 9.42888e-01
-
Node: 51 (pos: 0.515): 5.77813e-01, 9.71746e-01, 2.07914e-02, 3.28995e-01, 4.66376e-01, 9.59984e-01
Node: 52 (pos: 0.525): 7.03953e-01, 9.81824e-01, 8.38389e-02, 4.90909e-01, 6.13749e-01, 9.74202e-01
Node: 53 (pos: 0.535): 8.20812e-01, 9.89735e-01, 2.47992e-01, 6.70175e-01, 7.59880e-01, 9.85406e-01
Node: 54 (pos: 0.545): 9.15980e-01, 9.95425e-01, 5.38098e-01, 8.37048e-01, 8.85111e-01, 9.93487e-01
Node: 55 (pos: 0.556): 9.78299e-01, 9.98854e-01, 8.56476e-01, 9.56506e-01, 9.69950e-01, 9.98368e-01
Node: 62 (pos: 0.626): 4.53914e-01, 9.59568e-01, 3.78227e-03, 2.01721e-01, 3.33411e-01, 9.42888e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.07053472974179212
Step 50, mean loss 0.026773080899453842
Step 75, mean loss 0.03470958941589458
Step 100, mean loss 0.04019232185983421
Step 125, mean loss 0.07789612459445527
Step 150, mean loss 0.06644685315698834
Step 175, mean loss 0.11482643357210882
Step 200, mean loss 0.15185137339622495
Step 225, mean loss 0.10628937299490884
Unrolled forward losses 2.5143773568409005
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.1703150126799914, [0.004606550103974501, 0.08913913931695111, 0.0006753844922390435, 0.002257314892634773, 0.0034259306383552517, 0.06243680348166889]
Training Loss (progress: 0.08), 0.18836831279210373, [0.004720523112818565, 0.0907917855596013, 0.000701590077739935, 0.0023513174208996753, 0.003369379167469904, 0.06289567544639961]
Training Loss (progress: 0.16), 0.16501106109629698, [0.004711093470240931, 0.09245752909836788, 0.0006498012393692745, 0.0023323822896063997, 0.0033752109315853982, 0.06363290891755366]
Training Loss (progress: 0.24), 0.16913501316401214, [0.004530410795568376, 0.09348223818448613, 0.0006824970532387873, 0.0023530789845710195, 0.0033015744152139364, 0.06420057833437098]
Training Loss (progress: 0.32), 0.176564716053247, [0.004595297045686945, 0.09476375071960091, 0.0006685952980987573, 0.0023850043989171133, 0.0034122709952480682, 0.06487145841265578]
Training Loss (progress: 0.40), 0.18312193011106156, [0.004512320235886627, 0.0958568983857923, 0.0006642727201508592, 0.0022603877902421937, 0.0034054944533792888, 0.0653654385848036]
Training Loss (progress: 0.48), 0.17024882486761916, [0.004602336850639941, 0.09749001578217914, 0.0006861874726609151, 0.0023228718390126816, 0.0032561503398172405, 0.06591854375421126]
Training Loss (progress: 0.56), 0.1858356702435888, [0.004512369371232437, 0.09871070652180387, 0.0006904009720545026, 0.002280565519308043, 0.003336404969523754, 0.0665592462004813]
Training Loss (progress: 0.64), 0.17153343174211858, [0.0045589068036933494, 0.10012840673657783, 0.0006609380386830463, 0.0023198701810944887, 0.0034943182655034818, 0.06721774739023936]
Training Loss (progress: 0.72), 0.17381338372575975, [0.004570299708596164, 0.10077573825873071, 0.000690293351981533, 0.002277008667963361, 0.0034558019093328713, 0.06769582080410835]
Training Loss (progress: 0.80), 0.18568693398566855, [0.0047264429406913295, 0.10218306319813918, 0.000676427826295995, 0.0022626959740116638, 0.003441390345492693, 0.0683624855316078]
Training Loss (progress: 0.88), 0.16078323296026845, [0.004541410320222383, 0.10363547885368572, 0.0007070613145324128, 0.0023039127775926925, 0.0033993857006589896, 0.06908704678540606]
Training Loss (progress: 0.96), 0.17671715825703432, [0.0047805890686687755, 0.10520578169116863, 0.0006676957656904006, 0.002318034284157198, 0.003440905236673064, 0.06952265556314839]
Evaluation on validation dataset:
Step 25, mean loss 0.06310993119183773
Step 50, mean loss 0.028295972087594923
Step 75, mean loss 0.0440145862362052
Step 100, mean loss 0.0558168878584771
Step 125, mean loss 0.0753282346228723
Step 150, mean loss 0.05590893484166025
Step 175, mean loss 0.08540489257205144
Step 200, mean loss 0.26188232148994534
Step 225, mean loss 0.21010241559376513
Unrolled forward losses 2.7181445221038096
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.59474e-01, 9.65891e-01, 4.55649e-03, 2.00413e-01, 3.42514e-01, 9.48848e-01
Node: 01 (pos: 0.010): 5.82718e-01, 9.76188e-01, 2.36619e-02, 3.27511e-01, 4.75182e-01, 9.64194e-01
Node: 02 (pos: 0.020): 7.07772e-01, 9.84694e-01, 9.10734e-02, 4.89491e-01, 6.21141e-01, 9.76934e-01
Node: 03 (pos: 0.030): 8.23313e-01, 9.91361e-01, 2.59811e-01, 6.69085e-01, 7.65014e-01, 9.86959e-01
Node: 04 (pos: 0.040): 9.17220e-01, 9.96151e-01, 5.49348e-01, 8.36443e-01, 8.87764e-01, 9.94183e-01
Node: 05 (pos: 0.051): 9.78630e-01, 9.99036e-01, 8.60918e-01, 9.56333e-01, 9.70676e-01, 9.98543e-01
-
Node: 07 (pos: 0.071): 9.78630e-01, 9.99036e-01, 8.60918e-01, 9.56333e-01, 9.70676e-01, 9.98543e-01
Node: 08 (pos: 0.081): 9.17220e-01, 9.96151e-01, 5.49348e-01, 8.36443e-01, 8.87764e-01, 9.94183e-01
Node: 09 (pos: 0.091): 8.23313e-01, 9.91361e-01, 2.59811e-01, 6.69085e-01, 7.65014e-01, 9.86959e-01
Node: 10 (pos: 0.101): 7.07772e-01, 9.84694e-01, 9.10734e-02, 4.89491e-01, 6.21141e-01, 9.76934e-01
Node: 11 (pos: 0.111): 5.82718e-01, 9.76188e-01, 2.36619e-02, 3.27511e-01, 4.75182e-01, 9.64194e-01
Node: 12 (pos: 0.121): 4.59474e-01, 9.65891e-01, 4.55649e-03, 2.00413e-01, 3.42514e-01, 9.48848e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.78630e-01, 9.99036e-01, 8.60918e-01, 9.56333e-01, 9.70676e-01, 9.98543e-01
Node: 58 (pos: 0.586): 9.17220e-01, 9.96151e-01, 5.49348e-01, 8.36443e-01, 8.87764e-01, 9.94183e-01
Node: 59 (pos: 0.596): 8.23313e-01, 9.91361e-01, 2.59811e-01, 6.69085e-01, 7.65014e-01, 9.86959e-01
Node: 60 (pos: 0.606): 7.07772e-01, 9.84694e-01, 9.10734e-02, 4.89491e-01, 6.21141e-01, 9.76934e-01
Node: 61 (pos: 0.616): 5.82718e-01, 9.76188e-01, 2.36619e-02, 3.27511e-01, 4.75182e-01, 9.64194e-01
Node: 50 (pos: 0.505): 4.59474e-01, 9.65891e-01, 4.55649e-03, 2.00413e-01, 3.42514e-01, 9.48848e-01
-
Node: 51 (pos: 0.515): 5.82718e-01, 9.76188e-01, 2.36619e-02, 3.27511e-01, 4.75182e-01, 9.64194e-01
Node: 52 (pos: 0.525): 7.07772e-01, 9.84694e-01, 9.10734e-02, 4.89491e-01, 6.21141e-01, 9.76934e-01
Node: 53 (pos: 0.535): 8.23313e-01, 9.91361e-01, 2.59811e-01, 6.69085e-01, 7.65014e-01, 9.86959e-01
Node: 54 (pos: 0.545): 9.17220e-01, 9.96151e-01, 5.49348e-01, 8.36443e-01, 8.87764e-01, 9.94183e-01
Node: 55 (pos: 0.556): 9.78630e-01, 9.99036e-01, 8.60918e-01, 9.56333e-01, 9.70676e-01, 9.98543e-01
Node: 62 (pos: 0.626): 4.59474e-01, 9.65891e-01, 4.55649e-03, 2.00413e-01, 3.42514e-01, 9.48848e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.05088924758658104
Step 50, mean loss 0.02361383589895771
Step 75, mean loss 0.03486492777784063
Step 100, mean loss 0.0368819717594448
Step 125, mean loss 0.06684229885804586
Step 150, mean loss 0.058809525657019524
Step 175, mean loss 0.09670646178808401
Step 200, mean loss 0.10508300859662063
Step 225, mean loss 0.09755229414515215
Unrolled forward losses 2.432152057253713
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.14821403157747579, [0.004731697624861535, 0.10581527680951114, 0.0006579668355004842, 0.002376768758471284, 0.003511088663531438, 0.07000438980676404]
Training Loss (progress: 0.08), 0.14497657495690208, [0.004603520110836612, 0.10628830146509315, 0.0006778888079816138, 0.002267465871385362, 0.0034274266180781463, 0.07034895265492407]
Training Loss (progress: 0.16), 0.1430875187297957, [0.004511909483194397, 0.10707703203428448, 0.000693679900479436, 0.002271263647065352, 0.003434268968842661, 0.07053676411616823]
Training Loss (progress: 0.24), 0.14190516507913603, [0.00468164851887515, 0.10743086001719117, 0.0006409702360704054, 0.0022543505400548294, 0.0034700725114414814, 0.07068509041827581]
Training Loss (progress: 0.32), 0.14440689704261203, [0.004558543695969222, 0.10767874334078867, 0.0007232838808377592, 0.0022200321306229624, 0.003443393852527046, 0.0710592223621622]
Training Loss (progress: 0.40), 0.14567065468245516, [0.004607360013592332, 0.10810198757182823, 0.0006901301031320936, 0.0022218955199014797, 0.0034259521220349858, 0.07127653451157953]
Training Loss (progress: 0.48), 0.14740937617947383, [0.004549081047636638, 0.10880005610945988, 0.0006753612425299647, 0.0022380109756394723, 0.0034705440771350344, 0.0715822189826314]
Training Loss (progress: 0.56), 0.13056919216509738, [0.004438986945537836, 0.10899976056537287, 0.0006667672536451872, 0.002239995197262109, 0.003544208980662337, 0.07170753423182741]
Training Loss (progress: 0.64), 0.14544955494126743, [0.004566583830800306, 0.10911606711236953, 0.0006939571809340854, 0.0022747566068761684, 0.003573087782169646, 0.0721759596607698]
Training Loss (progress: 0.72), 0.15049662823056764, [0.004634377063108813, 0.10991608839051543, 0.0006419031404497771, 0.0022676368840659038, 0.0034299506612643074, 0.07243104031772846]
Training Loss (progress: 0.80), 0.15512866028494238, [0.004602764983347227, 0.11024372374791629, 0.0006739647377868162, 0.0022592715251529595, 0.0035167647052680292, 0.07272451028314551]
Training Loss (progress: 0.88), 0.14546198656545106, [0.004486755359984629, 0.11099937067024904, 0.0006666900872494505, 0.002258517642958662, 0.003429637891544014, 0.07304003570773092]
Training Loss (progress: 0.96), 0.14450031853384304, [0.004455525712806133, 0.111750698449171, 0.0006775352527816654, 0.002319674959836938, 0.003480054110131227, 0.07322056348845962]
Evaluation on validation dataset:
Step 25, mean loss 0.05212075894371715
Step 50, mean loss 0.021546553008756512
Step 75, mean loss 0.0367612674410426
Step 100, mean loss 0.04294174833445599
Step 125, mean loss 0.05860813554248713
Step 150, mean loss 0.046324227770132204
Step 175, mean loss 0.07524735135895798
Step 200, mean loss 0.21547572782080265
Step 225, mean loss 0.23532191221255863
Unrolled forward losses 2.0201473650413773
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.46016e-01, 9.67672e-01, 4.90117e-03, 1.93142e-01, 3.50646e-01, 9.51164e-01
Node: 01 (pos: 0.010): 5.70812e-01, 9.77437e-01, 2.48910e-02, 3.19214e-01, 4.82988e-01, 9.65827e-01
Node: 02 (pos: 0.020): 6.98483e-01, 9.85501e-01, 9.40733e-02, 4.81518e-01, 6.27653e-01, 9.77993e-01
Node: 03 (pos: 0.030): 8.17217e-01, 9.91818e-01, 2.64591e-01, 6.62933e-01, 7.69515e-01, 9.87561e-01
Node: 04 (pos: 0.040): 9.14195e-01, 9.96355e-01, 5.53817e-01, 8.33015e-01, 8.90082e-01, 9.94452e-01
Node: 05 (pos: 0.051): 9.77822e-01, 9.99088e-01, 8.62664e-01, 9.55352e-01, 9.71309e-01, 9.98610e-01
-
Node: 07 (pos: 0.071): 9.77822e-01, 9.99088e-01, 8.62664e-01, 9.55352e-01, 9.71309e-01, 9.98610e-01
Node: 08 (pos: 0.081): 9.14195e-01, 9.96355e-01, 5.53817e-01, 8.33015e-01, 8.90082e-01, 9.94452e-01
Node: 09 (pos: 0.091): 8.17217e-01, 9.91818e-01, 2.64591e-01, 6.62933e-01, 7.69515e-01, 9.87561e-01
Node: 10 (pos: 0.101): 6.98483e-01, 9.85501e-01, 9.40733e-02, 4.81518e-01, 6.27653e-01, 9.77993e-01
Node: 11 (pos: 0.111): 5.70812e-01, 9.77437e-01, 2.48910e-02, 3.19214e-01, 4.82988e-01, 9.65827e-01
Node: 12 (pos: 0.121): 4.46016e-01, 9.67672e-01, 4.90117e-03, 1.93142e-01, 3.50646e-01, 9.51164e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.77822e-01, 9.99088e-01, 8.62664e-01, 9.55352e-01, 9.71309e-01, 9.98610e-01
Node: 58 (pos: 0.586): 9.14195e-01, 9.96355e-01, 5.53817e-01, 8.33015e-01, 8.90082e-01, 9.94452e-01
Node: 59 (pos: 0.596): 8.17217e-01, 9.91818e-01, 2.64591e-01, 6.62933e-01, 7.69515e-01, 9.87561e-01
Node: 60 (pos: 0.606): 6.98483e-01, 9.85501e-01, 9.40733e-02, 4.81518e-01, 6.27653e-01, 9.77993e-01
Node: 61 (pos: 0.616): 5.70812e-01, 9.77437e-01, 2.48910e-02, 3.19214e-01, 4.82988e-01, 9.65827e-01
Node: 50 (pos: 0.505): 4.46016e-01, 9.67672e-01, 4.90117e-03, 1.93142e-01, 3.50646e-01, 9.51164e-01
-
Node: 51 (pos: 0.515): 5.70812e-01, 9.77437e-01, 2.48910e-02, 3.19214e-01, 4.82988e-01, 9.65827e-01
Node: 52 (pos: 0.525): 6.98483e-01, 9.85501e-01, 9.40733e-02, 4.81518e-01, 6.27653e-01, 9.77993e-01
Node: 53 (pos: 0.535): 8.17217e-01, 9.91818e-01, 2.64591e-01, 6.62933e-01, 7.69515e-01, 9.87561e-01
Node: 54 (pos: 0.545): 9.14195e-01, 9.96355e-01, 5.53817e-01, 8.33015e-01, 8.90082e-01, 9.94452e-01
Node: 55 (pos: 0.556): 9.77822e-01, 9.99088e-01, 8.62664e-01, 9.55352e-01, 9.71309e-01, 9.98610e-01
Node: 62 (pos: 0.626): 4.46016e-01, 9.67672e-01, 4.90117e-03, 1.93142e-01, 3.50646e-01, 9.51164e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.041013285120846225
Step 50, mean loss 0.017501355112783102
Step 75, mean loss 0.026820850139761564
Step 100, mean loss 0.03250626524373826
Step 125, mean loss 0.0554645891691629
Step 150, mean loss 0.0473400912248342
Step 175, mean loss 0.08650824761190273
Step 200, mean loss 0.10476336776355333
Step 225, mean loss 0.0894130424578674
Unrolled forward losses 1.8233723787303913
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.13268942166042383, [0.004445073871165883, 0.11168647109428367, 0.0006895016843551793, 0.00228591642489618, 0.0034990599107121278, 0.07339881022761878]
Training Loss (progress: 0.08), 0.14826359334931608, [0.004543888817414253, 0.11216619871024465, 0.000664416272724641, 0.0022149957057354657, 0.0035382786926686873, 0.07364007083094189]
Training Loss (progress: 0.16), 0.1528693645644052, [0.004464096947810077, 0.11268730161362399, 0.0006887899607734786, 0.002223064470861435, 0.0035435102112181603, 0.07391378296167342]
Training Loss (progress: 0.24), 0.14728264721312548, [0.004466666967672644, 0.11321286263753776, 0.0006502212783862498, 0.0022658362619615625, 0.003538757850314335, 0.07421741745288954]
Training Loss (progress: 0.32), 0.14059201914020172, [0.004556541783496831, 0.11349382328574555, 0.000683339786447319, 0.002225927043021094, 0.0034889091418299654, 0.07436568302998049]
Training Loss (progress: 0.40), 0.12981651448594755, [0.004510433554031234, 0.11405955189475424, 0.0006839749416874874, 0.002216440501746268, 0.003545952496792786, 0.07457081480212949]
Training Loss (progress: 0.48), 0.13443726680945214, [0.004504182838875855, 0.11437928925049447, 0.0006930194544340421, 0.0022126303596930567, 0.003561125313925246, 0.07474769979362919]
Training Loss (progress: 0.56), 0.1494890469612824, [0.004496914085860854, 0.11466191272671912, 0.0006872474572333987, 0.0022451390341784168, 0.003541584056692622, 0.07504266187294292]
Training Loss (progress: 0.64), 0.1423856609358423, [0.004424002352092723, 0.11507581864620592, 0.0006849375269420812, 0.002262763100782216, 0.003612071478956809, 0.07531360114516657]
Training Loss (progress: 0.72), 0.16060559156163928, [0.0044884934141100775, 0.1158420719842137, 0.0006889928352984356, 0.0022629777221411717, 0.003498279000893771, 0.07559958618607109]
Training Loss (progress: 0.80), 0.13230829447140677, [0.004455239935602915, 0.11615680151965939, 0.0006924615560279099, 0.002231370764141528, 0.003480019403762986, 0.07577248377715036]
Training Loss (progress: 0.88), 0.13081920722813367, [0.004399995895720131, 0.11648142759338766, 0.0006745354569825764, 0.002269930644378997, 0.0034538299093144985, 0.0758811179501357]
Training Loss (progress: 0.96), 0.14850952235632314, [0.004466034135948839, 0.11700159494135547, 0.0006684073042294218, 0.002236698564775851, 0.0035144790104814443, 0.07608466981759134]
Evaluation on validation dataset:
Step 25, mean loss 0.04844780159907184
Step 50, mean loss 0.023137621296188075
Step 75, mean loss 0.032918769712339715
Step 100, mean loss 0.04618066441155626
Step 125, mean loss 0.057701288141893056
Step 150, mean loss 0.0437488751014979
Step 175, mean loss 0.07566955209425266
Step 200, mean loss 0.20837624627579227
Step 225, mean loss 0.21971053356669137
Unrolled forward losses 2.3479428691386577
Unrolled forward base losses 2.565701273852575
Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.13513599379068408, [0.004513394771088796, 0.11733289825980356, 0.0006724604311318309, 0.00226474454636835, 0.0035709999727079377, 0.07615139702516034]
Training Loss (progress: 0.08), 0.14716868641625236, [0.0044706986101360185, 0.11788221372407658, 0.0006625104841491574, 0.002220918521310398, 0.003441626498128821, 0.07641455078563926]
Training Loss (progress: 0.16), 0.1262867420328828, [0.004382958856161265, 0.11836543228325061, 0.0006648662063186708, 0.0021773052274705433, 0.0034712807613845715, 0.07669809347835316]
Training Loss (progress: 0.24), 0.12342660706751804, [0.0044944888884974315, 0.11860235347330007, 0.0006753803189874741, 0.0022300345325245966, 0.0035065787288394465, 0.07692213131974678]
Training Loss (progress: 0.32), 0.12650218604713184, [0.004483089762093827, 0.11922787863276975, 0.0006735323540730531, 0.0022128225067532333, 0.00354994913141616, 0.07711764182325427]
Training Loss (progress: 0.40), 0.13583326867929602, [0.0044698255648540405, 0.11961295937404656, 0.0006789590900111392, 0.002218840388528192, 0.003494476021765449, 0.0772770626267475]
Training Loss (progress: 0.48), 0.14028801761142579, [0.0043922706051144, 0.12009440792008437, 0.0006675308388742366, 0.0022521355167684012, 0.003458772388584995, 0.07760063290766155]
Training Loss (progress: 0.56), 0.13698787070656732, [0.0044028829233781815, 0.12063982894658751, 0.0006756552635321173, 0.0022236731823446106, 0.0035904690269596144, 0.07774459222597858]
Training Loss (progress: 0.64), 0.13854915786126065, [0.0043909916310657165, 0.12131991495020811, 0.0007036159740683841, 0.0022636304551141156, 0.003505509803717346, 0.07800688592963959]
Training Loss (progress: 0.72), 0.12420291404660867, [0.004361327504708725, 0.1216704778383787, 0.0006501504634284882, 0.0022257088808957715, 0.003508240796472974, 0.07831395822773377]
Training Loss (progress: 0.80), 0.13672702612685356, [0.004397009210270985, 0.12223456385014811, 0.0006568913265198608, 0.0022723426516428774, 0.003521506852520432, 0.07849905358321638]
Training Loss (progress: 0.88), 0.13468262485410337, [0.004434227391401119, 0.12253611520464397, 0.0007048770036360279, 0.002258555350593571, 0.0035455115846097043, 0.07863455172164466]
Training Loss (progress: 0.96), 0.13100987366093772, [0.0043915052003049345, 0.12300529923084022, 0.0006546080075043306, 0.00222100738098241, 0.0036136469086734376, 0.07881457458578994]
Evaluation on validation dataset:
Step 25, mean loss 0.052379615797668755
Step 50, mean loss 0.02210043750998812
Step 75, mean loss 0.03173137448679929
Step 100, mean loss 0.03915950193310562
Step 125, mean loss 0.05314708239720426
Step 150, mean loss 0.04050106639312792
Step 175, mean loss 0.07747493417009584
Step 200, mean loss 0.2279648680870781
Step 225, mean loss 0.20230136465662538
Unrolled forward losses 2.027723405072299
Unrolled forward base losses 2.565701273852575
Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.13628407900109757, [0.004391842444123669, 0.12322896228889721, 0.0006659635262494138, 0.002174323955344174, 0.0036370249552046072, 0.0788612970350672]
Training Loss (progress: 0.08), 0.1370040437770299, [0.004375832537779208, 0.12352636676461522, 0.0006781994910947616, 0.0022027695690414587, 0.003516455996723759, 0.07916160673736695]
Training Loss (progress: 0.16), 0.12270391712565394, [0.004432402955137944, 0.12396814739987666, 0.0006057655681246628, 0.0022083054019294717, 0.0035154651176514044, 0.07935936384989825]
Training Loss (progress: 0.24), 0.11767268940202336, [0.0044470248986910625, 0.12453693793144541, 0.0006633068195154502, 0.00223442356718149, 0.0035759688013746543, 0.0795807876015505]
Training Loss (progress: 0.32), 0.13457431145737042, [0.004400019639242685, 0.12510982332135773, 0.0006726218913365892, 0.002243631165555169, 0.0035423100605748705, 0.07978766108336188]
Training Loss (progress: 0.40), 0.11907669207169713, [0.004343629777345417, 0.12553661115258302, 0.0006876785550572531, 0.002212353148393308, 0.0035500032572388204, 0.07996238169112692]
Training Loss (progress: 0.48), 0.14033701769089715, [0.004446722960424659, 0.1259725056057668, 0.0006663964952882607, 0.002254497176912548, 0.0035718196409194173, 0.08031552043113399]
Training Loss (progress: 0.56), 0.11613553609132306, [0.004389200707256012, 0.1265900181536996, 0.0006725309998805672, 0.0022468845999246423, 0.0035793986617804405, 0.0804443726972615]
Training Loss (progress: 0.64), 0.12639689129251616, [0.004353297599673006, 0.126825779195656, 0.0006476937950996351, 0.002263979668942479, 0.0036026373403545927, 0.08063221744347267]
Training Loss (progress: 0.72), 0.13281633551132063, [0.004342823947521951, 0.12723431362512533, 0.0006691915290513478, 0.0022537047667639675, 0.0035684732581750854, 0.08085961869231077]
Training Loss (progress: 0.80), 0.12423595167327756, [0.004357450669729635, 0.12772148714712842, 0.0006862032578250839, 0.002227605643207415, 0.003614319781734454, 0.08114469075135332]
Training Loss (progress: 0.88), 0.13007775198078367, [0.004354175760078933, 0.12807192374543028, 0.000675845117941121, 0.002231464978433678, 0.0036373099039277833, 0.08132194414998001]
Training Loss (progress: 0.96), 0.13919233201916234, [0.004355659051838717, 0.12857545058106232, 0.0007065389554879984, 0.0022609853280547397, 0.003613347799530885, 0.08154864476739791]
Evaluation on validation dataset:
Step 25, mean loss 0.03676774052168018
Step 50, mean loss 0.016894422647260154
Step 75, mean loss 0.03007388406285481
Step 100, mean loss 0.04262305169512164
Step 125, mean loss 0.055459292369709375
Step 150, mean loss 0.04457847864059955
Step 175, mean loss 0.06839118498195633
Step 200, mean loss 0.20711498417676075
Step 225, mean loss 0.22742710921673487
Unrolled forward losses 1.9638276056560138
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.31894e-01, 9.71894e-01, 5.17208e-03, 1.97839e-01, 3.63966e-01, 9.56050e-01
Node: 01 (pos: 0.010): 5.58200e-01, 9.80397e-01, 2.58385e-02, 3.24585e-01, 4.95657e-01, 9.69270e-01
Node: 02 (pos: 0.020): 6.88566e-01, 9.87410e-01, 9.63499e-02, 4.86687e-01, 6.38140e-01, 9.80223e-01
Node: 03 (pos: 0.030): 8.10670e-01, 9.92898e-01, 2.68174e-01, 6.66927e-01, 7.76721e-01, 9.88827e-01
Node: 04 (pos: 0.040): 9.10933e-01, 9.96837e-01, 5.57138e-01, 8.35242e-01, 8.93777e-01, 9.95019e-01
Node: 05 (pos: 0.051): 9.76948e-01, 9.99208e-01, 8.63954e-01, 9.55990e-01, 9.72316e-01, 9.98752e-01
-
Node: 07 (pos: 0.071): 9.76948e-01, 9.99208e-01, 8.63954e-01, 9.55990e-01, 9.72316e-01, 9.98752e-01
Node: 08 (pos: 0.081): 9.10933e-01, 9.96837e-01, 5.57138e-01, 8.35242e-01, 8.93777e-01, 9.95019e-01
Node: 09 (pos: 0.091): 8.10670e-01, 9.92898e-01, 2.68174e-01, 6.66927e-01, 7.76721e-01, 9.88827e-01
Node: 10 (pos: 0.101): 6.88566e-01, 9.87410e-01, 9.63499e-02, 4.86687e-01, 6.38140e-01, 9.80223e-01
Node: 11 (pos: 0.111): 5.58200e-01, 9.80397e-01, 2.58385e-02, 3.24585e-01, 4.95657e-01, 9.69270e-01
Node: 12 (pos: 0.121): 4.31894e-01, 9.71894e-01, 5.17208e-03, 1.97839e-01, 3.63966e-01, 9.56050e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.76948e-01, 9.99208e-01, 8.63954e-01, 9.55990e-01, 9.72316e-01, 9.98752e-01
Node: 58 (pos: 0.586): 9.10933e-01, 9.96837e-01, 5.57138e-01, 8.35242e-01, 8.93777e-01, 9.95019e-01
Node: 59 (pos: 0.596): 8.10670e-01, 9.92898e-01, 2.68174e-01, 6.66927e-01, 7.76721e-01, 9.88827e-01
Node: 60 (pos: 0.606): 6.88566e-01, 9.87410e-01, 9.63499e-02, 4.86687e-01, 6.38140e-01, 9.80223e-01
Node: 61 (pos: 0.616): 5.58200e-01, 9.80397e-01, 2.58385e-02, 3.24585e-01, 4.95657e-01, 9.69270e-01
Node: 50 (pos: 0.505): 4.31894e-01, 9.71894e-01, 5.17208e-03, 1.97839e-01, 3.63966e-01, 9.56050e-01
-
Node: 51 (pos: 0.515): 5.58200e-01, 9.80397e-01, 2.58385e-02, 3.24585e-01, 4.95657e-01, 9.69270e-01
Node: 52 (pos: 0.525): 6.88566e-01, 9.87410e-01, 9.63499e-02, 4.86687e-01, 6.38140e-01, 9.80223e-01
Node: 53 (pos: 0.535): 8.10670e-01, 9.92898e-01, 2.68174e-01, 6.66927e-01, 7.76721e-01, 9.88827e-01
Node: 54 (pos: 0.545): 9.10933e-01, 9.96837e-01, 5.57138e-01, 8.35242e-01, 8.93777e-01, 9.95019e-01
Node: 55 (pos: 0.556): 9.76948e-01, 9.99208e-01, 8.63954e-01, 9.55990e-01, 9.72316e-01, 9.98752e-01
Node: 62 (pos: 0.626): 4.31894e-01, 9.71894e-01, 5.17208e-03, 1.97839e-01, 3.63966e-01, 9.56050e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.029416951678789535
Step 50, mean loss 0.013110624135478536
Step 75, mean loss 0.02206820667544784
Step 100, mean loss 0.026604545310298724
Step 125, mean loss 0.048352683549591366
Step 150, mean loss 0.041960111210950696
Step 175, mean loss 0.07149539446583701
Step 200, mean loss 0.09732097435937737
Step 225, mean loss 0.08166852131261762
Unrolled forward losses 1.7357724342373542
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.12832500505726843, [0.004428730272781864, 0.1288004174775406, 0.0006746165966200491, 0.002264324665859402, 0.0036585097954600415, 0.0817479692905065]
Training Loss (progress: 0.08), 0.12364211761801787, [0.00429977812562663, 0.12922522121236474, 0.000656032492700064, 0.002220273033300371, 0.003585057695438106, 0.08191823280173781]
Training Loss (progress: 0.16), 0.13075200778929705, [0.004293974177817791, 0.12961480011922905, 0.0006816071375137802, 0.0021909595732021803, 0.0036208386878000855, 0.08204018306194603]
Training Loss (progress: 0.24), 0.12490844936762333, [0.004355258682489173, 0.13030733580958445, 0.0006700416723823323, 0.0022404772308811643, 0.0036115427276185975, 0.08228728699330813]
Training Loss (progress: 0.32), 0.13139544466342937, [0.004335208084197975, 0.13079082627397062, 0.0006817102377665806, 0.0021583553958524713, 0.003575956459025473, 0.0824804176449503]
Training Loss (progress: 0.40), 0.11572783472080606, [0.004284102682655811, 0.1311604080023657, 0.0006811675188912065, 0.002199618976673151, 0.0035932928612838334, 0.08268046338836627]
Training Loss (progress: 0.48), 0.12396730433752175, [0.004299670489039698, 0.13159472830657828, 0.0006766687182225626, 0.0021864861712615146, 0.003747407150255985, 0.08282088317972587]
Training Loss (progress: 0.56), 0.12614115679525556, [0.004369055244916051, 0.13211274622412328, 0.0006929032136130394, 0.0022180366704348093, 0.0036379605383357, 0.08307453602721965]
Training Loss (progress: 0.64), 0.12839559961892422, [0.004417644624569363, 0.13250286002689626, 0.0006962541031886186, 0.002173301467584179, 0.0036263932966476933, 0.08337488584058209]
Training Loss (progress: 0.72), 0.12026666094396284, [0.004385611895503994, 0.13291874541855983, 0.00066698063725593, 0.0022114388921648247, 0.003681040332092387, 0.08357811124905647]
Training Loss (progress: 0.80), 0.12856640287820614, [0.004426099752157526, 0.13327447585338445, 0.0006947652788894502, 0.0022989443931985118, 0.0036611321314411597, 0.08371456501507546]
Training Loss (progress: 0.88), 0.11152476837405122, [0.004348663443865597, 0.13389146664387372, 0.0006772967031431021, 0.0022262547041815945, 0.003682835300724466, 0.0839840029168351]
Training Loss (progress: 0.96), 0.12742252693774808, [0.004377420006379658, 0.13411954482017557, 0.0006575881865284337, 0.0022395164546780634, 0.0037043499178751023, 0.08401202312946135]
Evaluation on validation dataset:
Step 25, mean loss 0.037585856640934875
Step 50, mean loss 0.017123898738863573
Step 75, mean loss 0.031973888698174135
Step 100, mean loss 0.03797131529139297
Step 125, mean loss 0.05254655997811713
Step 150, mean loss 0.036028228841238415
Step 175, mean loss 0.06075678719015922
Step 200, mean loss 0.18279415997423154
Step 225, mean loss 0.21810494144973994
Unrolled forward losses 1.883306129587777
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.37347e-01, 9.73013e-01, 4.79750e-03, 1.91160e-01, 3.58563e-01, 9.57284e-01
Node: 01 (pos: 0.010): 5.63084e-01, 9.81181e-01, 2.45242e-02, 3.16935e-01, 4.90535e-01, 9.70139e-01
Node: 02 (pos: 0.020): 6.92416e-01, 9.87915e-01, 9.31838e-02, 4.79315e-01, 6.33912e-01, 9.80785e-01
Node: 03 (pos: 0.030): 8.13217e-01, 9.93184e-01, 2.63181e-01, 6.61225e-01, 7.73822e-01, 9.89146e-01
Node: 04 (pos: 0.040): 9.12204e-01, 9.96965e-01, 5.52504e-01, 8.32061e-01, 8.92292e-01, 9.95161e-01
Node: 05 (pos: 0.051): 9.77289e-01, 9.99240e-01, 8.62152e-01, 9.55078e-01, 9.71912e-01, 9.98788e-01
-
Node: 07 (pos: 0.071): 9.77289e-01, 9.99240e-01, 8.62152e-01, 9.55078e-01, 9.71912e-01, 9.98788e-01
Node: 08 (pos: 0.081): 9.12204e-01, 9.96965e-01, 5.52504e-01, 8.32061e-01, 8.92292e-01, 9.95161e-01
Node: 09 (pos: 0.091): 8.13217e-01, 9.93184e-01, 2.63181e-01, 6.61225e-01, 7.73822e-01, 9.89146e-01
Node: 10 (pos: 0.101): 6.92416e-01, 9.87915e-01, 9.31838e-02, 4.79315e-01, 6.33912e-01, 9.80785e-01
Node: 11 (pos: 0.111): 5.63084e-01, 9.81181e-01, 2.45242e-02, 3.16935e-01, 4.90535e-01, 9.70139e-01
Node: 12 (pos: 0.121): 4.37347e-01, 9.73013e-01, 4.79750e-03, 1.91160e-01, 3.58563e-01, 9.57284e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.77289e-01, 9.99240e-01, 8.62152e-01, 9.55078e-01, 9.71912e-01, 9.98788e-01
Node: 58 (pos: 0.586): 9.12204e-01, 9.96965e-01, 5.52504e-01, 8.32061e-01, 8.92292e-01, 9.95161e-01
Node: 59 (pos: 0.596): 8.13217e-01, 9.93184e-01, 2.63181e-01, 6.61225e-01, 7.73822e-01, 9.89146e-01
Node: 60 (pos: 0.606): 6.92416e-01, 9.87915e-01, 9.31838e-02, 4.79315e-01, 6.33912e-01, 9.80785e-01
Node: 61 (pos: 0.616): 5.63084e-01, 9.81181e-01, 2.45242e-02, 3.16935e-01, 4.90535e-01, 9.70139e-01
Node: 50 (pos: 0.505): 4.37347e-01, 9.73013e-01, 4.79750e-03, 1.91160e-01, 3.58563e-01, 9.57284e-01
-
Node: 51 (pos: 0.515): 5.63084e-01, 9.81181e-01, 2.45242e-02, 3.16935e-01, 4.90535e-01, 9.70139e-01
Node: 52 (pos: 0.525): 6.92416e-01, 9.87915e-01, 9.31838e-02, 4.79315e-01, 6.33912e-01, 9.80785e-01
Node: 53 (pos: 0.535): 8.13217e-01, 9.93184e-01, 2.63181e-01, 6.61225e-01, 7.73822e-01, 9.89146e-01
Node: 54 (pos: 0.545): 9.12204e-01, 9.96965e-01, 5.52504e-01, 8.32061e-01, 8.92292e-01, 9.95161e-01
Node: 55 (pos: 0.556): 9.77289e-01, 9.99240e-01, 8.62152e-01, 9.55078e-01, 9.71912e-01, 9.98788e-01
Node: 62 (pos: 0.626): 4.37347e-01, 9.73013e-01, 4.79750e-03, 1.91160e-01, 3.58563e-01, 9.57284e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.03111775835688086
Step 50, mean loss 0.014197483250933477
Step 75, mean loss 0.022079818396597114
Step 100, mean loss 0.026935280018407594
Step 125, mean loss 0.04950907169127417
Step 150, mean loss 0.038544000850470855
Step 175, mean loss 0.06445623755678867
Step 200, mean loss 0.08916189798177483
Step 225, mean loss 0.0770019047820942
Unrolled forward losses 1.6622650013767943
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00), 0.11617436216033426, [0.004370202647025022, 0.13430235990105643, 0.0006736339314543366, 0.002215841294079635, 0.0035838901827786895, 0.08414066134470857]
Training Loss (progress: 0.08), 0.11392812123992775, [0.004363816472437782, 0.13467246667660368, 0.0006709306106499806, 0.002234131839446176, 0.003694263824067335, 0.08433006535360246]
Training Loss (progress: 0.16), 0.11440737794384172, [0.00436961885756689, 0.13492046019322185, 0.0006894813588747989, 0.0022242401524383212, 0.0036935685255236566, 0.0844795159671767]
Training Loss (progress: 0.24), 0.12069673429196155, [0.004311336026350054, 0.13516136629795117, 0.0006819808229175077, 0.002228364513935878, 0.003704662179715116, 0.08461431160384536]
Training Loss (progress: 0.32), 0.1230364962961385, [0.004326477038719338, 0.13533673966077067, 0.0006755662442363372, 0.0022474936168465935, 0.003665294254582673, 0.08472851016847274]
Training Loss (progress: 0.40), 0.1113809405066893, [0.004388395818912622, 0.13564023790112253, 0.0006736097663215587, 0.002215756375972853, 0.003732442637964616, 0.08485695861017152]
Training Loss (progress: 0.48), 0.12354180868052328, [0.00438115417456589, 0.13576661029271692, 0.000676308123649384, 0.0022354610826000043, 0.003718417382396552, 0.08498896731964435]
Training Loss (progress: 0.56), 0.11344356011738188, [0.004333544012604038, 0.13599138023174243, 0.0006763494662567403, 0.0022419391437430236, 0.003680950582873958, 0.08507377222406041]
Training Loss (progress: 0.64), 0.11417445360134951, [0.004358807411697628, 0.13618966424444623, 0.0006637152169021158, 0.0022101353745150815, 0.0037084971863986646, 0.08517819122889907]
Training Loss (progress: 0.72), 0.1074026909783031, [0.004335222755152224, 0.13632900055391492, 0.0006929379079823702, 0.002229922504385409, 0.0037041162321588676, 0.0852993409019072]
Training Loss (progress: 0.80), 0.12472451829554777, [0.0043636377964401665, 0.136439348486341, 0.0006764938721028419, 0.0022360985711327576, 0.0037398382989366993, 0.08545935644785058]
Training Loss (progress: 0.88), 0.11848046961885111, [0.004310500667429049, 0.13663637650017232, 0.0006720046943034951, 0.002206906186520648, 0.003770169687618603, 0.08557557360793905]
Training Loss (progress: 0.96), 0.11547936794310577, [0.004363623173717159, 0.13675977416669802, 0.0006760305903467594, 0.0021946311110725607, 0.0037839774917919986, 0.08565967509506842]
Evaluation on validation dataset:
Step 25, mean loss 0.02961375146318676
Step 50, mean loss 0.015562242156668852
Step 75, mean loss 0.02814837406425362
Step 100, mean loss 0.04097446962644725
Step 125, mean loss 0.04796666759451901
Step 150, mean loss 0.03415603281850674
Step 175, mean loss 0.060425571518483705
Step 200, mean loss 0.19743199820963148
Step 225, mean loss 0.20248488334145875
Unrolled forward losses 1.6267451826871686
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.25859e-01, 9.73544e-01, 4.42081e-03, 1.91522e-01, 3.71794e-01, 9.58056e-01
Node: 01 (pos: 0.010): 5.52772e-01, 9.81553e-01, 2.31703e-02, 3.17352e-01, 5.03036e-01, 9.70682e-01
Node: 02 (pos: 0.020): 6.84273e-01, 9.88154e-01, 8.98580e-02, 4.79718e-01, 6.44204e-01, 9.81136e-01
Node: 03 (pos: 0.030): 8.07824e-01, 9.93319e-01, 2.57855e-01, 6.61538e-01, 7.80864e-01, 9.89345e-01
Node: 04 (pos: 0.040): 9.09510e-01, 9.97025e-01, 5.47506e-01, 8.32236e-01, 8.95892e-01, 9.95250e-01
Node: 05 (pos: 0.051): 9.76567e-01, 9.99255e-01, 8.60196e-01, 9.55128e-01, 9.72890e-01, 9.98810e-01
-
Node: 07 (pos: 0.071): 9.76567e-01, 9.99255e-01, 8.60196e-01, 9.55128e-01, 9.72890e-01, 9.98810e-01
Node: 08 (pos: 0.081): 9.09510e-01, 9.97025e-01, 5.47506e-01, 8.32236e-01, 8.95892e-01, 9.95250e-01
Node: 09 (pos: 0.091): 8.07824e-01, 9.93319e-01, 2.57855e-01, 6.61538e-01, 7.80864e-01, 9.89345e-01
Node: 10 (pos: 0.101): 6.84273e-01, 9.88154e-01, 8.98580e-02, 4.79718e-01, 6.44204e-01, 9.81136e-01
Node: 11 (pos: 0.111): 5.52772e-01, 9.81553e-01, 2.31703e-02, 3.17352e-01, 5.03036e-01, 9.70682e-01
Node: 12 (pos: 0.121): 4.25859e-01, 9.73544e-01, 4.42081e-03, 1.91522e-01, 3.71794e-01, 9.58056e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.76567e-01, 9.99255e-01, 8.60196e-01, 9.55128e-01, 9.72890e-01, 9.98810e-01
Node: 58 (pos: 0.586): 9.09510e-01, 9.97025e-01, 5.47506e-01, 8.32236e-01, 8.95892e-01, 9.95250e-01
Node: 59 (pos: 0.596): 8.07824e-01, 9.93319e-01, 2.57855e-01, 6.61538e-01, 7.80864e-01, 9.89345e-01
Node: 60 (pos: 0.606): 6.84273e-01, 9.88154e-01, 8.98580e-02, 4.79718e-01, 6.44204e-01, 9.81136e-01
Node: 61 (pos: 0.616): 5.52772e-01, 9.81553e-01, 2.31703e-02, 3.17352e-01, 5.03036e-01, 9.70682e-01
Node: 50 (pos: 0.505): 4.25859e-01, 9.73544e-01, 4.42081e-03, 1.91522e-01, 3.71794e-01, 9.58056e-01
-
Node: 51 (pos: 0.515): 5.52772e-01, 9.81553e-01, 2.31703e-02, 3.17352e-01, 5.03036e-01, 9.70682e-01
Node: 52 (pos: 0.525): 6.84273e-01, 9.88154e-01, 8.98580e-02, 4.79718e-01, 6.44204e-01, 9.81136e-01
Node: 53 (pos: 0.535): 8.07824e-01, 9.93319e-01, 2.57855e-01, 6.61538e-01, 7.80864e-01, 9.89345e-01
Node: 54 (pos: 0.545): 9.09510e-01, 9.97025e-01, 5.47506e-01, 8.32236e-01, 8.95892e-01, 9.95250e-01
Node: 55 (pos: 0.556): 9.76567e-01, 9.99255e-01, 8.60196e-01, 9.55128e-01, 9.72890e-01, 9.98810e-01
Node: 62 (pos: 0.626): 4.25859e-01, 9.73544e-01, 4.42081e-03, 1.91522e-01, 3.71794e-01, 9.58056e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.02441714893615928
Step 50, mean loss 0.01161355716316758
Step 75, mean loss 0.01994534442347007
Step 100, mean loss 0.023810113583544457
Step 125, mean loss 0.04165025521066941
Step 150, mean loss 0.03703363311772809
Step 175, mean loss 0.06448576278384174
Step 200, mean loss 0.09373734100306891
Step 225, mean loss 0.07217324954509904
Unrolled forward losses 1.4003949578441295
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00), 0.11889358917812339, [0.0042995873036731184, 0.13700101958198524, 0.0006931451922926849, 0.0021845809306454524, 0.003770538044439244, 0.08573351223309869]
Training Loss (progress: 0.08), 0.11179977133782039, [0.004370461893472874, 0.13715814974590257, 0.0006830821936097321, 0.002220760231146504, 0.003754968242316549, 0.08583500705598994]
Training Loss (progress: 0.16), 0.1286087977472797, [0.00431940008974709, 0.1373651689269383, 0.00068664627869685, 0.0022435660559548035, 0.0037745384845654074, 0.0859583859003166]
Training Loss (progress: 0.24), 0.12173631818824497, [0.004313422608840323, 0.1375281402445817, 0.0006750816095636938, 0.002217069013876313, 0.003761388972729241, 0.08609072991308236]
Training Loss (progress: 0.32), 0.11633623305842117, [0.004355889104713685, 0.13771046875476742, 0.0006905548807056428, 0.0021978940117857383, 0.003755094622464909, 0.08617750075635158]
Training Loss (progress: 0.40), 0.11628964766382442, [0.004272052525228196, 0.13787987359451315, 0.0007031253800447134, 0.0021750358142432888, 0.0037094416731549146, 0.08623944309673003]
Training Loss (progress: 0.48), 0.11748858797833495, [0.00431308194503439, 0.1380574400054816, 0.0006837998174726153, 0.0022346836211312665, 0.0037658758604930584, 0.08641373231373346]
Training Loss (progress: 0.56), 0.13110310688594223, [0.00432139574099806, 0.13812863323949354, 0.0006867744995094394, 0.002244185374320563, 0.0037617992765011745, 0.086514632648347]
Training Loss (progress: 0.64), 0.12431357741173397, [0.004357020624553624, 0.1384433902253991, 0.0006854419430090648, 0.0021984260708361953, 0.003769047975434332, 0.0865704375058439]
Training Loss (progress: 0.72), 0.10983860035462574, [0.00431708127146373, 0.13854121376091322, 0.0006820633602349811, 0.002216284482467813, 0.003780556853862082, 0.08666307612149592]
Training Loss (progress: 0.80), 0.11799696403767852, [0.0043118162522259515, 0.13877223457686325, 0.0006739358228272008, 0.002231500467409928, 0.0037523662578763054, 0.08676823132678882]
Training Loss (progress: 0.88), 0.11429285185992039, [0.004320616262636483, 0.13890889738155437, 0.0006576485355927011, 0.00220135776072504, 0.00377741901528253, 0.08686997004370224]
Training Loss (progress: 0.96), 0.11116164890633737, [0.004322681866190157, 0.1390489950101756, 0.000695437888359095, 0.002192673875467317, 0.0037447798812375397, 0.0869917603772444]
Evaluation on validation dataset:
Step 25, mean loss 0.028624852371367013
Step 50, mean loss 0.016099185845024854
Step 75, mean loss 0.028844933121932582
Step 100, mean loss 0.03758289713927643
Step 125, mean loss 0.04398579742225478
Step 150, mean loss 0.03487881357742417
Step 175, mean loss 0.059627510058510025
Step 200, mean loss 0.1820974755818098
Step 225, mean loss 0.20677838234508508
Unrolled forward losses 1.727110886643675
Unrolled forward base losses 2.565701273852575
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00), 0.09883660358312994, [0.004313398542313125, 0.13919714728414861, 0.0006880236033771472, 0.0022339474555249385, 0.003742287732143991, 0.08703420242244356]
Training Loss (progress: 0.08), 0.12090591253700456, [0.004350698684459638, 0.13929004512097445, 0.0006893165705706283, 0.0022437578397137173, 0.0037589713702340702, 0.08715105012748178]
Training Loss (progress: 0.16), 0.12979739146663608, [0.004357332596758367, 0.13961982770266115, 0.0007079675214390638, 0.002223588238362127, 0.003745137397782386, 0.0872180999126969]
Training Loss (progress: 0.24), 0.11182851252020558, [0.004318105509053081, 0.13977392242052286, 0.0006873677830804724, 0.002221312402962961, 0.0037720262137461696, 0.0873531377669379]
Training Loss (progress: 0.32), 0.11823722084081326, [0.004316424712912988, 0.13997137898149054, 0.0006763245782187825, 0.002229109390974546, 0.0037716985687995643, 0.08746436649208658]
Training Loss (progress: 0.40), 0.10646636779952505, [0.004322416562597893, 0.14026007429353798, 0.0006801540707435786, 0.0022159275143633344, 0.003769881913082125, 0.08757404006814706]
Training Loss (progress: 0.48), 0.11316041978391275, [0.00433304741977906, 0.14041757689677062, 0.0006757742620011371, 0.002248426199321449, 0.0038283796959610056, 0.08764615897263434]
Training Loss (progress: 0.56), 0.11375846367994454, [0.004309731148329632, 0.14057373879113788, 0.0006822430304966237, 0.0022241988779992186, 0.003784624232623748, 0.0877226903559837]
Training Loss (progress: 0.64), 0.11749071472306255, [0.004324719418226897, 0.14082643308388004, 0.0006954602985207442, 0.0022488009204180938, 0.0038147429589327486, 0.08789817855294846]
Training Loss (progress: 0.72), 0.11087794204516735, [0.004313670688963675, 0.14095100838994806, 0.0006929876886948267, 0.0022407511213290887, 0.0037499752491764976, 0.08798313810498808]
Training Loss (progress: 0.80), 0.11171168454641563, [0.004324425487934433, 0.14114274972373694, 0.000688613548386445, 0.002230090666908594, 0.003791471417105771, 0.088057434118278]
Training Loss (progress: 0.88), 0.10948742737900295, [0.004281703500094825, 0.14129300442670079, 0.0006863156486725752, 0.0022186265805088233, 0.003780089954210083, 0.08816354144675123]
Training Loss (progress: 0.96), 0.10593152531046018, [0.004358093242053327, 0.14154578465625958, 0.0006925454275593109, 0.002230304140206777, 0.0037715646536012047, 0.08825391698576487]
Evaluation on validation dataset:
Step 25, mean loss 0.02822700280090182
Step 50, mean loss 0.013802006306397215
Step 75, mean loss 0.026505288760821175
Step 100, mean loss 0.03285255866103005
Step 125, mean loss 0.0414890368242105
Step 150, mean loss 0.031880386820581405
Step 175, mean loss 0.0562615700303455
Step 200, mean loss 0.1821370047843695
Step 225, mean loss 0.21093712576350082
Unrolled forward losses 1.5402966619955925
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.29339e-01, 9.74394e-01, 4.88750e-03, 1.88569e-01, 3.84377e-01, 9.59240e-01
Node: 01 (pos: 0.010): 5.55904e-01, 9.82148e-01, 2.48427e-02, 3.13946e-01, 5.14798e-01, 9.71515e-01
Node: 02 (pos: 0.020): 6.86752e-01, 9.88537e-01, 9.39567e-02, 4.76417e-01, 6.53804e-01, 9.81675e-01
Node: 03 (pos: 0.030): 8.09469e-01, 9.93536e-01, 2.64406e-01, 6.58973e-01, 7.87389e-01, 9.89650e-01
Node: 04 (pos: 0.040): 9.10332e-01, 9.97122e-01, 5.53646e-01, 8.30801e-01, 8.99212e-01, 9.95387e-01
Node: 05 (pos: 0.051): 9.76787e-01, 9.99280e-01, 8.62597e-01, 9.54716e-01, 9.73790e-01, 9.98845e-01
-
Node: 07 (pos: 0.071): 9.76787e-01, 9.99280e-01, 8.62597e-01, 9.54716e-01, 9.73790e-01, 9.98845e-01
Node: 08 (pos: 0.081): 9.10332e-01, 9.97122e-01, 5.53646e-01, 8.30801e-01, 8.99212e-01, 9.95387e-01
Node: 09 (pos: 0.091): 8.09469e-01, 9.93536e-01, 2.64406e-01, 6.58973e-01, 7.87389e-01, 9.89650e-01
Node: 10 (pos: 0.101): 6.86752e-01, 9.88537e-01, 9.39567e-02, 4.76417e-01, 6.53804e-01, 9.81675e-01
Node: 11 (pos: 0.111): 5.55904e-01, 9.82148e-01, 2.48427e-02, 3.13946e-01, 5.14798e-01, 9.71515e-01
Node: 12 (pos: 0.121): 4.29339e-01, 9.74394e-01, 4.88750e-03, 1.88569e-01, 3.84377e-01, 9.59240e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.76787e-01, 9.99280e-01, 8.62597e-01, 9.54716e-01, 9.73790e-01, 9.98845e-01
Node: 58 (pos: 0.586): 9.10332e-01, 9.97122e-01, 5.53646e-01, 8.30801e-01, 8.99212e-01, 9.95387e-01
Node: 59 (pos: 0.596): 8.09469e-01, 9.93536e-01, 2.64406e-01, 6.58973e-01, 7.87389e-01, 9.89650e-01
Node: 60 (pos: 0.606): 6.86752e-01, 9.88537e-01, 9.39567e-02, 4.76417e-01, 6.53804e-01, 9.81675e-01
Node: 61 (pos: 0.616): 5.55904e-01, 9.82148e-01, 2.48427e-02, 3.13946e-01, 5.14798e-01, 9.71515e-01
Node: 50 (pos: 0.505): 4.29339e-01, 9.74394e-01, 4.88750e-03, 1.88569e-01, 3.84377e-01, 9.59240e-01
-
Node: 51 (pos: 0.515): 5.55904e-01, 9.82148e-01, 2.48427e-02, 3.13946e-01, 5.14798e-01, 9.71515e-01
Node: 52 (pos: 0.525): 6.86752e-01, 9.88537e-01, 9.39567e-02, 4.76417e-01, 6.53804e-01, 9.81675e-01
Node: 53 (pos: 0.535): 8.09469e-01, 9.93536e-01, 2.64406e-01, 6.58973e-01, 7.87389e-01, 9.89650e-01
Node: 54 (pos: 0.545): 9.10332e-01, 9.97122e-01, 5.53646e-01, 8.30801e-01, 8.99212e-01, 9.95387e-01
Node: 55 (pos: 0.556): 9.76787e-01, 9.99280e-01, 8.62597e-01, 9.54716e-01, 9.73790e-01, 9.98845e-01
Node: 62 (pos: 0.626): 4.29339e-01, 9.74394e-01, 4.88750e-03, 1.88569e-01, 3.84377e-01, 9.59240e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.022922225083681212
Step 50, mean loss 0.01075161998598095
Step 75, mean loss 0.018404723218771527
Step 100, mean loss 0.022125467306150934
Step 125, mean loss 0.03865075475031126
Step 150, mean loss 0.03429329958608818
Step 175, mean loss 0.06013590567095292
Step 200, mean loss 0.08600876335657215
Step 225, mean loss 0.07023231571375105
Unrolled forward losses 1.40196474588062
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00), 0.10612378018933312, [0.004334509370614444, 0.14162297888271663, 0.0006817210647501234, 0.002197288312972429, 0.0038386444101727825, 0.08827828297349144]
Training Loss (progress: 0.08), 0.12845327405764487, [0.00435974042554896, 0.1418051450125071, 0.0006854375559832696, 0.002207434291944509, 0.0038024873045050312, 0.088461923967204]
Training Loss (progress: 0.16), 0.10614358121576291, [0.004366828312419227, 0.14200951583686272, 0.0006818546377883824, 0.002242145086699492, 0.003818145167104292, 0.08853531897110214]
Training Loss (progress: 0.24), 0.11689281322242161, [0.0042952248436379315, 0.14211515086742604, 0.0006938313043935435, 0.0022328810074725555, 0.0038317427372137666, 0.08862468292422027]
Training Loss (progress: 0.32), 0.11402780079237922, [0.004307042026420558, 0.14223492413933697, 0.0006963097406770464, 0.0022184760624308496, 0.0037788490241148355, 0.0887364171306726]
Training Loss (progress: 0.40), 0.10548605019390056, [0.004267461324107342, 0.14239942264175856, 0.0006836151793402904, 0.002206304860197962, 0.003818070616028774, 0.08882119945695327]
Training Loss (progress: 0.48), 0.10662848770500317, [0.004297096005649567, 0.1426050968589536, 0.0006830904385486538, 0.0022274674263305354, 0.0038681030939545654, 0.08893888284687088]
Training Loss (progress: 0.56), 0.1115758697408754, [0.004271389311322994, 0.14271073001426499, 0.0006906400916765484, 0.0022185891243434357, 0.003832365040028487, 0.0890837536524788]
Training Loss (progress: 0.64), 0.10604625858184685, [0.004272730231741658, 0.14297586594772177, 0.0006843795303421612, 0.002217251112792364, 0.0038069622403289808, 0.08911072175990888]
Training Loss (progress: 0.72), 0.11529044698548063, [0.004333363273412081, 0.1431933429014554, 0.000677257204499229, 0.00220118849393199, 0.0037743727289793936, 0.08921816232907923]
Training Loss (progress: 0.80), 0.11478105151941155, [0.004306870825603246, 0.1433080185766018, 0.000681029378217107, 0.002195415329940238, 0.0038014425823140277, 0.08930950193379854]
Training Loss (progress: 0.88), 0.10991986012951857, [0.004290036518398365, 0.14339463733380267, 0.0007042961449383544, 0.002205725538485354, 0.0038106987373438335, 0.0894409108002121]
Training Loss (progress: 0.96), 0.10739418422590015, [0.004291197907863682, 0.143637289741305, 0.0006915135391369621, 0.0021883989450765477, 0.003840775478381108, 0.08946556921926375]
Evaluation on validation dataset:
Step 25, mean loss 0.02602657520604603
Step 50, mean loss 0.013544121620109591
Step 75, mean loss 0.02695223193386246
Step 100, mean loss 0.031491842532943945
Step 125, mean loss 0.04109935910967813
Step 150, mean loss 0.03154640032885789
Step 175, mean loss 0.053443518814046756
Step 200, mean loss 0.18011332220453513
Step 225, mean loss 0.21464977949110256
Unrolled forward losses 1.5090617189274576
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.21091e-01, 9.74775e-01, 5.09409e-03, 1.92223e-01, 3.86978e-01, 9.59798e-01
Node: 01 (pos: 0.010): 5.48466e-01, 9.82414e-01, 2.55673e-02, 3.18158e-01, 5.17215e-01, 9.71907e-01
Node: 02 (pos: 0.020): 6.80857e-01, 9.88709e-01, 9.57015e-02, 4.80498e-01, 6.55767e-01, 9.81929e-01
Node: 03 (pos: 0.030): 8.05553e-01, 9.93633e-01, 2.67157e-01, 6.62143e-01, 7.88718e-01, 9.89794e-01
Node: 04 (pos: 0.040): 9.08373e-01, 9.97165e-01, 5.56198e-01, 8.32574e-01, 8.99886e-01, 9.95451e-01
Node: 05 (pos: 0.051): 9.76261e-01, 9.99291e-01, 8.63590e-01, 9.55225e-01, 9.73973e-01, 9.98861e-01
-
Node: 07 (pos: 0.071): 9.76261e-01, 9.99291e-01, 8.63590e-01, 9.55225e-01, 9.73973e-01, 9.98861e-01
Node: 08 (pos: 0.081): 9.08373e-01, 9.97165e-01, 5.56198e-01, 8.32574e-01, 8.99886e-01, 9.95451e-01
Node: 09 (pos: 0.091): 8.05553e-01, 9.93633e-01, 2.67157e-01, 6.62143e-01, 7.88718e-01, 9.89794e-01
Node: 10 (pos: 0.101): 6.80857e-01, 9.88709e-01, 9.57015e-02, 4.80498e-01, 6.55767e-01, 9.81929e-01
Node: 11 (pos: 0.111): 5.48466e-01, 9.82414e-01, 2.55673e-02, 3.18158e-01, 5.17215e-01, 9.71907e-01
Node: 12 (pos: 0.121): 4.21091e-01, 9.74775e-01, 5.09409e-03, 1.92223e-01, 3.86978e-01, 9.59798e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.76261e-01, 9.99291e-01, 8.63590e-01, 9.55225e-01, 9.73973e-01, 9.98861e-01
Node: 58 (pos: 0.586): 9.08373e-01, 9.97165e-01, 5.56198e-01, 8.32574e-01, 8.99886e-01, 9.95451e-01
Node: 59 (pos: 0.596): 8.05553e-01, 9.93633e-01, 2.67157e-01, 6.62143e-01, 7.88718e-01, 9.89794e-01
Node: 60 (pos: 0.606): 6.80857e-01, 9.88709e-01, 9.57015e-02, 4.80498e-01, 6.55767e-01, 9.81929e-01
Node: 61 (pos: 0.616): 5.48466e-01, 9.82414e-01, 2.55673e-02, 3.18158e-01, 5.17215e-01, 9.71907e-01
Node: 50 (pos: 0.505): 4.21091e-01, 9.74775e-01, 5.09409e-03, 1.92223e-01, 3.86978e-01, 9.59798e-01
-
Node: 51 (pos: 0.515): 5.48466e-01, 9.82414e-01, 2.55673e-02, 3.18158e-01, 5.17215e-01, 9.71907e-01
Node: 52 (pos: 0.525): 6.80857e-01, 9.88709e-01, 9.57015e-02, 4.80498e-01, 6.55767e-01, 9.81929e-01
Node: 53 (pos: 0.535): 8.05553e-01, 9.93633e-01, 2.67157e-01, 6.62143e-01, 7.88718e-01, 9.89794e-01
Node: 54 (pos: 0.545): 9.08373e-01, 9.97165e-01, 5.56198e-01, 8.32574e-01, 8.99886e-01, 9.95451e-01
Node: 55 (pos: 0.556): 9.76261e-01, 9.99291e-01, 8.63590e-01, 9.55225e-01, 9.73973e-01, 9.98861e-01
Node: 62 (pos: 0.626): 4.21091e-01, 9.74775e-01, 5.09409e-03, 1.92223e-01, 3.86978e-01, 9.59798e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.021420322051171364
Step 50, mean loss 0.010573532159113632
Step 75, mean loss 0.01824092750864345
Step 100, mean loss 0.021796735974328667
Step 125, mean loss 0.035679014736172444
Step 150, mean loss 0.033749883598976155
Step 175, mean loss 0.05886910164323972
Step 200, mean loss 0.08521829912593387
Step 225, mean loss 0.06884760628016523
Unrolled forward losses 1.4131219726996878
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00), 0.11831366107483937, [0.004288623303401472, 0.14372595609902933, 0.0006936043264639399, 0.0022419351266907985, 0.0038650208662213015, 0.08952067266149565]
Training Loss (progress: 0.08), 0.10922510765906605, [0.004293757731410662, 0.1440000622202233, 0.0006953490880630053, 0.002235740628026892, 0.003918004384121287, 0.08962878765061548]
Training Loss (progress: 0.16), 0.12457364467355976, [0.004292134247609772, 0.14415750063205404, 0.0006887284434793585, 0.0022021272869978234, 0.003834286079451596, 0.0897388063363258]
Training Loss (progress: 0.24), 0.1147461984828775, [0.0042534633779046805, 0.14430894463816224, 0.0006807226314064604, 0.002222153538206643, 0.003834942873767275, 0.08985010789124147]
Training Loss (progress: 0.32), 0.10499357085521209, [0.004314021669416569, 0.14442046761027522, 0.0006730137968563936, 0.0022172947451704044, 0.0038318196091810595, 0.08990369421368918]
Training Loss (progress: 0.40), 0.11212506509558007, [0.004263498350727239, 0.144620175802972, 0.0007059132604049447, 0.0022264856169333055, 0.003898922051566845, 0.09005963684352232]
Training Loss (progress: 0.48), 0.1058059817431333, [0.004310291492759584, 0.14471707559797464, 0.0006959294197257538, 0.0022295226496826127, 0.003856909346289183, 0.09019755566129672]
Training Loss (progress: 0.56), 0.10608916631372685, [0.0043026954912634445, 0.14486962900256647, 0.0007094674421018477, 0.0022375940275866806, 0.0038789011849582186, 0.09023114011683099]
Training Loss (progress: 0.64), 0.10760994566561592, [0.0042871506219960415, 0.14503332123519364, 0.0006875378722021463, 0.0022238910681280665, 0.003804678006787902, 0.09028145958463106]
Training Loss (progress: 0.72), 0.11147865462908024, [0.004290815304276536, 0.1453015391272707, 0.0006847531561233703, 0.0022243563107597958, 0.0038630426981657393, 0.09039455535104354]
Training Loss (progress: 0.80), 0.11416031845674726, [0.0042811522278186675, 0.14544989482626472, 0.0006929234815760521, 0.0022129403171888347, 0.003831430755526022, 0.09051279427415337]
Training Loss (progress: 0.88), 0.10779465585050824, [0.004322942772567496, 0.14559720161975323, 0.000690053894629324, 0.0022040494743238485, 0.003876536784084481, 0.09059805498446634]
Training Loss (progress: 0.96), 0.12480933574171894, [0.004261527868626591, 0.14579482137548203, 0.0006797028693733374, 0.002241162940130911, 0.0038545533451063135, 0.09070420055952383]
Evaluation on validation dataset:
Step 25, mean loss 0.02623505469563865
Step 50, mean loss 0.013401075272806942
Step 75, mean loss 0.02547426835988067
Step 100, mean loss 0.03264335205733832
Step 125, mean loss 0.04018360249014401
Step 150, mean loss 0.031854221989921355
Step 175, mean loss 0.05436326617623313
Step 200, mean loss 0.18439364227175867
Step 225, mean loss 0.22285776732264648
Unrolled forward losses 1.5020020526105191
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.22862e-01, 9.75142e-01, 5.26408e-03, 1.91848e-01, 3.89044e-01, 9.60320e-01
Node: 01 (pos: 0.010): 5.50067e-01, 9.82671e-01, 2.61568e-02, 3.17727e-01, 5.19131e-01, 9.72274e-01
Node: 02 (pos: 0.020): 6.82128e-01, 9.88875e-01, 9.71078e-02, 4.80081e-01, 6.57321e-01, 9.82166e-01
Node: 03 (pos: 0.030): 8.06398e-01, 9.93727e-01, 2.69358e-01, 6.61819e-01, 7.89768e-01, 9.89929e-01
Node: 04 (pos: 0.040): 9.08796e-01, 9.97207e-01, 5.58231e-01, 8.32393e-01, 9.00418e-01, 9.95511e-01
Node: 05 (pos: 0.051): 9.76375e-01, 9.99301e-01, 8.64377e-01, 9.55173e-01, 9.74117e-01, 9.98876e-01
-
Node: 07 (pos: 0.071): 9.76375e-01, 9.99301e-01, 8.64377e-01, 9.55173e-01, 9.74117e-01, 9.98876e-01
Node: 08 (pos: 0.081): 9.08796e-01, 9.97207e-01, 5.58231e-01, 8.32393e-01, 9.00418e-01, 9.95511e-01
Node: 09 (pos: 0.091): 8.06398e-01, 9.93727e-01, 2.69358e-01, 6.61819e-01, 7.89768e-01, 9.89929e-01
Node: 10 (pos: 0.101): 6.82128e-01, 9.88875e-01, 9.71078e-02, 4.80081e-01, 6.57321e-01, 9.82166e-01
Node: 11 (pos: 0.111): 5.50067e-01, 9.82671e-01, 2.61568e-02, 3.17727e-01, 5.19131e-01, 9.72274e-01
Node: 12 (pos: 0.121): 4.22862e-01, 9.75142e-01, 5.26408e-03, 1.91848e-01, 3.89044e-01, 9.60320e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.76375e-01, 9.99301e-01, 8.64377e-01, 9.55173e-01, 9.74117e-01, 9.98876e-01
Node: 58 (pos: 0.586): 9.08796e-01, 9.97207e-01, 5.58231e-01, 8.32393e-01, 9.00418e-01, 9.95511e-01
Node: 59 (pos: 0.596): 8.06398e-01, 9.93727e-01, 2.69358e-01, 6.61819e-01, 7.89768e-01, 9.89929e-01
Node: 60 (pos: 0.606): 6.82128e-01, 9.88875e-01, 9.71078e-02, 4.80081e-01, 6.57321e-01, 9.82166e-01
Node: 61 (pos: 0.616): 5.50067e-01, 9.82671e-01, 2.61568e-02, 3.17727e-01, 5.19131e-01, 9.72274e-01
Node: 50 (pos: 0.505): 4.22862e-01, 9.75142e-01, 5.26408e-03, 1.91848e-01, 3.89044e-01, 9.60320e-01
-
Node: 51 (pos: 0.515): 5.50067e-01, 9.82671e-01, 2.61568e-02, 3.17727e-01, 5.19131e-01, 9.72274e-01
Node: 52 (pos: 0.525): 6.82128e-01, 9.88875e-01, 9.71078e-02, 4.80081e-01, 6.57321e-01, 9.82166e-01
Node: 53 (pos: 0.535): 8.06398e-01, 9.93727e-01, 2.69358e-01, 6.61819e-01, 7.89768e-01, 9.89929e-01
Node: 54 (pos: 0.545): 9.08796e-01, 9.97207e-01, 5.58231e-01, 8.32393e-01, 9.00418e-01, 9.95511e-01
Node: 55 (pos: 0.556): 9.76375e-01, 9.99301e-01, 8.64377e-01, 9.55173e-01, 9.74117e-01, 9.98876e-01
Node: 62 (pos: 0.626): 4.22862e-01, 9.75142e-01, 5.26408e-03, 1.91848e-01, 3.89044e-01, 9.60320e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.021795649843943436
Step 50, mean loss 0.010557483493947875
Step 75, mean loss 0.017493982972179804
Step 100, mean loss 0.02120645178749267
Step 125, mean loss 0.03813254048110007
Step 150, mean loss 0.03386735728272894
Step 175, mean loss 0.05460908985796726
Step 200, mean loss 0.08305023172093323
Step 225, mean loss 0.07174968629931841
Unrolled forward losses 1.4020797214145473
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time4301436.tar

Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00), 0.10821159230642227, [0.0042663445047836455, 0.14589624285529268, 0.0006978982433402401, 0.0022051399116844645, 0.0038703872640542787, 0.09072042970096003]
Training Loss (progress: 0.08), 0.11033027244105004, [0.004273655494929872, 0.1460247349154702, 0.0006862496735098776, 0.002223098118756559, 0.0038548944746155858, 0.09079296278861904]
Training Loss (progress: 0.16), 0.1091206931021734, [0.004270082261305209, 0.14613369971987386, 0.0006895166148432285, 0.0022295332149647453, 0.0038609129611807576, 0.09082076318443623]
Training Loss (progress: 0.24), 0.11103262535361194, [0.004269808017124145, 0.1462132511753453, 0.0006980187884049735, 0.0022185464375096267, 0.0038781130695053046, 0.09093300116185156]
Training Loss (progress: 0.32), 0.10748722728199242, [0.004278711811862944, 0.14626681915283252, 0.0006997099570042465, 0.0022286467872987357, 0.0038689750679944276, 0.09094067667709373]
Training Loss (progress: 0.40), 0.10264460738581835, [0.004278023825079208, 0.14631742795735378, 0.0006857534198876162, 0.0022263409768582534, 0.00390248551183064, 0.09100968720291558]
Training Loss (progress: 0.48), 0.09796451482772028, [0.004270587464806891, 0.14638287754996795, 0.0006923532273806085, 0.0022177948657868853, 0.0038999112831188997, 0.09101582028556154]
Training Loss (progress: 0.56), 0.10372749550058072, [0.004280597298303364, 0.1464765782132918, 0.0006944905034185513, 0.0022302013476611085, 0.00389248793523333, 0.09107024714540853]
Training Loss (progress: 0.64), 0.10632796560409889, [0.004269908327438013, 0.14659032697362712, 0.0006954280456031092, 0.0022213619793648924, 0.003896799692104016, 0.09114653322145376]
Training Loss (progress: 0.72), 0.10670897674335968, [0.004304455983867208, 0.14667982469548163, 0.0006849143610934976, 0.00220530702038047, 0.0038864068074447016, 0.0911812303098095]
Training Loss (progress: 0.80), 0.110996991941711, [0.004284612017978351, 0.14674818911034176, 0.0006886317566344585, 0.0022163967256357605, 0.0038917723543722246, 0.09121902956860979]
Training Loss (progress: 0.88), 0.11508667100815004, [0.004282137962174755, 0.1468455582062131, 0.0006897248500852782, 0.0022196571201477063, 0.003898449896977385, 0.09128136625803868]
Training Loss (progress: 0.96), 0.10187445327952514, [0.004265421700881759, 0.1469327277471832, 0.0006835475908813898, 0.002239944420752327, 0.003929881530765251, 0.09131932782819158]
Evaluation on validation dataset:
Step 25, mean loss 0.02435192091111167
Step 50, mean loss 0.014069404901712216
Step 75, mean loss 0.025445145770836557
Step 100, mean loss 0.03186108622167099
Step 125, mean loss 0.03970880246569948
Step 150, mean loss 0.0308234168617814
Step 175, mean loss 0.05181242762453121
Step 200, mean loss 0.17941718873138213
Step 225, mean loss 0.2048830237991246
Unrolled forward losses 1.5068965600862219
Unrolled forward base losses 2.565701273852575
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00), 0.09972032039554955, [0.004274736071302907, 0.14696538026686723, 0.0006853893010863382, 0.002237399917187474, 0.003915223245433959, 0.09133696491146585]
Training Loss (progress: 0.08), 0.10389821576705036, [0.004279060709299911, 0.14704765370635553, 0.0006917263833030086, 0.0022222337961438476, 0.003933464819940446, 0.09138330262147525]
Training Loss (progress: 0.16), 0.09968561943662284, [0.0042691029785725835, 0.1470653326133577, 0.000692047310483163, 0.0022255228735564916, 0.0039258138605264776, 0.09142850378026306]
Training Loss (progress: 0.24), 0.1007896619358018, [0.004278225405225414, 0.14714534819906458, 0.0006917925741307584, 0.0022268281405660798, 0.003925187702817347, 0.09146707669247284]
Training Loss (progress: 0.32), 0.10968758133271138, [0.004261741628818297, 0.14724884905690414, 0.000690239174601298, 0.0022241165432527717, 0.003938087240936079, 0.0915222231255713]
Training Loss (progress: 0.40), 0.11411341381757434, [0.004293748930203411, 0.14735088299944862, 0.0006903163517214587, 0.0022193636968329314, 0.003933685149520476, 0.09154041143217692]
Training Loss (progress: 0.48), 0.10408773054403717, [0.004272870923093117, 0.14745297151708534, 0.0006932330856846551, 0.0022308508301182267, 0.003938555324368341, 0.09162796826687906]
Training Loss (progress: 0.56), 0.10400977513746837, [0.004290258489025893, 0.14746584720047054, 0.0006874421829233183, 0.0022259013910303927, 0.003928719028125911, 0.09165725960452134]
Training Loss (progress: 0.64), 0.10532147559170725, [0.004278143086227189, 0.1475577564980071, 0.0006979092733043286, 0.002218386155985945, 0.003910083787199033, 0.09171741773229121]
Training Loss (progress: 0.72), 0.10981190459744554, [0.004272137364690603, 0.14760627219784095, 0.0006962139930963163, 0.00222285935801657, 0.0039020362524282864, 0.09177772291534883]
Training Loss (progress: 0.80), 0.11155115304526632, [0.0042717475081350655, 0.14765653721118482, 0.00069319362974512, 0.0022208469044927128, 0.00394040142848451, 0.09182841640389629]
Training Loss (progress: 0.88), 0.10362013363087644, [0.00428706382411665, 0.1477197904420098, 0.0006920544410259862, 0.002227752739949998, 0.003956770232594076, 0.09186065552210503]
Training Loss (progress: 0.96), 0.10842935811518326, [0.004244181037015946, 0.1478291443551251, 0.0006937972555755965, 0.002230625927081817, 0.0039411312322924375, 0.09190147230634871]
Evaluation on validation dataset:
Step 25, mean loss 0.024437623194017873
Step 50, mean loss 0.013492144716255608
Step 75, mean loss 0.024422108027816358
Step 100, mean loss 0.0323906333860069
Step 125, mean loss 0.03964164782312381
Step 150, mean loss 0.030625793414085847
Step 175, mean loss 0.05272419765531671
Step 200, mean loss 0.17480913131137804
Step 225, mean loss 0.21574294850009137
Unrolled forward losses 1.5852322392100056
Unrolled forward base losses 2.565701273852575
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00), 0.10520727665300118, [0.0042523696060948616, 0.1478219651109725, 0.0006893729372041213, 0.0022144022941854957, 0.003943737170600485, 0.091923102222893]
Training Loss (progress: 0.08), 0.1012695658431961, [0.004263125508345278, 0.14792397840948035, 0.0006916462757815467, 0.00222730360691958, 0.003964519202735115, 0.09194015280524274]
Training Loss (progress: 0.16), 0.11469038995426904, [0.004268616733985994, 0.1479886260240929, 0.0006869252211187118, 0.002214353736703638, 0.003944163327778768, 0.0919971012618393]
Training Loss (progress: 0.24), 0.10258605664623566, [0.00425094409675597, 0.14808692619670724, 0.0006927035837924516, 0.002219521885246508, 0.003949060092753309, 0.09201872308169158]
Training Loss (progress: 0.32), 0.10663202407429917, [0.0042653754450168585, 0.14811771335456508, 0.0007013988637508153, 0.0022242471288684952, 0.003928601906428674, 0.09206011841230788]
Training Loss (progress: 0.40), 0.10060433700844305, [0.004295481461072579, 0.14821790889245118, 0.0006884260691595336, 0.0022336789629049335, 0.0039162515217938815, 0.09208641262631881]
Training Loss (progress: 0.48), 0.11018821170973601, [0.004281819394430399, 0.1482717240661029, 0.0006934410093059489, 0.0022323994072690027, 0.0039432452408068655, 0.0921211852986695]
Training Loss (progress: 0.56), 0.11956263200303724, [0.004263091188193349, 0.1483415817661436, 0.0006838642517250336, 0.0022192946929897933, 0.003923444761012234, 0.09217736172164796]
Training Loss (progress: 0.64), 0.10177653982301428, [0.004266384376227026, 0.1483552571076118, 0.0006942027532049991, 0.002225512394625061, 0.0039404429648011935, 0.0921949611739484]
Training Loss (progress: 0.72), 0.10270589050643146, [0.004275286327428515, 0.14840116158353203, 0.0007008825456079865, 0.0022184116151515803, 0.003956580571913768, 0.09226672648589071]
Training Loss (progress: 0.80), 0.112967543138541, [0.004289325863825409, 0.14852542686453096, 0.0006794788748926747, 0.0022395359777705945, 0.003947685572423689, 0.0923199694266146]
Training Loss (progress: 0.88), 0.09877806994236461, [0.004266538487736335, 0.148601789572078, 0.0006965062062863355, 0.0022294401509104357, 0.003952058459595304, 0.09237884909132028]
Training Loss (progress: 0.96), 0.10267776891905943, [0.004280678918015155, 0.14870960228969357, 0.0006977113285100871, 0.0022273473407026963, 0.003946267889246698, 0.09244865920806276]
Evaluation on validation dataset:
Step 25, mean loss 0.023393056533162336
Step 50, mean loss 0.013191214646712492
Step 75, mean loss 0.02621574185831366
Step 100, mean loss 0.030934486431858643
Step 125, mean loss 0.04019550221927052
Step 150, mean loss 0.031204789699965894
Step 175, mean loss 0.05496767917491631
Step 200, mean loss 0.17257857693427012
Step 225, mean loss 0.21674850848019248
Unrolled forward losses 1.584883255387507
Unrolled forward base losses 2.565701273852575
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00), 0.10993155413894698, [0.004280500828224003, 0.14867690361147243, 0.0006993187520776656, 0.002229917189589953, 0.003928472722862829, 0.0924621593043206]
Training Loss (progress: 0.08), 0.1088095206674403, [0.004284495993038756, 0.14882239511684395, 0.0006967023940174106, 0.002223150207608057, 0.003929544753399362, 0.09248357531224217]
Training Loss (progress: 0.16), 0.1064204519111589, [0.00428084984337463, 0.14886547434978378, 0.0006940383249873143, 0.0022393769177400063, 0.003921903547968572, 0.09253450844649865]
Training Loss (progress: 0.24), 0.10555179444779005, [0.004277461451528382, 0.14898750027236243, 0.0006956273308195051, 0.0022310702455448674, 0.00395412824266356, 0.09258376197008385]
Training Loss (progress: 0.32), 0.11046312354928911, [0.004274961067712428, 0.14903360685914357, 0.0006958843752938252, 0.0022382306648786915, 0.003931320530094815, 0.09263834026873252]
Training Loss (progress: 0.40), 0.10428378876716733, [0.00427201274577491, 0.14907236014043151, 0.0006910222046292503, 0.002215764696248474, 0.003945461344028455, 0.09267845169780903]
Training Loss (progress: 0.48), 0.10004153813303583, [0.004229763665437317, 0.14914998760422563, 0.000706849158201156, 0.002220063866594478, 0.003933680600948796, 0.09272089563648808]
Training Loss (progress: 0.56), 0.09913596524891961, [0.0042268726422035295, 0.1492428106423686, 0.0006962849850583171, 0.0022023282205080115, 0.003955386805187548, 0.09275848502498536]
Training Loss (progress: 0.64), 0.11062949793556016, [0.0042349802317527925, 0.149305507983795, 0.0006929760908635548, 0.0022162769518068314, 0.003949500007108551, 0.09278690876888133]
Training Loss (progress: 0.72), 0.11648222144446842, [0.004244839078481781, 0.14941255496800032, 0.0006934561273231322, 0.002225302954602954, 0.003927591132969395, 0.09281100442997514]
Training Loss (progress: 0.80), 0.10236552457639644, [0.0042497769484576235, 0.14950959138969314, 0.0007006723610334379, 0.0022085595468660365, 0.0039728414881532855, 0.09283168642234105]
Training Loss (progress: 0.88), 0.09811619163728316, [0.004243894196880722, 0.14955926674038547, 0.000697300007100758, 0.0022238771857747692, 0.003978799875647159, 0.09287508587663743]
Training Loss (progress: 0.96), 0.10585286698428659, [0.004251444829713635, 0.1496301088958121, 0.0007019321740216976, 0.0022250631606989153, 0.003974169549170651, 0.09292882765560227]
Evaluation on validation dataset:
Step 25, mean loss 0.02346018492463591
Step 50, mean loss 0.01328316342755485
Step 75, mean loss 0.0244699699588255
Step 100, mean loss 0.03241989659706267
Step 125, mean loss 0.04030458947728362
Step 150, mean loss 0.029632313643557437
Step 175, mean loss 0.05257643774066388
Step 200, mean loss 0.18014824395817064
Step 225, mean loss 0.20971923289195554
Unrolled forward losses 1.5486530858773535
Unrolled forward base losses 2.565701273852575
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00), 0.10212164680446126, [0.0042277829793041085, 0.1496034324544253, 0.0006923819988844633, 0.0022195898524848957, 0.0039732962757207625, 0.09296241268801098]
Training Loss (progress: 0.08), 0.11251022576029295, [0.0042501967936195905, 0.1496765753206612, 0.0006939466387537626, 0.002214327128916403, 0.003985474291610264, 0.09298422119705181]
Training Loss (progress: 0.16), 0.1056848003644609, [0.004239212008793906, 0.14977533913952093, 0.000699146042029211, 0.0021985951860346515, 0.003983778818044198, 0.09302953922384656]
Training Loss (progress: 0.24), 0.10378226863964136, [0.004258948616708151, 0.1498533290190558, 0.0006880389547201816, 0.0022253653401318944, 0.0039880777273513844, 0.09306198598588708]
Training Loss (progress: 0.32), 0.10765655416842192, [0.0042384407107778944, 0.14985780579411193, 0.0006984739267025232, 0.0022147360669845504, 0.003972528612078898, 0.0931233778872198]
Training Loss (progress: 0.40), 0.11316906158457349, [0.004236963112531362, 0.14993629606474376, 0.0006956311933994206, 0.0022278809412004954, 0.0039851973695921765, 0.09316283209450216]
Training Loss (progress: 0.48), 0.10904275160434217, [0.004243152693385399, 0.15001988143911443, 0.0006959388581994558, 0.0022256082855827307, 0.00395619494123335, 0.0931645971856825]
Training Loss (progress: 0.56), 0.10395315059933036, [0.004249249676897627, 0.15006883186405992, 0.0007027681028207215, 0.0022374012666994464, 0.003981097007199125, 0.09320126806495617]
Training Loss (progress: 0.64), 0.10607368826237856, [0.004238891969140549, 0.15011449419567238, 0.0007030677798315901, 0.002223147362429844, 0.003981119363834779, 0.09326593830039409]
Training Loss (progress: 0.72), 0.09805338428645055, [0.004262088619424684, 0.1502064388201117, 0.0006981582486572804, 0.002211109037380957, 0.003970639515110167, 0.09332052382660956]
Training Loss (progress: 0.80), 0.10193232329704266, [0.00422233758322261, 0.1503051834346651, 0.000702310849303469, 0.002216213782500711, 0.004002306904978387, 0.09334348231612127]
Training Loss (progress: 0.88), 0.10615118541782939, [0.004246351919921895, 0.15035188251678064, 0.0007043066948114073, 0.002207341680781145, 0.003995389939296186, 0.09336884696813802]
Training Loss (progress: 0.96), 0.1100567237863947, [0.004252132346980355, 0.1504463124592114, 0.0006923538708323964, 0.0022093381409964176, 0.003976322769141546, 0.09342709837544752]
Evaluation on validation dataset:
Step 25, mean loss 0.02194587889010599
Step 50, mean loss 0.013192655147503885
Step 75, mean loss 0.025358194560117057
Step 100, mean loss 0.030081448105192993
Step 125, mean loss 0.03896816951477869
Step 150, mean loss 0.029201764865606744
Step 175, mean loss 0.0530104126088658
Step 200, mean loss 0.1732598559095966
Step 225, mean loss 0.21269424752829663
Unrolled forward losses 1.5802459311807096
Unrolled forward base losses 2.565701273852575
Test loss: 1.4020797214145473
