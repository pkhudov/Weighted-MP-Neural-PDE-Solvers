Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar
Number of parameters: 1035587
Epoch 0
Starting epoch 0...
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): -6.53370e-02, -1.20694e-01, 1.37599e-01, 1.78580e-02, 5.78461e-02, 1.29765e-01
Node: 01 (pos: 0.010): -6.45202e-02, -1.21516e-01, 1.39489e-01, 1.85567e-02, 5.59323e-02, 1.29731e-01
Node: 02 (pos: 0.020): -6.37044e-02, -1.22339e-01, 1.41381e-01, 1.92563e-02, 5.40251e-02, 1.29700e-01
Node: 03 (pos: 0.030): -6.28899e-02, -1.23164e-01, 1.43276e-01, 1.99568e-02, 5.21243e-02, 1.29672e-01
Node: 04 (pos: 0.040): -6.20764e-02, -1.23990e-01, 1.45173e-01, 2.06583e-02, 5.02300e-02, 1.29647e-01
Node: 05 (pos: 0.051): -6.12640e-02, -1.24817e-01, 1.47072e-01, 2.13606e-02, 4.83421e-02, 1.29625e-01
-
Node: 07 (pos: 0.071): -6.12640e-02, -1.24817e-01, 1.47072e-01, 2.13606e-02, 4.83421e-02, 1.29625e-01
Node: 08 (pos: 0.081): -6.20764e-02, -1.23990e-01, 1.45173e-01, 2.06583e-02, 5.02300e-02, 1.29647e-01
Node: 09 (pos: 0.091): -6.28899e-02, -1.23164e-01, 1.43276e-01, 1.99568e-02, 5.21243e-02, 1.29672e-01
Node: 10 (pos: 0.101): -6.37044e-02, -1.22339e-01, 1.41381e-01, 1.92563e-02, 5.40251e-02, 1.29700e-01
Node: 11 (pos: 0.111): -6.45202e-02, -1.21516e-01, 1.39489e-01, 1.85567e-02, 5.59323e-02, 1.29731e-01
Node: 12 (pos: 0.121): -6.53370e-02, -1.20694e-01, 1.37599e-01, 1.78580e-02, 5.78461e-02, 1.29765e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.39969e-02, 4.71661e-07, 5.98796e-09, 7.26943e-01, 3.52188e-02, 4.86284e-08
Node: 01 (pos: 0.010): 1.55631e-02, 3.86510e-07, 3.54688e-09, 7.08680e-01, 4.37867e-02, 4.90640e-08
Node: 02 (pos: 0.020): 1.72791e-02, 3.16204e-07, 2.08458e-09, 6.90177e-01, 5.40035e-02, 4.94627e-08
Node: 03 (pos: 0.030): 1.91561e-02, 2.58255e-07, 1.21559e-09, 6.71477e-01, 6.60766e-02, 4.98237e-08
Node: 04 (pos: 0.040): 2.12059e-02, 2.10575e-07, 7.03313e-10, 6.52618e-01, 8.02146e-02, 5.01460e-08
Node: 05 (pos: 0.051): 2.34407e-02, 1.71412e-07, 4.03734e-10, 6.33639e-01, 9.66213e-02, 5.04290e-08
-
Node: 07 (pos: 0.071): 2.34407e-02, 1.71412e-07, 4.03734e-10, 6.33639e-01, 9.66213e-02, 5.04290e-08
Node: 08 (pos: 0.081): 2.12059e-02, 2.10575e-07, 7.03313e-10, 6.52618e-01, 8.02146e-02, 5.01460e-08
Node: 09 (pos: 0.091): 1.91561e-02, 2.58255e-07, 1.21559e-09, 6.71477e-01, 6.60766e-02, 4.98237e-08
Node: 10 (pos: 0.101): 1.72791e-02, 3.16204e-07, 2.08458e-09, 6.90177e-01, 5.40035e-02, 4.94627e-08
Node: 11 (pos: 0.111): 1.55631e-02, 3.86510e-07, 3.54688e-09, 7.08680e-01, 4.37867e-02, 4.90640e-08
Node: 12 (pos: 0.121): 1.39969e-02, 4.71661e-07, 5.98796e-09, 7.26943e-01, 3.52188e-02, 4.86284e-08
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): -6.12640e-02, -1.24817e-01, 1.47072e-01, 2.13606e-02, 4.83421e-02, 1.29625e-01
Node: 01 (pos: 0.010): -6.20764e-02, -1.23990e-01, 1.45173e-01, 2.06583e-02, 5.02300e-02, 1.29647e-01
Node: 02 (pos: 0.020): -6.28899e-02, -1.23164e-01, 1.43276e-01, 1.99568e-02, 5.21243e-02, 1.29672e-01
Node: 03 (pos: 0.030): -6.37044e-02, -1.22339e-01, 1.41381e-01, 1.92563e-02, 5.40251e-02, 1.29700e-01
Node: 04 (pos: 0.040): -6.45202e-02, -1.21516e-01, 1.39489e-01, 1.85567e-02, 5.59323e-02, 1.29731e-01
Node: 05 (pos: 0.051): -6.53370e-02, -1.20694e-01, 1.37599e-01, 1.78580e-02, 5.78461e-02, 1.29765e-01
-
Node: 07 (pos: 0.071): -6.45202e-02, -1.21516e-01, 1.39489e-01, 1.85567e-02, 5.59323e-02, 1.29731e-01
Node: 08 (pos: 0.081): -6.37044e-02, -1.22339e-01, 1.41381e-01, 1.92563e-02, 5.40251e-02, 1.29700e-01
Node: 09 (pos: 0.091): -6.28899e-02, -1.23164e-01, 1.43276e-01, 1.99568e-02, 5.21243e-02, 1.29672e-01
Node: 10 (pos: 0.101): -6.20764e-02, -1.23990e-01, 1.45173e-01, 2.06583e-02, 5.02300e-02, 1.29647e-01
Node: 11 (pos: 0.111): -6.12640e-02, -1.24817e-01, 1.47072e-01, 2.13606e-02, 4.83421e-02, 1.29625e-01
Node: 12 (pos: 0.121): -6.53370e-02, -1.20694e-01, 1.37599e-01, 1.78580e-02, 5.78461e-02, 1.29765e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 2.34407e-02, 1.71412e-07, 4.03734e-10, 6.33639e-01, 9.66213e-02, 5.04290e-08
Node: 58 (pos: 0.586): 2.12059e-02, 2.10575e-07, 7.03313e-10, 6.52618e-01, 8.02146e-02, 5.01460e-08
Node: 59 (pos: 0.596): 1.91561e-02, 2.58255e-07, 1.21559e-09, 6.71477e-01, 6.60766e-02, 4.98237e-08
Node: 60 (pos: 0.606): 1.72791e-02, 3.16204e-07, 2.08458e-09, 6.90177e-01, 5.40035e-02, 4.94627e-08
Node: 61 (pos: 0.616): 1.55631e-02, 3.86510e-07, 3.54688e-09, 7.08680e-01, 4.37867e-02, 4.90640e-08
Node: 50 (pos: 0.505): 1.39969e-02, 4.71661e-07, 5.98796e-09, 7.26943e-01, 3.52188e-02, 4.86284e-08
-
Node: 51 (pos: 0.515): 1.55631e-02, 3.86510e-07, 3.54688e-09, 7.08680e-01, 4.37867e-02, 4.90640e-08
Node: 52 (pos: 0.525): 1.72791e-02, 3.16204e-07, 2.08458e-09, 6.90177e-01, 5.40035e-02, 4.94627e-08
Node: 53 (pos: 0.535): 1.91561e-02, 2.58255e-07, 1.21559e-09, 6.71477e-01, 6.60766e-02, 4.98237e-08
Node: 54 (pos: 0.545): 2.12059e-02, 2.10575e-07, 7.03313e-10, 6.52618e-01, 8.02146e-02, 5.01460e-08
Node: 55 (pos: 0.556): 2.34407e-02, 1.71412e-07, 4.03734e-10, 6.33639e-01, 9.66213e-02, 5.04290e-08
Node: 62 (pos: 0.626): 1.39969e-02, 4.71661e-07, 5.98796e-09, 7.26943e-01, 3.52188e-02, 4.86284e-08
=========================================================================================================
Training Loss (progress: 0.00), 1.2525806590438926, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.2576156374693896, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.20335570775962075, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.18070291528465726, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.15590931236306568, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.14630695122626555, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.1261626379515985, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.12720236837536586, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.11621378361952157, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.12263555943195759, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.10980534177256952, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.10225126638804992, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.09738873194142503, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.08924014631211247
Step 50, mean loss 0.10932024754916166
Step 75, mean loss 0.13947939702515413
Step 100, mean loss 0.2725890671631704
Step 125, mean loss 0.22933884724215636
Step 150, mean loss 0.18815269875407958
Step 175, mean loss 0.32859651738804446
Step 200, mean loss 0.9521464880216718
Step 225, mean loss 0.46825879342662685
Unrolled forward losses 14.726142496871987
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.43103e-01, 1.48764e-01, 1.60392e-01, -6.62256e-02, 6.81650e-02, 1.45420e-01
Node: 01 (pos: 0.010): 1.43673e-01, 1.47509e-01, 1.62265e-01, -5.45298e-02, 5.56693e-02, 1.45398e-01
Node: 02 (pos: 0.020): 1.44240e-01, 1.46248e-01, 1.64140e-01, -4.24739e-02, 4.33981e-02, 1.45379e-01
Node: 03 (pos: 0.030): 1.44802e-01, 1.44982e-01, 1.66018e-01, -3.00567e-02, 3.13536e-02, 1.45363e-01
Node: 04 (pos: 0.040): 1.45361e-01, 1.43712e-01, 1.67898e-01, -1.72773e-02, 1.95376e-02, 1.45351e-01
Node: 05 (pos: 0.051): 1.45915e-01, 1.42437e-01, 1.69781e-01, -4.13490e-03, 7.95194e-03, 1.45342e-01
-
Node: 07 (pos: 0.071): 1.45915e-01, 1.42437e-01, 1.69781e-01, -4.13490e-03, 7.95194e-03, 1.45342e-01
Node: 08 (pos: 0.081): 1.45361e-01, 1.43712e-01, 1.67898e-01, -1.72773e-02, 1.95376e-02, 1.45351e-01
Node: 09 (pos: 0.091): 1.44802e-01, 1.44982e-01, 1.66018e-01, -3.00567e-02, 3.13536e-02, 1.45363e-01
Node: 10 (pos: 0.101): 1.44240e-01, 1.46248e-01, 1.64140e-01, -4.24739e-02, 4.33981e-02, 1.45379e-01
Node: 11 (pos: 0.111): 1.43673e-01, 1.47509e-01, 1.62265e-01, -5.45298e-02, 5.56693e-02, 1.45398e-01
Node: 12 (pos: 0.121): 1.43103e-01, 1.48764e-01, 1.60392e-01, -6.62256e-02, 6.81650e-02, 1.45420e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.27754e-09, 2.44737e-10, 6.72171e-12, 1.24526e-02, 9.59541e-03, 6.54695e-10
Node: 01 (pos: 0.010): 1.08471e-09, 3.55037e-10, 3.67319e-12, 5.11242e-02, 4.50912e-02, 6.58858e-10
Node: 02 (pos: 0.020): 9.21457e-10, 5.14168e-10, 1.99164e-12, 1.64634e-01, 1.52073e-01, 6.62451e-10
Node: 03 (pos: 0.030): 7.83181e-10, 7.43317e-10, 1.07145e-12, 4.05187e-01, 3.74170e-01, 6.65465e-10
Node: 04 (pos: 0.040): 6.66011e-10, 1.07266e-09, 5.71904e-13, 7.41927e-01, 6.82688e-01, 6.67890e-10
Node: 05 (pos: 0.051): 5.66682e-10, 1.54507e-09, 3.02871e-13, 9.83048e-01, 9.38724e-01, 6.69722e-10
-
Node: 07 (pos: 0.071): 5.66682e-10, 1.54507e-09, 3.02871e-13, 9.83048e-01, 9.38724e-01, 6.69722e-10
Node: 08 (pos: 0.081): 6.66011e-10, 1.07266e-09, 5.71904e-13, 7.41927e-01, 6.82688e-01, 6.67890e-10
Node: 09 (pos: 0.091): 7.83181e-10, 7.43317e-10, 1.07145e-12, 4.05187e-01, 3.74170e-01, 6.65465e-10
Node: 10 (pos: 0.101): 9.21457e-10, 5.14168e-10, 1.99164e-12, 1.64634e-01, 1.52073e-01, 6.62451e-10
Node: 11 (pos: 0.111): 1.08471e-09, 3.55037e-10, 3.67319e-12, 5.11242e-02, 4.50912e-02, 6.58858e-10
Node: 12 (pos: 0.121): 1.27754e-09, 2.44737e-10, 6.72171e-12, 1.24526e-02, 9.59541e-03, 6.54695e-10
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.45915e-01, 1.42437e-01, 1.69781e-01, -4.13490e-03, 7.95194e-03, 1.45342e-01
Node: 01 (pos: 0.010): 1.45361e-01, 1.43712e-01, 1.67898e-01, -1.72773e-02, 1.95376e-02, 1.45351e-01
Node: 02 (pos: 0.020): 1.44802e-01, 1.44982e-01, 1.66018e-01, -3.00567e-02, 3.13536e-02, 1.45363e-01
Node: 03 (pos: 0.030): 1.44240e-01, 1.46248e-01, 1.64140e-01, -4.24739e-02, 4.33981e-02, 1.45379e-01
Node: 04 (pos: 0.040): 1.43673e-01, 1.47509e-01, 1.62265e-01, -5.45298e-02, 5.56693e-02, 1.45398e-01
Node: 05 (pos: 0.051): 1.43103e-01, 1.48764e-01, 1.60392e-01, -6.62256e-02, 6.81650e-02, 1.45420e-01
-
Node: 07 (pos: 0.071): 1.43673e-01, 1.47509e-01, 1.62265e-01, -5.45298e-02, 5.56693e-02, 1.45398e-01
Node: 08 (pos: 0.081): 1.44240e-01, 1.46248e-01, 1.64140e-01, -4.24739e-02, 4.33981e-02, 1.45379e-01
Node: 09 (pos: 0.091): 1.44802e-01, 1.44982e-01, 1.66018e-01, -3.00567e-02, 3.13536e-02, 1.45363e-01
Node: 10 (pos: 0.101): 1.45361e-01, 1.43712e-01, 1.67898e-01, -1.72773e-02, 1.95376e-02, 1.45351e-01
Node: 11 (pos: 0.111): 1.45915e-01, 1.42437e-01, 1.69781e-01, -4.13490e-03, 7.95194e-03, 1.45342e-01
Node: 12 (pos: 0.121): 1.43103e-01, 1.48764e-01, 1.60392e-01, -6.62256e-02, 6.81650e-02, 1.45420e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 5.66682e-10, 1.54507e-09, 3.02871e-13, 9.83048e-01, 9.38724e-01, 6.69722e-10
Node: 58 (pos: 0.586): 6.66011e-10, 1.07266e-09, 5.71904e-13, 7.41927e-01, 6.82688e-01, 6.67890e-10
Node: 59 (pos: 0.596): 7.83181e-10, 7.43317e-10, 1.07145e-12, 4.05187e-01, 3.74170e-01, 6.65465e-10
Node: 60 (pos: 0.606): 9.21457e-10, 5.14168e-10, 1.99164e-12, 1.64634e-01, 1.52073e-01, 6.62451e-10
Node: 61 (pos: 0.616): 1.08471e-09, 3.55037e-10, 3.67319e-12, 5.11242e-02, 4.50912e-02, 6.58858e-10
Node: 50 (pos: 0.505): 1.27754e-09, 2.44737e-10, 6.72171e-12, 1.24526e-02, 9.59541e-03, 6.54695e-10
-
Node: 51 (pos: 0.515): 1.08471e-09, 3.55037e-10, 3.67319e-12, 5.11242e-02, 4.50912e-02, 6.58858e-10
Node: 52 (pos: 0.525): 9.21457e-10, 5.14168e-10, 1.99164e-12, 1.64634e-01, 1.52073e-01, 6.62451e-10
Node: 53 (pos: 0.535): 7.83181e-10, 7.43317e-10, 1.07145e-12, 4.05187e-01, 3.74170e-01, 6.65465e-10
Node: 54 (pos: 0.545): 6.66011e-10, 1.07266e-09, 5.71904e-13, 7.41927e-01, 6.82688e-01, 6.67890e-10
Node: 55 (pos: 0.556): 5.66682e-10, 1.54507e-09, 3.02871e-13, 9.83048e-01, 9.38724e-01, 6.69722e-10
Node: 62 (pos: 0.626): 1.27754e-09, 2.44737e-10, 6.72171e-12, 1.24526e-02, 9.59541e-03, 6.54695e-10
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 1.2815467352099358e-12), ('0.bias', 1.135444568966827e-10), ('2.weight', 1.3587838620146732e-09), ('2.bias', 3.505218778325242e-10)] 

GNN_Layer 1 gradients:
[('0.weight', 1.6489224867681286e-12), ('0.bias', 2.817888570493907e-11), ('2.weight', 3.261616499212734e-10), ('2.bias', 8.658464338588482e-11)] 

GNN_Layer 2 gradients:
[('0.weight', 1.855711175307381e-14), ('0.bias', 3.694436035160784e-13), ('2.weight', 4.484907708636627e-12), ('2.bias', 1.0915585537682704e-12)] 

GNN_Layer 3 gradients:
[('0.weight', 0.007904832660401135), ('0.bias', 0.21936087043237043), ('2.weight', 1.2678273029879237), ('2.bias', 0.3862354469063928)] 

GNN_Layer 4 gradients:
[('0.weight', 0.00038383697915740487), ('0.bias', 0.010808799917511878), ('2.weight', 0.08443998453128798), ('2.bias', 0.022183217265359115)] 

GNN_Layer 5 gradients:
[('0.weight', 4.291999193200446e-12), ('0.bias', 1.1773703625623147e-10), ('2.weight', 1.4656811179535222e-09), ('2.bias', 3.7413459219828325e-10)] 

Evaluation on test dataset:
Step 25, mean loss 0.07656815558314409
Step 50, mean loss 0.09110895900681829
Step 75, mean loss 0.13504079874841726
Step 100, mean loss 0.13580659517832502
Step 125, mean loss 0.31600486406526984
Step 150, mean loss 0.19026698214566876
Step 175, mean loss 0.29675036840669144
Step 200, mean loss 0.3170285585458818
Step 225, mean loss 0.29749381221144233
Unrolled forward losses 13.139552654409487
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.228885272229512, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.21085244669056968, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.18687472384258272, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.2054284313387175, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.21139970640031397, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.17405538395295234, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.1941028714576665, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.1724961377570738, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.1946272066878292, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.15774365886527322, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.16218185660521414, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.15741421421843388, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.1542229220295063, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.10105468958215585
Step 50, mean loss 0.05689437053327549
Step 75, mean loss 0.07194175530571689
Step 100, mean loss 0.09703582471545615
Step 125, mean loss 0.13402691006883372
Step 150, mean loss 0.0902479091850164
Step 175, mean loss 0.1507485552696175
Step 200, mean loss 0.4021085834847108
Step 225, mean loss 0.2814786845124979
Unrolled forward losses 4.549394245486588
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.48898e-01, 1.50263e-01, 1.47378e-01, -6.77627e-02, 7.89509e-02, 1.42326e-01
Node: 01 (pos: 0.010): 1.49430e-01, 1.49077e-01, 1.49092e-01, -5.43296e-02, 6.18681e-02, 1.42314e-01
Node: 02 (pos: 0.020): 1.49959e-01, 1.47886e-01, 1.50808e-01, -4.04208e-02, 4.51989e-02, 1.42304e-01
Node: 03 (pos: 0.030): 1.50484e-01, 1.46691e-01, 1.52527e-01, -2.60346e-02, 2.89479e-02, 1.42298e-01
Node: 04 (pos: 0.040): 1.51005e-01, 1.45491e-01, 1.54247e-01, -1.11699e-02, 1.31194e-02, 1.42294e-01
Node: 05 (pos: 0.051): 1.51523e-01, 1.44288e-01, 1.55970e-01, 4.17425e-03, -2.28265e-03, 1.42294e-01
-
Node: 07 (pos: 0.071): 1.51523e-01, 1.44288e-01, 1.55970e-01, 4.17425e-03, -2.28265e-03, 1.42294e-01
Node: 08 (pos: 0.081): 1.51005e-01, 1.45491e-01, 1.54247e-01, -1.11699e-02, 1.31194e-02, 1.42294e-01
Node: 09 (pos: 0.091): 1.50484e-01, 1.46691e-01, 1.52527e-01, -2.60346e-02, 2.89479e-02, 1.42298e-01
Node: 10 (pos: 0.101): 1.49959e-01, 1.47886e-01, 1.50808e-01, -4.04208e-02, 4.51989e-02, 1.42304e-01
Node: 11 (pos: 0.111): 1.49430e-01, 1.49077e-01, 1.49092e-01, -5.43296e-02, 6.18681e-02, 1.42314e-01
Node: 12 (pos: 0.121): 1.48898e-01, 1.50263e-01, 1.47378e-01, -6.77627e-02, 7.89509e-02, 1.42326e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.35217e-10, 1.56358e-10, 3.68998e-10, 1.01348e-02, 1.96306e-03, 1.59458e-09
Node: 01 (pos: 0.010): 2.00681e-10, 2.23005e-10, 2.21988e-10, 5.22507e-02, 2.17604e-02, 1.60014e-09
Node: 02 (pos: 0.020): 1.71305e-10, 3.17587e-10, 1.32677e-10, 1.95179e-01, 1.29647e-01, 1.60438e-09
Node: 03 (pos: 0.030): 1.46308e-10, 4.51595e-10, 7.87812e-11, 5.07732e-01, 4.32583e-01, 1.60731e-09
Node: 04 (pos: 0.040): 1.25027e-10, 6.41146e-10, 4.64730e-11, 8.82703e-01, 8.41879e-01, 1.60892e-09
Node: 05 (pos: 0.051): 1.06901e-10, 9.08799e-10, 2.72350e-11, 9.82727e-01, 9.94803e-01, 1.60919e-09
-
Node: 07 (pos: 0.071): 1.06901e-10, 9.08799e-10, 2.72350e-11, 9.82727e-01, 9.94803e-01, 1.60919e-09
Node: 08 (pos: 0.081): 1.25027e-10, 6.41146e-10, 4.64730e-11, 8.82703e-01, 8.41879e-01, 1.60892e-09
Node: 09 (pos: 0.091): 1.46308e-10, 4.51595e-10, 7.87812e-11, 5.07732e-01, 4.32583e-01, 1.60731e-09
Node: 10 (pos: 0.101): 1.71305e-10, 3.17587e-10, 1.32677e-10, 1.95179e-01, 1.29647e-01, 1.60438e-09
Node: 11 (pos: 0.111): 2.00681e-10, 2.23005e-10, 2.21988e-10, 5.22507e-02, 2.17604e-02, 1.60014e-09
Node: 12 (pos: 0.121): 2.35217e-10, 1.56358e-10, 3.68998e-10, 1.01348e-02, 1.96306e-03, 1.59458e-09
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.51523e-01, 1.44288e-01, 1.55970e-01, 4.17425e-03, -2.28265e-03, 1.42294e-01
Node: 01 (pos: 0.010): 1.51005e-01, 1.45491e-01, 1.54247e-01, -1.11699e-02, 1.31194e-02, 1.42294e-01
Node: 02 (pos: 0.020): 1.50484e-01, 1.46691e-01, 1.52527e-01, -2.60346e-02, 2.89479e-02, 1.42298e-01
Node: 03 (pos: 0.030): 1.49959e-01, 1.47886e-01, 1.50808e-01, -4.04208e-02, 4.51989e-02, 1.42304e-01
Node: 04 (pos: 0.040): 1.49430e-01, 1.49077e-01, 1.49092e-01, -5.43296e-02, 6.18681e-02, 1.42314e-01
Node: 05 (pos: 0.051): 1.48898e-01, 1.50263e-01, 1.47378e-01, -6.77627e-02, 7.89509e-02, 1.42326e-01
-
Node: 07 (pos: 0.071): 1.49430e-01, 1.49077e-01, 1.49092e-01, -5.43296e-02, 6.18681e-02, 1.42314e-01
Node: 08 (pos: 0.081): 1.49959e-01, 1.47886e-01, 1.50808e-01, -4.04208e-02, 4.51989e-02, 1.42304e-01
Node: 09 (pos: 0.091): 1.50484e-01, 1.46691e-01, 1.52527e-01, -2.60346e-02, 2.89479e-02, 1.42298e-01
Node: 10 (pos: 0.101): 1.51005e-01, 1.45491e-01, 1.54247e-01, -1.11699e-02, 1.31194e-02, 1.42294e-01
Node: 11 (pos: 0.111): 1.51523e-01, 1.44288e-01, 1.55970e-01, 4.17425e-03, -2.28265e-03, 1.42294e-01
Node: 12 (pos: 0.121): 1.48898e-01, 1.50263e-01, 1.47378e-01, -6.77627e-02, 7.89509e-02, 1.42326e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.06901e-10, 9.08799e-10, 2.72350e-11, 9.82727e-01, 9.94803e-01, 1.60919e-09
Node: 58 (pos: 0.586): 1.25027e-10, 6.41146e-10, 4.64730e-11, 8.82703e-01, 8.41879e-01, 1.60892e-09
Node: 59 (pos: 0.596): 1.46308e-10, 4.51595e-10, 7.87812e-11, 5.07732e-01, 4.32583e-01, 1.60731e-09
Node: 60 (pos: 0.606): 1.71305e-10, 3.17587e-10, 1.32677e-10, 1.95179e-01, 1.29647e-01, 1.60438e-09
Node: 61 (pos: 0.616): 2.00681e-10, 2.23005e-10, 2.21988e-10, 5.22507e-02, 2.17604e-02, 1.60014e-09
Node: 50 (pos: 0.505): 2.35217e-10, 1.56358e-10, 3.68998e-10, 1.01348e-02, 1.96306e-03, 1.59458e-09
-
Node: 51 (pos: 0.515): 2.00681e-10, 2.23005e-10, 2.21988e-10, 5.22507e-02, 2.17604e-02, 1.60014e-09
Node: 52 (pos: 0.525): 1.71305e-10, 3.17587e-10, 1.32677e-10, 1.95179e-01, 1.29647e-01, 1.60438e-09
Node: 53 (pos: 0.535): 1.46308e-10, 4.51595e-10, 7.87812e-11, 5.07732e-01, 4.32583e-01, 1.60731e-09
Node: 54 (pos: 0.545): 1.25027e-10, 6.41146e-10, 4.64730e-11, 8.82703e-01, 8.41879e-01, 1.60892e-09
Node: 55 (pos: 0.556): 1.06901e-10, 9.08799e-10, 2.72350e-11, 9.82727e-01, 9.94803e-01, 1.60919e-09
Node: 62 (pos: 0.626): 2.35217e-10, 1.56358e-10, 3.68998e-10, 1.01348e-02, 1.96306e-03, 1.59458e-09
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 2.0694237042224848e-12), ('0.bias', 3.3028143688128135e-11), ('2.weight', 3.961946174895921e-10), ('2.bias', 1.0598395696537206e-10)] 

GNN_Layer 1 gradients:
[('0.weight', 2.4093981425949188e-12), ('0.bias', 6.048896758902028e-11), ('2.weight', 7.011219329118851e-10), ('2.bias', 1.9294320173533357e-10)] 

GNN_Layer 2 gradients:
[('0.weight', 6.647903198514164e-13), ('0.bias', 1.6262800816124127e-11), ('2.weight', 1.97484575231046e-10), ('2.bias', 4.993854762648153e-11)] 

GNN_Layer 3 gradients:
[('0.weight', 0.0021954840167666785), ('0.bias', 0.05036281135995991), ('2.weight', 0.24950878854816053), ('2.bias', 0.07897439815706864)] 

GNN_Layer 4 gradients:
[('0.weight', 0.0022148128005776515), ('0.bias', 0.07012343536220621), ('2.weight', 0.42863395491505346), ('2.bias', 0.1178087155504819)] 

GNN_Layer 5 gradients:
[('0.weight', 1.1517026137481988e-11), ('0.bias', 2.891220899393465e-10), ('2.weight', 3.6032146978348256e-09), ('2.bias', 9.530791834801617e-10)] 

Evaluation on test dataset:
Step 25, mean loss 0.08372528034940782
Step 50, mean loss 0.04238460254389345
Step 75, mean loss 0.058133659471738694
Step 100, mean loss 0.06687622879661351
Step 125, mean loss 0.0795073702678119
Step 150, mean loss 0.1023035685977587
Step 175, mean loss 0.14911030567989147
Step 200, mean loss 0.1946055208151365
Step 225, mean loss 0.18644603052020342
Unrolled forward losses 4.145453155983075
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.21468490159814885, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.1959220810568241, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.22261621946114213, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.22630532580110638, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.20346853099710258, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.21144050194653768, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.2218085925866676, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.19519934436547828, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.18607421960843507, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.18578742990823263, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.19744259267360936, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.1771624942029327, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.1815741966811619, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.07631016566928331
Step 50, mean loss 0.04032500086810025
Step 75, mean loss 0.05533679880951588
Step 100, mean loss 0.07589468593156705
Step 125, mean loss 0.07315074423782945
Step 150, mean loss 0.06552865875402734
Step 175, mean loss 0.10508365344749067
Step 200, mean loss 0.3753157310833324
Step 225, mean loss 0.21540566424476726
Unrolled forward losses 2.9255745710481023
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.47937e-01, 1.47408e-01, 1.41498e-01, -6.62660e-02, 7.23974e-02, 1.40226e-01
Node: 01 (pos: 0.010): 1.48453e-01, 1.46253e-01, 1.43152e-01, -5.27838e-02, 5.57291e-02, 1.40216e-01
Node: 02 (pos: 0.020): 1.48967e-01, 1.45093e-01, 1.44808e-01, -3.88262e-02, 3.94632e-02, 1.40208e-01
Node: 03 (pos: 0.030): 1.49476e-01, 1.43930e-01, 1.46466e-01, -2.43918e-02, 2.36039e-02, 1.40203e-01
Node: 04 (pos: 0.040): 1.49983e-01, 1.42761e-01, 1.48126e-01, -9.47921e-03, 8.15523e-03, 1.40201e-01
Node: 05 (pos: 0.051): 1.50486e-01, 1.41589e-01, 1.49788e-01, 5.91210e-03, -6.87922e-03, 1.40201e-01
-
Node: 07 (pos: 0.071): 1.50486e-01, 1.41589e-01, 1.49788e-01, 5.91210e-03, -6.87922e-03, 1.40201e-01
Node: 08 (pos: 0.081): 1.49983e-01, 1.42761e-01, 1.48126e-01, -9.47921e-03, 8.15523e-03, 1.40201e-01
Node: 09 (pos: 0.091): 1.49476e-01, 1.43930e-01, 1.46466e-01, -2.43918e-02, 2.36039e-02, 1.40203e-01
Node: 10 (pos: 0.101): 1.48967e-01, 1.45093e-01, 1.44808e-01, -3.88262e-02, 3.94632e-02, 1.40208e-01
Node: 11 (pos: 0.111): 1.48453e-01, 1.46253e-01, 1.43152e-01, -5.27838e-02, 5.57291e-02, 1.40216e-01
Node: 12 (pos: 0.121): 1.47937e-01, 1.47408e-01, 1.41498e-01, -6.62660e-02, 7.23974e-02, 1.40226e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.12876e-10, 3.65734e-10, 2.01677e-09, 1.23861e-02, 5.29296e-03, 2.88588e-09
Node: 01 (pos: 0.010): 2.68442e-10, 5.13442e-10, 1.25949e-09, 6.16596e-02, 4.47916e-02, 2.89452e-09
Node: 02 (pos: 0.020): 2.30435e-10, 7.19785e-10, 7.81797e-10, 2.21468e-01, 2.10695e-01, 2.90090e-09
Node: 03 (pos: 0.030): 1.97912e-10, 1.00759e-09, 4.82342e-10, 5.51586e-01, 5.72843e-01, 2.90499e-09
Node: 04 (pos: 0.040): 1.70069e-10, 1.40838e-09, 2.95781e-10, 9.14063e-01, 9.35656e-01, 2.90678e-09
Node: 05 (pos: 0.051): 1.46222e-10, 1.96558e-09, 1.80275e-10, 9.65651e-01, 9.53779e-01, 2.90627e-09
-
Node: 07 (pos: 0.071): 1.46222e-10, 1.96558e-09, 1.80275e-10, 9.65651e-01, 9.53779e-01, 2.90627e-09
Node: 08 (pos: 0.081): 1.70069e-10, 1.40838e-09, 2.95781e-10, 9.14063e-01, 9.35656e-01, 2.90678e-09
Node: 09 (pos: 0.091): 1.97912e-10, 1.00759e-09, 4.82342e-10, 5.51586e-01, 5.72843e-01, 2.90499e-09
Node: 10 (pos: 0.101): 2.30435e-10, 7.19785e-10, 7.81797e-10, 2.21468e-01, 2.10695e-01, 2.90090e-09
Node: 11 (pos: 0.111): 2.68442e-10, 5.13442e-10, 1.25949e-09, 6.16596e-02, 4.47916e-02, 2.89452e-09
Node: 12 (pos: 0.121): 3.12876e-10, 3.65734e-10, 2.01677e-09, 1.23861e-02, 5.29296e-03, 2.88588e-09
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.50486e-01, 1.41589e-01, 1.49788e-01, 5.91210e-03, -6.87922e-03, 1.40201e-01
Node: 01 (pos: 0.010): 1.49983e-01, 1.42761e-01, 1.48126e-01, -9.47921e-03, 8.15523e-03, 1.40201e-01
Node: 02 (pos: 0.020): 1.49476e-01, 1.43930e-01, 1.46466e-01, -2.43918e-02, 2.36039e-02, 1.40203e-01
Node: 03 (pos: 0.030): 1.48967e-01, 1.45093e-01, 1.44808e-01, -3.88262e-02, 3.94632e-02, 1.40208e-01
Node: 04 (pos: 0.040): 1.48453e-01, 1.46253e-01, 1.43152e-01, -5.27838e-02, 5.57291e-02, 1.40216e-01
Node: 05 (pos: 0.051): 1.47937e-01, 1.47408e-01, 1.41498e-01, -6.62660e-02, 7.23974e-02, 1.40226e-01
-
Node: 07 (pos: 0.071): 1.48453e-01, 1.46253e-01, 1.43152e-01, -5.27838e-02, 5.57291e-02, 1.40216e-01
Node: 08 (pos: 0.081): 1.48967e-01, 1.45093e-01, 1.44808e-01, -3.88262e-02, 3.94632e-02, 1.40208e-01
Node: 09 (pos: 0.091): 1.49476e-01, 1.43930e-01, 1.46466e-01, -2.43918e-02, 2.36039e-02, 1.40203e-01
Node: 10 (pos: 0.101): 1.49983e-01, 1.42761e-01, 1.48126e-01, -9.47921e-03, 8.15523e-03, 1.40201e-01
Node: 11 (pos: 0.111): 1.50486e-01, 1.41589e-01, 1.49788e-01, 5.91210e-03, -6.87922e-03, 1.40201e-01
Node: 12 (pos: 0.121): 1.47937e-01, 1.47408e-01, 1.41498e-01, -6.62660e-02, 7.23974e-02, 1.40226e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.46222e-10, 1.96558e-09, 1.80275e-10, 9.65651e-01, 9.53779e-01, 2.90627e-09
Node: 58 (pos: 0.586): 1.70069e-10, 1.40838e-09, 2.95781e-10, 9.14063e-01, 9.35656e-01, 2.90678e-09
Node: 59 (pos: 0.596): 1.97912e-10, 1.00759e-09, 4.82342e-10, 5.51586e-01, 5.72843e-01, 2.90499e-09
Node: 60 (pos: 0.606): 2.30435e-10, 7.19785e-10, 7.81797e-10, 2.21468e-01, 2.10695e-01, 2.90090e-09
Node: 61 (pos: 0.616): 2.68442e-10, 5.13442e-10, 1.25949e-09, 6.16596e-02, 4.47916e-02, 2.89452e-09
Node: 50 (pos: 0.505): 3.12876e-10, 3.65734e-10, 2.01677e-09, 1.23861e-02, 5.29296e-03, 2.88588e-09
-
Node: 51 (pos: 0.515): 2.68442e-10, 5.13442e-10, 1.25949e-09, 6.16596e-02, 4.47916e-02, 2.89452e-09
Node: 52 (pos: 0.525): 2.30435e-10, 7.19785e-10, 7.81797e-10, 2.21468e-01, 2.10695e-01, 2.90090e-09
Node: 53 (pos: 0.535): 1.97912e-10, 1.00759e-09, 4.82342e-10, 5.51586e-01, 5.72843e-01, 2.90499e-09
Node: 54 (pos: 0.545): 1.70069e-10, 1.40838e-09, 2.95781e-10, 9.14063e-01, 9.35656e-01, 2.90678e-09
Node: 55 (pos: 0.556): 1.46222e-10, 1.96558e-09, 1.80275e-10, 9.65651e-01, 9.53779e-01, 2.90627e-09
Node: 62 (pos: 0.626): 3.12876e-10, 3.65734e-10, 2.01677e-09, 1.23861e-02, 5.29296e-03, 2.88588e-09
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 1.1409435922984568e-12), ('0.bias', 4.412729461163685e-11), ('2.weight', 5.289092292865279e-10), ('2.bias', 1.4351641441362737e-10)] 

GNN_Layer 1 gradients:
[('0.weight', 1.0686016365720922e-12), ('0.bias', 3.047076424528476e-11), ('2.weight', 3.5348688909407535e-10), ('2.bias', 9.86723352421643e-11)] 

GNN_Layer 2 gradients:
[('0.weight', 2.495157916036511e-12), ('0.bias', 4.4554617336841284e-11), ('2.weight', 5.425731823667928e-10), ('2.bias', 1.39083540823069e-10)] 

GNN_Layer 3 gradients:
[('0.weight', 0.0016878314543961772), ('0.bias', 0.047120584119070656), ('2.weight', 0.2280284920563032), ('2.bias', 0.07339351125453074)] 

GNN_Layer 4 gradients:
[('0.weight', 6.113455819232727e-05), ('0.bias', 0.00899246695808791), ('2.weight', 0.05318215009567407), ('2.bias', 0.01493088797846821)] 

GNN_Layer 5 gradients:
[('0.weight', 1.4674650787222043e-11), ('0.bias', 3.9877929933956786e-10), ('2.weight', 4.972749791411331e-09), ('2.bias', 1.3337184000203051e-09)] 

Evaluation on test dataset:
Step 25, mean loss 0.06431339679935488
Step 50, mean loss 0.029691071325903297
Step 75, mean loss 0.04602802220878208
Step 100, mean loss 0.05109921712441922
Step 125, mean loss 0.058207073812002505
Step 150, mean loss 0.08175428110426722
Step 175, mean loss 0.0876719965579433
Step 200, mean loss 0.13152647178163246
Step 225, mean loss 0.11555104536059696
Unrolled forward losses 2.4789536932673544
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.17037889633021006, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.21680660416993083, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.1845270099202314, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.19251802408440036, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.19348319614027237, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.1721369671967263, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.17408821049261186, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.17092519636826017, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.16176080294155096, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.17336178358407522, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.17788047036957808, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.16308666212280704, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.178127286462936, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.06771321375538414
Step 50, mean loss 0.034329651472003855
Step 75, mean loss 0.044332143883180644
Step 100, mean loss 0.05747238772276907
Step 125, mean loss 0.06388675977524644
Step 150, mean loss 0.06515767756450268
Step 175, mean loss 0.1026993537889273
Step 200, mean loss 0.355135059656374
Step 225, mean loss 0.22126011585065752
Unrolled forward losses 2.528290564708337
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.47394e-01, 1.45854e-01, 1.34642e-01, -6.27123e-02, 7.58924e-02, 1.40749e-01
Node: 01 (pos: 0.010): 1.47896e-01, 1.44727e-01, 1.36238e-01, -4.91787e-02, 5.92255e-02, 1.40741e-01
Node: 02 (pos: 0.020): 1.48395e-01, 1.43597e-01, 1.37837e-01, -3.51748e-02, 4.29559e-02, 1.40736e-01
Node: 03 (pos: 0.030): 1.48890e-01, 1.42462e-01, 1.39437e-01, -2.06991e-02, 2.70878e-02, 1.40734e-01
Node: 04 (pos: 0.040): 1.49382e-01, 1.41323e-01, 1.41040e-01, -5.75055e-03, 1.16254e-02, 1.40735e-01
Node: 05 (pos: 0.051): 1.49870e-01, 1.40181e-01, 1.42644e-01, 9.67131e-03, -3.42785e-03, 1.40739e-01
-
Node: 07 (pos: 0.071): 1.49870e-01, 1.40181e-01, 1.42644e-01, 9.67131e-03, -3.42785e-03, 1.40739e-01
Node: 08 (pos: 0.081): 1.49382e-01, 1.41323e-01, 1.41040e-01, -5.75055e-03, 1.16254e-02, 1.40735e-01
Node: 09 (pos: 0.091): 1.48890e-01, 1.42462e-01, 1.39437e-01, -2.06991e-02, 2.70878e-02, 1.40734e-01
Node: 10 (pos: 0.101): 1.48395e-01, 1.43597e-01, 1.37837e-01, -3.51748e-02, 4.29559e-02, 1.40736e-01
Node: 11 (pos: 0.111): 1.47896e-01, 1.44727e-01, 1.36238e-01, -4.91787e-02, 5.92255e-02, 1.40741e-01
Node: 12 (pos: 0.121): 1.47394e-01, 1.45854e-01, 1.34642e-01, -6.27123e-02, 7.58924e-02, 1.40749e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.67192e-10, 5.76932e-10, 1.33944e-08, 1.95881e-02, 3.15219e-03, 2.49210e-09
Node: 01 (pos: 0.010): 3.16617e-10, 8.00329e-10, 8.69160e-09, 8.90508e-02, 2.99669e-02, 2.49737e-09
Node: 02 (pos: 0.020): 2.73143e-10, 1.10874e-09, 5.60828e-09, 2.90176e-01, 1.57993e-01, 2.50071e-09
Node: 03 (pos: 0.030): 2.35757e-10, 1.53388e-09, 3.59838e-09, 6.51517e-01, 4.80105e-01, 2.50211e-09
Node: 04 (pos: 0.040): 2.03593e-10, 2.11905e-09, 2.29576e-09, 9.67472e-01, 8.73585e-01, 2.50158e-09
Node: 05 (pos: 0.051): 1.75910e-10, 2.92323e-09, 1.45641e-09, 9.10707e-01, 9.88319e-01, 2.49910e-09
-
Node: 07 (pos: 0.071): 1.75910e-10, 2.92323e-09, 1.45641e-09, 9.10707e-01, 9.88319e-01, 2.49910e-09
Node: 08 (pos: 0.081): 2.03593e-10, 2.11905e-09, 2.29576e-09, 9.67472e-01, 8.73585e-01, 2.50158e-09
Node: 09 (pos: 0.091): 2.35757e-10, 1.53388e-09, 3.59838e-09, 6.51517e-01, 4.80105e-01, 2.50211e-09
Node: 10 (pos: 0.101): 2.73143e-10, 1.10874e-09, 5.60828e-09, 2.90176e-01, 1.57993e-01, 2.50071e-09
Node: 11 (pos: 0.111): 3.16617e-10, 8.00329e-10, 8.69160e-09, 8.90508e-02, 2.99669e-02, 2.49737e-09
Node: 12 (pos: 0.121): 3.67192e-10, 5.76932e-10, 1.33944e-08, 1.95881e-02, 3.15219e-03, 2.49210e-09
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.49870e-01, 1.40181e-01, 1.42644e-01, 9.67131e-03, -3.42785e-03, 1.40739e-01
Node: 01 (pos: 0.010): 1.49382e-01, 1.41323e-01, 1.41040e-01, -5.75055e-03, 1.16254e-02, 1.40735e-01
Node: 02 (pos: 0.020): 1.48890e-01, 1.42462e-01, 1.39437e-01, -2.06991e-02, 2.70878e-02, 1.40734e-01
Node: 03 (pos: 0.030): 1.48395e-01, 1.43597e-01, 1.37837e-01, -3.51748e-02, 4.29559e-02, 1.40736e-01
Node: 04 (pos: 0.040): 1.47896e-01, 1.44727e-01, 1.36238e-01, -4.91787e-02, 5.92255e-02, 1.40741e-01
Node: 05 (pos: 0.051): 1.47394e-01, 1.45854e-01, 1.34642e-01, -6.27123e-02, 7.58924e-02, 1.40749e-01
-
Node: 07 (pos: 0.071): 1.47896e-01, 1.44727e-01, 1.36238e-01, -4.91787e-02, 5.92255e-02, 1.40741e-01
Node: 08 (pos: 0.081): 1.48395e-01, 1.43597e-01, 1.37837e-01, -3.51748e-02, 4.29559e-02, 1.40736e-01
Node: 09 (pos: 0.091): 1.48890e-01, 1.42462e-01, 1.39437e-01, -2.06991e-02, 2.70878e-02, 1.40734e-01
Node: 10 (pos: 0.101): 1.49382e-01, 1.41323e-01, 1.41040e-01, -5.75055e-03, 1.16254e-02, 1.40735e-01
Node: 11 (pos: 0.111): 1.49870e-01, 1.40181e-01, 1.42644e-01, 9.67131e-03, -3.42785e-03, 1.40739e-01
Node: 12 (pos: 0.121): 1.47394e-01, 1.45854e-01, 1.34642e-01, -6.27123e-02, 7.58924e-02, 1.40749e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.75910e-10, 2.92323e-09, 1.45641e-09, 9.10707e-01, 9.88319e-01, 2.49910e-09
Node: 58 (pos: 0.586): 2.03593e-10, 2.11905e-09, 2.29576e-09, 9.67472e-01, 8.73585e-01, 2.50158e-09
Node: 59 (pos: 0.596): 2.35757e-10, 1.53388e-09, 3.59838e-09, 6.51517e-01, 4.80105e-01, 2.50211e-09
Node: 60 (pos: 0.606): 2.73143e-10, 1.10874e-09, 5.60828e-09, 2.90176e-01, 1.57993e-01, 2.50071e-09
Node: 61 (pos: 0.616): 3.16617e-10, 8.00329e-10, 8.69160e-09, 8.90508e-02, 2.99669e-02, 2.49737e-09
Node: 50 (pos: 0.505): 3.67192e-10, 5.76932e-10, 1.33944e-08, 1.95881e-02, 3.15219e-03, 2.49210e-09
-
Node: 51 (pos: 0.515): 3.16617e-10, 8.00329e-10, 8.69160e-09, 8.90508e-02, 2.99669e-02, 2.49737e-09
Node: 52 (pos: 0.525): 2.73143e-10, 1.10874e-09, 5.60828e-09, 2.90176e-01, 1.57993e-01, 2.50071e-09
Node: 53 (pos: 0.535): 2.35757e-10, 1.53388e-09, 3.59838e-09, 6.51517e-01, 4.80105e-01, 2.50211e-09
Node: 54 (pos: 0.545): 2.03593e-10, 2.11905e-09, 2.29576e-09, 9.67472e-01, 8.73585e-01, 2.50158e-09
Node: 55 (pos: 0.556): 1.75910e-10, 2.92323e-09, 1.45641e-09, 9.10707e-01, 9.88319e-01, 2.49910e-09
Node: 62 (pos: 0.626): 3.67192e-10, 5.76932e-10, 1.33944e-08, 1.95881e-02, 3.15219e-03, 2.49210e-09
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 1.7018885129912848e-12), ('0.bias', 8.216481922501923e-11), ('2.weight', 9.852542102448318e-10), ('2.bias', 2.711539494471544e-10)] 

GNN_Layer 1 gradients:
[('0.weight', 3.857609841236532e-12), ('0.bias', 1.4447667159523736e-10), ('2.weight', 1.677449968920374e-09), ('2.bias', 4.749229924057209e-10)] 

GNN_Layer 2 gradients:
[('0.weight', 2.1654787868442826e-11), ('0.bias', 3.3362739473966433e-10), ('2.weight', 4.072009204008339e-09), ('2.bias', 1.058566170360061e-09)] 

GNN_Layer 3 gradients:
[('0.weight', 0.00326038709786692), ('0.bias', 0.07040169900169774), ('2.weight', 0.33587722805900605), ('2.bias', 0.10948395370553457)] 

GNN_Layer 4 gradients:
[('0.weight', 0.0002820798343742944), ('0.bias', 0.013839591648983181), ('2.weight', 0.08175320042294142), ('2.bias', 0.023235356921297797)] 

GNN_Layer 5 gradients:
[('0.weight', 1.1915893589970098e-11), ('0.bias', 4.52576528098602e-10), ('2.weight', 5.642596486781971e-09), ('2.bias', 1.533614610827191e-09)] 

Evaluation on test dataset:
Step 25, mean loss 0.05687513372832011
Step 50, mean loss 0.021782235604602178
Step 75, mean loss 0.036279083552176475
Step 100, mean loss 0.040564675920269924
Step 125, mean loss 0.05182137480598478
Step 150, mean loss 0.07391455893213329
Step 175, mean loss 0.0843481693658697
Step 200, mean loss 0.11547651468256509
Step 225, mean loss 0.11699540967344785
Unrolled forward losses 2.24477473763383
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.17519171600275446, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.1842005238287933, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.1654539608810352, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.1778131297464721, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.16086153263448558, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.18638895691400295, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.1692474625800501, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.1772387328706031, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.17145089801426946, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.1785044410019318, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.1661075230486931, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.1553685018263554, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.16823348565919963, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.05620600851523971
Step 50, mean loss 0.034095121249173105
Step 75, mean loss 0.044626416617550235
Step 100, mean loss 0.04688234139701365
Step 125, mean loss 0.0574345371257258
Step 150, mean loss 0.049276741815856034
Step 175, mean loss 0.09594751288300075
Step 200, mean loss 0.2896397416632033
Step 225, mean loss 0.19865761698556766
Unrolled forward losses 2.7432067669627465
Unrolled forward base losses 2.565701273852575
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.14994280428765533, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.13798403961188171, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.1419532344413729, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.14656199842399834, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.13740668733965358, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.1355676204575655, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.1323093952771187, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.13078358615721894, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.13195205998654716, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.1373110912729357, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.12605199410471452, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.13018180330256332, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.1432884267198161, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.044234489581209166
Step 50, mean loss 0.019250563195639076
Step 75, mean loss 0.02890601761878111
Step 100, mean loss 0.04077626998610283
Step 125, mean loss 0.04703927278558981
Step 150, mean loss 0.04285146383620629
Step 175, mean loss 0.07884720422598465
Step 200, mean loss 0.31960791401737804
Step 225, mean loss 0.1673247163681763
Unrolled forward losses 1.6208763672914968
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.46134e-01, 1.42918e-01, 1.28523e-01, -6.22124e-02, 6.91037e-02, 1.39209e-01
Node: 01 (pos: 0.010): 1.46615e-01, 1.41831e-01, 1.30050e-01, -4.87882e-02, 5.28228e-02, 1.39204e-01
Node: 02 (pos: 0.020): 1.47094e-01, 1.40741e-01, 1.31579e-01, -3.49024e-02, 3.69294e-02, 1.39203e-01
Node: 03 (pos: 0.030): 1.47569e-01, 1.39646e-01, 1.33110e-01, -2.05537e-02, 2.14278e-02, 1.39203e-01
Node: 04 (pos: 0.040): 1.48041e-01, 1.38548e-01, 1.34643e-01, -5.74112e-03, 6.32167e-03, 1.39207e-01
Node: 05 (pos: 0.051): 1.48510e-01, 1.37446e-01, 1.36178e-01, 9.53576e-03, -8.38566e-03, 1.39213e-01
-
Node: 07 (pos: 0.071): 1.48510e-01, 1.37446e-01, 1.36178e-01, 9.53576e-03, -8.38566e-03, 1.39213e-01
Node: 08 (pos: 0.081): 1.48041e-01, 1.38548e-01, 1.34643e-01, -5.74112e-03, 6.32167e-03, 1.39207e-01
Node: 09 (pos: 0.091): 1.47569e-01, 1.39646e-01, 1.33110e-01, -2.05537e-02, 2.14278e-02, 1.39203e-01
Node: 10 (pos: 0.101): 1.47094e-01, 1.40741e-01, 1.31579e-01, -3.49024e-02, 3.69294e-02, 1.39203e-01
Node: 11 (pos: 0.111): 1.46615e-01, 1.41831e-01, 1.30050e-01, -4.87882e-02, 5.28228e-02, 1.39204e-01
Node: 12 (pos: 0.121): 1.46134e-01, 1.42918e-01, 1.28523e-01, -6.22124e-02, 6.91037e-02, 1.39209e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.31662e-10, 1.34694e-09, 6.70305e-08, 2.08503e-02, 8.43537e-03, 3.83480e-09
Node: 01 (pos: 0.010): 4.61739e-10, 1.83527e-09, 4.51607e-08, 9.25240e-02, 6.14063e-02, 3.83964e-09
Node: 02 (pos: 0.020): 4.01201e-10, 2.49753e-09, 3.02700e-08, 2.95769e-01, 2.55692e-01, 3.84164e-09
Node: 03 (pos: 0.030): 3.48767e-10, 3.39440e-09, 2.01848e-08, 6.55437e-01, 6.31819e-01, 3.84081e-09
Node: 04 (pos: 0.040): 3.03335e-10, 4.60728e-09, 1.33902e-08, 9.67577e-01, 9.60824e-01, 3.83714e-09
Node: 05 (pos: 0.051): 2.63952e-10, 6.24513e-09, 8.83694e-09, 9.13081e-01, 9.32096e-01, 3.83065e-09
-
Node: 07 (pos: 0.071): 2.63952e-10, 6.24513e-09, 8.83694e-09, 9.13081e-01, 9.32096e-01, 3.83065e-09
Node: 08 (pos: 0.081): 3.03335e-10, 4.60728e-09, 1.33902e-08, 9.67577e-01, 9.60824e-01, 3.83714e-09
Node: 09 (pos: 0.091): 3.48767e-10, 3.39440e-09, 2.01848e-08, 6.55437e-01, 6.31819e-01, 3.84081e-09
Node: 10 (pos: 0.101): 4.01201e-10, 2.49753e-09, 3.02700e-08, 2.95769e-01, 2.55692e-01, 3.84164e-09
Node: 11 (pos: 0.111): 4.61739e-10, 1.83527e-09, 4.51607e-08, 9.25240e-02, 6.14063e-02, 3.83964e-09
Node: 12 (pos: 0.121): 5.31662e-10, 1.34694e-09, 6.70305e-08, 2.08503e-02, 8.43537e-03, 3.83480e-09
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.48510e-01, 1.37446e-01, 1.36178e-01, 9.53576e-03, -8.38566e-03, 1.39213e-01
Node: 01 (pos: 0.010): 1.48041e-01, 1.38548e-01, 1.34643e-01, -5.74112e-03, 6.32167e-03, 1.39207e-01
Node: 02 (pos: 0.020): 1.47569e-01, 1.39646e-01, 1.33110e-01, -2.05537e-02, 2.14278e-02, 1.39203e-01
Node: 03 (pos: 0.030): 1.47094e-01, 1.40741e-01, 1.31579e-01, -3.49024e-02, 3.69294e-02, 1.39203e-01
Node: 04 (pos: 0.040): 1.46615e-01, 1.41831e-01, 1.30050e-01, -4.87882e-02, 5.28228e-02, 1.39204e-01
Node: 05 (pos: 0.051): 1.46134e-01, 1.42918e-01, 1.28523e-01, -6.22124e-02, 6.91037e-02, 1.39209e-01
-
Node: 07 (pos: 0.071): 1.46615e-01, 1.41831e-01, 1.30050e-01, -4.87882e-02, 5.28228e-02, 1.39204e-01
Node: 08 (pos: 0.081): 1.47094e-01, 1.40741e-01, 1.31579e-01, -3.49024e-02, 3.69294e-02, 1.39203e-01
Node: 09 (pos: 0.091): 1.47569e-01, 1.39646e-01, 1.33110e-01, -2.05537e-02, 2.14278e-02, 1.39203e-01
Node: 10 (pos: 0.101): 1.48041e-01, 1.38548e-01, 1.34643e-01, -5.74112e-03, 6.32167e-03, 1.39207e-01
Node: 11 (pos: 0.111): 1.48510e-01, 1.37446e-01, 1.36178e-01, 9.53576e-03, -8.38566e-03, 1.39213e-01
Node: 12 (pos: 0.121): 1.46134e-01, 1.42918e-01, 1.28523e-01, -6.22124e-02, 6.91037e-02, 1.39209e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 2.63952e-10, 6.24513e-09, 8.83694e-09, 9.13081e-01, 9.32096e-01, 3.83065e-09
Node: 58 (pos: 0.586): 3.03335e-10, 4.60728e-09, 1.33902e-08, 9.67577e-01, 9.60824e-01, 3.83714e-09
Node: 59 (pos: 0.596): 3.48767e-10, 3.39440e-09, 2.01848e-08, 6.55437e-01, 6.31819e-01, 3.84081e-09
Node: 60 (pos: 0.606): 4.01201e-10, 2.49753e-09, 3.02700e-08, 2.95769e-01, 2.55692e-01, 3.84164e-09
Node: 61 (pos: 0.616): 4.61739e-10, 1.83527e-09, 4.51607e-08, 9.25240e-02, 6.14063e-02, 3.83964e-09
Node: 50 (pos: 0.505): 5.31662e-10, 1.34694e-09, 6.70305e-08, 2.08503e-02, 8.43537e-03, 3.83480e-09
-
Node: 51 (pos: 0.515): 4.61739e-10, 1.83527e-09, 4.51607e-08, 9.25240e-02, 6.14063e-02, 3.83964e-09
Node: 52 (pos: 0.525): 4.01201e-10, 2.49753e-09, 3.02700e-08, 2.95769e-01, 2.55692e-01, 3.84164e-09
Node: 53 (pos: 0.535): 3.48767e-10, 3.39440e-09, 2.01848e-08, 6.55437e-01, 6.31819e-01, 3.84081e-09
Node: 54 (pos: 0.545): 3.03335e-10, 4.60728e-09, 1.33902e-08, 9.67577e-01, 9.60824e-01, 3.83714e-09
Node: 55 (pos: 0.556): 2.63952e-10, 6.24513e-09, 8.83694e-09, 9.13081e-01, 9.32096e-01, 3.83065e-09
Node: 62 (pos: 0.626): 5.31662e-10, 1.34694e-09, 6.70305e-08, 2.08503e-02, 8.43537e-03, 3.83480e-09
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 1.4936902352010475e-11), ('0.bias', 3.709997410302719e-10), ('2.weight', 4.454403360747176e-09), ('2.bias', 1.2509690756903304e-09)] 

GNN_Layer 1 gradients:
[('0.weight', 2.8507303370554212e-12), ('0.bias', 1.021785019969097e-10), ('2.weight', 1.187325090405806e-09), ('2.bias', 3.429209447450135e-10)] 

GNN_Layer 2 gradients:
[('0.weight', 7.881167785233175e-11), ('0.bias', 2.0888718174330785e-09), ('2.weight', 2.541956740450757e-08), ('2.bias', 6.763916638083481e-09)] 

GNN_Layer 3 gradients:
[('0.weight', 0.01050517245825939), ('0.bias', 0.31724771603515173), ('2.weight', 1.4716069197230541), ('2.bias', 0.4912776720739128)] 

GNN_Layer 4 gradients:
[('0.weight', 0.00018339252206661926), ('0.bias', 0.014105512339120984), ('2.weight', 0.08119602959488958), ('2.bias', 0.023610962630920076)] 

GNN_Layer 5 gradients:
[('0.weight', 2.2726486592958492e-11), ('0.bias', 6.439602605502157e-10), ('2.weight', 8.03301894138897e-09), ('2.bias', 2.2281560377288115e-09)] 

Evaluation on test dataset:
Step 25, mean loss 0.036432277042226874
Step 50, mean loss 0.013696052228579338
Step 75, mean loss 0.026612723779419326
Step 100, mean loss 0.027998465373115736
Step 125, mean loss 0.03509131422673237
Step 150, mean loss 0.04798300829676831
Step 175, mean loss 0.059723248124636044
Step 200, mean loss 0.07812593569683604
Step 225, mean loss 0.08504369276875445
Unrolled forward losses 1.553353399494645
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.13115122800157422, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.13739424666363578, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.14222790429255458, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.12776892881134258, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.1280138998873422, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.13870882562540307, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.12175445695221865, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.14549518822323995, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.13128715386177806, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.1340859910043289, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.1241953884167728, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.127610986000913, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.12886983950659187, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.05763389568950746
Step 50, mean loss 0.018188571111777473
Step 75, mean loss 0.030222048547713584
Step 100, mean loss 0.04277352533609459
Step 125, mean loss 0.04512068092570885
Step 150, mean loss 0.044836691287343716
Step 175, mean loss 0.07725855243245759
Step 200, mean loss 0.3212986750827018
Step 225, mean loss 0.16724452205438717
Unrolled forward losses 1.6366502582784512
Unrolled forward base losses 2.565701273852575
Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.12506316128058553, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.12940234541682918, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.12445221418708634, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.12788947948905618, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.13233676351995752, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.12837906034033658, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.1217120727382588, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.12957635143475427, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.12654348902940327, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.12273825184363682, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.1218381189363529, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.129298144561927, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.1396718285643217, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.03732371758481982
Step 50, mean loss 0.018441457994825133
Step 75, mean loss 0.029641927706768656
Step 100, mean loss 0.03446597756394833
Step 125, mean loss 0.04061000179893486
Step 150, mean loss 0.040739885876511416
Step 175, mean loss 0.07689246123038235
Step 200, mean loss 0.2986429757177479
Step 225, mean loss 0.1782154325847611
Unrolled forward losses 1.530529433064824
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.45264e-01, 1.40388e-01, 1.28763e-01, -6.15103e-02, 6.67882e-02, 1.38435e-01
Node: 01 (pos: 0.010): 1.45735e-01, 1.39324e-01, 1.30260e-01, -4.82081e-02, 5.08742e-02, 1.38432e-01
Node: 02 (pos: 0.020): 1.46202e-01, 1.38257e-01, 1.31758e-01, -3.44542e-02, 3.53330e-02, 1.38431e-01
Node: 03 (pos: 0.030): 1.46666e-01, 1.37186e-01, 1.33259e-01, -2.02473e-02, 2.01685e-02, 1.38433e-01
Node: 04 (pos: 0.040): 1.47127e-01, 1.36111e-01, 1.34761e-01, -5.58664e-03, 5.38419e-03, 1.38437e-01
Node: 05 (pos: 0.051): 1.47585e-01, 1.35033e-01, 1.36265e-01, 9.52837e-03, -9.01671e-03, 1.38445e-01
-
Node: 07 (pos: 0.071): 1.47585e-01, 1.35033e-01, 1.36265e-01, 9.52837e-03, -9.01671e-03, 1.38445e-01
Node: 08 (pos: 0.081): 1.47127e-01, 1.36111e-01, 1.34761e-01, -5.58664e-03, 5.38419e-03, 1.38437e-01
Node: 09 (pos: 0.091): 1.46666e-01, 1.37186e-01, 1.33259e-01, -2.02473e-02, 2.01685e-02, 1.38433e-01
Node: 10 (pos: 0.101): 1.46202e-01, 1.38257e-01, 1.31758e-01, -3.44542e-02, 3.53330e-02, 1.38431e-01
Node: 11 (pos: 0.111): 1.45735e-01, 1.39324e-01, 1.30260e-01, -4.82081e-02, 5.08742e-02, 1.38432e-01
Node: 12 (pos: 0.121): 1.45264e-01, 1.40388e-01, 1.28763e-01, -6.15103e-02, 6.67882e-02, 1.38435e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 6.84885e-10, 2.75803e-09, 6.30163e-08, 2.27425e-02, 1.15547e-02, 4.75428e-09
Node: 01 (pos: 0.010): 5.97291e-10, 3.71344e-09, 4.27633e-08, 9.78791e-02, 7.51566e-02, 4.75857e-09
Node: 02 (pos: 0.020): 5.21138e-10, 4.99379e-09, 2.88759e-08, 3.05107e-01, 2.86958e-01, 4.75945e-09
Node: 03 (pos: 0.030): 4.54907e-10, 6.70730e-09, 1.94018e-08, 6.63680e-01, 6.65799e-01, 4.75692e-09
Node: 04 (pos: 0.040): 3.97283e-10, 8.99739e-09, 1.29713e-08, 9.69271e-01, 9.71427e-01, 4.75097e-09
Node: 05 (pos: 0.051): 3.47125e-10, 1.20538e-08, 8.62898e-09, 9.13210e-01, 9.21916e-01, 4.74162e-09
-
Node: 07 (pos: 0.071): 3.47125e-10, 1.20538e-08, 8.62898e-09, 9.13210e-01, 9.21916e-01, 4.74162e-09
Node: 08 (pos: 0.081): 3.97283e-10, 8.99739e-09, 1.29713e-08, 9.69271e-01, 9.71427e-01, 4.75097e-09
Node: 09 (pos: 0.091): 4.54907e-10, 6.70730e-09, 1.94018e-08, 6.63680e-01, 6.65799e-01, 4.75692e-09
Node: 10 (pos: 0.101): 5.21138e-10, 4.99379e-09, 2.88759e-08, 3.05107e-01, 2.86958e-01, 4.75945e-09
Node: 11 (pos: 0.111): 5.97291e-10, 3.71344e-09, 4.27633e-08, 9.78791e-02, 7.51566e-02, 4.75857e-09
Node: 12 (pos: 0.121): 6.84885e-10, 2.75803e-09, 6.30163e-08, 2.27425e-02, 1.15547e-02, 4.75428e-09
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.47585e-01, 1.35033e-01, 1.36265e-01, 9.52837e-03, -9.01671e-03, 1.38445e-01
Node: 01 (pos: 0.010): 1.47127e-01, 1.36111e-01, 1.34761e-01, -5.58664e-03, 5.38419e-03, 1.38437e-01
Node: 02 (pos: 0.020): 1.46666e-01, 1.37186e-01, 1.33259e-01, -2.02473e-02, 2.01685e-02, 1.38433e-01
Node: 03 (pos: 0.030): 1.46202e-01, 1.38257e-01, 1.31758e-01, -3.44542e-02, 3.53330e-02, 1.38431e-01
Node: 04 (pos: 0.040): 1.45735e-01, 1.39324e-01, 1.30260e-01, -4.82081e-02, 5.08742e-02, 1.38432e-01
Node: 05 (pos: 0.051): 1.45264e-01, 1.40388e-01, 1.28763e-01, -6.15103e-02, 6.67882e-02, 1.38435e-01
-
Node: 07 (pos: 0.071): 1.45735e-01, 1.39324e-01, 1.30260e-01, -4.82081e-02, 5.08742e-02, 1.38432e-01
Node: 08 (pos: 0.081): 1.46202e-01, 1.38257e-01, 1.31758e-01, -3.44542e-02, 3.53330e-02, 1.38431e-01
Node: 09 (pos: 0.091): 1.46666e-01, 1.37186e-01, 1.33259e-01, -2.02473e-02, 2.01685e-02, 1.38433e-01
Node: 10 (pos: 0.101): 1.47127e-01, 1.36111e-01, 1.34761e-01, -5.58664e-03, 5.38419e-03, 1.38437e-01
Node: 11 (pos: 0.111): 1.47585e-01, 1.35033e-01, 1.36265e-01, 9.52837e-03, -9.01671e-03, 1.38445e-01
Node: 12 (pos: 0.121): 1.45264e-01, 1.40388e-01, 1.28763e-01, -6.15103e-02, 6.67882e-02, 1.38435e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 3.47125e-10, 1.20538e-08, 8.62898e-09, 9.13210e-01, 9.21916e-01, 4.74162e-09
Node: 58 (pos: 0.586): 3.97283e-10, 8.99739e-09, 1.29713e-08, 9.69271e-01, 9.71427e-01, 4.75097e-09
Node: 59 (pos: 0.596): 4.54907e-10, 6.70730e-09, 1.94018e-08, 6.63680e-01, 6.65799e-01, 4.75692e-09
Node: 60 (pos: 0.606): 5.21138e-10, 4.99379e-09, 2.88759e-08, 3.05107e-01, 2.86958e-01, 4.75945e-09
Node: 61 (pos: 0.616): 5.97291e-10, 3.71344e-09, 4.27633e-08, 9.78791e-02, 7.51566e-02, 4.75857e-09
Node: 50 (pos: 0.505): 6.84885e-10, 2.75803e-09, 6.30163e-08, 2.27425e-02, 1.15547e-02, 4.75428e-09
-
Node: 51 (pos: 0.515): 5.97291e-10, 3.71344e-09, 4.27633e-08, 9.78791e-02, 7.51566e-02, 4.75857e-09
Node: 52 (pos: 0.525): 5.21138e-10, 4.99379e-09, 2.88759e-08, 3.05107e-01, 2.86958e-01, 4.75945e-09
Node: 53 (pos: 0.535): 4.54907e-10, 6.70730e-09, 1.94018e-08, 6.63680e-01, 6.65799e-01, 4.75692e-09
Node: 54 (pos: 0.545): 3.97283e-10, 8.99739e-09, 1.29713e-08, 9.69271e-01, 9.71427e-01, 4.75097e-09
Node: 55 (pos: 0.556): 3.47125e-10, 1.20538e-08, 8.62898e-09, 9.13210e-01, 9.21916e-01, 4.74162e-09
Node: 62 (pos: 0.626): 6.84885e-10, 2.75803e-09, 6.30163e-08, 2.27425e-02, 1.15547e-02, 4.75428e-09
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 1.3184736503666532e-11), ('0.bias', 3.0507144560140207e-10), ('2.weight', 3.664830088025222e-09), ('2.bias', 1.0410077548345125e-09)] 

GNN_Layer 1 gradients:
[('0.weight', 2.6169686615672484e-12), ('0.bias', 5.622479579188841e-11), ('2.weight', 6.534321918115634e-10), ('2.bias', 1.90885078074905e-10)] 

GNN_Layer 2 gradients:
[('0.weight', 1.6996046017004185e-11), ('0.bias', 5.829024471223165e-10), ('2.weight', 7.084153774525522e-09), ('2.bias', 1.908751136655698e-09)] 

GNN_Layer 3 gradients:
[('0.weight', 0.002165430002234598), ('0.bias', 0.1067840905533517), ('2.weight', 0.4889801842419252), ('2.bias', 0.16555237311648016)] 

GNN_Layer 4 gradients:
[('0.weight', 0.00020395336230142247), ('0.bias', 0.006712275449284409), ('2.weight', 0.03897396178737206), ('2.bias', 0.01144021995870315)] 

GNN_Layer 5 gradients:
[('0.weight', 2.4112050780329867e-11), ('0.bias', 5.936109238125445e-10), ('2.weight', 7.407170683773107e-09), ('2.bias', 2.0784598959951925e-09)] 

Evaluation on test dataset:
Step 25, mean loss 0.03025095518216544
Step 50, mean loss 0.013734507695029121
Step 75, mean loss 0.026416052459980813
Step 100, mean loss 0.025000429964335057
Step 125, mean loss 0.033886344567098284
Step 150, mean loss 0.04465108081389939
Step 175, mean loss 0.05589984275200259
Step 200, mean loss 0.08196813505055461
Step 225, mean loss 0.07986754796433662
Unrolled forward losses 1.5099205108851756
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.12549451211063734, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.11820544657985067, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.11595371378995802, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.1185734195867028, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.12839497443781978, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.13742376269493262, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.12276465812376591, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.12215811718939569, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.1357855800005733, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.13295032787815247, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.1140562063356607, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.12639314115623368, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.1206321482240241, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.03203693415053015
Step 50, mean loss 0.0159974252268976
Step 75, mean loss 0.02625551089591963
Step 100, mean loss 0.03615451131272443
Step 125, mean loss 0.037373327802491405
Step 150, mean loss 0.03720519039331742
Step 175, mean loss 0.06786847084109945
Step 200, mean loss 0.30528783638417056
Step 225, mean loss 0.16256432864568054
Unrolled forward losses 1.7238743218749482
Unrolled forward base losses 2.565701273852575
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.11531207238113225, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.12150934481676842, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.12274783400190327, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.13553809416902698, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.1185330328240853, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.12648338209434093, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.11573056517326755, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.10014969117336123, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.1257170469925046, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.12431010429473054, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.12497643292573397, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.11764777542989367, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.11314440216698665, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.031899144488280434
Step 50, mean loss 0.015153007896141501
Step 75, mean loss 0.026536098487236436
Step 100, mean loss 0.03125925205381396
Step 125, mean loss 0.0379403871122197
Step 150, mean loss 0.03677897531943887
Step 175, mean loss 0.07057578758922431
Step 200, mean loss 0.2767392829390683
Step 225, mean loss 0.16435534542582853
Unrolled forward losses 1.4840434465139154
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.44456e-01, 1.40073e-01, 1.28792e-01, -6.23335e-02, 7.11308e-02, 1.39031e-01
Node: 01 (pos: 0.010): 1.44915e-01, 1.39029e-01, 1.30259e-01, -4.92332e-02, 5.53884e-02, 1.39029e-01
Node: 02 (pos: 0.020): 1.45372e-01, 1.37982e-01, 1.31728e-01, -3.56930e-02, 4.00049e-02, 1.39031e-01
Node: 03 (pos: 0.030): 1.45825e-01, 1.36931e-01, 1.33199e-01, -2.17115e-02, 2.49841e-02, 1.39035e-01
Node: 04 (pos: 0.040): 1.46276e-01, 1.35876e-01, 1.34672e-01, -7.28793e-03, 1.03294e-02, 1.39041e-01
Node: 05 (pos: 0.051): 1.46723e-01, 1.34818e-01, 1.36146e-01, 7.57823e-03, -3.95602e-03, 1.39050e-01
-
Node: 07 (pos: 0.071): 1.46723e-01, 1.34818e-01, 1.36146e-01, 7.57823e-03, -3.95602e-03, 1.39050e-01
Node: 08 (pos: 0.081): 1.46276e-01, 1.35876e-01, 1.34672e-01, -7.28793e-03, 1.03294e-02, 1.39041e-01
Node: 09 (pos: 0.091): 1.45825e-01, 1.36931e-01, 1.33199e-01, -2.17115e-02, 2.49841e-02, 1.39035e-01
Node: 10 (pos: 0.101): 1.45372e-01, 1.37982e-01, 1.31728e-01, -3.56930e-02, 4.00049e-02, 1.39031e-01
Node: 11 (pos: 0.111): 1.44915e-01, 1.39029e-01, 1.30259e-01, -4.92332e-02, 5.53884e-02, 1.39029e-01
Node: 12 (pos: 0.121): 1.44456e-01, 1.40073e-01, 1.28792e-01, -6.23335e-02, 7.11308e-02, 1.39031e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 8.65673e-10, 3.01307e-09, 6.25499e-08, 2.05384e-02, 6.34816e-03, 4.02989e-09
Node: 01 (pos: 0.010): 7.57921e-10, 4.03185e-09, 4.27701e-08, 8.85748e-02, 4.65198e-02, 4.03124e-09
Node: 02 (pos: 0.020): 6.63876e-10, 5.38885e-09, 2.91057e-08, 2.79714e-01, 2.01817e-01, 4.02974e-09
Node: 03 (pos: 0.030): 5.81764e-10, 7.19406e-09, 1.97122e-08, 6.24135e-01, 5.35686e-01, 4.02540e-09
Node: 04 (pos: 0.040): 5.10044e-10, 9.59234e-09, 1.32864e-08, 9.48272e-01, 8.98798e-01, 4.01821e-09
Node: 05 (pos: 0.051): 4.47375e-10, 1.27743e-08, 8.91236e-09, 9.44188e-01, 9.84472e-01, 4.00821e-09
-
Node: 07 (pos: 0.071): 4.47375e-10, 1.27743e-08, 8.91236e-09, 9.44188e-01, 9.84472e-01, 4.00821e-09
Node: 08 (pos: 0.081): 5.10044e-10, 9.59234e-09, 1.32864e-08, 9.48272e-01, 8.98798e-01, 4.01821e-09
Node: 09 (pos: 0.091): 5.81764e-10, 7.19406e-09, 1.97122e-08, 6.24135e-01, 5.35686e-01, 4.02540e-09
Node: 10 (pos: 0.101): 6.63876e-10, 5.38885e-09, 2.91057e-08, 2.79714e-01, 2.01817e-01, 4.02974e-09
Node: 11 (pos: 0.111): 7.57921e-10, 4.03185e-09, 4.27701e-08, 8.85748e-02, 4.65198e-02, 4.03124e-09
Node: 12 (pos: 0.121): 8.65673e-10, 3.01307e-09, 6.25499e-08, 2.05384e-02, 6.34816e-03, 4.02989e-09
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.46723e-01, 1.34818e-01, 1.36146e-01, 7.57823e-03, -3.95602e-03, 1.39050e-01
Node: 01 (pos: 0.010): 1.46276e-01, 1.35876e-01, 1.34672e-01, -7.28793e-03, 1.03294e-02, 1.39041e-01
Node: 02 (pos: 0.020): 1.45825e-01, 1.36931e-01, 1.33199e-01, -2.17115e-02, 2.49841e-02, 1.39035e-01
Node: 03 (pos: 0.030): 1.45372e-01, 1.37982e-01, 1.31728e-01, -3.56930e-02, 4.00049e-02, 1.39031e-01
Node: 04 (pos: 0.040): 1.44915e-01, 1.39029e-01, 1.30259e-01, -4.92332e-02, 5.53884e-02, 1.39029e-01
Node: 05 (pos: 0.051): 1.44456e-01, 1.40073e-01, 1.28792e-01, -6.23335e-02, 7.11308e-02, 1.39031e-01
-
Node: 07 (pos: 0.071): 1.44915e-01, 1.39029e-01, 1.30259e-01, -4.92332e-02, 5.53884e-02, 1.39029e-01
Node: 08 (pos: 0.081): 1.45372e-01, 1.37982e-01, 1.31728e-01, -3.56930e-02, 4.00049e-02, 1.39031e-01
Node: 09 (pos: 0.091): 1.45825e-01, 1.36931e-01, 1.33199e-01, -2.17115e-02, 2.49841e-02, 1.39035e-01
Node: 10 (pos: 0.101): 1.46276e-01, 1.35876e-01, 1.34672e-01, -7.28793e-03, 1.03294e-02, 1.39041e-01
Node: 11 (pos: 0.111): 1.46723e-01, 1.34818e-01, 1.36146e-01, 7.57823e-03, -3.95602e-03, 1.39050e-01
Node: 12 (pos: 0.121): 1.44456e-01, 1.40073e-01, 1.28792e-01, -6.23335e-02, 7.11308e-02, 1.39031e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 4.47375e-10, 1.27743e-08, 8.91236e-09, 9.44188e-01, 9.84472e-01, 4.00821e-09
Node: 58 (pos: 0.586): 5.10044e-10, 9.59234e-09, 1.32864e-08, 9.48272e-01, 8.98798e-01, 4.01821e-09
Node: 59 (pos: 0.596): 5.81764e-10, 7.19406e-09, 1.97122e-08, 6.24135e-01, 5.35686e-01, 4.02540e-09
Node: 60 (pos: 0.606): 6.63876e-10, 5.38885e-09, 2.91057e-08, 2.79714e-01, 2.01817e-01, 4.02974e-09
Node: 61 (pos: 0.616): 7.57921e-10, 4.03185e-09, 4.27701e-08, 8.85748e-02, 4.65198e-02, 4.03124e-09
Node: 50 (pos: 0.505): 8.65673e-10, 3.01307e-09, 6.25499e-08, 2.05384e-02, 6.34816e-03, 4.02989e-09
-
Node: 51 (pos: 0.515): 7.57921e-10, 4.03185e-09, 4.27701e-08, 8.85748e-02, 4.65198e-02, 4.03124e-09
Node: 52 (pos: 0.525): 6.63876e-10, 5.38885e-09, 2.91057e-08, 2.79714e-01, 2.01817e-01, 4.02974e-09
Node: 53 (pos: 0.535): 5.81764e-10, 7.19406e-09, 1.97122e-08, 6.24135e-01, 5.35686e-01, 4.02540e-09
Node: 54 (pos: 0.545): 5.10044e-10, 9.59234e-09, 1.32864e-08, 9.48272e-01, 8.98798e-01, 4.01821e-09
Node: 55 (pos: 0.556): 4.47375e-10, 1.27743e-08, 8.91236e-09, 9.44188e-01, 9.84472e-01, 4.00821e-09
Node: 62 (pos: 0.626): 8.65673e-10, 3.01307e-09, 6.25499e-08, 2.05384e-02, 6.34816e-03, 4.02989e-09
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 8.909562710893954e-12), ('0.bias', 2.726959047947087e-10), ('2.weight', 3.2761024433360004e-09), ('2.bias', 9.41153650449072e-10)] 

GNN_Layer 1 gradients:
[('0.weight', 8.551453219774707e-12), ('0.bias', 2.603252591365487e-10), ('2.weight', 3.027287667924471e-09), ('2.bias', 8.944462005671806e-10)] 

GNN_Layer 2 gradients:
[('0.weight', 1.3887767635507145e-11), ('0.bias', 4.3462521185799747e-10), ('2.weight', 5.282375203872303e-09), ('2.bias', 1.4400111325996543e-09)] 

GNN_Layer 3 gradients:
[('0.weight', 0.0026867120533949), ('0.bias', 0.039075806261250304), ('2.weight', 0.18065959810564206), ('2.bias', 0.06120166987337876)] 

GNN_Layer 4 gradients:
[('0.weight', 0.0013490264757050827), ('0.bias', 0.03732346898878249), ('2.weight', 0.21700014333754547), ('2.bias', 0.06440380685015895)] 

GNN_Layer 5 gradients:
[('0.weight', 3.050116330821116e-13), ('0.bias', 3.455045035288645e-11), ('2.weight', 4.3105715316137096e-10), ('2.bias', 1.2179502063463698e-10)] 

Evaluation on test dataset:
Step 25, mean loss 0.025858641025031555
Step 50, mean loss 0.011572551905261078
Step 75, mean loss 0.023618273936198184
Step 100, mean loss 0.02498103918978764
Step 125, mean loss 0.030639223560854835
Step 150, mean loss 0.04000357324953584
Step 175, mean loss 0.04903490927219155
Step 200, mean loss 0.06860929871474257
Step 225, mean loss 0.07332783827522676
Unrolled forward losses 1.475658444397879
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar

Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00), 0.12173858870005506, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.12019477371775895, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.11540515709520358, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.11296278361853354, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.12497597117646873, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.10786313025235217, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.11839415632982801, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.11744131405801557, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.11690283013588865, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.11275660450751898, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.10933202787882255, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.11820573939563779, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.10043180940935077, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.02742882310024987
Step 50, mean loss 0.014144546802031215
Step 75, mean loss 0.023229469108848884
Step 100, mean loss 0.029750644441108608
Step 125, mean loss 0.031228235602757372
Step 150, mean loss 0.03222307830944584
Step 175, mean loss 0.059149115849073175
Step 200, mean loss 0.2609124245528202
Step 225, mean loss 0.1703854187412731
Unrolled forward losses 1.3470965243008601
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.44140e-01, 1.37429e-01, 1.26670e-01, -6.16857e-02, 6.32673e-02, 1.37711e-01
Node: 01 (pos: 0.010): 1.44597e-01, 1.36393e-01, 1.28130e-01, -4.85953e-02, 4.78070e-02, 1.37709e-01
Node: 02 (pos: 0.020): 1.45051e-01, 1.35352e-01, 1.29591e-01, -3.50670e-02, 3.27023e-02, 1.37710e-01
Node: 03 (pos: 0.030): 1.45502e-01, 1.34308e-01, 1.31054e-01, -2.10995e-02, 1.79569e-02, 1.37713e-01
Node: 04 (pos: 0.040): 1.45950e-01, 1.33260e-01, 1.32519e-01, -6.69203e-03, 3.57401e-03, 1.37719e-01
Node: 05 (pos: 0.051): 1.46396e-01, 1.32209e-01, 1.33986e-01, 8.15590e-03, -1.04435e-02, 1.37727e-01
-
Node: 07 (pos: 0.071): 1.46396e-01, 1.32209e-01, 1.33986e-01, 8.15590e-03, -1.04435e-02, 1.37727e-01
Node: 08 (pos: 0.081): 1.45950e-01, 1.33260e-01, 1.32519e-01, -6.69203e-03, 3.57401e-03, 1.37719e-01
Node: 09 (pos: 0.091): 1.45502e-01, 1.34308e-01, 1.31054e-01, -2.10995e-02, 1.79569e-02, 1.37713e-01
Node: 10 (pos: 0.101): 1.45051e-01, 1.35352e-01, 1.29591e-01, -3.50670e-02, 3.27023e-02, 1.37710e-01
Node: 11 (pos: 0.111): 1.44597e-01, 1.36393e-01, 1.28130e-01, -4.85953e-02, 4.78070e-02, 1.37709e-01
Node: 12 (pos: 0.121): 1.44140e-01, 1.37429e-01, 1.26670e-01, -6.16857e-02, 6.32673e-02, 1.37711e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 9.48377e-10, 6.27399e-09, 1.07553e-07, 2.22563e-02, 1.82654e-02, 5.80659e-09
Node: 01 (pos: 0.010): 8.31112e-10, 8.33366e-09, 7.41470e-08, 9.42782e-02, 1.01723e-01, 5.80939e-09
Node: 02 (pos: 0.020): 7.28668e-10, 1.10567e-08, 5.08762e-08, 2.92382e-01, 3.43200e-01, 5.80814e-09
Node: 03 (pos: 0.030): 6.39140e-10, 1.46523e-08, 3.47440e-08, 6.40703e-01, 7.24371e-01, 5.80286e-09
Node: 04 (pos: 0.040): 5.60868e-10, 1.93936e-08, 2.36149e-08, 9.56205e-01, 9.87308e-01, 5.79356e-09
Node: 05 (pos: 0.051): 4.92411e-10, 2.56375e-08, 1.59745e-08, 9.35645e-01, 8.96671e-01, 5.78025e-09
-
Node: 07 (pos: 0.071): 4.92411e-10, 2.56375e-08, 1.59745e-08, 9.35645e-01, 8.96671e-01, 5.78025e-09
Node: 08 (pos: 0.081): 5.60868e-10, 1.93936e-08, 2.36149e-08, 9.56205e-01, 9.87308e-01, 5.79356e-09
Node: 09 (pos: 0.091): 6.39140e-10, 1.46523e-08, 3.47440e-08, 6.40703e-01, 7.24371e-01, 5.80286e-09
Node: 10 (pos: 0.101): 7.28668e-10, 1.10567e-08, 5.08762e-08, 2.92382e-01, 3.43200e-01, 5.80814e-09
Node: 11 (pos: 0.111): 8.31112e-10, 8.33366e-09, 7.41470e-08, 9.42782e-02, 1.01723e-01, 5.80939e-09
Node: 12 (pos: 0.121): 9.48377e-10, 6.27399e-09, 1.07553e-07, 2.22563e-02, 1.82654e-02, 5.80659e-09
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.46396e-01, 1.32209e-01, 1.33986e-01, 8.15590e-03, -1.04435e-02, 1.37727e-01
Node: 01 (pos: 0.010): 1.45950e-01, 1.33260e-01, 1.32519e-01, -6.69203e-03, 3.57401e-03, 1.37719e-01
Node: 02 (pos: 0.020): 1.45502e-01, 1.34308e-01, 1.31054e-01, -2.10995e-02, 1.79569e-02, 1.37713e-01
Node: 03 (pos: 0.030): 1.45051e-01, 1.35352e-01, 1.29591e-01, -3.50670e-02, 3.27023e-02, 1.37710e-01
Node: 04 (pos: 0.040): 1.44597e-01, 1.36393e-01, 1.28130e-01, -4.85953e-02, 4.78070e-02, 1.37709e-01
Node: 05 (pos: 0.051): 1.44140e-01, 1.37429e-01, 1.26670e-01, -6.16857e-02, 6.32673e-02, 1.37711e-01
-
Node: 07 (pos: 0.071): 1.44597e-01, 1.36393e-01, 1.28130e-01, -4.85953e-02, 4.78070e-02, 1.37709e-01
Node: 08 (pos: 0.081): 1.45051e-01, 1.35352e-01, 1.29591e-01, -3.50670e-02, 3.27023e-02, 1.37710e-01
Node: 09 (pos: 0.091): 1.45502e-01, 1.34308e-01, 1.31054e-01, -2.10995e-02, 1.79569e-02, 1.37713e-01
Node: 10 (pos: 0.101): 1.45950e-01, 1.33260e-01, 1.32519e-01, -6.69203e-03, 3.57401e-03, 1.37719e-01
Node: 11 (pos: 0.111): 1.46396e-01, 1.32209e-01, 1.33986e-01, 8.15590e-03, -1.04435e-02, 1.37727e-01
Node: 12 (pos: 0.121): 1.44140e-01, 1.37429e-01, 1.26670e-01, -6.16857e-02, 6.32673e-02, 1.37711e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 4.92411e-10, 2.56375e-08, 1.59745e-08, 9.35645e-01, 8.96671e-01, 5.78025e-09
Node: 58 (pos: 0.586): 5.60868e-10, 1.93936e-08, 2.36149e-08, 9.56205e-01, 9.87308e-01, 5.79356e-09
Node: 59 (pos: 0.596): 6.39140e-10, 1.46523e-08, 3.47440e-08, 6.40703e-01, 7.24371e-01, 5.80286e-09
Node: 60 (pos: 0.606): 7.28668e-10, 1.10567e-08, 5.08762e-08, 2.92382e-01, 3.43200e-01, 5.80814e-09
Node: 61 (pos: 0.616): 8.31112e-10, 8.33366e-09, 7.41470e-08, 9.42782e-02, 1.01723e-01, 5.80939e-09
Node: 50 (pos: 0.505): 9.48377e-10, 6.27399e-09, 1.07553e-07, 2.22563e-02, 1.82654e-02, 5.80659e-09
-
Node: 51 (pos: 0.515): 8.31112e-10, 8.33366e-09, 7.41470e-08, 9.42782e-02, 1.01723e-01, 5.80939e-09
Node: 52 (pos: 0.525): 7.28668e-10, 1.10567e-08, 5.08762e-08, 2.92382e-01, 3.43200e-01, 5.80814e-09
Node: 53 (pos: 0.535): 6.39140e-10, 1.46523e-08, 3.47440e-08, 6.40703e-01, 7.24371e-01, 5.80286e-09
Node: 54 (pos: 0.545): 5.60868e-10, 1.93936e-08, 2.36149e-08, 9.56205e-01, 9.87308e-01, 5.79356e-09
Node: 55 (pos: 0.556): 4.92411e-10, 2.56375e-08, 1.59745e-08, 9.35645e-01, 8.96671e-01, 5.78025e-09
Node: 62 (pos: 0.626): 9.48377e-10, 6.27399e-09, 1.07553e-07, 2.22563e-02, 1.82654e-02, 5.80659e-09
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 1.546661369443183e-11), ('0.bias', 1.8029282444091876e-10), ('2.weight', 2.172047132454006e-09), ('2.bias', 6.249226714434856e-10)] 

GNN_Layer 1 gradients:
[('0.weight', 5.368945140286064e-11), ('0.bias', 7.477276079586749e-10), ('2.weight', 8.695195912379443e-09), ('2.bias', 2.5734257558460814e-09)] 

GNN_Layer 2 gradients:
[('0.weight', 7.364356025705195e-11), ('0.bias', 6.543858904281327e-11), ('2.weight', 1.11474024745672e-09), ('2.bias', 1.84381399633067e-10)] 

GNN_Layer 3 gradients:
[('0.weight', 0.004267501883750862), ('0.bias', 0.13445132598721124), ('2.weight', 0.61275920502271), ('2.bias', 0.20987703999400636)] 

GNN_Layer 4 gradients:
[('0.weight', 0.002296939768054213), ('0.bias', 0.0033352793380868667), ('2.weight', 0.029869772494488862), ('2.bias', 0.006822313112605435)] 

GNN_Layer 5 gradients:
[('0.weight', 3.667230031458002e-11), ('0.bias', 1.176613827108674e-09), ('2.weight', 1.4682486438665117e-08), ('2.bias', 4.172972020099675e-09)] 

Evaluation on test dataset:
Step 25, mean loss 0.0221454509165245
Step 50, mean loss 0.010621117639058378
Step 75, mean loss 0.022038825444535688
Step 100, mean loss 0.021018722275356845
Step 125, mean loss 0.028572120907833662
Step 150, mean loss 0.03681535934730832
Step 175, mean loss 0.048462691985814
Step 200, mean loss 0.06681651777235795
Step 225, mean loss 0.06608732319300961
Unrolled forward losses 1.3606705308690088
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00), 0.10485559573279543, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.1134284581392062, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.10767180823771011, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.11835481689630484, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.12335548049023419, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.10306698791909116, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.1132420925073936, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.10215282116236, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.10527075026939195, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.12557117379652802, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.1063921927419102, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.1186310907752733, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.1162605714112366, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.026126899949387127
Step 50, mean loss 0.014074753958830288
Step 75, mean loss 0.023473080161363027
Step 100, mean loss 0.03069514738795668
Step 125, mean loss 0.03367934407976526
Step 150, mean loss 0.032632123402776214
Step 175, mean loss 0.058271849067969755
Step 200, mean loss 0.251927937029401
Step 225, mean loss 0.15471430412186388
Unrolled forward losses 1.431713542358099
Unrolled forward base losses 2.565701273852575
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00), 0.11077430020402759, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.10939956328724158, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.11434177856654254, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.11138947714275235, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.10834674777732411, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.10818135668427883, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.10972618832930604, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.1134090715293118, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.10657136646748411, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.10971663230064693, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.10767392342419327, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.10804320798409689, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.0986199245191092, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.02471400220889411
Step 50, mean loss 0.012991848233213968
Step 75, mean loss 0.02228207099586763
Step 100, mean loss 0.02947078576387071
Step 125, mean loss 0.030640885323432468
Step 150, mean loss 0.03075767777023996
Step 175, mean loss 0.0565521092338978
Step 200, mean loss 0.2602277886038837
Step 225, mean loss 0.15350936650807
Unrolled forward losses 1.3486347752191366
Unrolled forward base losses 2.565701273852575
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00), 0.10156733372353634, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.10104424003378872, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.10660850559100502, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.11343963082700396, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.10404408760238903, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.11390110165253318, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.11736742122590818, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.10761305084334025, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.10582203754567036, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.10525680139582036, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.10978608970741388, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.10757461157743627, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.10884844095959473, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.02326967811862008
Step 50, mean loss 0.013199228193726062
Step 75, mean loss 0.023504940062308473
Step 100, mean loss 0.02988172607640454
Step 125, mean loss 0.03128420945768261
Step 150, mean loss 0.032614197766158926
Step 175, mean loss 0.05937499349766362
Step 200, mean loss 0.24150920904526887
Step 225, mean loss 0.1623999620016924
Unrolled forward losses 1.4685692179068712
Unrolled forward base losses 2.565701273852575
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00), 0.12077998390681204, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.10622539853806652, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.10586258594637879, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.10578180249971454, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.11569889501684956, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.09094819093404134, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.10893287460560089, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.10259843368952366, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.10542931138862964, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.10258657254528472, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.10422653185577951, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.10193648980627495, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.09580348834217858, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.023743432520714175
Step 50, mean loss 0.01335204818912862
Step 75, mean loss 0.02217086922038791
Step 100, mean loss 0.027559912463581693
Step 125, mean loss 0.030248882635174293
Step 150, mean loss 0.031006690232461564
Step 175, mean loss 0.055132125175804944
Step 200, mean loss 0.25838478799159914
Step 225, mean loss 0.1554229980742179
Unrolled forward losses 1.349979537324605
Unrolled forward base losses 2.565701273852575
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00), 0.09902685893429962, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.09541015782066317, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.09918265960159334, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.09937744695782243, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.10394705916167582, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.10289748212816337, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.10626260099078673, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.09868105564044402, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.09953482631806883, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.09328912296048665, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.1080099449859497, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.10177487089707234, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.0992869037049855, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.022299458760642186
Step 50, mean loss 0.012162237083102746
Step 75, mean loss 0.021346948156905247
Step 100, mean loss 0.02632136481601976
Step 125, mean loss 0.028458632959556314
Step 150, mean loss 0.02971191710373664
Step 175, mean loss 0.054627078496850175
Step 200, mean loss 0.24665588172196148
Step 225, mean loss 0.15563270998972895
Unrolled forward losses 1.3031301062196983
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.42681e-01, 1.31069e-01, 1.19435e-01, -6.07497e-02, 6.11567e-02, 1.35462e-01
Node: 01 (pos: 0.010): 1.43128e-01, 1.30054e-01, 1.20872e-01, -4.77910e-02, 4.60641e-02, 1.35459e-01
Node: 02 (pos: 0.020): 1.43573e-01, 1.29035e-01, 1.22310e-01, -3.44051e-02, 3.13125e-02, 1.35459e-01
Node: 03 (pos: 0.030): 1.44015e-01, 1.28012e-01, 1.23750e-01, -2.05908e-02, 1.69051e-02, 1.35462e-01
Node: 04 (pos: 0.040): 1.44453e-01, 1.26986e-01, 1.25192e-01, -6.34728e-03, 2.84517e-03, 1.35467e-01
Node: 05 (pos: 0.051): 1.44889e-01, 1.25956e-01, 1.26636e-01, 8.32590e-03, -1.08647e-02, 1.35474e-01
-
Node: 07 (pos: 0.071): 1.44889e-01, 1.25956e-01, 1.26636e-01, 8.32590e-03, -1.08647e-02, 1.35474e-01
Node: 08 (pos: 0.081): 1.44453e-01, 1.26986e-01, 1.25192e-01, -6.34728e-03, 2.84517e-03, 1.35467e-01
Node: 09 (pos: 0.091): 1.44015e-01, 1.28012e-01, 1.23750e-01, -2.05908e-02, 1.69051e-02, 1.35462e-01
Node: 10 (pos: 0.101): 1.43573e-01, 1.29035e-01, 1.22310e-01, -3.44051e-02, 3.13125e-02, 1.35459e-01
Node: 11 (pos: 0.111): 1.43128e-01, 1.30054e-01, 1.20872e-01, -4.77910e-02, 4.60641e-02, 1.35459e-01
Node: 12 (pos: 0.121): 1.42681e-01, 1.31069e-01, 1.19435e-01, -6.07497e-02, 6.11567e-02, 1.35462e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.44103e-09, 3.46075e-08, 6.38079e-07, 2.49589e-02, 2.37506e-02, 1.07334e-08
Node: 01 (pos: 0.010): 1.26807e-09, 4.51175e-08, 4.51802e-07, 1.01878e-01, 1.19804e-01, 1.07405e-08
Node: 02 (pos: 0.020): 1.11635e-09, 5.87524e-08, 3.18450e-07, 3.06140e-01, 3.75135e-01, 1.07404e-08
Node: 03 (pos: 0.030): 9.83216e-10, 7.64188e-08, 2.23434e-07, 6.54436e-01, 7.51425e-01, 1.07331e-08
Node: 04 (pos: 0.040): 8.66340e-10, 9.92789e-08, 1.56052e-07, 9.60513e-01, 9.91938e-01, 1.07187e-08
Node: 05 (pos: 0.051): 7.63700e-10, 1.28821e-07, 1.08492e-07, 9.33027e-01, 8.88660e-01, 1.06971e-08
-
Node: 07 (pos: 0.071): 7.63700e-10, 1.28821e-07, 1.08492e-07, 9.33027e-01, 8.88660e-01, 1.06971e-08
Node: 08 (pos: 0.081): 8.66340e-10, 9.92789e-08, 1.56052e-07, 9.60513e-01, 9.91938e-01, 1.07187e-08
Node: 09 (pos: 0.091): 9.83216e-10, 7.64188e-08, 2.23434e-07, 6.54436e-01, 7.51425e-01, 1.07331e-08
Node: 10 (pos: 0.101): 1.11635e-09, 5.87524e-08, 3.18450e-07, 3.06140e-01, 3.75135e-01, 1.07404e-08
Node: 11 (pos: 0.111): 1.26807e-09, 4.51175e-08, 4.51802e-07, 1.01878e-01, 1.19804e-01, 1.07405e-08
Node: 12 (pos: 0.121): 1.44103e-09, 3.46075e-08, 6.38079e-07, 2.49589e-02, 2.37506e-02, 1.07334e-08
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.44889e-01, 1.25956e-01, 1.26636e-01, 8.32590e-03, -1.08647e-02, 1.35474e-01
Node: 01 (pos: 0.010): 1.44453e-01, 1.26986e-01, 1.25192e-01, -6.34728e-03, 2.84517e-03, 1.35467e-01
Node: 02 (pos: 0.020): 1.44015e-01, 1.28012e-01, 1.23750e-01, -2.05908e-02, 1.69051e-02, 1.35462e-01
Node: 03 (pos: 0.030): 1.43573e-01, 1.29035e-01, 1.22310e-01, -3.44051e-02, 3.13125e-02, 1.35459e-01
Node: 04 (pos: 0.040): 1.43128e-01, 1.30054e-01, 1.20872e-01, -4.77910e-02, 4.60641e-02, 1.35459e-01
Node: 05 (pos: 0.051): 1.42681e-01, 1.31069e-01, 1.19435e-01, -6.07497e-02, 6.11567e-02, 1.35462e-01
-
Node: 07 (pos: 0.071): 1.43128e-01, 1.30054e-01, 1.20872e-01, -4.77910e-02, 4.60641e-02, 1.35459e-01
Node: 08 (pos: 0.081): 1.43573e-01, 1.29035e-01, 1.22310e-01, -3.44051e-02, 3.13125e-02, 1.35459e-01
Node: 09 (pos: 0.091): 1.44015e-01, 1.28012e-01, 1.23750e-01, -2.05908e-02, 1.69051e-02, 1.35462e-01
Node: 10 (pos: 0.101): 1.44453e-01, 1.26986e-01, 1.25192e-01, -6.34728e-03, 2.84517e-03, 1.35467e-01
Node: 11 (pos: 0.111): 1.44889e-01, 1.25956e-01, 1.26636e-01, 8.32590e-03, -1.08647e-02, 1.35474e-01
Node: 12 (pos: 0.121): 1.42681e-01, 1.31069e-01, 1.19435e-01, -6.07497e-02, 6.11567e-02, 1.35462e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 7.63700e-10, 1.28821e-07, 1.08492e-07, 9.33027e-01, 8.88660e-01, 1.06971e-08
Node: 58 (pos: 0.586): 8.66340e-10, 9.92789e-08, 1.56052e-07, 9.60513e-01, 9.91938e-01, 1.07187e-08
Node: 59 (pos: 0.596): 9.83216e-10, 7.64188e-08, 2.23434e-07, 6.54436e-01, 7.51425e-01, 1.07331e-08
Node: 60 (pos: 0.606): 1.11635e-09, 5.87524e-08, 3.18450e-07, 3.06140e-01, 3.75135e-01, 1.07404e-08
Node: 61 (pos: 0.616): 1.26807e-09, 4.51175e-08, 4.51802e-07, 1.01878e-01, 1.19804e-01, 1.07405e-08
Node: 50 (pos: 0.505): 1.44103e-09, 3.46075e-08, 6.38079e-07, 2.49589e-02, 2.37506e-02, 1.07334e-08
-
Node: 51 (pos: 0.515): 1.26807e-09, 4.51175e-08, 4.51802e-07, 1.01878e-01, 1.19804e-01, 1.07405e-08
Node: 52 (pos: 0.525): 1.11635e-09, 5.87524e-08, 3.18450e-07, 3.06140e-01, 3.75135e-01, 1.07404e-08
Node: 53 (pos: 0.535): 9.83216e-10, 7.64188e-08, 2.23434e-07, 6.54436e-01, 7.51425e-01, 1.07331e-08
Node: 54 (pos: 0.545): 8.66340e-10, 9.92789e-08, 1.56052e-07, 9.60513e-01, 9.91938e-01, 1.07187e-08
Node: 55 (pos: 0.556): 7.63700e-10, 1.28821e-07, 1.08492e-07, 9.33027e-01, 8.88660e-01, 1.06971e-08
Node: 62 (pos: 0.626): 1.44103e-09, 3.46075e-08, 6.38079e-07, 2.49589e-02, 2.37506e-02, 1.07334e-08
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 9.653591192084902e-13), ('0.bias', 1.1723469506280004e-10), ('2.weight', 1.4086350395303616e-09), ('2.bias', 4.0941576959693825e-10)] 

GNN_Layer 1 gradients:
[('0.weight', 1.542709201140209e-11), ('0.bias', 2.0205843275798487e-09), ('2.weight', 2.3551257727018172e-08), ('2.bias', 7.0402104543181795e-09)] 

GNN_Layer 2 gradients:
[('0.weight', 1.5511128700950168e-09), ('0.bias', 3.710996691622438e-08), ('2.weight', 4.5218573985968426e-07), ('2.bias', 1.2476503830454143e-07)] 

GNN_Layer 3 gradients:
[('0.weight', 0.005664167044723643), ('0.bias', 0.12738438029215662), ('2.weight', 0.5799139462110245), ('2.bias', 0.20006040554579493)] 

GNN_Layer 4 gradients:
[('0.weight', 0.0009167650432968501), ('0.bias', 0.04103748191678741), ('2.weight', 0.23697870991610512), ('2.bias', 0.07138587195733813)] 

GNN_Layer 5 gradients:
[('0.weight', 1.052218131168717e-11), ('0.bias', 5.957155285873658e-10), ('2.weight', 7.437681750837694e-09), ('2.bias', 2.132584526749016e-09)] 

Evaluation on test dataset:
Step 25, mean loss 0.018307833752716846
Step 50, mean loss 0.009000052948188255
Step 75, mean loss 0.01888595578896265
Step 100, mean loss 0.01914236795531192
Step 125, mean loss 0.026611832395718616
Step 150, mean loss 0.034282591497704365
Step 175, mean loss 0.04356868164082569
Step 200, mean loss 0.06478581065259816
Step 225, mean loss 0.06553523430499225
Unrolled forward losses 1.2846088008485936
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time54940.tar

Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00), 0.09729877558025332, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.10202359004268523, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.10093180176407941, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.10156525667174947, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.09595469821698434, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.0954605563799069, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.10453925270157047, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.10539058853193264, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.09793456280632208, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.1002163924983278, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.10096706898771811, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.09758750718398113, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.1044356020649938, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.023190475844466794
Step 50, mean loss 0.012721352605560999
Step 75, mean loss 0.02186903324618581
Step 100, mean loss 0.02746529372350711
Step 125, mean loss 0.02894095433835675
Step 150, mean loss 0.030454418340822936
Step 175, mean loss 0.05390614736488334
Step 200, mean loss 0.2440435837648065
Step 225, mean loss 0.1604894842721949
Unrolled forward losses 1.4377042603493049
Unrolled forward base losses 2.565701273852575
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00), 0.09923455073446869, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.09990490436388802, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.10030760519755001, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.09885645685433815, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.10466498749810091, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.11247937010207931, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.10248648407422974, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.10504966767156912, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.09802479569735804, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.09360815100579228, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.09631006634908676, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.09484787995823295, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.10472649203958971, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.022455842940445093
Step 50, mean loss 0.013466166818363481
Step 75, mean loss 0.020947392305016937
Step 100, mean loss 0.02618393209174958
Step 125, mean loss 0.02947412508273064
Step 150, mean loss 0.029701106813072184
Step 175, mean loss 0.054572685357555266
Step 200, mean loss 0.24855536728081937
Step 225, mean loss 0.16185180821150524
Unrolled forward losses 1.3465398473463677
Unrolled forward base losses 2.565701273852575
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00), 0.1134633258905367, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.10338189796592605, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.10191926243018111, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.10595305591043316, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.10538314530691911, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.10159776840389761, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.10696341706831736, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.09428863445900088, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.09928708935514957, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.11017208345909353, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.0986504584886568, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.09331243880626722, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.09520278615561893, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.024117642419834048
Step 50, mean loss 0.013378693082671641
Step 75, mean loss 0.020941683215771726
Step 100, mean loss 0.026599032620085228
Step 125, mean loss 0.02917258644151291
Step 150, mean loss 0.029488996374461573
Step 175, mean loss 0.0529112355297641
Step 200, mean loss 0.23988672923878518
Step 225, mean loss 0.15440071057191956
Unrolled forward losses 1.335753632253267
Unrolled forward base losses 2.565701273852575
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00), 0.09793080382171732, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.08), 0.10140136336521215, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.16), 0.09483124319703472, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.24), 0.09876937229559556, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.32), 0.11261296341367581, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.40), 0.10637047063810394, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.48), 0.09557644020279615, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.56), 0.0901898984809503, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.64), 0.0997147128333207, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.72), 0.10194713276055029, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.80), 0.10046641653171252, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.88), 0.09455760345380292, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Training Loss (progress: 0.96), 0.09757560399355214, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001]
Evaluation on validation dataset:
Step 25, mean loss 0.021544993170402215
Step 50, mean loss 0.012790671088341529
Step 75, mean loss 0.021679251797725476
Step 100, mean loss 0.027153837862766268
Step 125, mean loss 0.02846307448685237
Step 150, mean loss 0.029794501613965352
Step 175, mean loss 0.052296346068831656
Step 200, mean loss 0.24492798743000138
Step 225, mean loss 0.16000087350534253
Unrolled forward losses 1.3860310140057783
Unrolled forward base losses 2.565701273852575
Test loss: 1.2846088008485936
