Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar
Number of parameters: 1034609.0
Epoch 0
Starting epoch 0...
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.23210e-01, 5.16358e-01, 5.09954e-01, 4.96168e-01, 5.00325e-01, 4.95472e-01
Node: 01 (pos: 0.010): 5.19524e-01, 5.13486e-01, 5.08257e-01, 4.96913e-01, 5.00342e-01, 4.96633e-01
Node: 02 (pos: 0.020): 5.15764e-01, 5.10672e-01, 5.06576e-01, 4.97616e-01, 5.00331e-01, 4.97633e-01
Node: 03 (pos: 0.030): 5.11932e-01, 5.07916e-01, 5.04909e-01, 4.98276e-01, 5.00292e-01, 4.98469e-01
Node: 04 (pos: 0.040): 5.08027e-01, 5.05218e-01, 5.03258e-01, 4.98894e-01, 5.00223e-01, 4.99143e-01
Node: 05 (pos: 0.051): 5.04050e-01, 5.02580e-01, 5.01621e-01, 4.99468e-01, 5.00126e-01, 4.99653e-01
-
Node: 07 (pos: 0.071): 5.04050e-01, 5.02580e-01, 5.01621e-01, 4.99468e-01, 5.00126e-01, 4.99653e-01
Node: 08 (pos: 0.081): 5.08027e-01, 5.05218e-01, 5.03258e-01, 4.98894e-01, 5.00223e-01, 4.99143e-01
Node: 09 (pos: 0.091): 5.11932e-01, 5.07916e-01, 5.04909e-01, 4.98276e-01, 5.00292e-01, 4.98469e-01
Node: 10 (pos: 0.101): 5.15764e-01, 5.10672e-01, 5.06576e-01, 4.97616e-01, 5.00331e-01, 4.97633e-01
Node: 11 (pos: 0.111): 5.19524e-01, 5.13486e-01, 5.08257e-01, 4.96913e-01, 5.00342e-01, 4.96633e-01
Node: 12 (pos: 0.121): 5.23210e-01, 5.16358e-01, 5.09954e-01, 4.96168e-01, 5.00325e-01, 4.95472e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 6.47327e-02, 6.95117e-02, 7.42339e-02, 8.52790e-02, 8.18186e-02, 8.58697e-02
Node: 01 (pos: 0.010): 6.72694e-02, 7.15985e-02, 7.55277e-02, 8.46503e-02, 8.18043e-02, 8.48859e-02
Node: 02 (pos: 0.020): 6.99391e-02, 7.36922e-02, 7.68277e-02, 8.40608e-02, 8.18133e-02, 8.40466e-02
Node: 03 (pos: 0.030): 7.27485e-02, 7.57903e-02, 7.81337e-02, 8.35099e-02, 8.18458e-02, 8.33490e-02
Node: 04 (pos: 0.040): 7.57044e-02, 7.78901e-02, 7.94455e-02, 8.29973e-02, 8.19019e-02, 8.27908e-02
Node: 05 (pos: 0.051): 7.88142e-02, 7.99892e-02, 8.07627e-02, 8.25224e-02, 8.19816e-02, 8.23699e-02
-
Node: 07 (pos: 0.071): 7.88142e-02, 7.99892e-02, 8.07627e-02, 8.25224e-02, 8.19816e-02, 8.23699e-02
Node: 08 (pos: 0.081): 7.57044e-02, 7.78901e-02, 7.94455e-02, 8.29973e-02, 8.19019e-02, 8.27908e-02
Node: 09 (pos: 0.091): 7.27485e-02, 7.57903e-02, 7.81337e-02, 8.35099e-02, 8.18458e-02, 8.33490e-02
Node: 10 (pos: 0.101): 6.99391e-02, 7.36922e-02, 7.68277e-02, 8.40608e-02, 8.18133e-02, 8.40466e-02
Node: 11 (pos: 0.111): 6.72694e-02, 7.15985e-02, 7.55277e-02, 8.46503e-02, 8.18043e-02, 8.48859e-02
Node: 12 (pos: 0.121): 6.47327e-02, 6.95117e-02, 7.42339e-02, 8.52790e-02, 8.18186e-02, 8.58697e-02
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 5.04050e-01, 5.02580e-01, 5.01621e-01, 4.99468e-01, 5.00126e-01, 4.99653e-01
Node: 01 (pos: 0.010): 5.08027e-01, 5.05218e-01, 5.03258e-01, 4.98894e-01, 5.00223e-01, 4.99143e-01
Node: 02 (pos: 0.020): 5.11932e-01, 5.07916e-01, 5.04909e-01, 4.98276e-01, 5.00292e-01, 4.98469e-01
Node: 03 (pos: 0.030): 5.15764e-01, 5.10672e-01, 5.06576e-01, 4.97616e-01, 5.00331e-01, 4.97633e-01
Node: 04 (pos: 0.040): 5.19524e-01, 5.13486e-01, 5.08257e-01, 4.96913e-01, 5.00342e-01, 4.96633e-01
Node: 05 (pos: 0.051): 5.23210e-01, 5.16358e-01, 5.09954e-01, 4.96168e-01, 5.00325e-01, 4.95472e-01
-
Node: 07 (pos: 0.071): 5.19524e-01, 5.13486e-01, 5.08257e-01, 4.96913e-01, 5.00342e-01, 4.96633e-01
Node: 08 (pos: 0.081): 5.15764e-01, 5.10672e-01, 5.06576e-01, 4.97616e-01, 5.00331e-01, 4.97633e-01
Node: 09 (pos: 0.091): 5.11932e-01, 5.07916e-01, 5.04909e-01, 4.98276e-01, 5.00292e-01, 4.98469e-01
Node: 10 (pos: 0.101): 5.08027e-01, 5.05218e-01, 5.03258e-01, 4.98894e-01, 5.00223e-01, 4.99143e-01
Node: 11 (pos: 0.111): 5.04050e-01, 5.02580e-01, 5.01621e-01, 4.99468e-01, 5.00126e-01, 4.99653e-01
Node: 12 (pos: 0.121): 5.23210e-01, 5.16358e-01, 5.09954e-01, 4.96168e-01, 5.00325e-01, 4.95472e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 7.88142e-02, 7.99892e-02, 8.07627e-02, 8.25224e-02, 8.19816e-02, 8.23699e-02
Node: 58 (pos: 0.586): 7.57044e-02, 7.78901e-02, 7.94455e-02, 8.29973e-02, 8.19019e-02, 8.27908e-02
Node: 59 (pos: 0.596): 7.27485e-02, 7.57903e-02, 7.81337e-02, 8.35099e-02, 8.18458e-02, 8.33490e-02
Node: 60 (pos: 0.606): 6.99391e-02, 7.36922e-02, 7.68277e-02, 8.40608e-02, 8.18133e-02, 8.40466e-02
Node: 61 (pos: 0.616): 6.72694e-02, 7.15985e-02, 7.55277e-02, 8.46503e-02, 8.18043e-02, 8.48859e-02
Node: 50 (pos: 0.505): 6.47327e-02, 6.95117e-02, 7.42339e-02, 8.52790e-02, 8.18186e-02, 8.58697e-02
-
Node: 51 (pos: 0.515): 6.72694e-02, 7.15985e-02, 7.55277e-02, 8.46503e-02, 8.18043e-02, 8.48859e-02
Node: 52 (pos: 0.525): 6.99391e-02, 7.36922e-02, 7.68277e-02, 8.40608e-02, 8.18133e-02, 8.40466e-02
Node: 53 (pos: 0.535): 7.27485e-02, 7.57903e-02, 7.81337e-02, 8.35099e-02, 8.18458e-02, 8.33490e-02
Node: 54 (pos: 0.545): 7.57044e-02, 7.78901e-02, 7.94455e-02, 8.29973e-02, 8.19019e-02, 8.27908e-02
Node: 55 (pos: 0.556): 7.88142e-02, 7.99892e-02, 8.07627e-02, 8.25224e-02, 8.19816e-02, 8.23699e-02
Node: 62 (pos: 0.626): 6.47327e-02, 6.95117e-02, 7.42339e-02, 8.52790e-02, 8.18186e-02, 8.58697e-02
=========================================================================================================
Training Loss (progress: 0.00), 1.3709303127767989, [0.11106896494135308, 0.11719195366876466, 0.11672679116459908, 0.1168080138203364, 0.11747636190007818, 0.11663876853923111]
Training Loss (progress: 0.08), 0.2609385119181935, [0.11612752398779942, 0.12940114494581179, 0.12899346378682766, 0.13206903192400304, 0.1432595603354511, 0.1464737785382153]
Training Loss (progress: 0.16), 0.19782369882418885, [0.11611432257805858, 0.128627999353423, 0.12765150418218157, 0.13482587536478988, 0.15062960382755866, 0.1548119033403136]
Training Loss (progress: 0.24), 0.1691548693052206, [0.11596238546685539, 0.12721125066523198, 0.1261873784322695, 0.13770004166683586, 0.15590417864017816, 0.16057913699834828]
Training Loss (progress: 0.32), 0.14858387846816362, [0.11575096332055951, 0.1258031219078649, 0.12467332034545098, 0.14061379493117657, 0.1602143334414563, 0.16569166182667774]
Training Loss (progress: 0.40), 0.13989361080847823, [0.11572456320631358, 0.12454488703268317, 0.12331871802816478, 0.1433962178283986, 0.16427669547881332, 0.1700829689632745]
Training Loss (progress: 0.48), 0.13246762440852933, [0.11559048507506253, 0.12324256119940878, 0.12194500614511529, 0.14577936368412003, 0.16680016278574483, 0.17416313720237034]
Training Loss (progress: 0.56), 0.12546920624545368, [0.11523754150947838, 0.12237928244100735, 0.12076113229314105, 0.14832659526677985, 0.1702878984530906, 0.17718274175883517]
Training Loss (progress: 0.64), 0.12095601721545542, [0.11531246310142443, 0.12105710486930812, 0.11976543691725322, 0.15036400354766843, 0.17373333861373752, 0.1803286954960895]
Training Loss (progress: 0.72), 0.1038491182534811, [0.11492873888590745, 0.11988520155475738, 0.11852120977443023, 0.15242000013156873, 0.17581442702560632, 0.18299024762439867]
Training Loss (progress: 0.80), 0.11330380362913622, [0.11475387818732065, 0.1188913937758036, 0.11759768303551675, 0.15442871314731363, 0.1792617759036867, 0.18561219231332546]
Training Loss (progress: 0.88), 0.1053282207792505, [0.11450780076670586, 0.11798180184641865, 0.1164319698604057, 0.15563245813054882, 0.18123934736775565, 0.18800574970423736]
Training Loss (progress: 0.96), 0.10437506245244792, [0.1143490879146579, 0.11717637365567594, 0.11539278727171565, 0.15754373112115927, 0.1841561090856999, 0.19031453538433557]
Evaluation on validation dataset:
Step 25, mean loss 0.08524666175884942
Step 50, mean loss 0.08967625571499832
Step 75, mean loss 0.10526697672112048
Step 100, mean loss 0.2857744928086531
Step 125, mean loss 0.2653585825008188
Step 150, mean loss 0.18881304407638344
Step 175, mean loss 0.31989677684664086
Step 200, mean loss 0.5284152741488122
Step 225, mean loss 0.5161782704881084
Unrolled forward losses 18.19657160366859
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.13410e-01, 5.86619e-01, 5.76776e-01, 3.36860e-01, 2.33091e-01, 1.97221e-01
Node: 01 (pos: 0.010): 5.03675e-01, 5.45821e-01, 5.41954e-01, 3.29984e-01, 2.29070e-01, 1.91830e-01
Node: 02 (pos: 0.020): 4.93882e-01, 5.04500e-01, 5.06708e-01, 3.23155e-01, 2.25061e-01, 1.86390e-01
Node: 03 (pos: 0.030): 4.84041e-01, 4.63217e-01, 4.71387e-01, 3.16376e-01, 2.21064e-01, 1.80909e-01
Node: 04 (pos: 0.040): 4.74157e-01, 4.22532e-01, 4.36342e-01, 3.09649e-01, 2.17081e-01, 1.75398e-01
Node: 05 (pos: 0.051): 4.64239e-01, 3.82968e-01, 4.01913e-01, 3.02977e-01, 2.13114e-01, 1.69869e-01
-
Node: 07 (pos: 0.071): 4.64239e-01, 3.82968e-01, 4.01913e-01, 3.02977e-01, 2.13114e-01, 1.69869e-01
Node: 08 (pos: 0.081): 4.74157e-01, 4.22532e-01, 4.36342e-01, 3.09649e-01, 2.17081e-01, 1.75398e-01
Node: 09 (pos: 0.091): 4.84041e-01, 4.63217e-01, 4.71387e-01, 3.16376e-01, 2.21064e-01, 1.80909e-01
Node: 10 (pos: 0.101): 4.93882e-01, 5.04500e-01, 5.06708e-01, 3.23155e-01, 2.25061e-01, 1.86390e-01
Node: 11 (pos: 0.111): 5.03675e-01, 5.45821e-01, 5.41954e-01, 3.29984e-01, 2.29070e-01, 1.91830e-01
Node: 12 (pos: 0.121): 5.13410e-01, 5.86619e-01, 5.76776e-01, 3.36860e-01, 2.33091e-01, 1.97221e-01

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 9.93776e-02, 5.27713e-02, 5.54507e-02, 4.87328e-01, 7.46097e-01, 8.15850e-01
Node: 01 (pos: 0.010): 1.08382e-01, 7.83297e-02, 7.78038e-02, 5.01690e-01, 7.53608e-01, 8.24852e-01
Node: 02 (pos: 0.020): 1.18063e-01, 1.13517e-01, 1.07289e-01, 5.16066e-01, 7.61042e-01, 8.33782e-01
Node: 03 (pos: 0.030): 1.28448e-01, 1.59727e-01, 1.44877e-01, 5.30436e-01, 7.68393e-01, 8.42610e-01
Node: 04 (pos: 0.040): 1.39558e-01, 2.17355e-01, 1.91035e-01, 5.44777e-01, 7.75656e-01, 8.51312e-01
Node: 05 (pos: 0.051): 1.51412e-01, 2.85422e-01, 2.45518e-01, 5.59067e-01, 7.82825e-01, 8.59859e-01
-
Node: 07 (pos: 0.071): 1.51412e-01, 2.85422e-01, 2.45518e-01, 5.59067e-01, 7.82825e-01, 8.59859e-01
Node: 08 (pos: 0.081): 1.39558e-01, 2.17355e-01, 1.91035e-01, 5.44777e-01, 7.75656e-01, 8.51312e-01
Node: 09 (pos: 0.091): 1.28448e-01, 1.59727e-01, 1.44877e-01, 5.30436e-01, 7.68393e-01, 8.42610e-01
Node: 10 (pos: 0.101): 1.18063e-01, 1.13517e-01, 1.07289e-01, 5.16066e-01, 7.61042e-01, 8.33782e-01
Node: 11 (pos: 0.111): 1.08382e-01, 7.83297e-02, 7.78038e-02, 5.01690e-01, 7.53608e-01, 8.24852e-01
Node: 12 (pos: 0.121): 9.93776e-02, 5.27713e-02, 5.54507e-02, 4.87328e-01, 7.46097e-01, 8.15850e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.64239e-01, 3.82968e-01, 4.01913e-01, 3.02977e-01, 2.13114e-01, 1.69869e-01
Node: 01 (pos: 0.010): 4.74157e-01, 4.22532e-01, 4.36342e-01, 3.09649e-01, 2.17081e-01, 1.75398e-01
Node: 02 (pos: 0.020): 4.84041e-01, 4.63217e-01, 4.71387e-01, 3.16376e-01, 2.21064e-01, 1.80909e-01
Node: 03 (pos: 0.030): 4.93882e-01, 5.04500e-01, 5.06708e-01, 3.23155e-01, 2.25061e-01, 1.86390e-01
Node: 04 (pos: 0.040): 5.03675e-01, 5.45821e-01, 5.41954e-01, 3.29984e-01, 2.29070e-01, 1.91830e-01
Node: 05 (pos: 0.051): 5.13410e-01, 5.86619e-01, 5.76776e-01, 3.36860e-01, 2.33091e-01, 1.97221e-01
-
Node: 07 (pos: 0.071): 5.03675e-01, 5.45821e-01, 5.41954e-01, 3.29984e-01, 2.29070e-01, 1.91830e-01
Node: 08 (pos: 0.081): 4.93882e-01, 5.04500e-01, 5.06708e-01, 3.23155e-01, 2.25061e-01, 1.86390e-01
Node: 09 (pos: 0.091): 4.84041e-01, 4.63217e-01, 4.71387e-01, 3.16376e-01, 2.21064e-01, 1.80909e-01
Node: 10 (pos: 0.101): 4.74157e-01, 4.22532e-01, 4.36342e-01, 3.09649e-01, 2.17081e-01, 1.75398e-01
Node: 11 (pos: 0.111): 4.64239e-01, 3.82968e-01, 4.01913e-01, 3.02977e-01, 2.13114e-01, 1.69869e-01
Node: 12 (pos: 0.121): 5.13410e-01, 5.86619e-01, 5.76776e-01, 3.36860e-01, 2.33091e-01, 1.97221e-01

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.51412e-01, 2.85422e-01, 2.45518e-01, 5.59067e-01, 7.82825e-01, 8.59859e-01
Node: 58 (pos: 0.586): 1.39558e-01, 2.17355e-01, 1.91035e-01, 5.44777e-01, 7.75656e-01, 8.51312e-01
Node: 59 (pos: 0.596): 1.28448e-01, 1.59727e-01, 1.44877e-01, 5.30436e-01, 7.68393e-01, 8.42610e-01
Node: 60 (pos: 0.606): 1.18063e-01, 1.13517e-01, 1.07289e-01, 5.16066e-01, 7.61042e-01, 8.33782e-01
Node: 61 (pos: 0.616): 1.08382e-01, 7.83297e-02, 7.78038e-02, 5.01690e-01, 7.53608e-01, 8.24852e-01
Node: 50 (pos: 0.505): 9.93776e-02, 5.27713e-02, 5.54507e-02, 4.87328e-01, 7.46097e-01, 8.15850e-01
-
Node: 51 (pos: 0.515): 1.08382e-01, 7.83297e-02, 7.78038e-02, 5.01690e-01, 7.53608e-01, 8.24852e-01
Node: 52 (pos: 0.525): 1.18063e-01, 1.13517e-01, 1.07289e-01, 5.16066e-01, 7.61042e-01, 8.33782e-01
Node: 53 (pos: 0.535): 1.28448e-01, 1.59727e-01, 1.44877e-01, 5.30436e-01, 7.68393e-01, 8.42610e-01
Node: 54 (pos: 0.545): 1.39558e-01, 2.17355e-01, 1.91035e-01, 5.44777e-01, 7.75656e-01, 8.51312e-01
Node: 55 (pos: 0.556): 1.51412e-01, 2.85422e-01, 2.45518e-01, 5.59067e-01, 7.82825e-01, 8.59859e-01
Node: 62 (pos: 0.626): 9.93776e-02, 5.27713e-02, 5.54507e-02, 4.87328e-01, 7.46097e-01, 8.15850e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.05441497341205561), ('0.bias', 1.453795023329589), ('2.weight', 0.5301371295421715), ('2.bias', 1.5333407759459823)] 

GNN_Layer 1 gradients:
[('0.weight', 0.019852895153076814), ('0.bias', 0.19676922292511714), ('2.weight', 0.09350591892149547), ('2.bias', 0.10851091381912142)] 

GNN_Layer 2 gradients:
[('0.weight', 0.06768903780326735), ('0.bias', 0.9942855224459741), ('2.weight', 0.32165680887218967), ('2.bias', 0.5468306344625551)] 

GNN_Layer 3 gradients:
[('0.weight', 0.02799366442103421), ('0.bias', 0.7174759647248546), ('2.weight', 0.32006881392073), ('2.bias', 0.6057442364688679)] 

GNN_Layer 4 gradients:
[('0.weight', 0.005180939666698186), ('0.bias', 0.1426753662600764), ('2.weight', 0.08136794493883263), ('2.bias', 0.12073469401945401)] 

GNN_Layer 5 gradients:
[('0.weight', 0.006182009005574845), ('0.bias', 0.12044463125139007), ('2.weight', 0.07454745563660423), ('2.bias', 0.08906401013465012)] 

Evaluation on test dataset:
Step 25, mean loss 0.07403418870387787
Step 50, mean loss 0.07163747387838762
Step 75, mean loss 0.11599603946874532
Step 100, mean loss 0.1429670865790571
Step 125, mean loss 0.328878523760767
Step 150, mean loss 0.1962490748462855
Step 175, mean loss 0.3835696384025571
Step 200, mean loss 0.4813161899088539
Step 225, mean loss 0.26753696566024154
Unrolled forward losses 15.882885564690168
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.22916679946210197, [0.11422045751145925, 0.11713932065043259, 0.11502018318757172, 0.15815742114465928, 0.18550911777721582, 0.19137487564644917]
Training Loss (progress: 0.08), 0.21890458187981277, [0.1148704777090245, 0.11635615840581902, 0.11434968201061302, 0.160151371914819, 0.18953636970939353, 0.19509605145382858]
Training Loss (progress: 0.16), 0.23389189229803758, [0.11511120013352787, 0.11617198190576505, 0.1136087075603891, 0.1618249062937919, 0.19292520724458997, 0.19797655288682237]
Training Loss (progress: 0.24), 0.20218581710983088, [0.11508682294152565, 0.11541293530018912, 0.11296492779013444, 0.16289065868150654, 0.19555586721535914, 0.200669701383988]
Training Loss (progress: 0.32), 0.19414247768767331, [0.11541207188063231, 0.11514377902626632, 0.11222896464411178, 0.16457489943961504, 0.19871507887636922, 0.20300530723544222]
Training Loss (progress: 0.40), 0.18296170823527252, [0.1152721262291175, 0.11481567359685971, 0.11152593843619299, 0.16609372456728466, 0.20148088566984473, 0.2055251319581369]
Training Loss (progress: 0.48), 0.18771766941384035, [0.11553485740584628, 0.11425153182368339, 0.11082334802661865, 0.16752595593837266, 0.2054725415856116, 0.2088082068303157]
Training Loss (progress: 0.56), 0.2040670020942353, [0.11548332778658188, 0.11411700768331479, 0.11012353697415199, 0.16964854417790845, 0.20771233400883926, 0.21087704673175647]
Training Loss (progress: 0.64), 0.18544628218023257, [0.11560339171418917, 0.11304094589176027, 0.10941674755496465, 0.17121950475127956, 0.21018465658524238, 0.21313692275661894]
Training Loss (progress: 0.72), 0.1980128456323501, [0.11549262893549492, 0.11277176805080129, 0.10882277625642997, 0.17205660211206994, 0.213660821225834, 0.2153709853257438]
Training Loss (progress: 0.80), 0.17700059400619522, [0.11561174365871531, 0.11221575624777366, 0.10787445007412151, 0.17396500972025522, 0.2164797850158747, 0.21804522688871203]
Training Loss (progress: 0.88), 0.1630091477456311, [0.11580033768597386, 0.11189382998440124, 0.10720087374572315, 0.17515116275253667, 0.2198171872010878, 0.22010496073887295]
Training Loss (progress: 0.96), 0.16292997712906265, [0.11591264849356563, 0.11102613296169679, 0.10626194314338086, 0.1770829168563072, 0.22312964625798754, 0.22254375799166853]
Evaluation on validation dataset:
Step 25, mean loss 0.1017051465632938
Step 50, mean loss 0.057087746938039904
Step 75, mean loss 0.09010950943908325
Step 100, mean loss 0.22242258205405352
Step 125, mean loss 0.11146955000624645
Step 150, mean loss 0.09381392901383398
Step 175, mean loss 0.17020353799480817
Step 200, mean loss 0.3861852566473657
Step 225, mean loss 0.36434194393236163
Unrolled forward losses 4.6511993200524495
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.06062e-01, 5.95557e-01, 5.99472e-01, 2.43618e-01, 9.47947e-02, 8.45723e-02
Node: 01 (pos: 0.010): 4.95428e-01, 5.46066e-01, 5.56179e-01, 2.38649e-01, 9.32603e-02, 8.18467e-02
Node: 02 (pos: 0.020): 4.84750e-01, 4.95742e-01, 5.11989e-01, 2.33722e-01, 9.17271e-02, 7.91134e-02
Node: 03 (pos: 0.030): 4.74037e-01, 4.45599e-01, 4.67584e-01, 2.28841e-01, 9.01960e-02, 7.63785e-02
Node: 04 (pos: 0.040): 4.63299e-01, 3.96631e-01, 4.23662e-01, 2.24006e-01, 8.86675e-02, 7.36478e-02
Node: 05 (pos: 0.051): 4.52547e-01, 3.49738e-01, 3.80889e-01, 2.19218e-01, 8.71425e-02, 7.09275e-02
-
Node: 07 (pos: 0.071): 4.52547e-01, 3.49738e-01, 3.80889e-01, 2.19218e-01, 8.71425e-02, 7.09275e-02
Node: 08 (pos: 0.081): 4.63299e-01, 3.96631e-01, 4.23662e-01, 2.24006e-01, 8.86675e-02, 7.36478e-02
Node: 09 (pos: 0.091): 4.74037e-01, 4.45599e-01, 4.67584e-01, 2.28841e-01, 9.01960e-02, 7.63785e-02
Node: 10 (pos: 0.101): 4.84750e-01, 4.95742e-01, 5.11989e-01, 2.33722e-01, 9.17271e-02, 7.91134e-02
Node: 11 (pos: 0.111): 4.95428e-01, 5.46066e-01, 5.56179e-01, 2.38649e-01, 9.32603e-02, 8.18467e-02
Node: 12 (pos: 0.121): 5.06062e-01, 5.95557e-01, 5.99472e-01, 2.43618e-01, 9.47947e-02, 8.45723e-02

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.09673e-01, 4.06001e-02, 3.39015e-02, 7.16047e-01, 9.60753e-01, 9.68544e-01
Node: 01 (pos: 0.010): 1.20231e-01, 6.76367e-02, 5.43058e-02, 7.25770e-01, 9.61989e-01, 9.70509e-01
Node: 02 (pos: 0.020): 1.31597e-01, 1.08607e-01, 8.47032e-02, 7.35337e-01, 9.63205e-01, 9.72419e-01
Node: 03 (pos: 0.030): 1.43796e-01, 1.66355e-01, 1.27585e-01, 7.44740e-01, 9.64401e-01, 9.74268e-01
Node: 04 (pos: 0.040): 1.56845e-01, 2.41454e-01, 1.84460e-01, 7.53974e-01, 9.65577e-01, 9.76053e-01
Node: 05 (pos: 0.051): 1.70757e-01, 3.31238e-01, 2.55064e-01, 7.63033e-01, 9.66731e-01, 9.77770e-01
-
Node: 07 (pos: 0.071): 1.70757e-01, 3.31238e-01, 2.55064e-01, 7.63033e-01, 9.66731e-01, 9.77770e-01
Node: 08 (pos: 0.081): 1.56845e-01, 2.41454e-01, 1.84460e-01, 7.53974e-01, 9.65577e-01, 9.76053e-01
Node: 09 (pos: 0.091): 1.43796e-01, 1.66355e-01, 1.27585e-01, 7.44740e-01, 9.64401e-01, 9.74268e-01
Node: 10 (pos: 0.101): 1.31597e-01, 1.08607e-01, 8.47032e-02, 7.35337e-01, 9.63205e-01, 9.72419e-01
Node: 11 (pos: 0.111): 1.20231e-01, 6.76367e-02, 5.43058e-02, 7.25770e-01, 9.61989e-01, 9.70509e-01
Node: 12 (pos: 0.121): 1.09673e-01, 4.06001e-02, 3.39015e-02, 7.16047e-01, 9.60753e-01, 9.68544e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.52547e-01, 3.49738e-01, 3.80889e-01, 2.19218e-01, 8.71425e-02, 7.09275e-02
Node: 01 (pos: 0.010): 4.63299e-01, 3.96631e-01, 4.23662e-01, 2.24006e-01, 8.86675e-02, 7.36478e-02
Node: 02 (pos: 0.020): 4.74037e-01, 4.45599e-01, 4.67584e-01, 2.28841e-01, 9.01960e-02, 7.63785e-02
Node: 03 (pos: 0.030): 4.84750e-01, 4.95742e-01, 5.11989e-01, 2.33722e-01, 9.17271e-02, 7.91134e-02
Node: 04 (pos: 0.040): 4.95428e-01, 5.46066e-01, 5.56179e-01, 2.38649e-01, 9.32603e-02, 8.18467e-02
Node: 05 (pos: 0.051): 5.06062e-01, 5.95557e-01, 5.99472e-01, 2.43618e-01, 9.47947e-02, 8.45723e-02
-
Node: 07 (pos: 0.071): 4.95428e-01, 5.46066e-01, 5.56179e-01, 2.38649e-01, 9.32603e-02, 8.18467e-02
Node: 08 (pos: 0.081): 4.84750e-01, 4.95742e-01, 5.11989e-01, 2.33722e-01, 9.17271e-02, 7.91134e-02
Node: 09 (pos: 0.091): 4.74037e-01, 4.45599e-01, 4.67584e-01, 2.28841e-01, 9.01960e-02, 7.63785e-02
Node: 10 (pos: 0.101): 4.63299e-01, 3.96631e-01, 4.23662e-01, 2.24006e-01, 8.86675e-02, 7.36478e-02
Node: 11 (pos: 0.111): 4.52547e-01, 3.49738e-01, 3.80889e-01, 2.19218e-01, 8.71425e-02, 7.09275e-02
Node: 12 (pos: 0.121): 5.06062e-01, 5.95557e-01, 5.99472e-01, 2.43618e-01, 9.47947e-02, 8.45723e-02

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.70757e-01, 3.31238e-01, 2.55064e-01, 7.63033e-01, 9.66731e-01, 9.77770e-01
Node: 58 (pos: 0.586): 1.56845e-01, 2.41454e-01, 1.84460e-01, 7.53974e-01, 9.65577e-01, 9.76053e-01
Node: 59 (pos: 0.596): 1.43796e-01, 1.66355e-01, 1.27585e-01, 7.44740e-01, 9.64401e-01, 9.74268e-01
Node: 60 (pos: 0.606): 1.31597e-01, 1.08607e-01, 8.47032e-02, 7.35337e-01, 9.63205e-01, 9.72419e-01
Node: 61 (pos: 0.616): 1.20231e-01, 6.76367e-02, 5.43058e-02, 7.25770e-01, 9.61989e-01, 9.70509e-01
Node: 50 (pos: 0.505): 1.09673e-01, 4.06001e-02, 3.39015e-02, 7.16047e-01, 9.60753e-01, 9.68544e-01
-
Node: 51 (pos: 0.515): 1.20231e-01, 6.76367e-02, 5.43058e-02, 7.25770e-01, 9.61989e-01, 9.70509e-01
Node: 52 (pos: 0.525): 1.31597e-01, 1.08607e-01, 8.47032e-02, 7.35337e-01, 9.63205e-01, 9.72419e-01
Node: 53 (pos: 0.535): 1.43796e-01, 1.66355e-01, 1.27585e-01, 7.44740e-01, 9.64401e-01, 9.74268e-01
Node: 54 (pos: 0.545): 1.56845e-01, 2.41454e-01, 1.84460e-01, 7.53974e-01, 9.65577e-01, 9.76053e-01
Node: 55 (pos: 0.556): 1.70757e-01, 3.31238e-01, 2.55064e-01, 7.63033e-01, 9.66731e-01, 9.77770e-01
Node: 62 (pos: 0.626): 1.09673e-01, 4.06001e-02, 3.39015e-02, 7.16047e-01, 9.60753e-01, 9.68544e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.021422232270568622), ('0.bias', 0.24675526788469723), ('2.weight', 0.19339543711327004), ('2.bias', 0.25303359101578304)] 

GNN_Layer 1 gradients:
[('0.weight', 0.009702567417063452), ('0.bias', 0.1803082828168653), ('2.weight', 0.03986982648538527), ('2.bias', 0.08790429679159623)] 

GNN_Layer 2 gradients:
[('0.weight', 0.13494331722960407), ('0.bias', 3.4758240885833147), ('2.weight', 0.5503914543123908), ('2.bias', 1.6270701258553706)] 

GNN_Layer 3 gradients:
[('0.weight', 0.00395110827003367), ('0.bias', 0.173454436937232), ('2.weight', 0.07795523382165738), ('2.bias', 0.135359582434945)] 

GNN_Layer 4 gradients:
[('0.weight', 0.001842040466628496), ('0.bias', 0.03468115648964818), ('2.weight', 0.024112719592761452), ('2.bias', 0.02431076420347429)] 

GNN_Layer 5 gradients:
[('0.weight', 0.0028134650885626557), ('0.bias', 0.06758957889559153), ('2.weight', 0.04191696912184302), ('2.bias', 0.042601988253829014)] 

Evaluation on test dataset:
Step 25, mean loss 0.08210121593052033
Step 50, mean loss 0.044529514167330905
Step 75, mean loss 0.0680302517200598
Step 100, mean loss 0.08168486731098124
Step 125, mean loss 0.2548495081439968
Step 150, mean loss 0.10021016571052992
Step 175, mean loss 0.1937940569861757
Step 200, mean loss 0.2525315831893922
Step 225, mean loss 0.2387045708135099
Unrolled forward losses 3.8742085645124575
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.23849101413175186, [0.11597671403749561, 0.11072817173600775, 0.10620019908243057, 0.17762975043103998, 0.22468373236472214, 0.2238696892098985]
Training Loss (progress: 0.08), 0.2460179370781525, [0.11592710755671189, 0.11084930834684087, 0.10605811347496139, 0.1787710397831667, 0.22743912439748573, 0.2256004283151726]
Training Loss (progress: 0.16), 0.21215191909338257, [0.11599018135010396, 0.11068200703401819, 0.10584877886953933, 0.17969702437498794, 0.2291246213744617, 0.2272875350449193]
Training Loss (progress: 0.24), 0.21599277113528842, [0.1159528496066895, 0.11075716623253344, 0.10567688910569059, 0.18048721013897334, 0.23096572829739018, 0.22901996042532566]
Training Loss (progress: 0.32), 0.19596292835648826, [0.11597047857867554, 0.11055945305487044, 0.10550794179447873, 0.18140859934317283, 0.23312590749597562, 0.23035359987063536]
Training Loss (progress: 0.40), 0.22118039072428758, [0.11588270813012286, 0.1104340062347298, 0.10512451426392325, 0.1819689956081009, 0.23493223533892535, 0.23217327038338118]
Training Loss (progress: 0.48), 0.20072831160767926, [0.11589859207285913, 0.11021364150237328, 0.10506772956942072, 0.18275986130325889, 0.23701403268135282, 0.23388226570840737]
Training Loss (progress: 0.56), 0.21900390927074181, [0.11593921274834444, 0.11014256254983913, 0.1048414881462766, 0.18378633436389702, 0.2384445974843946, 0.23509290723199572]
Training Loss (progress: 0.64), 0.2038242774538225, [0.1161494528575657, 0.1097685000932676, 0.10466805315891024, 0.18437372215639738, 0.2402256541065002, 0.2365950868471235]
Training Loss (progress: 0.72), 0.1974623208117087, [0.11608550669388387, 0.10987504379467608, 0.10431858681829964, 0.18532816727035184, 0.2421702002104751, 0.23777936661121704]
Training Loss (progress: 0.80), 0.20782486350563847, [0.11622495438918859, 0.10965265902115821, 0.10424035643320367, 0.18646004981353503, 0.24415461767048285, 0.2391437570763862]
Training Loss (progress: 0.88), 0.19290150368903627, [0.11615188178569937, 0.10946104473088568, 0.10400828979745551, 0.18715967666898095, 0.24537735144173217, 0.24041507143530166]
Training Loss (progress: 0.96), 0.1834393176799207, [0.11613094198716817, 0.10949842296852626, 0.10378754171974675, 0.1880476173386794, 0.24714142691035587, 0.24163755678250226]
Evaluation on validation dataset:
Step 25, mean loss 0.08673855949271043
Step 50, mean loss 0.03699319895599346
Step 75, mean loss 0.07685051987118263
Step 100, mean loss 0.10938190818001076
Step 125, mean loss 0.09273826715179531
Step 150, mean loss 0.08233186569590317
Step 175, mean loss 0.12463913039095173
Step 200, mean loss 0.3468629338809187
Step 225, mean loss 0.4516079720156648
Unrolled forward losses 3.061376830656381
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.02330e-01, 5.87632e-01, 5.99692e-01, 1.95890e-01, 4.57851e-02, 4.57256e-02
Node: 01 (pos: 0.010): 4.91506e-01, 5.36486e-01, 5.54947e-01, 1.92320e-01, 4.52075e-02, 4.42886e-02
Node: 02 (pos: 0.020): 4.80643e-01, 4.84652e-01, 5.09264e-01, 1.88772e-01, 4.46249e-02, 4.28422e-02
Node: 03 (pos: 0.030): 4.69751e-01, 4.33237e-01, 4.63396e-01, 1.85249e-01, 4.40379e-02, 4.13901e-02
Node: 04 (pos: 0.040): 4.58841e-01, 3.83308e-01, 4.18110e-01, 1.81751e-01, 4.34468e-02, 3.99360e-02
Node: 05 (pos: 0.051): 4.47923e-01, 3.35807e-01, 3.74136e-01, 1.78279e-01, 4.28520e-02, 3.84833e-02
-
Node: 07 (pos: 0.071): 4.47923e-01, 3.35807e-01, 3.74136e-01, 1.78279e-01, 4.28520e-02, 3.84833e-02
Node: 08 (pos: 0.081): 4.58841e-01, 3.83308e-01, 4.18110e-01, 1.81751e-01, 4.34468e-02, 3.99360e-02
Node: 09 (pos: 0.091): 4.69751e-01, 4.33237e-01, 4.63396e-01, 1.85249e-01, 4.40379e-02, 4.13901e-02
Node: 10 (pos: 0.101): 4.80643e-01, 4.84652e-01, 5.09264e-01, 1.88772e-01, 4.46249e-02, 4.28422e-02
Node: 11 (pos: 0.111): 4.91506e-01, 5.36486e-01, 5.54947e-01, 1.92320e-01, 4.52075e-02, 4.42886e-02
Node: 12 (pos: 0.121): 5.02330e-01, 5.87632e-01, 5.99692e-01, 1.95890e-01, 4.57851e-02, 4.57256e-02

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.14167e-01, 4.26933e-02, 3.12193e-02, 8.15671e-01, 9.91579e-01, 9.91419e-01
Node: 01 (pos: 0.010): 1.25233e-01, 7.21779e-02, 5.13704e-02, 8.21697e-01, 9.91789e-01, 9.91947e-01
Node: 02 (pos: 0.020): 1.37139e-01, 1.17042e-01, 8.20814e-02, 8.27616e-01, 9.91998e-01, 9.92463e-01
Node: 03 (pos: 0.030): 1.49908e-01, 1.80107e-01, 1.26188e-01, 8.33426e-01, 9.92207e-01, 9.92963e-01
Node: 04 (pos: 0.040): 1.63555e-01, 2.61360e-01, 1.85413e-01, 8.39127e-01, 9.92414e-01, 9.93447e-01
Node: 05 (pos: 0.051): 1.78089e-01, 3.57047e-01, 2.59411e-01, 8.44715e-01, 9.92619e-01, 9.93914e-01
-
Node: 07 (pos: 0.071): 1.78089e-01, 3.57047e-01, 2.59411e-01, 8.44715e-01, 9.92619e-01, 9.93914e-01
Node: 08 (pos: 0.081): 1.63555e-01, 2.61360e-01, 1.85413e-01, 8.39127e-01, 9.92414e-01, 9.93447e-01
Node: 09 (pos: 0.091): 1.49908e-01, 1.80107e-01, 1.26188e-01, 8.33426e-01, 9.92207e-01, 9.92963e-01
Node: 10 (pos: 0.101): 1.37139e-01, 1.17042e-01, 8.20814e-02, 8.27616e-01, 9.91998e-01, 9.92463e-01
Node: 11 (pos: 0.111): 1.25233e-01, 7.21779e-02, 5.13704e-02, 8.21697e-01, 9.91789e-01, 9.91947e-01
Node: 12 (pos: 0.121): 1.14167e-01, 4.26933e-02, 3.12193e-02, 8.15671e-01, 9.91579e-01, 9.91419e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.47923e-01, 3.35807e-01, 3.74136e-01, 1.78279e-01, 4.28520e-02, 3.84833e-02
Node: 01 (pos: 0.010): 4.58841e-01, 3.83308e-01, 4.18110e-01, 1.81751e-01, 4.34468e-02, 3.99360e-02
Node: 02 (pos: 0.020): 4.69751e-01, 4.33237e-01, 4.63396e-01, 1.85249e-01, 4.40379e-02, 4.13901e-02
Node: 03 (pos: 0.030): 4.80643e-01, 4.84652e-01, 5.09264e-01, 1.88772e-01, 4.46249e-02, 4.28422e-02
Node: 04 (pos: 0.040): 4.91506e-01, 5.36486e-01, 5.54947e-01, 1.92320e-01, 4.52075e-02, 4.42886e-02
Node: 05 (pos: 0.051): 5.02330e-01, 5.87632e-01, 5.99692e-01, 1.95890e-01, 4.57851e-02, 4.57256e-02
-
Node: 07 (pos: 0.071): 4.91506e-01, 5.36486e-01, 5.54947e-01, 1.92320e-01, 4.52075e-02, 4.42886e-02
Node: 08 (pos: 0.081): 4.80643e-01, 4.84652e-01, 5.09264e-01, 1.88772e-01, 4.46249e-02, 4.28422e-02
Node: 09 (pos: 0.091): 4.69751e-01, 4.33237e-01, 4.63396e-01, 1.85249e-01, 4.40379e-02, 4.13901e-02
Node: 10 (pos: 0.101): 4.58841e-01, 3.83308e-01, 4.18110e-01, 1.81751e-01, 4.34468e-02, 3.99360e-02
Node: 11 (pos: 0.111): 4.47923e-01, 3.35807e-01, 3.74136e-01, 1.78279e-01, 4.28520e-02, 3.84833e-02
Node: 12 (pos: 0.121): 5.02330e-01, 5.87632e-01, 5.99692e-01, 1.95890e-01, 4.57851e-02, 4.57256e-02

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.78089e-01, 3.57047e-01, 2.59411e-01, 8.44715e-01, 9.92619e-01, 9.93914e-01
Node: 58 (pos: 0.586): 1.63555e-01, 2.61360e-01, 1.85413e-01, 8.39127e-01, 9.92414e-01, 9.93447e-01
Node: 59 (pos: 0.596): 1.49908e-01, 1.80107e-01, 1.26188e-01, 8.33426e-01, 9.92207e-01, 9.92963e-01
Node: 60 (pos: 0.606): 1.37139e-01, 1.17042e-01, 8.20814e-02, 8.27616e-01, 9.91998e-01, 9.92463e-01
Node: 61 (pos: 0.616): 1.25233e-01, 7.21779e-02, 5.13704e-02, 8.21697e-01, 9.91789e-01, 9.91947e-01
Node: 50 (pos: 0.505): 1.14167e-01, 4.26933e-02, 3.12193e-02, 8.15671e-01, 9.91579e-01, 9.91419e-01
-
Node: 51 (pos: 0.515): 1.25233e-01, 7.21779e-02, 5.13704e-02, 8.21697e-01, 9.91789e-01, 9.91947e-01
Node: 52 (pos: 0.525): 1.37139e-01, 1.17042e-01, 8.20814e-02, 8.27616e-01, 9.91998e-01, 9.92463e-01
Node: 53 (pos: 0.535): 1.49908e-01, 1.80107e-01, 1.26188e-01, 8.33426e-01, 9.92207e-01, 9.92963e-01
Node: 54 (pos: 0.545): 1.63555e-01, 2.61360e-01, 1.85413e-01, 8.39127e-01, 9.92414e-01, 9.93447e-01
Node: 55 (pos: 0.556): 1.78089e-01, 3.57047e-01, 2.59411e-01, 8.44715e-01, 9.92619e-01, 9.93914e-01
Node: 62 (pos: 0.626): 1.14167e-01, 4.26933e-02, 3.12193e-02, 8.15671e-01, 9.91579e-01, 9.91419e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.04659186924375602), ('0.bias', 1.0128941361989647), ('2.weight', 0.4071359909643547), ('2.bias', 1.0438200815190668)] 

GNN_Layer 1 gradients:
[('0.weight', 0.020265675766215043), ('0.bias', 1.3852548075023392), ('2.weight', 0.16726913072303837), ('2.bias', 0.6606154396506236)] 

GNN_Layer 2 gradients:
[('0.weight', 0.060205055275387755), ('0.bias', 1.6662340534540077), ('2.weight', 0.23849309853035283), ('2.bias', 0.7601116817987488)] 

GNN_Layer 3 gradients:
[('0.weight', 0.000687982405266064), ('0.bias', 0.014817892886012145), ('2.weight', 0.008190690841929279), ('2.bias', 0.011075438391245904)] 

GNN_Layer 4 gradients:
[('0.weight', 0.0004901652844976944), ('0.bias', 0.009798535195732285), ('2.weight', 0.007025850623621802), ('2.bias', 0.0061905727338693785)] 

GNN_Layer 5 gradients:
[('0.weight', 0.0007506789479509107), ('0.bias', 0.016619513593120618), ('2.weight', 0.010890850474435084), ('2.bias', 0.00968719157881021)] 

Evaluation on test dataset:
Step 25, mean loss 0.07087189805966698
Step 50, mean loss 0.028817224785124516
Step 75, mean loss 0.04959973484382939
Step 100, mean loss 0.06660086024395001
Step 125, mean loss 0.1613838488956816
Step 150, mean loss 0.10160150072760527
Step 175, mean loss 0.15838274423906956
Step 200, mean loss 0.17810614268931657
Step 225, mean loss 0.16893472516123673
Unrolled forward losses 2.5999739668005115
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.18202101010654775, [0.11613233639214493, 0.10952085862979447, 0.103739076404286, 0.1883849386031645, 0.2480590578824247, 0.24237800156628658]
Training Loss (progress: 0.08), 0.18866341355367486, [0.11611807847491842, 0.10910499079903493, 0.1035209190926523, 0.18935364939435334, 0.24954113848145232, 0.2437486406168637]
Training Loss (progress: 0.16), 0.20890393177535527, [0.11621757469309632, 0.10878824743570853, 0.10335910740034934, 0.1901123481256592, 0.25115004532865604, 0.2447433632115059]
Training Loss (progress: 0.24), 0.1966650711880957, [0.11614778506398661, 0.10867956042778552, 0.10316321410617202, 0.1909026528308473, 0.25283368813034496, 0.24634004425286762]
Training Loss (progress: 0.32), 0.19943120064491104, [0.11612276206879969, 0.1083881882269507, 0.10299062237293108, 0.19184958062520815, 0.25442967717768417, 0.24726851586313595]
Training Loss (progress: 0.40), 0.20112652231210532, [0.11622783944331276, 0.1083828417370535, 0.10278989803654758, 0.1924907480403535, 0.25560564002750924, 0.24864292613446692]
Training Loss (progress: 0.48), 0.1704245168796146, [0.11634773581532175, 0.10828758583002634, 0.10260690362356319, 0.1932185731851787, 0.25756446340056066, 0.2500605060962215]
Training Loss (progress: 0.56), 0.22387979458898707, [0.1162064231434137, 0.1079891694912105, 0.10251297517185462, 0.19442623201028653, 0.25914025365333554, 0.2510381453291445]
Training Loss (progress: 0.64), 0.19216753130630781, [0.11631632775132725, 0.10782396331810098, 0.10231197063024747, 0.19522148057630012, 0.26086162909570426, 0.25227823460415655]
Training Loss (progress: 0.72), 0.17992166571235818, [0.1163491141023989, 0.10781041629486382, 0.10211453446843453, 0.19606873526201765, 0.26242064177510377, 0.2536913158034727]
Training Loss (progress: 0.80), 0.19990165394838857, [0.11619768539034642, 0.10762596992639333, 0.1018868823039891, 0.19683301978879444, 0.2642815254003504, 0.2545916612906778]
Training Loss (progress: 0.88), 0.19615437198100433, [0.11613588121474536, 0.10737579348256675, 0.10172005818107246, 0.1977486206896175, 0.26578718288347686, 0.2557693468429238]
Training Loss (progress: 0.96), 0.16728369688407785, [0.116134309111143, 0.10723705741513301, 0.10145363372409515, 0.19913820572485852, 0.26735703582815024, 0.2573969747339504]
Evaluation on validation dataset:
Step 25, mean loss 0.06949317806147978
Step 50, mean loss 0.031443414560930194
Step 75, mean loss 0.04328780520328912
Step 100, mean loss 0.06960437181191434
Step 125, mean loss 0.07605018349057133
Step 150, mean loss 0.0637705560925158
Step 175, mean loss 0.12685109873158598
Step 200, mean loss 0.3268204778160861
Step 225, mean loss 0.27426689620151623
Unrolled forward losses 2.1858039403461618
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.01449e-01, 5.86335e-01, 5.99924e-01, 1.52597e-01, 2.19597e-02, 2.60319e-02
Node: 01 (pos: 0.010): 4.90248e-01, 5.33611e-01, 5.54059e-01, 1.50124e-01, 2.17842e-02, 2.52154e-02
Node: 02 (pos: 0.020): 4.79012e-01, 4.80214e-01, 5.07222e-01, 1.47660e-01, 2.16038e-02, 2.43925e-02
Node: 03 (pos: 0.030): 4.67751e-01, 4.27354e-01, 4.60226e-01, 1.45206e-01, 2.14187e-02, 2.35655e-02
Node: 04 (pos: 0.040): 4.56478e-01, 3.76188e-01, 4.13896e-01, 1.42763e-01, 2.12289e-02, 2.27364e-02
Node: 05 (pos: 0.051): 4.45205e-01, 3.27723e-01, 3.69011e-01, 1.40330e-01, 2.10348e-02, 2.19074e-02
-
Node: 07 (pos: 0.071): 4.45205e-01, 3.27723e-01, 3.69011e-01, 1.40330e-01, 2.10348e-02, 2.19074e-02
Node: 08 (pos: 0.081): 4.56478e-01, 3.76188e-01, 4.13896e-01, 1.42763e-01, 2.12289e-02, 2.27364e-02
Node: 09 (pos: 0.091): 4.67751e-01, 4.27354e-01, 4.60226e-01, 1.45206e-01, 2.14187e-02, 2.35655e-02
Node: 10 (pos: 0.101): 4.79012e-01, 4.80214e-01, 5.07222e-01, 1.47660e-01, 2.16038e-02, 2.43925e-02
Node: 11 (pos: 0.111): 4.90248e-01, 5.33611e-01, 5.54059e-01, 1.50124e-01, 2.17842e-02, 2.52154e-02
Node: 12 (pos: 0.121): 5.01449e-01, 5.86335e-01, 5.99924e-01, 1.52597e-01, 2.19597e-02, 2.60319e-02

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.14455e-01, 4.03736e-02, 2.86336e-02, 8.89685e-01, 9.98203e-01, 9.97377e-01
Node: 01 (pos: 0.010): 1.25956e-01, 7.00667e-02, 4.82843e-02, 8.93035e-01, 9.98231e-01, 9.97539e-01
Node: 02 (pos: 0.020): 1.38353e-01, 1.16145e-01, 7.88726e-02, 8.96330e-01, 9.98260e-01, 9.97696e-01
Node: 03 (pos: 0.030): 1.51671e-01, 1.81766e-01, 1.23556e-01, 8.99569e-01, 9.98290e-01, 9.97850e-01
Node: 04 (pos: 0.040): 1.65923e-01, 2.66817e-01, 1.84290e-01, 9.02753e-01, 9.98320e-01, 9.97998e-01
Node: 05 (pos: 0.051): 1.81119e-01, 3.66889e-01, 2.60716e-01, 9.05879e-01, 9.98351e-01, 9.98142e-01
-
Node: 07 (pos: 0.071): 1.81119e-01, 3.66889e-01, 2.60716e-01, 9.05879e-01, 9.98351e-01, 9.98142e-01
Node: 08 (pos: 0.081): 1.65923e-01, 2.66817e-01, 1.84290e-01, 9.02753e-01, 9.98320e-01, 9.97998e-01
Node: 09 (pos: 0.091): 1.51671e-01, 1.81766e-01, 1.23556e-01, 8.99569e-01, 9.98290e-01, 9.97850e-01
Node: 10 (pos: 0.101): 1.38353e-01, 1.16145e-01, 7.88726e-02, 8.96330e-01, 9.98260e-01, 9.97696e-01
Node: 11 (pos: 0.111): 1.25956e-01, 7.00667e-02, 4.82843e-02, 8.93035e-01, 9.98231e-01, 9.97539e-01
Node: 12 (pos: 0.121): 1.14455e-01, 4.03736e-02, 2.86336e-02, 8.89685e-01, 9.98203e-01, 9.97377e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.45205e-01, 3.27723e-01, 3.69011e-01, 1.40330e-01, 2.10348e-02, 2.19074e-02
Node: 01 (pos: 0.010): 4.56478e-01, 3.76188e-01, 4.13896e-01, 1.42763e-01, 2.12289e-02, 2.27364e-02
Node: 02 (pos: 0.020): 4.67751e-01, 4.27354e-01, 4.60226e-01, 1.45206e-01, 2.14187e-02, 2.35655e-02
Node: 03 (pos: 0.030): 4.79012e-01, 4.80214e-01, 5.07222e-01, 1.47660e-01, 2.16038e-02, 2.43925e-02
Node: 04 (pos: 0.040): 4.90248e-01, 5.33611e-01, 5.54059e-01, 1.50124e-01, 2.17842e-02, 2.52154e-02
Node: 05 (pos: 0.051): 5.01449e-01, 5.86335e-01, 5.99924e-01, 1.52597e-01, 2.19597e-02, 2.60319e-02
-
Node: 07 (pos: 0.071): 4.90248e-01, 5.33611e-01, 5.54059e-01, 1.50124e-01, 2.17842e-02, 2.52154e-02
Node: 08 (pos: 0.081): 4.79012e-01, 4.80214e-01, 5.07222e-01, 1.47660e-01, 2.16038e-02, 2.43925e-02
Node: 09 (pos: 0.091): 4.67751e-01, 4.27354e-01, 4.60226e-01, 1.45206e-01, 2.14187e-02, 2.35655e-02
Node: 10 (pos: 0.101): 4.56478e-01, 3.76188e-01, 4.13896e-01, 1.42763e-01, 2.12289e-02, 2.27364e-02
Node: 11 (pos: 0.111): 4.45205e-01, 3.27723e-01, 3.69011e-01, 1.40330e-01, 2.10348e-02, 2.19074e-02
Node: 12 (pos: 0.121): 5.01449e-01, 5.86335e-01, 5.99924e-01, 1.52597e-01, 2.19597e-02, 2.60319e-02

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.81119e-01, 3.66889e-01, 2.60716e-01, 9.05879e-01, 9.98351e-01, 9.98142e-01
Node: 58 (pos: 0.586): 1.65923e-01, 2.66817e-01, 1.84290e-01, 9.02753e-01, 9.98320e-01, 9.97998e-01
Node: 59 (pos: 0.596): 1.51671e-01, 1.81766e-01, 1.23556e-01, 8.99569e-01, 9.98290e-01, 9.97850e-01
Node: 60 (pos: 0.606): 1.38353e-01, 1.16145e-01, 7.88726e-02, 8.96330e-01, 9.98260e-01, 9.97696e-01
Node: 61 (pos: 0.616): 1.25956e-01, 7.00667e-02, 4.82843e-02, 8.93035e-01, 9.98231e-01, 9.97539e-01
Node: 50 (pos: 0.505): 1.14455e-01, 4.03736e-02, 2.86336e-02, 8.89685e-01, 9.98203e-01, 9.97377e-01
-
Node: 51 (pos: 0.515): 1.25956e-01, 7.00667e-02, 4.82843e-02, 8.93035e-01, 9.98231e-01, 9.97539e-01
Node: 52 (pos: 0.525): 1.38353e-01, 1.16145e-01, 7.88726e-02, 8.96330e-01, 9.98260e-01, 9.97696e-01
Node: 53 (pos: 0.535): 1.51671e-01, 1.81766e-01, 1.23556e-01, 8.99569e-01, 9.98290e-01, 9.97850e-01
Node: 54 (pos: 0.545): 1.65923e-01, 2.66817e-01, 1.84290e-01, 9.02753e-01, 9.98320e-01, 9.97998e-01
Node: 55 (pos: 0.556): 1.81119e-01, 3.66889e-01, 2.60716e-01, 9.05879e-01, 9.98351e-01, 9.98142e-01
Node: 62 (pos: 0.626): 1.14455e-01, 4.03736e-02, 2.86336e-02, 8.89685e-01, 9.98203e-01, 9.97377e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.019969549044717785), ('0.bias', 0.5621683818295475), ('2.weight', 0.17391096660969305), ('2.bias', 0.5779551724233258)] 

GNN_Layer 1 gradients:
[('0.weight', 0.05059115885385751), ('0.bias', 0.9500377799711692), ('2.weight', 0.19268494072430575), ('2.bias', 0.4423796756298546)] 

GNN_Layer 2 gradients:
[('0.weight', 0.0009355052401018079), ('0.bias', 0.46782468727256254), ('2.weight', 0.042320686322880566), ('2.bias', 0.20867980379661133)] 

GNN_Layer 3 gradients:
[('0.weight', 0.0037516462670322713), ('0.bias', 0.08606864951782114), ('2.weight', 0.04909668184700712), ('2.bias', 0.06177046671113447)] 

GNN_Layer 4 gradients:
[('0.weight', 1.1895279127732003e-05), ('0.bias', 0.0005379330235099988), ('2.weight', 0.00035937738133586943), ('2.bias', 0.00031094943514196037)] 

GNN_Layer 5 gradients:
[('0.weight', 3.6283162792811695e-06), ('0.bias', 0.0016613467255427888), ('2.weight', 0.000991019476523027), ('2.bias', 0.0009015931476857394)] 

Evaluation on test dataset:
Step 25, mean loss 0.056798991448856175
Step 50, mean loss 0.02534339515064902
Step 75, mean loss 0.03387374716693729
Step 100, mean loss 0.045330059354109276
Step 125, mean loss 0.11147100228190672
Step 150, mean loss 0.06896586854780583
Step 175, mean loss 0.14165634632437452
Step 200, mean loss 0.13935505270777598
Step 225, mean loss 0.12005300358862525
Unrolled forward losses 1.9676557778686148
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.1833143122375468, [0.11614607889390471, 0.10702763593633584, 0.10131889341644887, 0.19941904344909528, 0.2684779661731921, 0.258227052559384]
Training Loss (progress: 0.08), 0.18497173583778698, [0.11612561804129845, 0.10710997880809911, 0.10125935394382592, 0.20023982441324878, 0.26995901311907855, 0.25906423967952047]
Training Loss (progress: 0.16), 0.1824445507748107, [0.11609547391966142, 0.10683171533704922, 0.10107071468333433, 0.20081318656175148, 0.271293444265883, 0.26033495709259]
Training Loss (progress: 0.24), 0.16930477567635063, [0.11602883967312805, 0.10685488171558583, 0.10090985728847934, 0.20172092317577126, 0.2730846722793042, 0.26122383856505155]
Training Loss (progress: 0.32), 0.18252618800524426, [0.1159792116734459, 0.10658898444962428, 0.10074695816587996, 0.20261013041179413, 0.2747797463632616, 0.2622463230639325]
Training Loss (progress: 0.40), 0.16806528444845403, [0.11624572212285511, 0.10635954011071694, 0.10040082199819107, 0.20334368658055763, 0.27621404877347244, 0.2631046094964615]
Training Loss (progress: 0.48), 0.18180739185219438, [0.11617627511803282, 0.10611731841322772, 0.10029599098992092, 0.20450534964275544, 0.2780091330393717, 0.2644484929499524]
Training Loss (progress: 0.56), 0.16932650937423932, [0.11617231938465328, 0.10603646014574489, 0.10007695842538873, 0.20531463115615492, 0.27952889100292105, 0.26557966276850814]
Training Loss (progress: 0.64), 0.18189169564700694, [0.1159508680873076, 0.10610408351713742, 0.0999844350046245, 0.20621692759188112, 0.2809410426373656, 0.26682313132123797]
Training Loss (progress: 0.72), 0.15283470671717056, [0.11613293027121711, 0.10598499420028794, 0.09977279144381886, 0.20732280077884196, 0.28296959488150164, 0.2680784051588474]
Training Loss (progress: 0.80), 0.16965123262015772, [0.11599759502562845, 0.10572741210114564, 0.09968173224330559, 0.20775258571216376, 0.2839826203745805, 0.2688029995198098]
Training Loss (progress: 0.88), 0.17214300171212474, [0.11605990217697777, 0.10565010452215438, 0.09937204578550944, 0.20824512700130124, 0.2853792262330557, 0.27011469446111014]
Training Loss (progress: 0.96), 0.17313491125318128, [0.11613620828433281, 0.10520852432810614, 0.09930305008510601, 0.20953486110321004, 0.2869946174580942, 0.270778199754016]
Evaluation on validation dataset:
Step 25, mean loss 0.06268719099649994
Step 50, mean loss 0.03197833419622109
Step 75, mean loss 0.042087041677918414
Step 100, mean loss 0.05215091360425589
Step 125, mean loss 0.06462644514005184
Step 150, mean loss 0.054837712956257736
Step 175, mean loss 0.09700641505954455
Step 200, mean loss 0.2965714824149916
Step 225, mean loss 0.24811583755727695
Unrolled forward losses 2.660358505973004
Unrolled forward base losses 2.565701273852575
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.1413875961500641, [0.11605198495922252, 0.10538846492019174, 0.09916297937116623, 0.21010945386250815, 0.2878820666284233, 0.2715571148033901]
Training Loss (progress: 0.08), 0.1539913043352522, [0.11596857131592885, 0.1052706087170111, 0.09917203219285071, 0.2106314267354351, 0.28853256016361073, 0.27238315029437593]
Training Loss (progress: 0.16), 0.15026264421729615, [0.11604218171814569, 0.10523678144154816, 0.0990934755503106, 0.21099451692886573, 0.28969164858189994, 0.2730416538234072]
Training Loss (progress: 0.24), 0.13544010484452162, [0.11606796993431691, 0.10526590793457075, 0.09901819419760036, 0.2117913912364317, 0.29065587155016787, 0.2737403985653231]
Training Loss (progress: 0.32), 0.15471318347371493, [0.11606943542925251, 0.10519755384597528, 0.09900258854244437, 0.21220555891167148, 0.29155863851981345, 0.27449982236967374]
Training Loss (progress: 0.40), 0.1496989229903045, [0.11606854230891177, 0.10516438782219738, 0.09895956753907233, 0.21276103995491488, 0.29249657922559397, 0.27502300100234306]
Training Loss (progress: 0.48), 0.13631015033107893, [0.11605928427425476, 0.10509781004818994, 0.09887400169452241, 0.21323089729612066, 0.2933916834619794, 0.27574162248307266]
Training Loss (progress: 0.56), 0.1756899592109573, [0.1160190763449951, 0.10495247788777101, 0.09884640634900009, 0.21380162880385095, 0.2938948388554918, 0.27636965017124865]
Training Loss (progress: 0.64), 0.14325286905333076, [0.11603164147198948, 0.10491397386838407, 0.09880585855069973, 0.21435559908415958, 0.2946307675610355, 0.2770811648938368]
Training Loss (progress: 0.72), 0.15327302840611026, [0.11604243176721873, 0.1049098683253469, 0.09873725908602961, 0.21474865400981535, 0.29549377234196117, 0.27758194182105367]
Training Loss (progress: 0.80), 0.14420033880191102, [0.1160765334759639, 0.1049089303648333, 0.09870266221599923, 0.21533519087670974, 0.2963648406025824, 0.2782198528168738]
Training Loss (progress: 0.88), 0.13432321623321877, [0.11605369004691386, 0.10480243991293854, 0.0985826779530548, 0.21571967755436555, 0.2970293035222932, 0.27878485413878706]
Training Loss (progress: 0.96), 0.12919307439565433, [0.1160143459408024, 0.10481945681950271, 0.0985617408781996, 0.216103828528479, 0.2978930918186177, 0.27918959649350444]
Evaluation on validation dataset:
Step 25, mean loss 0.048320661042031365
Step 50, mean loss 0.022449240127722467
Step 75, mean loss 0.03902681038530803
Step 100, mean loss 0.04621527910365608
Step 125, mean loss 0.06049782104347943
Step 150, mean loss 0.04914957945809331
Step 175, mean loss 0.09465932714838853
Step 200, mean loss 0.2640767154862362
Step 225, mean loss 0.27019640487008617
Unrolled forward losses 2.0144819803332883
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.97889e-01, 5.78843e-01, 5.96073e-01, 9.67473e-02, 6.24762e-03, 1.08985e-02
Node: 01 (pos: 0.010): 4.86389e-01, 5.24676e-01, 5.49089e-01, 9.54849e-02, 6.24946e-03, 1.05619e-02
Node: 02 (pos: 0.020): 4.74860e-01, 4.70009e-01, 5.01177e-01, 9.42192e-02, 6.24928e-03, 1.02219e-02
Node: 03 (pos: 0.030): 4.63314e-01, 4.16137e-01, 4.53210e-01, 9.29506e-02, 6.24710e-03, 9.87945e-03
Node: 04 (pos: 0.040): 4.51764e-01, 3.64277e-01, 4.06063e-01, 9.16794e-02, 6.24291e-03, 9.53560e-03
Node: 05 (pos: 0.051): 4.40222e-01, 3.15464e-01, 3.60554e-01, 9.04060e-02, 6.23673e-03, 9.19127e-03
-
Node: 07 (pos: 0.071): 4.40222e-01, 3.15464e-01, 3.60554e-01, 9.04060e-02, 6.23673e-03, 9.19127e-03
Node: 08 (pos: 0.081): 4.51764e-01, 3.64277e-01, 4.06063e-01, 9.16794e-02, 6.24291e-03, 9.53560e-03
Node: 09 (pos: 0.091): 4.63314e-01, 4.16137e-01, 4.53210e-01, 9.29506e-02, 6.24710e-03, 9.87945e-03
Node: 10 (pos: 0.101): 4.74860e-01, 4.70009e-01, 5.01177e-01, 9.42192e-02, 6.24928e-03, 1.02219e-02
Node: 11 (pos: 0.111): 4.86389e-01, 5.24676e-01, 5.49089e-01, 9.54849e-02, 6.24946e-03, 1.05619e-02
Node: 12 (pos: 0.121): 4.97889e-01, 5.78843e-01, 5.96073e-01, 9.67473e-02, 6.24762e-03, 1.08985e-02

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.18055e-01, 4.09023e-02, 2.71752e-02, 9.57701e-01, 9.99869e-01, 9.99575e-01
Node: 01 (pos: 0.010): 1.30153e-01, 7.23453e-02, 4.69129e-02, 9.58775e-01, 9.99869e-01, 9.99601e-01
Node: 02 (pos: 0.020): 1.43199e-01, 1.21537e-01, 7.81719e-02, 9.59838e-01, 9.99869e-01, 9.99626e-01
Node: 03 (pos: 0.030): 1.57212e-01, 1.91649e-01, 1.24394e-01, 9.60891e-01, 9.99869e-01, 9.99651e-01
Node: 04 (pos: 0.040): 1.72206e-01, 2.81964e-01, 1.87646e-01, 9.61933e-01, 9.99869e-01, 9.99675e-01
Node: 05 (pos: 0.051): 1.88184e-01, 3.86961e-01, 2.67357e-01, 9.62964e-01, 9.99870e-01, 9.99698e-01
-
Node: 07 (pos: 0.071): 1.88184e-01, 3.86961e-01, 2.67357e-01, 9.62964e-01, 9.99870e-01, 9.99698e-01
Node: 08 (pos: 0.081): 1.72206e-01, 2.81964e-01, 1.87646e-01, 9.61933e-01, 9.99869e-01, 9.99675e-01
Node: 09 (pos: 0.091): 1.57212e-01, 1.91649e-01, 1.24394e-01, 9.60891e-01, 9.99869e-01, 9.99651e-01
Node: 10 (pos: 0.101): 1.43199e-01, 1.21537e-01, 7.81719e-02, 9.59838e-01, 9.99869e-01, 9.99626e-01
Node: 11 (pos: 0.111): 1.30153e-01, 7.23453e-02, 4.69129e-02, 9.58775e-01, 9.99869e-01, 9.99601e-01
Node: 12 (pos: 0.121): 1.18055e-01, 4.09023e-02, 2.71752e-02, 9.57701e-01, 9.99869e-01, 9.99575e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.40222e-01, 3.15464e-01, 3.60554e-01, 9.04060e-02, 6.23673e-03, 9.19127e-03
Node: 01 (pos: 0.010): 4.51764e-01, 3.64277e-01, 4.06063e-01, 9.16794e-02, 6.24291e-03, 9.53560e-03
Node: 02 (pos: 0.020): 4.63314e-01, 4.16137e-01, 4.53210e-01, 9.29506e-02, 6.24710e-03, 9.87945e-03
Node: 03 (pos: 0.030): 4.74860e-01, 4.70009e-01, 5.01177e-01, 9.42192e-02, 6.24928e-03, 1.02219e-02
Node: 04 (pos: 0.040): 4.86389e-01, 5.24676e-01, 5.49089e-01, 9.54849e-02, 6.24946e-03, 1.05619e-02
Node: 05 (pos: 0.051): 4.97889e-01, 5.78843e-01, 5.96073e-01, 9.67473e-02, 6.24762e-03, 1.08985e-02
-
Node: 07 (pos: 0.071): 4.86389e-01, 5.24676e-01, 5.49089e-01, 9.54849e-02, 6.24946e-03, 1.05619e-02
Node: 08 (pos: 0.081): 4.74860e-01, 4.70009e-01, 5.01177e-01, 9.42192e-02, 6.24928e-03, 1.02219e-02
Node: 09 (pos: 0.091): 4.63314e-01, 4.16137e-01, 4.53210e-01, 9.29506e-02, 6.24710e-03, 9.87945e-03
Node: 10 (pos: 0.101): 4.51764e-01, 3.64277e-01, 4.06063e-01, 9.16794e-02, 6.24291e-03, 9.53560e-03
Node: 11 (pos: 0.111): 4.40222e-01, 3.15464e-01, 3.60554e-01, 9.04060e-02, 6.23673e-03, 9.19127e-03
Node: 12 (pos: 0.121): 4.97889e-01, 5.78843e-01, 5.96073e-01, 9.67473e-02, 6.24762e-03, 1.08985e-02

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.88184e-01, 3.86961e-01, 2.67357e-01, 9.62964e-01, 9.99870e-01, 9.99698e-01
Node: 58 (pos: 0.586): 1.72206e-01, 2.81964e-01, 1.87646e-01, 9.61933e-01, 9.99869e-01, 9.99675e-01
Node: 59 (pos: 0.596): 1.57212e-01, 1.91649e-01, 1.24394e-01, 9.60891e-01, 9.99869e-01, 9.99651e-01
Node: 60 (pos: 0.606): 1.43199e-01, 1.21537e-01, 7.81719e-02, 9.59838e-01, 9.99869e-01, 9.99626e-01
Node: 61 (pos: 0.616): 1.30153e-01, 7.23453e-02, 4.69129e-02, 9.58775e-01, 9.99869e-01, 9.99601e-01
Node: 50 (pos: 0.505): 1.18055e-01, 4.09023e-02, 2.71752e-02, 9.57701e-01, 9.99869e-01, 9.99575e-01
-
Node: 51 (pos: 0.515): 1.30153e-01, 7.23453e-02, 4.69129e-02, 9.58775e-01, 9.99869e-01, 9.99601e-01
Node: 52 (pos: 0.525): 1.43199e-01, 1.21537e-01, 7.81719e-02, 9.59838e-01, 9.99869e-01, 9.99626e-01
Node: 53 (pos: 0.535): 1.57212e-01, 1.91649e-01, 1.24394e-01, 9.60891e-01, 9.99869e-01, 9.99651e-01
Node: 54 (pos: 0.545): 1.72206e-01, 2.81964e-01, 1.87646e-01, 9.61933e-01, 9.99869e-01, 9.99675e-01
Node: 55 (pos: 0.556): 1.88184e-01, 3.86961e-01, 2.67357e-01, 9.62964e-01, 9.99870e-01, 9.99698e-01
Node: 62 (pos: 0.626): 1.18055e-01, 4.09023e-02, 2.71752e-02, 9.57701e-01, 9.99869e-01, 9.99575e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.035498606469833216), ('0.bias', 0.7054869729106154), ('2.weight', 0.2969592437328266), ('2.bias', 0.7202544166826195)] 

GNN_Layer 1 gradients:
[('0.weight', 0.0008956221115832911), ('0.bias', 0.32066477151544726), ('2.weight', 0.039686539638821), ('2.bias', 0.14658226104636496)] 

GNN_Layer 2 gradients:
[('0.weight', 0.03576154362971267), ('0.bias', 1.5614792096171624), ('2.weight', 0.1595862170320206), ('2.bias', 0.6844728148269636)] 

GNN_Layer 3 gradients:
[('0.weight', 0.00024946420582234427), ('0.bias', 0.014527409217899195), ('2.weight', 0.008128431764381022), ('2.bias', 0.009794582106388679)] 

GNN_Layer 4 gradients:
[('0.weight', 3.4199679749599263e-06), ('0.bias', 3.857974083921847e-05), ('2.weight', 3.2539587352498786e-05), ('2.bias', 1.9986610384724062e-05)] 

GNN_Layer 5 gradients:
[('0.weight', 1.699134616574112e-06), ('0.bias', 2.5797950456190053e-06), ('2.weight', 8.13998815692246e-06), ('2.bias', 5.903270176622232e-07)] 

Evaluation on test dataset:
Step 25, mean loss 0.03937930303427789
Step 50, mean loss 0.01898816728427069
Step 75, mean loss 0.02794715284213825
Step 100, mean loss 0.035454201704623184
Step 125, mean loss 0.06935134741460398
Step 150, mean loss 0.06033597392287376
Step 175, mean loss 0.08189180117705784
Step 200, mean loss 0.12084365579773691
Step 225, mean loss 0.10104921689132523
Unrolled forward losses 1.6145831719460797
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.144739117184287, [0.11605585508533842, 0.10479490860740318, 0.09851099761905206, 0.21659132881493315, 0.2982203790178946, 0.2794877621853902]
Training Loss (progress: 0.08), 0.13337199307644046, [0.11608992351799824, 0.10473617697716463, 0.09848530622772092, 0.21717834756116233, 0.2992097722004993, 0.280155899738777]
Training Loss (progress: 0.16), 0.14976756796079463, [0.1160523796983756, 0.10457096686668618, 0.0983240363007186, 0.21752786825709525, 0.2999461989456222, 0.28087406340054094]
Training Loss (progress: 0.24), 0.14168477924299674, [0.11604593531358005, 0.10458045064228277, 0.09828817805994193, 0.2183628364989768, 0.3007733864403348, 0.2814867285605977]
Training Loss (progress: 0.32), 0.1519616571580189, [0.11607731573520101, 0.10451743288495066, 0.09823153768314906, 0.21874185644674535, 0.3017200111274399, 0.2820592183018485]
Training Loss (progress: 0.40), 0.15942968754355702, [0.11604285609562137, 0.10455474902983478, 0.09819516386264363, 0.2192874619035537, 0.30253284399565517, 0.2827810967796329]
Training Loss (progress: 0.48), 0.14267361042397692, [0.11613395263361394, 0.10449631800852043, 0.09810410465763517, 0.2198168215193679, 0.30302975003233534, 0.28324766338823926]
Training Loss (progress: 0.56), 0.14984109738250517, [0.11603914113489784, 0.10445441661023233, 0.09806999612064671, 0.2202999478124204, 0.30395072963370096, 0.2836990229300184]
Training Loss (progress: 0.64), 0.13091826910024848, [0.11602788497118852, 0.10435232360276611, 0.09800412075057773, 0.2208501288525568, 0.30478712938182034, 0.28424282444441923]
Training Loss (progress: 0.72), 0.1518943401274716, [0.11611145957899838, 0.10437414012653855, 0.09796786724208152, 0.2213748381386445, 0.30561712449669615, 0.2848201191506697]
Training Loss (progress: 0.80), 0.1339103287077895, [0.1160274602536434, 0.10433172673598215, 0.09793509892713283, 0.22193359323687123, 0.3065191448238644, 0.28546091255561806]
Training Loss (progress: 0.88), 0.14655572225352267, [0.1160167439901082, 0.10436264178461295, 0.09788081588285272, 0.2223468665682212, 0.3074169256184496, 0.28609626897556945]
Training Loss (progress: 0.96), 0.1333693653468021, [0.11605393051393363, 0.104233161214549, 0.09779737114270909, 0.2231526450844725, 0.3081484385835121, 0.28663754909554506]
Evaluation on validation dataset:
Step 25, mean loss 0.04361587344269134
Step 50, mean loss 0.019832119092726874
Step 75, mean loss 0.034594380892520496
Step 100, mean loss 0.04075870080845336
Step 125, mean loss 0.05639679884994092
Step 150, mean loss 0.047630789977332534
Step 175, mean loss 0.08619475184326852
Step 200, mean loss 0.27072275305978744
Step 225, mean loss 0.2623596087144141
Unrolled forward losses 2.0187687947545347
Unrolled forward base losses 2.565701273852575
Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.15097744681479622, [0.11608120693169671, 0.10424849081214715, 0.09781852347419354, 0.22355231085974547, 0.3086031812199581, 0.287046440506521]
Training Loss (progress: 0.08), 0.13840302325451173, [0.11606944838842566, 0.10420707436526522, 0.09774029997319551, 0.2241578720769267, 0.30926401362589306, 0.2875333977010625]
Training Loss (progress: 0.16), 0.13312514427759078, [0.11603783870506258, 0.10412958923416729, 0.09762527130816868, 0.22471719090613063, 0.30990980679204644, 0.2880767563606834]
Training Loss (progress: 0.24), 0.14356459655163717, [0.11603752435466427, 0.10411429674374573, 0.09760942015336818, 0.2251719566679235, 0.3107414004334165, 0.2886346359483681]
Training Loss (progress: 0.32), 0.12647843786061422, [0.1160090338201343, 0.10405624511938284, 0.09751269636734565, 0.2257914258839705, 0.31139407812824843, 0.2891690311634932]
Training Loss (progress: 0.40), 0.1503387433754795, [0.11601752924495357, 0.10400643781116149, 0.09745087888495922, 0.22629104200581485, 0.3121359288209292, 0.2898791526023515]
Training Loss (progress: 0.48), 0.13616813943860678, [0.11602088136594665, 0.10397061362473217, 0.0973870578524583, 0.22684250535737271, 0.3128643364224189, 0.2904121555714509]
Training Loss (progress: 0.56), 0.13855187075712913, [0.11599226842794186, 0.10393906036156672, 0.09734496285628147, 0.22745490142283017, 0.31368990421542775, 0.29103504604309444]
Training Loss (progress: 0.64), 0.13188227425745566, [0.1160043332384922, 0.10390047518252368, 0.09727621131462703, 0.22792318045781998, 0.31443090724136874, 0.2916645240065709]
Training Loss (progress: 0.72), 0.13779459482463152, [0.11593390866395994, 0.10379300388743537, 0.09726523522676617, 0.22855742809237944, 0.31516195958424537, 0.2923551563508643]
Training Loss (progress: 0.80), 0.13543654006791497, [0.11596926655470284, 0.10374467282327375, 0.09719467748347017, 0.22893447020945815, 0.3156697879480409, 0.29277727328789444]
Training Loss (progress: 0.88), 0.14223708836220425, [0.11599826055822665, 0.10374395502762818, 0.09715122887255802, 0.22949331312012308, 0.3165617967646384, 0.29326726769955497]
Training Loss (progress: 0.96), 0.12650519750048028, [0.11593268681192365, 0.10367083770031502, 0.09706743396628566, 0.2298900167409883, 0.3171515569707827, 0.2937953076053692]
Evaluation on validation dataset:
Step 25, mean loss 0.08068802255349487
Step 50, mean loss 0.02900246840724617
Step 75, mean loss 0.04000369694373232
Step 100, mean loss 0.03667717853663474
Step 125, mean loss 0.04915475767641342
Step 150, mean loss 0.041730383095096496
Step 175, mean loss 0.08808591628301288
Step 200, mean loss 0.24873320014140698
Step 225, mean loss 0.26159647848551854
Unrolled forward losses 2.2342207699767824
Unrolled forward base losses 2.565701273852575
Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.14076274682584303, [0.1159676087035751, 0.10373542515192478, 0.09707906589278976, 0.2301049364000908, 0.31731004207536345, 0.29387030098801586]
Training Loss (progress: 0.08), 0.1343519544379339, [0.11601857900909979, 0.10366940158573927, 0.09701536908166254, 0.23070197751259103, 0.318201902140612, 0.2947788774104418]
Training Loss (progress: 0.16), 0.1339415231072191, [0.11592205369700109, 0.10367051627471924, 0.09696024650971458, 0.23135411774863324, 0.31892541966353843, 0.2951972350447077]
Training Loss (progress: 0.24), 0.1472903116497183, [0.11596296308137946, 0.10355831231366637, 0.09696542101022419, 0.23206889264737307, 0.3196836648504794, 0.2956806999671431]
Training Loss (progress: 0.32), 0.1424790016555184, [0.11598950523730726, 0.10344210307291038, 0.09681929447097258, 0.23249693129404667, 0.3202596299555083, 0.29607860913295375]
Training Loss (progress: 0.40), 0.13153897644657922, [0.11593723419638488, 0.10346945549715524, 0.09677555517054569, 0.23313335565716112, 0.32120151142262954, 0.2967279867742333]
Training Loss (progress: 0.48), 0.12281159591811516, [0.11595571233438719, 0.10346288754790453, 0.09668486389180554, 0.23344483652624692, 0.3218113070418106, 0.2974040370626867]
Training Loss (progress: 0.56), 0.14024500094447148, [0.11597183066084761, 0.10335180270426411, 0.09666159855350569, 0.23419675628098116, 0.32249095748176043, 0.29770739126454654]
Training Loss (progress: 0.64), 0.12156218820830578, [0.11597296221248789, 0.10335816258802995, 0.09662317281533557, 0.23454373345325116, 0.32318111344291583, 0.2983751484495078]
Training Loss (progress: 0.72), 0.13724182455745396, [0.11600137344122469, 0.10329366486476003, 0.09654181604183895, 0.23531781043592098, 0.32405731758814593, 0.29900517600107995]
Training Loss (progress: 0.80), 0.13718972848831126, [0.11591741126002399, 0.10324463382493046, 0.09646710553857205, 0.23576555475772715, 0.32456919944195206, 0.29945854556158813]
Training Loss (progress: 0.88), 0.13450548040672533, [0.11582505183293665, 0.10327735761189973, 0.09641129450628846, 0.23647047222364875, 0.3253338244608957, 0.3001226821855551]
Training Loss (progress: 0.96), 0.13340978987119773, [0.11593952866548322, 0.10316605630312496, 0.09639905799628191, 0.23691510467329413, 0.3260889179499349, 0.3006956484087856]
Evaluation on validation dataset:
Step 25, mean loss 0.03714616169485903
Step 50, mean loss 0.01803738477816349
Step 75, mean loss 0.03762090966094936
Step 100, mean loss 0.036864253067229374
Step 125, mean loss 0.046057511166162274
Step 150, mean loss 0.04264001280206605
Step 175, mean loss 0.07507745029793939
Step 200, mean loss 0.2581144716610684
Step 225, mean loss 0.2777185154541616
Unrolled forward losses 1.7242762206909168
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.95475e-01, 5.70325e-01, 5.91627e-01, 5.14268e-02, 1.63991e-03, 4.19574e-03
Node: 01 (pos: 0.010): 4.83531e-01, 5.15304e-01, 5.44131e-01, 5.09612e-02, 1.65487e-03, 4.07272e-03
Node: 02 (pos: 0.020): 4.71564e-01, 4.59993e-01, 4.95782e-01, 5.04883e-02, 1.66937e-03, 3.94788e-03
Node: 03 (pos: 0.030): 4.59587e-01, 4.05732e-01, 4.47477e-01, 5.00083e-02, 1.68342e-03, 3.82160e-03
Node: 04 (pos: 0.040): 4.47614e-01, 3.53757e-01, 4.00109e-01, 4.95214e-02, 1.69699e-03, 3.69426e-03
Node: 05 (pos: 0.051): 4.35660e-01, 3.05095e-01, 3.54505e-01, 4.90277e-02, 1.71009e-03, 3.56625e-03
-
Node: 07 (pos: 0.071): 4.35660e-01, 3.05095e-01, 3.54505e-01, 4.90277e-02, 1.71009e-03, 3.56625e-03
Node: 08 (pos: 0.081): 4.47614e-01, 3.53757e-01, 4.00109e-01, 4.95214e-02, 1.69699e-03, 3.69426e-03
Node: 09 (pos: 0.091): 4.59587e-01, 4.05732e-01, 4.47477e-01, 5.00083e-02, 1.68342e-03, 3.82160e-03
Node: 10 (pos: 0.101): 4.71564e-01, 4.59993e-01, 4.95782e-01, 5.04883e-02, 1.66937e-03, 3.94788e-03
Node: 11 (pos: 0.111): 4.83531e-01, 5.15304e-01, 5.44131e-01, 5.09612e-02, 1.65487e-03, 4.07272e-03
Node: 12 (pos: 0.121): 4.95475e-01, 5.70325e-01, 5.91627e-01, 5.14268e-02, 1.63991e-03, 4.19574e-03

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.20265e-01, 4.27114e-02, 2.65124e-02, 9.88915e-01, 9.99992e-01, 9.99941e-01
Node: 01 (pos: 0.010): 1.33031e-01, 7.62130e-02, 4.63897e-02, 9.89114e-01, 9.99992e-01, 9.99945e-01
Node: 02 (pos: 0.020): 1.46818e-01, 1.28572e-01, 7.81417e-02, 9.89314e-01, 9.99991e-01, 9.99948e-01
Node: 03 (pos: 0.030): 1.61647e-01, 2.02731e-01, 1.25346e-01, 9.89515e-01, 9.99991e-01, 9.99951e-01
Node: 04 (pos: 0.040): 1.77527e-01, 2.97246e-01, 1.90084e-01, 9.89717e-01, 9.99991e-01, 9.99955e-01
Node: 05 (pos: 0.051): 1.94458e-01, 4.05602e-01, 2.71611e-01, 9.89920e-01, 9.99991e-01, 9.99958e-01
-
Node: 07 (pos: 0.071): 1.94458e-01, 4.05602e-01, 2.71611e-01, 9.89920e-01, 9.99991e-01, 9.99958e-01
Node: 08 (pos: 0.081): 1.77527e-01, 2.97246e-01, 1.90084e-01, 9.89717e-01, 9.99991e-01, 9.99955e-01
Node: 09 (pos: 0.091): 1.61647e-01, 2.02731e-01, 1.25346e-01, 9.89515e-01, 9.99991e-01, 9.99951e-01
Node: 10 (pos: 0.101): 1.46818e-01, 1.28572e-01, 7.81417e-02, 9.89314e-01, 9.99991e-01, 9.99948e-01
Node: 11 (pos: 0.111): 1.33031e-01, 7.62130e-02, 4.63897e-02, 9.89114e-01, 9.99992e-01, 9.99945e-01
Node: 12 (pos: 0.121): 1.20265e-01, 4.27114e-02, 2.65124e-02, 9.88915e-01, 9.99992e-01, 9.99941e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.35660e-01, 3.05095e-01, 3.54505e-01, 4.90277e-02, 1.71009e-03, 3.56625e-03
Node: 01 (pos: 0.010): 4.47614e-01, 3.53757e-01, 4.00109e-01, 4.95214e-02, 1.69699e-03, 3.69426e-03
Node: 02 (pos: 0.020): 4.59587e-01, 4.05732e-01, 4.47477e-01, 5.00083e-02, 1.68342e-03, 3.82160e-03
Node: 03 (pos: 0.030): 4.71564e-01, 4.59993e-01, 4.95782e-01, 5.04883e-02, 1.66937e-03, 3.94788e-03
Node: 04 (pos: 0.040): 4.83531e-01, 5.15304e-01, 5.44131e-01, 5.09612e-02, 1.65487e-03, 4.07272e-03
Node: 05 (pos: 0.051): 4.95475e-01, 5.70325e-01, 5.91627e-01, 5.14268e-02, 1.63991e-03, 4.19574e-03
-
Node: 07 (pos: 0.071): 4.83531e-01, 5.15304e-01, 5.44131e-01, 5.09612e-02, 1.65487e-03, 4.07272e-03
Node: 08 (pos: 0.081): 4.71564e-01, 4.59993e-01, 4.95782e-01, 5.04883e-02, 1.66937e-03, 3.94788e-03
Node: 09 (pos: 0.091): 4.59587e-01, 4.05732e-01, 4.47477e-01, 5.00083e-02, 1.68342e-03, 3.82160e-03
Node: 10 (pos: 0.101): 4.47614e-01, 3.53757e-01, 4.00109e-01, 4.95214e-02, 1.69699e-03, 3.69426e-03
Node: 11 (pos: 0.111): 4.35660e-01, 3.05095e-01, 3.54505e-01, 4.90277e-02, 1.71009e-03, 3.56625e-03
Node: 12 (pos: 0.121): 4.95475e-01, 5.70325e-01, 5.91627e-01, 5.14268e-02, 1.63991e-03, 4.19574e-03

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.94458e-01, 4.05602e-01, 2.71611e-01, 9.89920e-01, 9.99991e-01, 9.99958e-01
Node: 58 (pos: 0.586): 1.77527e-01, 2.97246e-01, 1.90084e-01, 9.89717e-01, 9.99991e-01, 9.99955e-01
Node: 59 (pos: 0.596): 1.61647e-01, 2.02731e-01, 1.25346e-01, 9.89515e-01, 9.99991e-01, 9.99951e-01
Node: 60 (pos: 0.606): 1.46818e-01, 1.28572e-01, 7.81417e-02, 9.89314e-01, 9.99991e-01, 9.99948e-01
Node: 61 (pos: 0.616): 1.33031e-01, 7.62130e-02, 4.63897e-02, 9.89114e-01, 9.99992e-01, 9.99945e-01
Node: 50 (pos: 0.505): 1.20265e-01, 4.27114e-02, 2.65124e-02, 9.88915e-01, 9.99992e-01, 9.99941e-01
-
Node: 51 (pos: 0.515): 1.33031e-01, 7.62130e-02, 4.63897e-02, 9.89114e-01, 9.99992e-01, 9.99945e-01
Node: 52 (pos: 0.525): 1.46818e-01, 1.28572e-01, 7.81417e-02, 9.89314e-01, 9.99991e-01, 9.99948e-01
Node: 53 (pos: 0.535): 1.61647e-01, 2.02731e-01, 1.25346e-01, 9.89515e-01, 9.99991e-01, 9.99951e-01
Node: 54 (pos: 0.545): 1.77527e-01, 2.97246e-01, 1.90084e-01, 9.89717e-01, 9.99991e-01, 9.99955e-01
Node: 55 (pos: 0.556): 1.94458e-01, 4.05602e-01, 2.71611e-01, 9.89920e-01, 9.99991e-01, 9.99958e-01
Node: 62 (pos: 0.626): 1.20265e-01, 4.27114e-02, 2.65124e-02, 9.88915e-01, 9.99992e-01, 9.99941e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.08629176565319799), ('0.bias', 1.963690806114997), ('2.weight', 0.7108882302370233), ('2.bias', 1.9884126021335424)] 

GNN_Layer 1 gradients:
[('0.weight', 0.06192785649780981), ('0.bias', 2.233634387534952), ('2.weight', 0.2968312468985454), ('2.bias', 1.00764064732656)] 

GNN_Layer 2 gradients:
[('0.weight', 0.50801248504861), ('0.bias', 10.812508861202161), ('2.weight', 1.6946942549831627), ('2.bias', 4.702583709133901)] 

GNN_Layer 3 gradients:
[('0.weight', 0.0005080503654337655), ('0.bias', 0.000554681838883152), ('2.weight', 0.0025295683231872047), ('2.bias', 0.00019537782926197034)] 

GNN_Layer 4 gradients:
[('0.weight', 8.848967395913936e-08), ('0.bias', 1.2080004262649604e-06), ('2.weight', 8.938855131547829e-07), ('2.bias', 5.605986961844132e-07)] 

GNN_Layer 5 gradients:
[('0.weight', 9.650003954141584e-06), ('0.bias', 0.00021975498068988838), ('2.weight', 0.00015592652984083226), ('2.bias', 0.00010303449268348841)] 

Evaluation on test dataset:
Step 25, mean loss 0.03127775475797375
Step 50, mean loss 0.014864273160979886
Step 75, mean loss 0.02641640209350706
Step 100, mean loss 0.036969271870371335
Step 125, mean loss 0.06738636153330192
Step 150, mean loss 0.05164373128842405
Step 175, mean loss 0.06353459633565353
Step 200, mean loss 0.11051616687713359
Step 225, mean loss 0.08333545923264879
Unrolled forward losses 1.5918902459888855
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.13109004558007997, [0.11592352469745425, 0.10315821799985625, 0.09641807777308826, 0.23733262129197508, 0.32658980567632645, 0.3008870773100775]
Training Loss (progress: 0.08), 0.1311562008393802, [0.11589643212471057, 0.10314631115632009, 0.09633531145504544, 0.2379566137193824, 0.32726943228876737, 0.301400199053698]
Training Loss (progress: 0.16), 0.1346386935236589, [0.11595874238794428, 0.10305272317285215, 0.096255958268148, 0.23832103397684046, 0.327743389416971, 0.3018650846636606]
Training Loss (progress: 0.24), 0.13496736861683672, [0.11591856659971164, 0.10304736224150624, 0.09617921135102907, 0.238889212742769, 0.3285017055203503, 0.30247222973263854]
Training Loss (progress: 0.32), 0.1322405792360047, [0.11597603001422682, 0.1028898384772872, 0.09616269657627574, 0.2394184171841888, 0.3291844475595051, 0.3027749406828947]
Training Loss (progress: 0.40), 0.13343068915257655, [0.11597607242216511, 0.10289176543725406, 0.09609034586772881, 0.2398776123667574, 0.3298099443131162, 0.3034247319218047]
Training Loss (progress: 0.48), 0.1437808952825003, [0.11590450171687472, 0.102833555859681, 0.09613923744220744, 0.24041767113865598, 0.3305519479749698, 0.30394797994539136]
Training Loss (progress: 0.56), 0.11529047442654815, [0.11593756551110158, 0.10291695621045101, 0.09604927251564298, 0.24099341783234732, 0.3311593439137388, 0.30444173429985383]
Training Loss (progress: 0.64), 0.13944689216060757, [0.11594175829542691, 0.10274339658580409, 0.0960002035774189, 0.24150166754743682, 0.33188554308064777, 0.30496586780066537]
Training Loss (progress: 0.72), 0.14067324653086194, [0.11589334243399703, 0.10269746290374297, 0.09591503847449893, 0.24210477178694192, 0.3325049300952665, 0.3055220516190993]
Training Loss (progress: 0.80), 0.12758087215611186, [0.11593826272074051, 0.10277459838330111, 0.09589196818184624, 0.24284014074836435, 0.3334553585741052, 0.30607362191436105]
Training Loss (progress: 0.88), 0.1307517016056985, [0.11595588886123595, 0.10267184233404589, 0.09584118690877193, 0.24345194398845033, 0.334079863071063, 0.3066003720415912]
Training Loss (progress: 0.96), 0.12319052033331071, [0.1159491349142308, 0.10265273137683298, 0.09573829634331138, 0.243971430466607, 0.33468936358854556, 0.30714797773924046]
Evaluation on validation dataset:
Step 25, mean loss 0.03980096263948638
Step 50, mean loss 0.017354057683652772
Step 75, mean loss 0.03223520527161106
Step 100, mean loss 0.03872478977912544
Step 125, mean loss 0.048689722798587
Step 150, mean loss 0.04353841585776111
Step 175, mean loss 0.08231236166096145
Step 200, mean loss 0.2515138092638181
Step 225, mean loss 0.2359329639298266
Unrolled forward losses 1.8395632074570292
Unrolled forward base losses 2.565701273852575
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00), 0.12941701598835098, [0.11593983064627893, 0.10255336810691275, 0.09575204982280656, 0.2441763227330532, 0.33506229302630436, 0.30746109409676625]
Training Loss (progress: 0.08), 0.11366062894675605, [0.11591716637367869, 0.10253620417660499, 0.09575415147950098, 0.2445434156339124, 0.33553798218215936, 0.3078628790394287]
Training Loss (progress: 0.16), 0.12234744671549257, [0.11593530597917832, 0.10251526582272774, 0.09571934516717374, 0.24491250238881854, 0.33595356041002467, 0.3081560077440788]
Training Loss (progress: 0.24), 0.13225453498780962, [0.1159578183136181, 0.10258942926743662, 0.0956935471555064, 0.24521876370314843, 0.3363047804740844, 0.30848362441087157]
Training Loss (progress: 0.32), 0.11999749858126657, [0.11592742469358594, 0.10250039469487764, 0.09568140777261924, 0.2454882359245788, 0.3367336074642769, 0.3086877382878623]
Training Loss (progress: 0.40), 0.11512672332590997, [0.11592788430431705, 0.10252980520435455, 0.09566900827770956, 0.24578977930601428, 0.3370638820775036, 0.30901690564309414]
Training Loss (progress: 0.48), 0.12519123706960786, [0.1159288028733335, 0.10255426260796356, 0.09564327856474215, 0.24606740240350197, 0.3374402757717202, 0.3092450820230477]
Training Loss (progress: 0.56), 0.12272136436692072, [0.11592891219870255, 0.1025061915836457, 0.09561922111921213, 0.24631614113756142, 0.3377395338839826, 0.3095585132852688]
Training Loss (progress: 0.64), 0.1311581866189282, [0.11595202766835105, 0.10252659003270381, 0.09559879120827122, 0.24654425272106145, 0.3381680614198078, 0.3098122238450919]
Training Loss (progress: 0.72), 0.11988831310784814, [0.11591161111225246, 0.1024810531792156, 0.09557167682437949, 0.24694162715936882, 0.33851662294078605, 0.31015275575454493]
Training Loss (progress: 0.80), 0.12576795105445596, [0.11590947994678781, 0.10246001160842003, 0.09556704926037435, 0.24716752203425224, 0.33889693959595457, 0.31037181811745074]
Training Loss (progress: 0.88), 0.12566367777152304, [0.11594667692193154, 0.10242639107240341, 0.09555336238802219, 0.24752727411486594, 0.3392206820190734, 0.3107164626466961]
Training Loss (progress: 0.96), 0.11540017952788117, [0.11591693584128138, 0.10246864635399418, 0.09554125666417294, 0.2478580089776876, 0.3396408162103918, 0.3110849130500058]
Evaluation on validation dataset:
Step 25, mean loss 0.031057453593710104
Step 50, mean loss 0.015396537921557797
Step 75, mean loss 0.029126095358090794
Step 100, mean loss 0.03242088875704806
Step 125, mean loss 0.043379611729929476
Step 150, mean loss 0.03801537969767509
Step 175, mean loss 0.07225751380577003
Step 200, mean loss 0.2361296889831732
Step 225, mean loss 0.23769184146804606
Unrolled forward losses 1.691993862189595
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.93920e-01, 5.65989e-01, 5.89165e-01, 3.56099e-02, 8.39366e-04, 2.56456e-03
Node: 01 (pos: 0.010): 4.81816e-01, 5.10640e-01, 5.41477e-01, 3.53804e-02, 8.50509e-04, 2.49249e-03
Node: 02 (pos: 0.020): 4.69691e-01, 4.55111e-01, 4.92981e-01, 3.51440e-02, 8.61488e-04, 2.41909e-03
Node: 03 (pos: 0.030): 4.57560e-01, 4.00757e-01, 4.44580e-01, 3.49006e-02, 8.72295e-04, 2.34459e-03
Node: 04 (pos: 0.040): 4.45438e-01, 3.48816e-01, 3.97175e-01, 3.46504e-02, 8.82920e-04, 2.26923e-03
Node: 05 (pos: 0.051): 4.33339e-01, 3.00304e-01, 3.51591e-01, 3.43935e-02, 8.93356e-04, 2.19324e-03
-
Node: 07 (pos: 0.071): 4.33339e-01, 3.00304e-01, 3.51591e-01, 3.43935e-02, 8.93356e-04, 2.19324e-03
Node: 08 (pos: 0.081): 4.45438e-01, 3.48816e-01, 3.97175e-01, 3.46504e-02, 8.82920e-04, 2.26923e-03
Node: 09 (pos: 0.091): 4.57560e-01, 4.00757e-01, 4.44580e-01, 3.49006e-02, 8.72295e-04, 2.34459e-03
Node: 10 (pos: 0.101): 4.69691e-01, 4.55111e-01, 4.92981e-01, 3.51440e-02, 8.61488e-04, 2.41909e-03
Node: 11 (pos: 0.111): 4.81816e-01, 5.10640e-01, 5.41477e-01, 3.53804e-02, 8.50509e-04, 2.49249e-03
Node: 12 (pos: 0.121): 4.93920e-01, 5.65989e-01, 5.89165e-01, 3.56099e-02, 8.39366e-04, 2.56456e-03

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.21886e-01, 4.38694e-02, 2.64274e-02, 9.94901e-01, 9.99998e-01, 9.99979e-01
Node: 01 (pos: 0.010): 1.34960e-01, 7.84777e-02, 4.64685e-02, 9.94966e-01, 9.99998e-01, 9.99980e-01
Node: 02 (pos: 0.020): 1.49084e-01, 1.32451e-01, 7.85622e-02, 9.95033e-01, 9.99998e-01, 9.99981e-01
Node: 03 (pos: 0.030): 1.64277e-01, 2.08564e-01, 1.26327e-01, 9.95102e-01, 9.99998e-01, 9.99982e-01
Node: 04 (pos: 0.040): 1.80547e-01, 3.04977e-01, 1.91821e-01, 9.95171e-01, 9.99998e-01, 9.99983e-01
Node: 05 (pos: 0.051): 1.97891e-01, 4.14709e-01, 2.74192e-01, 9.95243e-01, 9.99998e-01, 9.99985e-01
-
Node: 07 (pos: 0.071): 1.97891e-01, 4.14709e-01, 2.74192e-01, 9.95243e-01, 9.99998e-01, 9.99985e-01
Node: 08 (pos: 0.081): 1.80547e-01, 3.04977e-01, 1.91821e-01, 9.95171e-01, 9.99998e-01, 9.99983e-01
Node: 09 (pos: 0.091): 1.64277e-01, 2.08564e-01, 1.26327e-01, 9.95102e-01, 9.99998e-01, 9.99982e-01
Node: 10 (pos: 0.101): 1.49084e-01, 1.32451e-01, 7.85622e-02, 9.95033e-01, 9.99998e-01, 9.99981e-01
Node: 11 (pos: 0.111): 1.34960e-01, 7.84777e-02, 4.64685e-02, 9.94966e-01, 9.99998e-01, 9.99980e-01
Node: 12 (pos: 0.121): 1.21886e-01, 4.38694e-02, 2.64274e-02, 9.94901e-01, 9.99998e-01, 9.99979e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.33339e-01, 3.00304e-01, 3.51591e-01, 3.43935e-02, 8.93356e-04, 2.19324e-03
Node: 01 (pos: 0.010): 4.45438e-01, 3.48816e-01, 3.97175e-01, 3.46504e-02, 8.82920e-04, 2.26923e-03
Node: 02 (pos: 0.020): 4.57560e-01, 4.00757e-01, 4.44580e-01, 3.49006e-02, 8.72295e-04, 2.34459e-03
Node: 03 (pos: 0.030): 4.69691e-01, 4.55111e-01, 4.92981e-01, 3.51440e-02, 8.61488e-04, 2.41909e-03
Node: 04 (pos: 0.040): 4.81816e-01, 5.10640e-01, 5.41477e-01, 3.53804e-02, 8.50509e-04, 2.49249e-03
Node: 05 (pos: 0.051): 4.93920e-01, 5.65989e-01, 5.89165e-01, 3.56099e-02, 8.39366e-04, 2.56456e-03
-
Node: 07 (pos: 0.071): 4.81816e-01, 5.10640e-01, 5.41477e-01, 3.53804e-02, 8.50509e-04, 2.49249e-03
Node: 08 (pos: 0.081): 4.69691e-01, 4.55111e-01, 4.92981e-01, 3.51440e-02, 8.61488e-04, 2.41909e-03
Node: 09 (pos: 0.091): 4.57560e-01, 4.00757e-01, 4.44580e-01, 3.49006e-02, 8.72295e-04, 2.34459e-03
Node: 10 (pos: 0.101): 4.45438e-01, 3.48816e-01, 3.97175e-01, 3.46504e-02, 8.82920e-04, 2.26923e-03
Node: 11 (pos: 0.111): 4.33339e-01, 3.00304e-01, 3.51591e-01, 3.43935e-02, 8.93356e-04, 2.19324e-03
Node: 12 (pos: 0.121): 4.93920e-01, 5.65989e-01, 5.89165e-01, 3.56099e-02, 8.39366e-04, 2.56456e-03

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.97891e-01, 4.14709e-01, 2.74192e-01, 9.95243e-01, 9.99998e-01, 9.99985e-01
Node: 58 (pos: 0.586): 1.80547e-01, 3.04977e-01, 1.91821e-01, 9.95171e-01, 9.99998e-01, 9.99983e-01
Node: 59 (pos: 0.596): 1.64277e-01, 2.08564e-01, 1.26327e-01, 9.95102e-01, 9.99998e-01, 9.99982e-01
Node: 60 (pos: 0.606): 1.49084e-01, 1.32451e-01, 7.85622e-02, 9.95033e-01, 9.99998e-01, 9.99981e-01
Node: 61 (pos: 0.616): 1.34960e-01, 7.84777e-02, 4.64685e-02, 9.94966e-01, 9.99998e-01, 9.99980e-01
Node: 50 (pos: 0.505): 1.21886e-01, 4.38694e-02, 2.64274e-02, 9.94901e-01, 9.99998e-01, 9.99979e-01
-
Node: 51 (pos: 0.515): 1.34960e-01, 7.84777e-02, 4.64685e-02, 9.94966e-01, 9.99998e-01, 9.99980e-01
Node: 52 (pos: 0.525): 1.49084e-01, 1.32451e-01, 7.85622e-02, 9.95033e-01, 9.99998e-01, 9.99981e-01
Node: 53 (pos: 0.535): 1.64277e-01, 2.08564e-01, 1.26327e-01, 9.95102e-01, 9.99998e-01, 9.99982e-01
Node: 54 (pos: 0.545): 1.80547e-01, 3.04977e-01, 1.91821e-01, 9.95171e-01, 9.99998e-01, 9.99983e-01
Node: 55 (pos: 0.556): 1.97891e-01, 4.14709e-01, 2.74192e-01, 9.95243e-01, 9.99998e-01, 9.99985e-01
Node: 62 (pos: 0.626): 1.21886e-01, 4.38694e-02, 2.64274e-02, 9.94901e-01, 9.99998e-01, 9.99979e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.07371586463267991), ('0.bias', 1.9378736447975595), ('2.weight', 0.6121757426731804), ('2.bias', 1.9561600505521297)] 

GNN_Layer 1 gradients:
[('0.weight', 0.09151420841659755), ('0.bias', 2.565581622383542), ('2.weight', 0.3734653486053221), ('2.bias', 1.1510004291459315)] 

GNN_Layer 2 gradients:
[('0.weight', 0.12344461583601311), ('0.bias', 3.7496682855965657), ('2.weight', 0.44702677839598326), ('2.bias', 1.623220585364749)] 

GNN_Layer 3 gradients:
[('0.weight', 0.00032298032474052625), ('0.bias', 0.009605309850935391), ('2.weight', 0.0062318338884693155), ('2.bias', 0.005748852289539654)] 

GNN_Layer 4 gradients:
[('0.weight', 1.526692535537506e-07), ('0.bias', 4.051881159522682e-06), ('2.weight', 2.9763229798409943e-06), ('2.bias', 1.8078766013097161e-06)] 

GNN_Layer 5 gradients:
[('0.weight', 1.0581453146700763e-06), ('0.bias', 5.213569405822142e-06), ('2.weight', 5.229777502041167e-06), ('2.bias', 2.166804499255963e-06)] 

Evaluation on test dataset:
Step 25, mean loss 0.026965667697617428
Step 50, mean loss 0.013176577564976
Step 75, mean loss 0.020963259676218177
Step 100, mean loss 0.027117370260415167
Step 125, mean loss 0.06240718809342804
Step 150, mean loss 0.04507392240529109
Step 175, mean loss 0.06234655408740385
Step 200, mean loss 0.10697363794033121
Step 225, mean loss 0.08047882050354244
Unrolled forward losses 1.4426409408015162
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00), 0.12950889326977535, [0.11595411189736099, 0.10246795503817689, 0.0955279841726089, 0.2479932618134553, 0.33984710443237603, 0.311248743362096]
Training Loss (progress: 0.08), 0.1159084190198787, [0.11594150645623236, 0.1024319907812264, 0.0955048938561324, 0.24828964170270904, 0.34014597371590255, 0.31147808784336856]
Training Loss (progress: 0.16), 0.10815095606867298, [0.11592288184003875, 0.10243126152357267, 0.09549586565258784, 0.24863203683655152, 0.34042068324359515, 0.31173350111094333]
Training Loss (progress: 0.24), 0.11913141919548507, [0.11596168961152419, 0.10240814304890669, 0.09547990100877615, 0.2489712949256935, 0.34080479116007684, 0.31200607574634864]
Training Loss (progress: 0.32), 0.12606144146387138, [0.1159234857454113, 0.1024312898442663, 0.09543443722303795, 0.24927767798526626, 0.341158038274455, 0.31230838900387436]
Training Loss (progress: 0.40), 0.11521961864609621, [0.11592268894540468, 0.10239703670404662, 0.0954202239544476, 0.24952740127968795, 0.34154317966464076, 0.3125175583482853]
Training Loss (progress: 0.48), 0.11977655004048268, [0.1159206754034047, 0.10237752145524147, 0.09542785490125777, 0.24985980665916704, 0.34186565581296724, 0.3128634660776216]
Training Loss (progress: 0.56), 0.1108666586608163, [0.1159572780067019, 0.10237640915968514, 0.09536465544450376, 0.250142552807785, 0.3422228785009701, 0.3130778157757534]
Training Loss (progress: 0.64), 0.11394385901615878, [0.11596062250557658, 0.10234536926649003, 0.09535170319743333, 0.2504104776833905, 0.34254170830046804, 0.313359726577412]
Training Loss (progress: 0.72), 0.1219264346198628, [0.11595666561429736, 0.10235734064775676, 0.09535016297725014, 0.2507475498467687, 0.3429321595409905, 0.3136400154615541]
Training Loss (progress: 0.80), 0.11060312821279232, [0.11593843453599063, 0.10227763002798444, 0.09532469302364766, 0.2509839889746222, 0.3433303710294678, 0.31391949551134063]
Training Loss (progress: 0.88), 0.13162710452476534, [0.11595679132814204, 0.10230192431933346, 0.09530309536686145, 0.2513808308612169, 0.3437161544514679, 0.3142697859165852]
Training Loss (progress: 0.96), 0.11545077955726453, [0.11594494265365961, 0.10230353281176062, 0.09530840030824665, 0.2515962071248749, 0.3439709179163626, 0.31450034218505496]
Evaluation on validation dataset:
Step 25, mean loss 0.030559172814093975
Step 50, mean loss 0.014873746472795843
Step 75, mean loss 0.028894279702730383
Step 100, mean loss 0.03115864217322452
Step 125, mean loss 0.041106497068208125
Step 150, mean loss 0.03586077615394796
Step 175, mean loss 0.06781375115413157
Step 200, mean loss 0.23095019962502678
Step 225, mean loss 0.25445251865268653
Unrolled forward losses 1.5096075615878441
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.93497e-01, 5.64447e-01, 5.88580e-01, 3.12278e-02, 6.77867e-04, 2.18179e-03
Node: 01 (pos: 0.010): 4.81324e-01, 5.09040e-01, 5.40858e-01, 3.10569e-02, 6.87673e-04, 2.12131e-03
Node: 02 (pos: 0.020): 4.69132e-01, 4.53492e-01, 4.92337e-01, 3.08794e-02, 6.97365e-04, 2.05963e-03
Node: 03 (pos: 0.030): 4.56935e-01, 3.99159e-01, 4.43925e-01, 3.06953e-02, 7.06937e-04, 1.99697e-03
Node: 04 (pos: 0.040): 4.44748e-01, 3.47274e-01, 3.96520e-01, 3.05046e-02, 7.16380e-04, 1.93351e-03
Node: 05 (pos: 0.051): 4.32587e-01, 2.98851e-01, 3.50949e-01, 3.03074e-02, 7.25688e-04, 1.86946e-03
-
Node: 07 (pos: 0.071): 4.32587e-01, 2.98851e-01, 3.50949e-01, 3.03074e-02, 7.25688e-04, 1.86946e-03
Node: 08 (pos: 0.081): 4.44748e-01, 3.47274e-01, 3.96520e-01, 3.05046e-02, 7.16380e-04, 1.93351e-03
Node: 09 (pos: 0.091): 4.56935e-01, 3.99159e-01, 4.43925e-01, 3.06953e-02, 7.06937e-04, 1.99697e-03
Node: 10 (pos: 0.101): 4.69132e-01, 4.53492e-01, 4.92337e-01, 3.08794e-02, 6.97365e-04, 2.05963e-03
Node: 11 (pos: 0.111): 4.81324e-01, 5.09040e-01, 5.40858e-01, 3.10569e-02, 6.87673e-04, 2.12131e-03
Node: 12 (pos: 0.121): 4.93497e-01, 5.64447e-01, 5.88580e-01, 3.12278e-02, 6.77867e-04, 2.18179e-03

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.22347e-01, 4.44144e-02, 2.63418e-02, 9.96134e-01, 9.99999e-01, 9.99985e-01
Node: 01 (pos: 0.010): 1.35534e-01, 7.94353e-02, 4.63847e-02, 9.96176e-01, 9.99999e-01, 9.99986e-01
Node: 02 (pos: 0.020): 1.49783e-01, 1.33962e-01, 7.85092e-02, 9.96220e-01, 9.99999e-01, 9.99987e-01
Node: 03 (pos: 0.030): 1.65113e-01, 2.10691e-01, 1.26347e-01, 9.96264e-01, 9.99999e-01, 9.99987e-01
Node: 04 (pos: 0.040): 1.81530e-01, 3.07644e-01, 1.91955e-01, 9.96311e-01, 9.99999e-01, 9.99988e-01
Node: 05 (pos: 0.051): 1.99032e-01, 4.17702e-01, 2.74467e-01, 9.96358e-01, 9.99998e-01, 9.99989e-01
-
Node: 07 (pos: 0.071): 1.99032e-01, 4.17702e-01, 2.74467e-01, 9.96358e-01, 9.99998e-01, 9.99989e-01
Node: 08 (pos: 0.081): 1.81530e-01, 3.07644e-01, 1.91955e-01, 9.96311e-01, 9.99999e-01, 9.99988e-01
Node: 09 (pos: 0.091): 1.65113e-01, 2.10691e-01, 1.26347e-01, 9.96264e-01, 9.99999e-01, 9.99987e-01
Node: 10 (pos: 0.101): 1.49783e-01, 1.33962e-01, 7.85092e-02, 9.96220e-01, 9.99999e-01, 9.99987e-01
Node: 11 (pos: 0.111): 1.35534e-01, 7.94353e-02, 4.63847e-02, 9.96176e-01, 9.99999e-01, 9.99986e-01
Node: 12 (pos: 0.121): 1.22347e-01, 4.44144e-02, 2.63418e-02, 9.96134e-01, 9.99999e-01, 9.99985e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.32587e-01, 2.98851e-01, 3.50949e-01, 3.03074e-02, 7.25688e-04, 1.86946e-03
Node: 01 (pos: 0.010): 4.44748e-01, 3.47274e-01, 3.96520e-01, 3.05046e-02, 7.16380e-04, 1.93351e-03
Node: 02 (pos: 0.020): 4.56935e-01, 3.99159e-01, 4.43925e-01, 3.06953e-02, 7.06937e-04, 1.99697e-03
Node: 03 (pos: 0.030): 4.69132e-01, 4.53492e-01, 4.92337e-01, 3.08794e-02, 6.97365e-04, 2.05963e-03
Node: 04 (pos: 0.040): 4.81324e-01, 5.09040e-01, 5.40858e-01, 3.10569e-02, 6.87673e-04, 2.12131e-03
Node: 05 (pos: 0.051): 4.93497e-01, 5.64447e-01, 5.88580e-01, 3.12278e-02, 6.77867e-04, 2.18179e-03
-
Node: 07 (pos: 0.071): 4.81324e-01, 5.09040e-01, 5.40858e-01, 3.10569e-02, 6.87673e-04, 2.12131e-03
Node: 08 (pos: 0.081): 4.69132e-01, 4.53492e-01, 4.92337e-01, 3.08794e-02, 6.97365e-04, 2.05963e-03
Node: 09 (pos: 0.091): 4.56935e-01, 3.99159e-01, 4.43925e-01, 3.06953e-02, 7.06937e-04, 1.99697e-03
Node: 10 (pos: 0.101): 4.44748e-01, 3.47274e-01, 3.96520e-01, 3.05046e-02, 7.16380e-04, 1.93351e-03
Node: 11 (pos: 0.111): 4.32587e-01, 2.98851e-01, 3.50949e-01, 3.03074e-02, 7.25688e-04, 1.86946e-03
Node: 12 (pos: 0.121): 4.93497e-01, 5.64447e-01, 5.88580e-01, 3.12278e-02, 6.77867e-04, 2.18179e-03

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.99032e-01, 4.17702e-01, 2.74467e-01, 9.96358e-01, 9.99998e-01, 9.99989e-01
Node: 58 (pos: 0.586): 1.81530e-01, 3.07644e-01, 1.91955e-01, 9.96311e-01, 9.99999e-01, 9.99988e-01
Node: 59 (pos: 0.596): 1.65113e-01, 2.10691e-01, 1.26347e-01, 9.96264e-01, 9.99999e-01, 9.99987e-01
Node: 60 (pos: 0.606): 1.49783e-01, 1.33962e-01, 7.85092e-02, 9.96220e-01, 9.99999e-01, 9.99987e-01
Node: 61 (pos: 0.616): 1.35534e-01, 7.94353e-02, 4.63847e-02, 9.96176e-01, 9.99999e-01, 9.99986e-01
Node: 50 (pos: 0.505): 1.22347e-01, 4.44144e-02, 2.63418e-02, 9.96134e-01, 9.99999e-01, 9.99985e-01
-
Node: 51 (pos: 0.515): 1.35534e-01, 7.94353e-02, 4.63847e-02, 9.96176e-01, 9.99999e-01, 9.99986e-01
Node: 52 (pos: 0.525): 1.49783e-01, 1.33962e-01, 7.85092e-02, 9.96220e-01, 9.99999e-01, 9.99987e-01
Node: 53 (pos: 0.535): 1.65113e-01, 2.10691e-01, 1.26347e-01, 9.96264e-01, 9.99999e-01, 9.99987e-01
Node: 54 (pos: 0.545): 1.81530e-01, 3.07644e-01, 1.91955e-01, 9.96311e-01, 9.99999e-01, 9.99988e-01
Node: 55 (pos: 0.556): 1.99032e-01, 4.17702e-01, 2.74467e-01, 9.96358e-01, 9.99998e-01, 9.99989e-01
Node: 62 (pos: 0.626): 1.22347e-01, 4.44144e-02, 2.63418e-02, 9.96134e-01, 9.99999e-01, 9.99985e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.05520425140273726), ('0.bias', 1.1926739522509113), ('2.weight', 0.4479109987667028), ('2.bias', 1.2003368149151048)] 

GNN_Layer 1 gradients:
[('0.weight', 0.03155807021506724), ('0.bias', 1.2261152955174741), ('2.weight', 0.15928403237055355), ('2.bias', 0.5496080966474809)] 

GNN_Layer 2 gradients:
[('0.weight', 0.14450112618503427), ('0.bias', 3.4721897560018764), ('2.weight', 0.4859071350798007), ('2.bias', 1.5028042608767906)] 

GNN_Layer 3 gradients:
[('0.weight', 1.715461062951174e-05), ('0.bias', 0.0021618809576405785), ('2.weight', 0.0013336900306179422), ('2.bias', 0.0012824630883759122)] 

GNN_Layer 4 gradients:
[('0.weight', 6.84758613822783e-08), ('0.bias', 1.445388223667065e-07), ('2.weight', 2.42280133715197e-07), ('2.bias', 5.505720062110366e-08)] 

GNN_Layer 5 gradients:
[('0.weight', 9.593905102026784e-07), ('0.bias', 2.405994478033189e-05), ('2.weight', 1.717095839543433e-05), ('2.bias', 1.0773478882412307e-05)] 

Evaluation on test dataset:
Step 25, mean loss 0.02512923720816451
Step 50, mean loss 0.012663260690076898
Step 75, mean loss 0.019864567983192766
Step 100, mean loss 0.02570354385218567
Step 125, mean loss 0.06467951484626827
Step 150, mean loss 0.04394627781784215
Step 175, mean loss 0.060690186093837244
Step 200, mean loss 0.10540937375409488
Step 225, mean loss 0.0765603317075508
Unrolled forward losses 1.4518472387054135
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00), 0.11182834599031866, [0.11595294972449467, 0.10232389936591645, 0.09526916964180207, 0.25178284091464315, 0.3441041700607224, 0.3145748274170554]
Training Loss (progress: 0.08), 0.12257595692676027, [0.11597142976545069, 0.10230787917567521, 0.09526229134918517, 0.2520616200417266, 0.34450163062778916, 0.31493858121177754]
Training Loss (progress: 0.16), 0.11329385360980151, [0.11592778288507048, 0.10225765299858398, 0.09526061449272374, 0.25237900028989374, 0.3448557749551364, 0.31514980303263457]
Training Loss (progress: 0.24), 0.10955084217221639, [0.11597329293081353, 0.10228588072640246, 0.0951860896590646, 0.25254747576665326, 0.3452938707603327, 0.31540880941615274]
Training Loss (progress: 0.32), 0.11634101211887014, [0.11598408131642993, 0.10223628383987945, 0.09520829934827989, 0.25297662419207106, 0.34564647332482545, 0.31567866378074927]
Training Loss (progress: 0.40), 0.12048590808999055, [0.11593371812780796, 0.10221577608032792, 0.09520868090819697, 0.25319036049840904, 0.34590334701682257, 0.3160168269583343]
Training Loss (progress: 0.48), 0.11754402216821683, [0.11593839765639334, 0.10219791050993948, 0.09516677812170064, 0.25352482412295746, 0.34627413613989944, 0.3163196212079884]
Training Loss (progress: 0.56), 0.11617298858898346, [0.1159571235878478, 0.1021880894319115, 0.09513467959919354, 0.2538446667313146, 0.346716738221763, 0.31652026491010915]
Training Loss (progress: 0.64), 0.11968971212353845, [0.11597603609150385, 0.10221454172935478, 0.09510790676792333, 0.25403422484690513, 0.34702996117150187, 0.31681266520704754]
Training Loss (progress: 0.72), 0.11345757426588678, [0.11596904883645122, 0.10215833999078945, 0.09509923651825598, 0.25430962538673624, 0.34745935270782485, 0.317040317041529]
Training Loss (progress: 0.80), 0.11094407976233865, [0.11595570314042683, 0.10217194480851641, 0.09507769561061455, 0.25461875005384194, 0.3476938320312511, 0.3173765551949119]
Training Loss (progress: 0.88), 0.12624579508259867, [0.11592062982838534, 0.10218180592889381, 0.09506251140413657, 0.25493346947666135, 0.3480439402719991, 0.3177097082382447]
Training Loss (progress: 0.96), 0.11583998925738777, [0.11591677100822304, 0.10214887824292689, 0.09502821265553858, 0.25527186988842276, 0.3484079812062221, 0.31797309224974224]
Evaluation on validation dataset:
Step 25, mean loss 0.028314213765227126
Step 50, mean loss 0.01485619747117689
Step 75, mean loss 0.029762306149863645
Step 100, mean loss 0.028783261703066127
Step 125, mean loss 0.03875229140586489
Step 150, mean loss 0.03667216372426799
Step 175, mean loss 0.07143964327011157
Step 200, mean loss 0.22759539422358013
Step 225, mean loss 0.23573730380548463
Unrolled forward losses 1.5577966523518514
Unrolled forward base losses 2.565701273852575
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00), 0.11431720092423134, [0.11593312927889139, 0.10212839936866057, 0.09504911204620135, 0.2554110288651653, 0.3485560767162354, 0.3181289997156814]
Training Loss (progress: 0.08), 0.11495178458186049, [0.11593016683617521, 0.10211023596906008, 0.0950432378290198, 0.25562250154358684, 0.3488164555821127, 0.3184059918764494]
Training Loss (progress: 0.16), 0.11872036997385645, [0.11594900338871372, 0.10210363242765684, 0.09503849967609033, 0.25589825557775325, 0.3491331706028285, 0.3186627604446166]
Training Loss (progress: 0.24), 0.10577903097559711, [0.11594889887019562, 0.1021393572127138, 0.09499902912731062, 0.2561766718187708, 0.34945773855724843, 0.31888841918858724]
Training Loss (progress: 0.32), 0.12362426650869963, [0.11598978241919457, 0.10209980021916633, 0.09495574532663642, 0.2564377477232569, 0.3497387698246805, 0.31915865217843886]
Training Loss (progress: 0.40), 0.12044175115319004, [0.11597173822931661, 0.10206543689063743, 0.09495170059061737, 0.25670806054215195, 0.3500939697321094, 0.3194425836144189]
Training Loss (progress: 0.48), 0.11253354148656616, [0.1159295349066297, 0.10204247413398046, 0.09494288432051606, 0.2569394881474337, 0.35052918832641367, 0.319727131198419]
Training Loss (progress: 0.56), 0.11663518915428273, [0.11597081440537568, 0.10204824922390793, 0.0949048085020695, 0.25727824031622165, 0.35078874631063306, 0.319934005557101]
Training Loss (progress: 0.64), 0.11054072388614962, [0.11594438439918255, 0.10199987816290847, 0.09490653021935477, 0.2575450314014581, 0.35106582486107396, 0.3202451271566153]
Training Loss (progress: 0.72), 0.10764255321274545, [0.11594371624005247, 0.10197677008339741, 0.0949164251640053, 0.2579112243786316, 0.35142323690429955, 0.3204933499703625]
Training Loss (progress: 0.80), 0.1080177859700575, [0.11594813485872979, 0.10198731444654066, 0.09488265123040382, 0.2582038522641656, 0.3517100698118509, 0.32083212707996084]
Training Loss (progress: 0.88), 0.12127731550215189, [0.11595182007196456, 0.1019664640025705, 0.09485985412976158, 0.2585542336562194, 0.3519259800373574, 0.3210542507766]
Training Loss (progress: 0.96), 0.1129975105672782, [0.11593109962866462, 0.1019403288434052, 0.09482030992246636, 0.25884470916240165, 0.3523685237089923, 0.32129569981067146]
Evaluation on validation dataset:
Step 25, mean loss 0.029982227848923015
Step 50, mean loss 0.01459761373200151
Step 75, mean loss 0.029508101938801323
Step 100, mean loss 0.03017316547332141
Step 125, mean loss 0.03951543199635402
Step 150, mean loss 0.03610262041493012
Step 175, mean loss 0.0693279012246358
Step 200, mean loss 0.2238331599747624
Step 225, mean loss 0.22785022250036233
Unrolled forward losses 1.4894667127337984
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.92619e-01, 5.61875e-01, 5.86887e-01, 2.39736e-02, 4.49153e-04, 1.55781e-03
Node: 01 (pos: 0.010): 4.80315e-01, 5.06285e-01, 5.39104e-01, 2.38904e-02, 4.56590e-04, 1.51612e-03
Node: 02 (pos: 0.020): 4.67994e-01, 4.50621e-01, 4.90555e-01, 2.38015e-02, 4.63976e-04, 1.47348e-03
Node: 03 (pos: 0.030): 4.55671e-01, 3.96244e-01, 4.42148e-01, 2.37068e-02, 4.71307e-04, 1.43003e-03
Node: 04 (pos: 0.040): 4.43361e-01, 3.44392e-01, 3.94781e-01, 2.36062e-02, 4.78576e-04, 1.38592e-03
Node: 05 (pos: 0.051): 4.31079e-01, 2.96067e-01, 3.49278e-01, 2.34999e-02, 4.85779e-04, 1.34128e-03
-
Node: 07 (pos: 0.071): 4.31079e-01, 2.96067e-01, 3.49278e-01, 2.34999e-02, 4.85779e-04, 1.34128e-03
Node: 08 (pos: 0.081): 4.43361e-01, 3.44392e-01, 3.94781e-01, 2.36062e-02, 4.78576e-04, 1.38592e-03
Node: 09 (pos: 0.091): 4.55671e-01, 3.96244e-01, 4.42148e-01, 2.37068e-02, 4.71307e-04, 1.43003e-03
Node: 10 (pos: 0.101): 4.67994e-01, 4.50621e-01, 4.90555e-01, 2.38015e-02, 4.63976e-04, 1.47348e-03
Node: 11 (pos: 0.111): 4.80315e-01, 5.06285e-01, 5.39104e-01, 2.38904e-02, 4.56590e-04, 1.51612e-03
Node: 12 (pos: 0.121): 4.92619e-01, 5.61875e-01, 5.86887e-01, 2.39736e-02, 4.49153e-04, 1.55781e-03

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.23310e-01, 4.51515e-02, 2.64321e-02, 9.97783e-01, 9.99999e-01, 9.99992e-01
Node: 01 (pos: 0.010): 1.36721e-01, 8.08551e-02, 4.66234e-02, 9.97798e-01, 9.99999e-01, 9.99993e-01
Node: 02 (pos: 0.020): 1.51217e-01, 1.36361e-01, 7.89958e-02, 9.97815e-01, 9.99999e-01, 9.99993e-01
Node: 03 (pos: 0.030): 1.66816e-01, 2.14252e-01, 1.27185e-01, 9.97832e-01, 9.99999e-01, 9.99994e-01
Node: 04 (pos: 0.040): 1.83524e-01, 3.12304e-01, 1.93215e-01, 9.97850e-01, 9.99999e-01, 9.99994e-01
Node: 05 (pos: 0.051): 2.01337e-01, 4.23123e-01, 2.76147e-01, 9.97870e-01, 9.99999e-01, 9.99994e-01
-
Node: 07 (pos: 0.071): 2.01337e-01, 4.23123e-01, 2.76147e-01, 9.97870e-01, 9.99999e-01, 9.99994e-01
Node: 08 (pos: 0.081): 1.83524e-01, 3.12304e-01, 1.93215e-01, 9.97850e-01, 9.99999e-01, 9.99994e-01
Node: 09 (pos: 0.091): 1.66816e-01, 2.14252e-01, 1.27185e-01, 9.97832e-01, 9.99999e-01, 9.99994e-01
Node: 10 (pos: 0.101): 1.51217e-01, 1.36361e-01, 7.89958e-02, 9.97815e-01, 9.99999e-01, 9.99993e-01
Node: 11 (pos: 0.111): 1.36721e-01, 8.08551e-02, 4.66234e-02, 9.97798e-01, 9.99999e-01, 9.99993e-01
Node: 12 (pos: 0.121): 1.23310e-01, 4.51515e-02, 2.64321e-02, 9.97783e-01, 9.99999e-01, 9.99992e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.31079e-01, 2.96067e-01, 3.49278e-01, 2.34999e-02, 4.85779e-04, 1.34128e-03
Node: 01 (pos: 0.010): 4.43361e-01, 3.44392e-01, 3.94781e-01, 2.36062e-02, 4.78576e-04, 1.38592e-03
Node: 02 (pos: 0.020): 4.55671e-01, 3.96244e-01, 4.42148e-01, 2.37068e-02, 4.71307e-04, 1.43003e-03
Node: 03 (pos: 0.030): 4.67994e-01, 4.50621e-01, 4.90555e-01, 2.38015e-02, 4.63976e-04, 1.47348e-03
Node: 04 (pos: 0.040): 4.80315e-01, 5.06285e-01, 5.39104e-01, 2.38904e-02, 4.56590e-04, 1.51612e-03
Node: 05 (pos: 0.051): 4.92619e-01, 5.61875e-01, 5.86887e-01, 2.39736e-02, 4.49153e-04, 1.55781e-03
-
Node: 07 (pos: 0.071): 4.80315e-01, 5.06285e-01, 5.39104e-01, 2.38904e-02, 4.56590e-04, 1.51612e-03
Node: 08 (pos: 0.081): 4.67994e-01, 4.50621e-01, 4.90555e-01, 2.38015e-02, 4.63976e-04, 1.47348e-03
Node: 09 (pos: 0.091): 4.55671e-01, 3.96244e-01, 4.42148e-01, 2.37068e-02, 4.71307e-04, 1.43003e-03
Node: 10 (pos: 0.101): 4.43361e-01, 3.44392e-01, 3.94781e-01, 2.36062e-02, 4.78576e-04, 1.38592e-03
Node: 11 (pos: 0.111): 4.31079e-01, 2.96067e-01, 3.49278e-01, 2.34999e-02, 4.85779e-04, 1.34128e-03
Node: 12 (pos: 0.121): 4.92619e-01, 5.61875e-01, 5.86887e-01, 2.39736e-02, 4.49153e-04, 1.55781e-03

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 2.01337e-01, 4.23123e-01, 2.76147e-01, 9.97870e-01, 9.99999e-01, 9.99994e-01
Node: 58 (pos: 0.586): 1.83524e-01, 3.12304e-01, 1.93215e-01, 9.97850e-01, 9.99999e-01, 9.99994e-01
Node: 59 (pos: 0.596): 1.66816e-01, 2.14252e-01, 1.27185e-01, 9.97832e-01, 9.99999e-01, 9.99994e-01
Node: 60 (pos: 0.606): 1.51217e-01, 1.36361e-01, 7.89958e-02, 9.97815e-01, 9.99999e-01, 9.99993e-01
Node: 61 (pos: 0.616): 1.36721e-01, 8.08551e-02, 4.66234e-02, 9.97798e-01, 9.99999e-01, 9.99993e-01
Node: 50 (pos: 0.505): 1.23310e-01, 4.51515e-02, 2.64321e-02, 9.97783e-01, 9.99999e-01, 9.99992e-01
-
Node: 51 (pos: 0.515): 1.36721e-01, 8.08551e-02, 4.66234e-02, 9.97798e-01, 9.99999e-01, 9.99993e-01
Node: 52 (pos: 0.525): 1.51217e-01, 1.36361e-01, 7.89958e-02, 9.97815e-01, 9.99999e-01, 9.99993e-01
Node: 53 (pos: 0.535): 1.66816e-01, 2.14252e-01, 1.27185e-01, 9.97832e-01, 9.99999e-01, 9.99994e-01
Node: 54 (pos: 0.545): 1.83524e-01, 3.12304e-01, 1.93215e-01, 9.97850e-01, 9.99999e-01, 9.99994e-01
Node: 55 (pos: 0.556): 2.01337e-01, 4.23123e-01, 2.76147e-01, 9.97870e-01, 9.99999e-01, 9.99994e-01
Node: 62 (pos: 0.626): 1.23310e-01, 4.51515e-02, 2.64321e-02, 9.97783e-01, 9.99999e-01, 9.99992e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.0007993171440941495), ('0.bias', 0.0235110112936641), ('2.weight', 0.009231159386048219), ('2.bias', 0.023791280544189386)] 

GNN_Layer 1 gradients:
[('0.weight', 0.020999154404940244), ('0.bias', 0.7064604652452772), ('2.weight', 0.09554849716864805), ('2.bias', 0.31568797305208884)] 

GNN_Layer 2 gradients:
[('0.weight', 0.07916580892660004), ('0.bias', 0.4762897559224093), ('2.weight', 0.25261359262283045), ('2.bias', 0.20559833692838814)] 

GNN_Layer 3 gradients:
[('0.weight', 2.9465090725504275e-05), ('0.bias', 0.00023715603801459674), ('2.weight', 0.00019008544657953184), ('2.bias', 0.00013766965365652744)] 

GNN_Layer 4 gradients:
[('0.weight', 2.3789826012299012e-08), ('0.bias', 9.329692930403652e-07), ('2.weight', 7.22112080139721e-07), ('2.bias', 4.0226699821155784e-07)] 

GNN_Layer 5 gradients:
[('0.weight', 4.103915053756788e-07), ('0.bias', 6.054380208997781e-06), ('2.weight', 4.659954970987244e-06), ('2.bias', 2.6634244109755313e-06)] 

Evaluation on test dataset:
Step 25, mean loss 0.026364848398205333
Step 50, mean loss 0.012015670427514658
Step 75, mean loss 0.020291313729708233
Step 100, mean loss 0.025070861900172315
Step 125, mean loss 0.05766141832078559
Step 150, mean loss 0.04250215770996286
Step 175, mean loss 0.055644127968042786
Step 200, mean loss 0.10737508862745615
Step 225, mean loss 0.07735113446108718
Unrolled forward losses 1.3655167414978786
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00), 0.1119948572964103, [0.11597028254010613, 0.10191705144238311, 0.09480179672551818, 0.2589849930661416, 0.352484864175524, 0.32141248674187123]
Training Loss (progress: 0.08), 0.11695636052223427, [0.11593124517449746, 0.10189632100728091, 0.09481121519482257, 0.25923254067076135, 0.3528067919861955, 0.32163898516194145]
Training Loss (progress: 0.16), 0.10710768667551733, [0.11591686794912473, 0.10189512465456876, 0.09475090717406395, 0.2594423454993308, 0.35303819727158336, 0.32193385562316734]
Training Loss (progress: 0.24), 0.11179947113704114, [0.11596958466779017, 0.1018648014140774, 0.09474778044940826, 0.25977529861727794, 0.3534584187826637, 0.3221742354501461]
Training Loss (progress: 0.32), 0.11330287501823805, [0.11600865499102721, 0.10187301440591658, 0.09475763443986794, 0.2600752248956748, 0.3538134482901301, 0.3225375865221811]
Training Loss (progress: 0.40), 0.11743397261489617, [0.1159608617258589, 0.10190597566853077, 0.09472715034866398, 0.260431446153568, 0.3540666847209197, 0.32273613663726713]
Training Loss (progress: 0.48), 0.12089842531865885, [0.11597316362409575, 0.10188471178437049, 0.09471448984143906, 0.26065508541067556, 0.3544514548809848, 0.3230657174039664]
Training Loss (progress: 0.56), 0.11144775728144535, [0.11595361919584589, 0.10187341131701265, 0.09469819712593458, 0.260944984829341, 0.3548154786345289, 0.32336207144808765]
Training Loss (progress: 0.64), 0.11159477953823677, [0.1159613834575927, 0.10184155986973649, 0.09468315257898029, 0.2612170533090184, 0.35510223040622513, 0.32361221231934234]
Training Loss (progress: 0.72), 0.10594435645979053, [0.11596195779053484, 0.10182590675882518, 0.09463970119491191, 0.2614511396366498, 0.3555083295962504, 0.32386453334793036]
Training Loss (progress: 0.80), 0.11723583598154924, [0.1159731818450032, 0.10180255885579298, 0.09464372527451365, 0.2616836724144819, 0.3558211425758859, 0.32412622698435084]
Training Loss (progress: 0.88), 0.11570706029081784, [0.11595377863438687, 0.10180053945377322, 0.09462257077897801, 0.26201638775898295, 0.3561611953728043, 0.32432948817958684]
Training Loss (progress: 0.96), 0.11771616883339087, [0.11596908491771922, 0.10177797500711117, 0.09461569563205458, 0.26237178982616144, 0.3564142020597721, 0.3246583135610471]
Evaluation on validation dataset:
Step 25, mean loss 0.03555695248962676
Step 50, mean loss 0.014799456755925929
Step 75, mean loss 0.030699890105541874
Step 100, mean loss 0.03301312663518751
Step 125, mean loss 0.03970847725635673
Step 150, mean loss 0.03658114550309083
Step 175, mean loss 0.07069867152958548
Step 200, mean loss 0.2215335884027388
Step 225, mean loss 0.2447292412097791
Unrolled forward losses 1.5532915488587196
Unrolled forward base losses 2.565701273852575
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00), 0.11446918940720914, [0.11594330814958799, 0.10175708874243347, 0.09459948218565095, 0.2625248180986761, 0.35661057394531254, 0.3247590525283152]
Training Loss (progress: 0.08), 0.10756336800770148, [0.11597237994917371, 0.10174173089392975, 0.09456390687322898, 0.2626318821684151, 0.3567642187264708, 0.3248870063308608]
Training Loss (progress: 0.16), 0.1050229333728087, [0.1159746779535529, 0.10173695491170259, 0.09456370036909602, 0.26269940810678355, 0.3569130845858459, 0.3250061292550222]
Training Loss (progress: 0.24), 0.12004385634948997, [0.11594053909475106, 0.10173060965373774, 0.09456268815087492, 0.26283726437129323, 0.35710972020703446, 0.32516089534254144]
Training Loss (progress: 0.32), 0.10758107045011024, [0.11596880426262046, 0.10174360150294692, 0.09455371652319097, 0.2629735312155687, 0.3572934371131833, 0.3253013978423324]
Training Loss (progress: 0.40), 0.1102631001110089, [0.11597622243216164, 0.10176361446461173, 0.09456796461655122, 0.26313732797295686, 0.35745218582675775, 0.3253926678334408]
Training Loss (progress: 0.48), 0.10222521882382984, [0.11598940987313472, 0.10175186776476283, 0.09455216084160956, 0.2632819269036927, 0.35763898097893365, 0.32556422898808174]
Training Loss (progress: 0.56), 0.1133635488120152, [0.11595274333319021, 0.10172287627666796, 0.09453393677594349, 0.2634356510349604, 0.3578285932322656, 0.32567020453616713]
Training Loss (progress: 0.64), 0.11718855343623363, [0.11598677685132557, 0.10170836159102745, 0.09455164275772963, 0.2635348713145453, 0.35793475271670144, 0.3258183537115581]
Training Loss (progress: 0.72), 0.1085031882620655, [0.11597218181174153, 0.10169610459389929, 0.0945340477319905, 0.2636726539798898, 0.3581009464837271, 0.32597970330863324]
Training Loss (progress: 0.80), 0.11563027027227472, [0.11596750728476804, 0.10171703433987395, 0.09453288920617592, 0.26380648710756505, 0.3582798117564119, 0.32610870183790347]
Training Loss (progress: 0.88), 0.10813206667023106, [0.11598246376884248, 0.1016928318359463, 0.09452483018665302, 0.26393364294076305, 0.3584056953850727, 0.3262484011191681]
Training Loss (progress: 0.96), 0.1058664122077899, [0.1159947962965187, 0.10170508160987332, 0.09450197330070341, 0.26405342980365487, 0.3585635346914554, 0.3263587545346788]
Evaluation on validation dataset:
Step 25, mean loss 0.026528838556526206
Step 50, mean loss 0.013986216941077535
Step 75, mean loss 0.028324362645785372
Step 100, mean loss 0.02958261612803957
Step 125, mean loss 0.03767857638827919
Step 150, mean loss 0.03528108117208851
Step 175, mean loss 0.06628338032819603
Step 200, mean loss 0.21559573391287024
Step 225, mean loss 0.24761064180642045
Unrolled forward losses 1.5256911269153064
Unrolled forward base losses 2.565701273852575
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00), 0.1160030734116647, [0.11598599363054886, 0.10169679865088697, 0.09452335359174671, 0.264136450774848, 0.35862439340693786, 0.3264156826424078]
Training Loss (progress: 0.08), 0.11414398052909715, [0.11598074694314851, 0.10170529396167687, 0.09450388812466702, 0.26426522277642245, 0.3587730494440053, 0.32654199266861583]
Training Loss (progress: 0.16), 0.10771092731994006, [0.11596368250601097, 0.10169223114197602, 0.09449393897606717, 0.26440551285523795, 0.3589125903253238, 0.32665871765687227]
Training Loss (progress: 0.24), 0.11283792484439514, [0.11597777908337872, 0.10170789795182512, 0.09449417973766228, 0.2645002226688072, 0.3590502833698007, 0.32678345442711104]
Training Loss (progress: 0.32), 0.11001500969739533, [0.11597904648720649, 0.10169943461567554, 0.09449919456193226, 0.2646538015593501, 0.35920472311824486, 0.32688970374204246]
Training Loss (progress: 0.40), 0.10938878736410212, [0.11599293512562127, 0.1016775940653438, 0.09449349170625536, 0.2647888503633814, 0.3593595082694181, 0.32702709115216977]
Training Loss (progress: 0.48), 0.11482006143754894, [0.1159761724546155, 0.10166652901380183, 0.09446048756494223, 0.2649187098220412, 0.35951994730628395, 0.32713120585470357]
Training Loss (progress: 0.56), 0.11639855255987061, [0.11598076223761852, 0.10168259266606554, 0.09447087363877299, 0.2650882139606096, 0.3596629140985598, 0.32726391071030186]
Training Loss (progress: 0.64), 0.11550402893925829, [0.1159781671267072, 0.10164940613713401, 0.09445548344520906, 0.2652079379059707, 0.3597969577022329, 0.3273932586808058]
Training Loss (progress: 0.72), 0.09934528029142783, [0.11597912048568403, 0.10168330140676989, 0.09445501998618246, 0.26531338020531425, 0.35998431195339536, 0.32750992889787783]
Training Loss (progress: 0.80), 0.1098153409098051, [0.11600391222966476, 0.10164833939013006, 0.09443607906341348, 0.26545100153119927, 0.36014649148228894, 0.32760032744295325]
Training Loss (progress: 0.88), 0.10809597245769383, [0.11597423971231088, 0.10167153208160731, 0.0944181638276705, 0.2655477182949119, 0.3602870529286141, 0.3277503217629349]
Training Loss (progress: 0.96), 0.10614075510729074, [0.115974117510733, 0.10164600607954431, 0.09442762255126806, 0.2656913534221476, 0.3604723306850582, 0.327914078338987]
Evaluation on validation dataset:
Step 25, mean loss 0.02478063094271079
Step 50, mean loss 0.013713039744336077
Step 75, mean loss 0.028145765277709428
Step 100, mean loss 0.027075651081100285
Step 125, mean loss 0.03705424394615121
Step 150, mean loss 0.03369091854799547
Step 175, mean loss 0.06668156493242891
Step 200, mean loss 0.21419696865762505
Step 225, mean loss 0.2391278472462453
Unrolled forward losses 1.506811999788576
Unrolled forward base losses 2.565701273852575
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00), 0.1093454788498955, [0.11599486324331583, 0.1016348044407467, 0.09441954922100201, 0.2657407785458201, 0.3605536643311744, 0.3279344163332352]
Training Loss (progress: 0.08), 0.1152579742635503, [0.11599123165391347, 0.10163608458832091, 0.09440534082210639, 0.26590733503716685, 0.3607413202482223, 0.3280575586550128]
Training Loss (progress: 0.16), 0.12000902652970039, [0.11599236604779024, 0.1016095815049445, 0.09441051462932942, 0.2660698061596861, 0.3608869560218907, 0.3281407122123291]
Training Loss (progress: 0.24), 0.10841278952233625, [0.11598492643702948, 0.10163003178555685, 0.09439076647755719, 0.2661506832508982, 0.36100808095643516, 0.32824746520892195]
Training Loss (progress: 0.32), 0.11632382825674054, [0.11598373620370009, 0.10164226661777519, 0.09437773228498783, 0.2662926132063958, 0.3611092082657914, 0.3283688707975287]
Training Loss (progress: 0.40), 0.10294001902045721, [0.11596961271297881, 0.10162440320124712, 0.09438323706849243, 0.2664412112094918, 0.3612842803835378, 0.3284970345962999]
Training Loss (progress: 0.48), 0.11303768001978552, [0.11598497151348702, 0.10162913117725415, 0.09438021736954827, 0.26654587023261717, 0.36145871888542075, 0.32864173856487067]
Training Loss (progress: 0.56), 0.10786397678362915, [0.11598863751945084, 0.10161678402520491, 0.09437468797482584, 0.2667091358306324, 0.3616197957234119, 0.32873198333111353]
Training Loss (progress: 0.64), 0.11388166197380002, [0.11599455912057997, 0.10162861879602275, 0.09437418162487927, 0.26681603974031265, 0.3617470501273733, 0.32887390854979476]
Training Loss (progress: 0.72), 0.10106820959430346, [0.1159879209026419, 0.1016287941199616, 0.09435815582298529, 0.26685600038258156, 0.3618739193083774, 0.32896948301949125]
Training Loss (progress: 0.80), 0.10542065671565012, [0.11598033186555255, 0.10164638179107988, 0.09437292739564086, 0.26699537024613545, 0.3620033161132126, 0.32914212766955725]
Training Loss (progress: 0.88), 0.10417111688305081, [0.11601071774190753, 0.101628543395718, 0.09435183935307168, 0.2671440813650108, 0.36216503474339584, 0.32925339858812613]
Training Loss (progress: 0.96), 0.10785586298988309, [0.11602943683304927, 0.10161235018269256, 0.09433291559873716, 0.26731000944407696, 0.3623291370649738, 0.32937319225729533]
Evaluation on validation dataset:
Step 25, mean loss 0.025420856989657858
Step 50, mean loss 0.01391628711321829
Step 75, mean loss 0.028991283033021335
Step 100, mean loss 0.027958989794295567
Step 125, mean loss 0.03665460232510624
Step 150, mean loss 0.03405688799640898
Step 175, mean loss 0.07006910072209925
Step 200, mean loss 0.2129237695420951
Step 225, mean loss 0.23478432115848732
Unrolled forward losses 1.5137144056921172
Unrolled forward base losses 2.565701273852575
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00), 0.11024646801660715, [0.11600923516325498, 0.10159557761901829, 0.09433488855538227, 0.26741487058700175, 0.3623764564197292, 0.3294363492704433]
Training Loss (progress: 0.08), 0.10251439576252126, [0.11599035547084426, 0.10162177964875524, 0.094340610435338, 0.2675104800227425, 0.3625361465514829, 0.32951489197136585]
Training Loss (progress: 0.16), 0.10093763411440798, [0.11600456925386149, 0.10158125458107536, 0.0943224142801512, 0.2676178726519475, 0.36267693097269976, 0.32966504189329177]
Training Loss (progress: 0.24), 0.11763139280178442, [0.11601378261952723, 0.10159770724924667, 0.09429540014467389, 0.2677803169218596, 0.3628037183984554, 0.329833468522891]
Training Loss (progress: 0.32), 0.11373487212099559, [0.11600303006485833, 0.10155713245299247, 0.0943035474180477, 0.267910518547852, 0.3629566323120626, 0.32993496898940833]
Training Loss (progress: 0.40), 0.1087794595006914, [0.1160182887336638, 0.1015789334808994, 0.09430907889002206, 0.2680493945245499, 0.36313050845451345, 0.33005388534922825]
Training Loss (progress: 0.48), 0.11325006584339359, [0.11602240593782731, 0.10157703354640263, 0.09429455203944967, 0.26813857397769814, 0.3632313094316682, 0.3301585885418535]
Training Loss (progress: 0.56), 0.11092002915415428, [0.11600764688584339, 0.10153842324085478, 0.09428165834778421, 0.26822720024510033, 0.3633776649280599, 0.33023965641425573]
Training Loss (progress: 0.64), 0.10979810655675581, [0.11601534546839531, 0.10157037915806155, 0.09425931926356092, 0.2683534153177614, 0.36348710732890166, 0.3303822595040439]
Training Loss (progress: 0.72), 0.10689671244866629, [0.11602341654768066, 0.10153626855733346, 0.09425311637984259, 0.26851547053798114, 0.3636447995487219, 0.33051293340809323]
Training Loss (progress: 0.80), 0.11676470050282453, [0.1160231452650645, 0.10155362996643941, 0.09424601016120583, 0.2686265211512209, 0.363826982954385, 0.3306238938283924]
Training Loss (progress: 0.88), 0.10920305998100857, [0.116026461875876, 0.1015395860144433, 0.09423529091263208, 0.2687081837433648, 0.36396430491401655, 0.33071905951381764]
Training Loss (progress: 0.96), 0.11446646587084973, [0.11601736925469701, 0.10151960739504118, 0.09423650213242017, 0.2688815716041759, 0.3640948550969613, 0.3308836264449738]
Evaluation on validation dataset:
Step 25, mean loss 0.024196966021805207
Step 50, mean loss 0.013639361524484847
Step 75, mean loss 0.0263781730795574
Step 100, mean loss 0.027603124797340256
Step 125, mean loss 0.03888079655824121
Step 150, mean loss 0.03363764000198172
Step 175, mean loss 0.06413972806515081
Step 200, mean loss 0.21826665731403483
Step 225, mean loss 0.23019201985968396
Unrolled forward losses 1.5505367211844236
Unrolled forward base losses 2.565701273852575
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00), 0.11499885109423245, [0.11602960495166863, 0.10153706987848549, 0.09423901183184781, 0.26889619060510495, 0.3641470873732026, 0.3309434323784379]
Training Loss (progress: 0.08), 0.10625367130099758, [0.11599666643408515, 0.10152955927193438, 0.09423549335561644, 0.2690246959273288, 0.3642713358630275, 0.3310481761736416]
Training Loss (progress: 0.16), 0.10334032740874545, [0.11602640205175324, 0.10154267832056575, 0.0942376568578191, 0.2691699828651757, 0.3644310545910289, 0.3311814364782952]
Training Loss (progress: 0.24), 0.10124702846540837, [0.11600700788889559, 0.10154672069101892, 0.0942294348463271, 0.26937324975611415, 0.36462810577410243, 0.33132187484306225]
Training Loss (progress: 0.32), 0.10829296721367627, [0.11603643253377617, 0.10154607218410053, 0.09422481260867167, 0.269482885361607, 0.36472746861786204, 0.3314219890204822]
Training Loss (progress: 0.40), 0.10977254756648495, [0.11599665208628669, 0.10151408950638291, 0.09421018200814203, 0.26962397219983436, 0.3648186229083548, 0.3315503973114063]
Training Loss (progress: 0.48), 0.11665987499382825, [0.11600115701045756, 0.10153099136588595, 0.09420818625922557, 0.2697504753549468, 0.364961082088174, 0.33165328586572124]
Training Loss (progress: 0.56), 0.10250615569240593, [0.11600073019080542, 0.10151317874963611, 0.09420587295100917, 0.26987567204722496, 0.3650717945037, 0.33177285001787105]
Training Loss (progress: 0.64), 0.11332374495237603, [0.11601242497853011, 0.10152078691473317, 0.09420064979716106, 0.26995878883030605, 0.36524526536255353, 0.3318702301310444]
Training Loss (progress: 0.72), 0.11033412622633373, [0.11601556141061699, 0.1014911904045794, 0.09419235360149146, 0.270108784672797, 0.36540308814722483, 0.3319960197420222]
Training Loss (progress: 0.80), 0.10867187462736724, [0.11601559877967046, 0.10149260405456233, 0.09418084804691285, 0.27025400953555745, 0.36553651426804323, 0.3321269641793653]
Training Loss (progress: 0.88), 0.10689497687326881, [0.11598382399181095, 0.10150529002826969, 0.09418614937269207, 0.2703330785904644, 0.3656565357163072, 0.3322382549601178]
Training Loss (progress: 0.96), 0.11075772019866245, [0.11600748792861135, 0.10150237443685568, 0.09418059038672463, 0.2705273617900092, 0.36581629329521587, 0.33236549702899937]
Evaluation on validation dataset:
Step 25, mean loss 0.02560902335995488
Step 50, mean loss 0.013631895664406021
Step 75, mean loss 0.027355363048230632
Step 100, mean loss 0.030016486729389606
Step 125, mean loss 0.03736755323636277
Step 150, mean loss 0.03406468652451962
Step 175, mean loss 0.06751619975837836
Step 200, mean loss 0.2163041174809214
Step 225, mean loss 0.2332919231886416
Unrolled forward losses 1.4700988768257859
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.91228e-01, 5.56751e-01, 5.84038e-01, 1.53484e-02, 2.48799e-04, 8.97092e-04
Node: 01 (pos: 0.010): 4.78693e-01, 5.00901e-01, 5.36152e-01, 1.53473e-02, 2.53610e-04, 8.74469e-04
Node: 02 (pos: 0.020): 4.66144e-01, 4.45108e-01, 4.87553e-01, 1.53419e-02, 2.58416e-04, 8.51209e-04
Node: 03 (pos: 0.030): 4.53597e-01, 3.90742e-01, 4.39153e-01, 1.53323e-02, 2.63212e-04, 8.27394e-04
Node: 04 (pos: 0.040): 4.41067e-01, 3.39034e-01, 3.91848e-01, 1.53185e-02, 2.67995e-04, 8.03103e-04
Node: 05 (pos: 0.051): 4.28572e-01, 2.90968e-01, 3.46458e-01, 1.53003e-02, 2.72761e-04, 7.78418e-04
-
Node: 07 (pos: 0.071): 4.28572e-01, 2.90968e-01, 3.46458e-01, 1.53003e-02, 2.72761e-04, 7.78418e-04
Node: 08 (pos: 0.081): 4.41067e-01, 3.39034e-01, 3.91848e-01, 1.53185e-02, 2.67995e-04, 8.03103e-04
Node: 09 (pos: 0.091): 4.53597e-01, 3.90742e-01, 4.39153e-01, 1.53323e-02, 2.63212e-04, 8.27394e-04
Node: 10 (pos: 0.101): 4.66144e-01, 4.45108e-01, 4.87553e-01, 1.53419e-02, 2.58416e-04, 8.51209e-04
Node: 11 (pos: 0.111): 4.78693e-01, 5.00901e-01, 5.36152e-01, 1.53473e-02, 2.53610e-04, 8.74469e-04
Node: 12 (pos: 0.121): 4.91228e-01, 5.56751e-01, 5.84038e-01, 1.53484e-02, 2.48799e-04, 8.97092e-04

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.24926e-01, 4.71626e-02, 2.67174e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
Node: 01 (pos: 0.010): 1.38729e-01, 8.44049e-02, 4.72276e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
Node: 02 (pos: 0.020): 1.53657e-01, 1.41978e-01, 8.01039e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
Node: 03 (pos: 0.030): 1.69729e-01, 2.22162e-01, 1.28980e-01, 9.99131e-01, 1.00000e+00, 9.99998e-01
Node: 04 (pos: 0.040): 1.86947e-01, 3.22213e-01, 1.95807e-01, 9.99133e-01, 1.00000e+00, 9.99998e-01
Node: 05 (pos: 0.051): 2.05304e-01, 4.34230e-01, 2.79505e-01, 9.99135e-01, 1.00000e+00, 9.99998e-01
-
Node: 07 (pos: 0.071): 2.05304e-01, 4.34230e-01, 2.79505e-01, 9.99135e-01, 1.00000e+00, 9.99998e-01
Node: 08 (pos: 0.081): 1.86947e-01, 3.22213e-01, 1.95807e-01, 9.99133e-01, 1.00000e+00, 9.99998e-01
Node: 09 (pos: 0.091): 1.69729e-01, 2.22162e-01, 1.28980e-01, 9.99131e-01, 1.00000e+00, 9.99998e-01
Node: 10 (pos: 0.101): 1.53657e-01, 1.41978e-01, 8.01039e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
Node: 11 (pos: 0.111): 1.38729e-01, 8.44049e-02, 4.72276e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
Node: 12 (pos: 0.121): 1.24926e-01, 4.71626e-02, 2.67174e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 4.28572e-01, 2.90968e-01, 3.46458e-01, 1.53003e-02, 2.72761e-04, 7.78418e-04
Node: 01 (pos: 0.010): 4.41067e-01, 3.39034e-01, 3.91848e-01, 1.53185e-02, 2.67995e-04, 8.03103e-04
Node: 02 (pos: 0.020): 4.53597e-01, 3.90742e-01, 4.39153e-01, 1.53323e-02, 2.63212e-04, 8.27394e-04
Node: 03 (pos: 0.030): 4.66144e-01, 4.45108e-01, 4.87553e-01, 1.53419e-02, 2.58416e-04, 8.51209e-04
Node: 04 (pos: 0.040): 4.78693e-01, 5.00901e-01, 5.36152e-01, 1.53473e-02, 2.53610e-04, 8.74469e-04
Node: 05 (pos: 0.051): 4.91228e-01, 5.56751e-01, 5.84038e-01, 1.53484e-02, 2.48799e-04, 8.97092e-04
-
Node: 07 (pos: 0.071): 4.78693e-01, 5.00901e-01, 5.36152e-01, 1.53473e-02, 2.53610e-04, 8.74469e-04
Node: 08 (pos: 0.081): 4.66144e-01, 4.45108e-01, 4.87553e-01, 1.53419e-02, 2.58416e-04, 8.51209e-04
Node: 09 (pos: 0.091): 4.53597e-01, 3.90742e-01, 4.39153e-01, 1.53323e-02, 2.63212e-04, 8.27394e-04
Node: 10 (pos: 0.101): 4.41067e-01, 3.39034e-01, 3.91848e-01, 1.53185e-02, 2.67995e-04, 8.03103e-04
Node: 11 (pos: 0.111): 4.28572e-01, 2.90968e-01, 3.46458e-01, 1.53003e-02, 2.72761e-04, 7.78418e-04
Node: 12 (pos: 0.121): 4.91228e-01, 5.56751e-01, 5.84038e-01, 1.53484e-02, 2.48799e-04, 8.97092e-04

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 2.05304e-01, 4.34230e-01, 2.79505e-01, 9.99135e-01, 1.00000e+00, 9.99998e-01
Node: 58 (pos: 0.586): 1.86947e-01, 3.22213e-01, 1.95807e-01, 9.99133e-01, 1.00000e+00, 9.99998e-01
Node: 59 (pos: 0.596): 1.69729e-01, 2.22162e-01, 1.28980e-01, 9.99131e-01, 1.00000e+00, 9.99998e-01
Node: 60 (pos: 0.606): 1.53657e-01, 1.41978e-01, 8.01039e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
Node: 61 (pos: 0.616): 1.38729e-01, 8.44049e-02, 4.72276e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
Node: 50 (pos: 0.505): 1.24926e-01, 4.71626e-02, 2.67174e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
-
Node: 51 (pos: 0.515): 1.38729e-01, 8.44049e-02, 4.72276e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
Node: 52 (pos: 0.525): 1.53657e-01, 1.41978e-01, 8.01039e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
Node: 53 (pos: 0.535): 1.69729e-01, 2.22162e-01, 1.28980e-01, 9.99131e-01, 1.00000e+00, 9.99998e-01
Node: 54 (pos: 0.545): 1.86947e-01, 3.22213e-01, 1.95807e-01, 9.99133e-01, 1.00000e+00, 9.99998e-01
Node: 55 (pos: 0.556): 2.05304e-01, 4.34230e-01, 2.79505e-01, 9.99135e-01, 1.00000e+00, 9.99998e-01
Node: 62 (pos: 0.626): 1.24926e-01, 4.71626e-02, 2.67174e-02, 9.99130e-01, 1.00000e+00, 9.99998e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.04874669510664984), ('0.bias', 1.2595699132787765), ('2.weight', 0.39849226799302356), ('2.bias', 1.2565696991545212)] 

GNN_Layer 1 gradients:
[('0.weight', 0.000849182251733975), ('0.bias', 0.3406166215434187), ('2.weight', 0.04640968978510824), ('2.bias', 0.15152907071876193)] 

GNN_Layer 2 gradients:
[('0.weight', 0.14259015906830402), ('0.bias', 3.440363647939871), ('2.weight', 0.4726337542115766), ('2.bias', 1.4833601637470823)] 

GNN_Layer 3 gradients:
[('0.weight', 1.4241272232165019e-06), ('0.bias', 0.00038299954876736355), ('2.weight', 0.0002484456495477472), ('2.bias', 0.00021274180497663612)] 

GNN_Layer 4 gradients:
[('0.weight', 6.351301423993479e-09), ('0.bias', 3.0560029341747516e-08), ('2.weight', 3.3518702303103793e-08), ('2.bias', 1.2606798314920027e-08)] 

GNN_Layer 5 gradients:
[('0.weight', 3.670852154502408e-09), ('0.bias', 1.0582728198661487e-07), ('2.weight', 7.624485915586522e-08), ('2.bias', 4.478206166752265e-08)] 

Evaluation on test dataset:
Step 25, mean loss 0.022053985564104865
Step 50, mean loss 0.01107073944858491
Step 75, mean loss 0.020484070330641937
Step 100, mean loss 0.024016108235877832
Step 125, mean loss 0.06004139064803885
Step 150, mean loss 0.04002086551600579
Step 175, mean loss 0.05323168259596327
Step 200, mean loss 0.09992118535944028
Step 225, mean loss 0.07483766569435003
Unrolled forward losses 1.3700918650895728
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.1_tw25_unrolling2_time512329.tar

Test loss: 1.3700918650895728
