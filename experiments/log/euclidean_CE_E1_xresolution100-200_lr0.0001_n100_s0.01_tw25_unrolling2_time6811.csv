Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar
Number of parameters: 1031657.0
Saved initial model at models/init6811.pt
Epoch 0
Starting epoch 0...
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 2.51399e-02, 2.51399e-02, 2.51399e-02, 2.51399e-02, 2.51399e-02, 2.51399e-02
Node: 21 (pos: 0.212): 1.68869e-02, 1.68869e-02, 1.68869e-02, 1.68869e-02, 1.68869e-02, 1.68869e-02
Node: 22 (pos: 0.222): 1.11141e-02, 1.11141e-02, 1.11141e-02, 1.11141e-02, 1.11141e-02, 1.11141e-02
Node: 23 (pos: 0.232): 7.16698e-03, 7.16698e-03, 7.16698e-03, 7.16698e-03, 7.16698e-03, 7.16698e-03
Node: 24 (pos: 0.242): 4.52830e-03, 4.52830e-03, 4.52830e-03, 4.52830e-03, 4.52830e-03, 4.52830e-03
Node: 25 (pos: 0.253): 2.80332e-03, 2.80332e-03, 2.80332e-03, 2.80332e-03, 2.80332e-03, 2.80332e-03
-
Node: 26 (pos: 0.263): 1.70039e-03, 1.70039e-03, 1.70039e-03, 1.70039e-03, 1.70039e-03, 1.70039e-03
Node: 27 (pos: 0.273): 1.01056e-03, 1.01056e-03, 1.01056e-03, 1.01056e-03, 1.01056e-03, 1.01056e-03
Node: 28 (pos: 0.283): 5.88451e-04, 5.88451e-04, 5.88451e-04, 5.88451e-04, 5.88451e-04, 5.88451e-04
Node: 29 (pos: 0.293): 3.35737e-04, 3.35737e-04, 3.35737e-04, 3.35737e-04, 3.35737e-04, 3.35737e-04
Node: 30 (pos: 0.303): 1.87683e-04, 1.87683e-04, 1.87683e-04, 1.87683e-04, 1.87683e-04, 1.87683e-04
Node: 31 (pos: 0.313): 1.02799e-04, 1.02799e-04, 1.02799e-04, 1.02799e-04, 1.02799e-04, 1.02799e-04
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 1.78295e-01, 1.78295e-01, 1.78295e-01, 1.78295e-01, 1.78295e-01, 1.78295e-01
Node: 08 (pos: 0.081): 2.30101e-01, 2.30101e-01, 2.30101e-01, 2.30101e-01, 2.30101e-01, 2.30101e-01
Node: 09 (pos: 0.091): 2.90960e-01, 2.90960e-01, 2.90960e-01, 2.90960e-01, 2.90960e-01, 2.90960e-01
Node: 10 (pos: 0.101): 3.60485e-01, 3.60485e-01, 3.60485e-01, 3.60485e-01, 3.60485e-01, 3.60485e-01
Node: 11 (pos: 0.111): 4.37602e-01, 4.37602e-01, 4.37602e-01, 4.37602e-01, 4.37602e-01, 4.37602e-01
Node: 12 (pos: 0.121): 5.20485e-01, 5.20485e-01, 5.20485e-01, 5.20485e-01, 5.20485e-01, 5.20485e-01
-
Node: 00 (pos: 0.000): 1.68869e-02, 1.68869e-02, 1.68869e-02, 1.68869e-02, 1.68869e-02, 1.68869e-02
Node: 01 (pos: 0.010): 2.51399e-02, 2.51399e-02, 2.51399e-02, 2.51399e-02, 2.51399e-02, 2.51399e-02
Node: 02 (pos: 0.020): 3.66704e-02, 3.66704e-02, 3.66704e-02, 3.66704e-02, 3.66704e-02, 3.66704e-02
Node: 03 (pos: 0.030): 5.24089e-02, 5.24089e-02, 5.24089e-02, 5.24089e-02, 5.24089e-02, 5.24089e-02
Node: 04 (pos: 0.040): 7.33892e-02, 7.33892e-02, 7.33892e-02, 7.33892e-02, 7.33892e-02, 7.33892e-02
Node: 05 (pos: 0.051): 1.00692e-01, 1.00692e-01, 1.00692e-01, 1.00692e-01, 1.00692e-01, 1.00692e-01
=========================================================================================================
Training Loss (progress: 0.00), 1.3060988238153, [0.004950246704524206, 0.016168510471302827, 0.017204736206107775, 0.016083579287963917, 0.016668970901811225, 0.01718699116557256], [1.0072595201604029, 1.0133911106309834, 1.0135237598517441, 1.0131445012611617, 1.0130842748908144, 1.012740590136439]
Training Loss (progress: 0.08), 0.28568640988683225, [0.0003227306778806932, 0.0016156117343812117, 0.003746675063865256, 0.0016076238684763465, 0.0020676743210196486, 0.007834879822650201], [1.0291888833771803, 1.034906506041288, 1.0393694738764208, 1.0398581329365137, 1.040936795323479, 1.0608933834558931]
Training Loss (progress: 0.16), 0.23575504044807796, [0.0003123519138963917, 0.001419214558173729, 0.0029308407736942667, 0.0013136844646321633, 0.0016710781958883634, 0.0066415132766442665], [1.03319241163278, 1.038759164178051, 1.051992383162116, 1.0465125395207442, 1.0516248336060559, 1.095602346528447]
Training Loss (progress: 0.24), 0.2029943855831409, [0.0002554908080060318, 0.0011866900587153826, 0.0024103577892029097, 0.0013352031341843055, 0.0012553701240312555, 0.005941557252079227], [1.0355428767695705, 1.0430103514291593, 1.0637817138259564, 1.051371361056676, 1.0624042753743668, 1.126930327785023]
Training Loss (progress: 0.32), 0.20324818594483596, [0.0002977665353643819, 0.0012570455441131738, 0.0021691080214954026, 0.0013453248394265274, 0.0010003189231949472, 0.0056286865073397864], [1.0360678414899989, 1.0452146503251758, 1.0728455594012805, 1.055897327595827, 1.0710065349879314, 1.1514061811643777]
Training Loss (progress: 0.40), 0.16999303300085208, [0.0002475408345430333, 0.0012305484498161838, 0.0024609142073727507, 0.0012255949115397681, 0.000988930374407734, 0.005127734346106455], [1.035935379775117, 1.0468903000426981, 1.080740371801637, 1.0590167741104852, 1.080862035009495, 1.1705193728778327]
Training Loss (progress: 0.48), 0.1493633764614908, [0.0003034245640957238, 0.0011728675208317976, 0.0023495045000688575, 0.0014560119393907621, 0.0008750849819482711, 0.00497956924885952], [1.0350687864389532, 1.0478866945288965, 1.086975585808621, 1.0608734074779647, 1.0909686206396703, 1.1878299386631843]
Training Loss (progress: 0.56), 0.14582631018337383, [0.00022059473922146085, 0.0013479405205916032, 0.002512748311996223, 0.0014018545177944045, 0.0007431044368817596, 0.004467834492645377], [1.0345217517362282, 1.049282032189308, 1.0944884699307993, 1.0630366641138072, 1.1007109259569277, 1.2007042891792354]
Training Loss (progress: 0.64), 0.13770776530808201, [0.0002895142892044125, 0.0012823607789018581, 0.002458976514522976, 0.0013459023409072312, 0.0009235439295220842, 0.00448599093866723], [1.032759479421204, 1.050124772113334, 1.1010880526058606, 1.0654558119449564, 1.110156846114625, 1.2129361895037507]
Training Loss (progress: 0.72), 0.13496460329251703, [0.00033453049846639905, 0.0012872717767145267, 0.0022196525272113726, 0.0014082608117366934, 0.0009307377118214758, 0.0044483547834666326], [1.031539947669738, 1.0508019265117536, 1.1075995274898285, 1.0665525494880512, 1.1186793380220377, 1.2228148577138573]
Training Loss (progress: 0.80), 0.12644039492930867, [0.0003009207040619888, 0.0013465048998119798, 0.0021880075232823416, 0.0014729114031193766, 0.0009438926279066711, 0.004127561824359702], [1.0305343790701578, 1.051318019693045, 1.1137084599511966, 1.0685838911508867, 1.1276191297936855, 1.2321316450094315]
Training Loss (progress: 0.88), 0.12317063798898772, [0.00038845315844751935, 0.0013530438833064973, 0.0023745359684319064, 0.0014959550374761316, 0.0008977697886261552, 0.004182333296510185], [1.0281022365018642, 1.0524107722453602, 1.1223170004889422, 1.0698452564458087, 1.1347565139760871, 1.241225825706078]
Training Loss (progress: 0.96), 0.12846330534295733, [0.0002996900318853813, 0.0014946395585265237, 0.002249390633864846, 0.0016896926046020113, 0.001152400825058591, 0.004465041917946372], [1.0247339948347536, 1.0528116440940245, 1.1289088800212894, 1.0725265486630462, 1.143429188711055, 1.2503010204123934]
Evaluation on validation dataset:
Step 25, mean loss 0.09322256539824551
Step 50, mean loss 0.1037635015665907
Step 75, mean loss 0.1507221454929079
Step 100, mean loss 0.2645652124983924
Step 125, mean loss 0.16431939821115815
Step 150, mean loss 0.240096715812253
Step 175, mean loss 0.3385859238548021
Step 200, mean loss 0.3843865703186503
Step 225, mean loss 0.5045270731112277
Unrolled forward losses 40.72571988407845
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 3.01985e-51, 6.31056e-12, 2.07943e-08, 2.52823e-11, 8.58333e-18, 1.50537e-04
Node: 21 (pos: 0.212): 1.04951e-56, 3.86959e-13, 3.03519e-09, 1.79738e-12, 1.21190e-19, 5.67667e-05
Node: 22 (pos: 0.222): 1.91442e-62, 2.05630e-14, 4.01390e-10, 1.11578e-13, 1.37529e-21, 2.03622e-05
Node: 23 (pos: 0.232): 1.83291e-68, 9.46968e-16, 4.80938e-11, 6.04839e-15, 1.25441e-23, 6.94758e-06
Node: 24 (pos: 0.242): 9.21075e-75, 3.77928e-17, 5.22097e-12, 2.86299e-16, 9.19609e-26, 2.25488e-06
Node: 25 (pos: 0.253): 2.42941e-81, 1.30710e-18, 5.13517e-13, 1.18336e-17, 5.41859e-28, 6.96132e-07
-
Node: 26 (pos: 0.263): 3.36324e-88, 3.91771e-20, 4.57613e-14, 4.27105e-19, 2.56618e-30, 2.04428e-07
Node: 27 (pos: 0.273): 2.44380e-95, 1.01761e-21, 3.69473e-15, 1.34608e-20, 9.76804e-33, 5.71041e-08
Node: 28 (pos: 0.283): 9.32019e-103, 2.29064e-23, 2.70276e-16, 3.70447e-22, 2.98845e-35, 1.51731e-08
Node: 29 (pos: 0.293): 1.86567e-110, 4.46846e-25, 1.79132e-17, 8.90226e-24, 7.34856e-38, 3.83496e-09
Node: 30 (pos: 0.303): 1.96019e-118, 7.55413e-27, 1.07567e-18, 1.86807e-25, 1.45237e-40, 9.21993e-10
Node: 31 (pos: 0.313): 1.08096e-126, 1.10672e-28, 5.85229e-20, 3.42300e-27, 2.30712e-43, 2.10850e-10
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 2.26496e-24, 5.87248e-06, 2.70676e-04, 1.13602e-05, 1.10227e-08, 1.83151e-02
Node: 08 (pos: 0.081): 7.15188e-21, 3.51563e-05, 9.29380e-04, 6.18584e-05, 1.69164e-07, 3.42228e-02
Node: 09 (pos: 0.091): 1.18530e-17, 1.82394e-04, 2.89119e-03, 2.94123e-04, 2.08663e-06, 6.08276e-02
Node: 10 (pos: 0.101): 1.03108e-14, 8.20054e-04, 8.14894e-03, 1.22118e-03, 2.06872e-05, 1.02841e-01
Node: 11 (pos: 0.111): 4.70765e-12, 3.19522e-03, 2.08097e-02, 4.42739e-03, 1.64845e-04, 1.65390e-01
Node: 12 (pos: 0.121): 1.12815e-09, 1.07891e-02, 4.81472e-02, 1.40164e-02, 1.05577e-03, 2.53008e-01
-
Node: 00 (pos: 0.000): 1.04951e-56, 3.86959e-13, 3.03519e-09, 1.79738e-12, 1.21190e-19, 5.67667e-05
Node: 01 (pos: 0.010): 3.01985e-51, 6.31056e-12, 2.07943e-08, 2.52823e-11, 8.58333e-18, 1.50537e-04
Node: 02 (pos: 0.020): 4.56076e-46, 8.91860e-11, 1.29076e-07, 3.10538e-10, 4.88613e-16, 3.79727e-04
Node: 03 (pos: 0.030): 3.61526e-41, 1.09232e-09, 7.25912e-07, 3.33066e-09, 2.23559e-14, 9.11130e-04
Node: 04 (pos: 0.040): 1.50416e-36, 1.15939e-08, 3.69883e-06, 3.11937e-08, 8.22126e-13, 2.07955e-03
Node: 05 (pos: 0.051): 3.28471e-32, 1.06644e-07, 1.70760e-05, 2.55106e-07, 2.42998e-11, 4.51477e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.07238385980417181
Step 50, mean loss 0.09133957842997648
Step 75, mean loss 0.11413074283769986
Step 100, mean loss 0.14825608882891206
Step 125, mean loss 0.2674362654696014
Step 150, mean loss 0.8019367890760231
Step 175, mean loss 0.6006204158676337
Step 200, mean loss 0.46949865186154305
Step 225, mean loss 0.29224888001645855
Unrolled forward losses 36.52759356116047
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.2993547468449602, [0.00036876012754286097, 0.0013633601004597574, 0.002297197248392282, 0.0013819595850454512, 0.0011222620168963103, 0.004416008866098402], [1.0249974582946073, 1.0530490623800968, 1.133055861128817, 1.073758911419028, 1.1474666944157224, 1.2551816242715494]
Training Loss (progress: 0.08), 0.266852484944053, [0.0002865358343744671, 0.0015980433524682945, 0.0026468800519960944, 0.0016587895536151727, 0.0011079798535684547, 0.004870799501879397], [1.0210509583624492, 1.0522112050476193, 1.137879515014443, 1.0762697116666018, 1.152893883318442, 1.2644868358413257]
Training Loss (progress: 0.16), 0.2874068195938305, [0.0002562199342472743, 0.0016411380932224635, 0.0029862695336908057, 0.0019157808949847063, 0.0010991126634758506, 0.004805491378549107], [1.016483393387922, 1.0520961779461744, 1.144873840728884, 1.0788173546006579, 1.1582704732761873, 1.2732301863063678]
Training Loss (progress: 0.24), 0.2750244699219044, [0.00031449910757724105, 0.0017766217553090344, 0.0031712432293697196, 0.0018542956935995523, 0.001310841763024789, 0.005334117246097184], [1.0151151253389776, 1.0544851755279843, 1.14989498222876, 1.082751276346786, 1.1633666684985584, 1.2818350603811275]
Training Loss (progress: 0.32), 0.24384090646929316, [0.0004230823113695561, 0.001712490338130742, 0.003528136470692568, 0.0022245674642844527, 0.0015479439849743276, 0.005187904644974117], [1.0113102595624857, 1.0550169178837463, 1.1553226836848745, 1.0863876799681655, 1.1691650227165438, 1.2911046692616588]
Training Loss (progress: 0.40), 0.23797645332882214, [0.000437163369663039, 0.0017670070134141777, 0.0036572270608328907, 0.00218769536498717, 0.0014014461205950968, 0.005451098221287353], [1.0089508458285805, 1.055883341559677, 1.159935245084483, 1.0896455737080504, 1.1744799100468974, 1.2990963367226178]
Training Loss (progress: 0.48), 0.2438829547530867, [0.0003406351391565126, 0.0016293083372266248, 0.003857868756010883, 0.002486185258508945, 0.0018431992951402666, 0.005498029041446643], [1.0072392349251065, 1.0574131170212895, 1.1647125978149733, 1.0934477815971926, 1.1782329848959676, 1.3071580849251887]
Training Loss (progress: 0.56), 0.211641792522166, [0.0003919206507006171, 0.0018855414680558754, 0.00356319975944488, 0.002258220706454867, 0.001865722092249614, 0.005016350085911], [1.0056736227923544, 1.0604029074611936, 1.1680765390308059, 1.0956100718274757, 1.183271349978726, 1.3146978302705539]
Training Loss (progress: 0.64), 0.22543444581499172, [0.00043030576440070004, 0.0016156273641864968, 0.0035744853921706302, 0.002408165454023906, 0.002231108081171589, 0.0050189984992744475], [1.0033455694740234, 1.0604370847459923, 1.170708574577031, 1.0992416327030041, 1.1873364729659734, 1.320805066342362]
Training Loss (progress: 0.72), 0.2027215068594184, [0.00045661136810559505, 0.0016607127424945883, 0.00338760907168742, 0.002247124923194793, 0.0016918722509513752, 0.0049760790971672625], [1.0015406899367172, 1.0615850834962148, 1.1730502172661443, 1.1012970837867015, 1.1915552243820533, 1.3274198072083634]
Training Loss (progress: 0.80), 0.2016083178106946, [0.0005737694377498052, 0.0017406036222582097, 0.0036979486498642856, 0.0023082675860601936, 0.001975630619768339, 0.005203067874566276], [1.0000989255761747, 1.0639979747893131, 1.1759711524707193, 1.1034685422856854, 1.1948510544010433, 1.3341473750894093]
Training Loss (progress: 0.88), 0.2026342639228732, [0.0004349024500935825, 0.0016366392582167742, 0.003839648930079314, 0.0023011658469948536, 0.0019474141866926665, 0.004955646795744536], [0.9980325610114604, 1.0646305451316074, 1.1779457278425645, 1.104866136532581, 1.1989027700262271, 1.339317653535135]
Training Loss (progress: 0.96), 0.1885512469908705, [0.00044569404350326014, 0.001787157432925492, 0.0038150722759614838, 0.0022230082075976594, 0.001978719975180791, 0.005201455134655615], [0.9970118327471496, 1.0652089140955419, 1.1794365518809888, 1.1067911045146797, 1.201007849671967, 1.344438100798666]
Evaluation on validation dataset:
Step 25, mean loss 0.13657631671418693
Step 50, mean loss 0.10631438509286975
Step 75, mean loss 0.1418196913066458
Step 100, mean loss 0.15904261931793706
Step 125, mean loss 0.16953398725903523
Step 150, mean loss 0.16558811905006302
Step 175, mean loss 0.25909003327501384
Step 200, mean loss 0.36514234816083463
Step 225, mean loss 0.43736202889467923
Unrolled forward losses 6.4526196558793885
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 1.52007e-36, 6.16602e-10, 5.71593e-05, 1.38528e-08, 1.57182e-08, 1.05169e-03
Node: 21 (pos: 0.212): 2.05349e-40, 6.19501e-11, 1.95398e-05, 1.93984e-09, 2.21142e-09, 4.85493e-04
Node: 22 (pos: 0.222): 1.75667e-44, 5.53225e-12, 6.32187e-06, 2.45591e-10, 2.81360e-10, 2.15408e-04
Node: 23 (pos: 0.232): 9.51613e-49, 4.39121e-13, 1.93582e-06, 2.81109e-11, 3.23724e-11, 9.18599e-05
Node: 24 (pos: 0.242): 3.26438e-53, 3.09805e-14, 5.61022e-07, 2.90907e-12, 3.36829e-12, 3.76508e-05
Node: 25 (pos: 0.253): 7.09106e-58, 1.94274e-15, 1.53882e-07, 2.72176e-13, 3.16931e-13, 1.48322e-05
-
Node: 26 (pos: 0.263): 9.75421e-63, 1.08284e-16, 3.99475e-08, 2.30230e-14, 2.69676e-14, 5.61595e-06
Node: 27 (pos: 0.273): 8.49658e-68, 5.36458e-18, 9.81489e-09, 1.76073e-15, 2.07511e-15, 2.04374e-06
Node: 28 (pos: 0.283): 4.68669e-73, 2.36227e-19, 2.28231e-09, 1.21742e-16, 1.44398e-16, 7.14843e-07
Node: 29 (pos: 0.293): 1.63704e-78, 9.24585e-21, 5.02296e-10, 7.61032e-18, 9.08661e-18, 2.40315e-07
Node: 30 (pos: 0.303): 3.62096e-84, 3.21652e-22, 1.04625e-10, 4.30114e-19, 5.17089e-19, 7.76488e-08
Node: 31 (pos: 0.313): 5.07175e-90, 9.94597e-24, 2.06257e-11, 2.19776e-20, 2.66103e-20, 2.41142e-08
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 1.70248e-17, 5.04722e-05, 1.12737e-02, 2.21167e-04, 2.45209e-04, 4.72704e-02
Node: 08 (pos: 0.081): 5.14574e-15, 2.20177e-04, 2.24333e-02, 7.79846e-04, 8.62020e-04, 7.75862e-02
Node: 09 (pos: 0.091): 9.84885e-13, 8.53718e-04, 4.22486e-02, 2.48608e-03, 2.74044e-03, 1.22395e-01
Node: 10 (pos: 0.101): 1.19370e-10, 2.94225e-03, 7.53053e-02, 7.16536e-03, 7.87851e-03, 1.85579e-01
Node: 11 (pos: 0.111): 9.16162e-09, 9.01293e-03, 1.27038e-01, 1.86715e-02, 2.04828e-02, 2.70444e-01
Node: 12 (pos: 0.121): 4.45268e-07, 2.45400e-02, 2.02831e-01, 4.39881e-02, 4.81567e-02, 3.78800e-01
-
Node: 00 (pos: 0.000): 2.05349e-40, 6.19501e-11, 1.95398e-05, 1.93984e-09, 2.21142e-09, 4.85493e-04
Node: 01 (pos: 0.010): 1.52007e-36, 6.16602e-10, 5.71593e-05, 1.38528e-08, 1.57182e-08, 1.05169e-03
Node: 02 (pos: 0.020): 7.12538e-33, 5.45494e-09, 1.58252e-04, 8.94388e-08, 1.01031e-07, 2.18966e-03
Node: 03 (pos: 0.030): 2.11505e-29, 4.28941e-08, 4.14672e-04, 5.22073e-07, 5.87256e-07, 4.38178e-03
Node: 04 (pos: 0.040): 3.97562e-26, 2.99797e-07, 1.02838e-03, 2.75520e-06, 3.08690e-06, 8.42769e-03
Node: 05 (pos: 0.051): 4.73217e-23, 1.86243e-06, 2.41378e-03, 1.31459e-05, 1.46737e-05, 1.55794e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.10520104086312035
Step 50, mean loss 0.08311772553688711
Step 75, mean loss 0.10260654449065429
Step 100, mean loss 0.12869006736271194
Step 125, mean loss 0.14233007538137435
Step 150, mean loss 0.3681509229230835
Step 175, mean loss 0.24190089155922767
Step 200, mean loss 0.32852744429848435
Step 225, mean loss 0.2823726300754817
Unrolled forward losses 4.834846059914909
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.2703480150128958, [0.00043293004414010714, 0.0017113603727839535, 0.003741213454599729, 0.0023499068767377567, 0.002383605515247045, 0.005147076910609903], [0.9961932410614763, 1.0654351282564622, 1.180759956127793, 1.1079630470126722, 1.2033850004858822, 1.3468812132811663]
Training Loss (progress: 0.08), 0.2639961766061569, [0.0004190231056041988, 0.0017198128994646395, 0.0037725448849728438, 0.0023072893893732608, 0.0021281020444918635, 0.004990578411583654], [0.9954163248704386, 1.0665742691098148, 1.18086335632245, 1.108689260964786, 1.2047452096520035, 1.3494835569630952]
Training Loss (progress: 0.16), 0.25794480596383873, [0.0004674273304222243, 0.0015597536946140248, 0.0037690369259418687, 0.00226714469802118, 0.002129923414815052, 0.004950320752907498], [0.9945387962087511, 1.0666120617983068, 1.1825548308517415, 1.108864620531165, 1.2063386509885619, 1.351941145853652]
Training Loss (progress: 0.24), 0.2658537672298853, [0.00043350263284719744, 0.0016150512578190117, 0.0040407407204765084, 0.0022619052408480505, 0.0020068881642080487, 0.005029463763567169], [0.9945196621357394, 1.066977662501425, 1.183759862647756, 1.1097143603194928, 1.2073947126970515, 1.354310472044388]
Training Loss (progress: 0.32), 0.25959319749690907, [0.0004353210366796408, 0.0015945380202264767, 0.0037448120437862664, 0.002215286478885313, 0.0022307137497466186, 0.004877768484116574], [0.9935392371655676, 1.0684481805071002, 1.1858289714587003, 1.1099876000772693, 1.2093242029651874, 1.35663967480787]
Training Loss (progress: 0.40), 0.2586179718061289, [0.0004298076347323913, 0.0015646265147333804, 0.0036527054530889097, 0.0022282442474872333, 0.002156882586818707, 0.004931654919049862], [0.9923652099257003, 1.0693587774775735, 1.186468332307301, 1.1106098285375796, 1.2102439069062996, 1.3583852493834145]
Training Loss (progress: 0.48), 0.21284759009607718, [0.0004086990700851279, 0.0015789712501401208, 0.0037131787063520005, 0.0023003120730381273, 0.001901896961236645, 0.004796453810272765], [0.9915348915324279, 1.0699236642175511, 1.1870633588666124, 1.1115606334193107, 1.2121532426489412, 1.3605113553794415]
Training Loss (progress: 0.56), 0.2547825909998381, [0.0004437801880208135, 0.0017071635922455983, 0.003759285334410084, 0.002380442218735357, 0.002310021038049148, 0.005033706927759623], [0.9909430830290678, 1.0702497388357246, 1.187620670335263, 1.1116988329254096, 1.2133975742615524, 1.3623694402957383]
Training Loss (progress: 0.64), 0.22524665384807804, [0.0004194882789416371, 0.0016184798361216558, 0.003593445696801638, 0.002262657536159911, 0.002033431737639722, 0.004689799661739934], [0.9904825877035731, 1.070594020136573, 1.1886456274204267, 1.1125314272996392, 1.2144678290250652, 1.3641835600021743]
Training Loss (progress: 0.72), 0.22953468386005021, [0.00043913850281583654, 0.0014752382013151993, 0.003738081378778522, 0.0022473989374925517, 0.0021933913195168716, 0.004734858376421586], [0.9898016019459138, 1.070391548700202, 1.189340456523071, 1.1125765103179752, 1.2162081168607008, 1.3660284577155826]
Training Loss (progress: 0.80), 0.24524968082703585, [0.00047581343242541666, 0.0015752941302766906, 0.0036567920735290087, 0.0021852660291584365, 0.002130367483936721, 0.0048549040058063625], [0.9891608843955503, 1.0710421658728164, 1.1908394562691271, 1.1134200241644938, 1.2173856459306038, 1.36776372028362]
Training Loss (progress: 0.88), 0.21358560367511503, [0.00043474240255153486, 0.0014680392067029776, 0.003729039568732212, 0.0022437915079085487, 0.0021064870998666655, 0.004850526437222781], [0.9886915974922078, 1.0714793702627707, 1.1913392838669807, 1.1139770341570885, 1.2184497580799258, 1.3695219699941192]
Training Loss (progress: 0.96), 0.21293514811089825, [0.0004730095015330802, 0.0015844193273626577, 0.003743470066368469, 0.002306431160169851, 0.002076526279576828, 0.00475342976898087], [0.9880496835272384, 1.071832479749681, 1.1929780226023499, 1.1144525627112352, 1.219195158636276, 1.3713037413094071]
Evaluation on validation dataset:
Step 25, mean loss 0.106266858428332
Step 50, mean loss 0.06304058125895584
Step 75, mean loss 0.121817710871922
Step 100, mean loss 0.12606444491592123
Step 125, mean loss 0.1295721270242799
Step 150, mean loss 0.12462081260885033
Step 175, mean loss 0.18393420875112243
Step 200, mean loss 0.2750262403727375
Step 225, mean loss 0.3903772287514956
Unrolled forward losses 4.405640911435656
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 9.33322e-36, 8.43124e-11, 7.86075e-05, 1.55107e-07, 2.76555e-08, 6.72779e-04
Node: 21 (pos: 0.212): 1.53532e-39, 6.82776e-12, 2.77804e-05, 2.81777e-08, 4.12983e-09, 2.95349e-04
Node: 22 (pos: 0.222): 1.61557e-43, 4.86054e-13, 9.30783e-06, 4.69024e-09, 5.59413e-10, 1.24298e-04
Node: 23 (pos: 0.232): 1.08745e-47, 3.04166e-14, 2.95660e-06, 7.15317e-10, 6.87356e-11, 5.01483e-05
Node: 24 (pos: 0.242): 4.68217e-52, 1.67323e-15, 8.90371e-07, 9.99577e-11, 7.66089e-12, 1.93961e-05
Node: 25 (pos: 0.253): 1.28957e-56, 8.09138e-17, 2.54205e-07, 1.27982e-11, 7.74507e-13, 7.19177e-06
-
Node: 26 (pos: 0.263): 2.27195e-61, 3.43960e-18, 6.88070e-08, 1.50139e-12, 7.10265e-14, 2.55636e-06
Node: 27 (pos: 0.273): 2.56042e-66, 1.28533e-19, 1.76569e-08, 1.61382e-13, 5.90833e-15, 8.71113e-07
Node: 28 (pos: 0.283): 1.84578e-71, 4.22220e-21, 4.29568e-09, 1.58938e-14, 4.45818e-16, 2.84571e-07
Node: 29 (pos: 0.293): 8.51153e-77, 1.21923e-22, 9.90795e-10, 1.43422e-15, 3.05140e-17, 8.91195e-08
Node: 30 (pos: 0.303): 2.51068e-82, 3.09492e-24, 2.16656e-10, 1.18582e-16, 1.89448e-18, 2.67558e-08
Node: 31 (pos: 0.313): 4.73732e-88, 6.90611e-26, 4.49150e-11, 8.98328e-18, 1.06691e-19, 7.70069e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 3.96394e-17, 1.99521e-05, 1.31626e-02, 6.87503e-04, 3.21735e-04, 3.87306e-02
Node: 08 (pos: 0.081): 1.05599e-14, 9.99404e-05, 2.56395e-02, 2.05163e-03, 1.08865e-03, 6.56514e-02
Node: 09 (pos: 0.091): 1.79950e-12, 4.40061e-04, 4.73490e-02, 5.60965e-03, 3.34139e-03, 1.06684e-01
Node: 10 (pos: 0.101): 1.96155e-10, 1.70335e-03, 8.28987e-02, 1.40536e-02, 9.30283e-03, 1.66195e-01
Node: 11 (pos: 0.111): 1.36774e-08, 5.79584e-03, 1.37600e-01, 3.22592e-02, 2.34937e-02, 2.48201e-01
Node: 12 (pos: 0.121): 6.10052e-07, 1.73360e-02, 2.16533e-01, 6.78475e-02, 5.38192e-02, 3.55347e-01
-
Node: 00 (pos: 0.000): 1.53532e-39, 6.82776e-12, 2.77804e-05, 2.81777e-08, 4.12983e-09, 2.95349e-04
Node: 01 (pos: 0.010): 9.33322e-36, 8.43124e-11, 7.86075e-05, 1.55107e-07, 2.76555e-08, 6.72779e-04
Node: 02 (pos: 0.020): 3.62928e-32, 9.15219e-10, 2.10874e-04, 7.82292e-07, 1.67988e-07, 1.46918e-03
Node: 03 (pos: 0.030): 9.02750e-29, 8.73329e-09, 5.36313e-04, 3.61511e-06, 9.25604e-07, 3.07567e-03
Node: 04 (pos: 0.040): 1.43639e-25, 7.32573e-08, 1.29314e-03, 1.53070e-05, 4.62616e-06, 6.17265e-03
Node: 05 (pos: 0.051): 1.46195e-22, 5.40187e-07, 2.95604e-03, 5.93841e-05, 2.09732e-05, 1.18759e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.0790184635088137
Step 50, mean loss 0.04718166482939644
Step 75, mean loss 0.0715536823107034
Step 100, mean loss 0.09536617443979117
Step 125, mean loss 0.08817011565436683
Step 150, mean loss 0.17901109307737445
Step 175, mean loss 0.18270207528292137
Step 200, mean loss 0.2088278554047729
Step 225, mean loss 0.2536488334010598
Unrolled forward losses 3.0609703023136703
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.23159354137003385, [0.00044399582922896846, 0.0015085029700907982, 0.0038121123727376228, 0.0022367484047665885, 0.0019948399853849464, 0.0047968297098203985], [0.9878957636476059, 1.0722008685844253, 1.1935260364381697, 1.1146922045389671, 1.2196509755954639, 1.3721285993831431]
Training Loss (progress: 0.08), 0.21918075953433366, [0.0004760186493679388, 0.001665896118816295, 0.0037714560200270224, 0.0022802446282052338, 0.0021868285068823547, 0.0047698458498418635], [0.9868313464032596, 1.0728802408176974, 1.1932365781082863, 1.1148943249805512, 1.22065903741289, 1.3739862729672077]
Training Loss (progress: 0.16), 0.20388301530654754, [0.00044228906613363037, 0.001597370905742045, 0.0038968501651631946, 0.002140225654723059, 0.002070917015699135, 0.004818030700848052], [0.9867309231525894, 1.0736332966308617, 1.1940272209623686, 1.1155287975317238, 1.222341776450089, 1.3760254950075521]
Training Loss (progress: 0.24), 0.2325066333454381, [0.00043418169016344507, 0.0015817994956986478, 0.003809792833353832, 0.0021725322364521925, 0.0020796291997827896, 0.004773049839410598], [0.9861894691848573, 1.0742982378128867, 1.1949016849517804, 1.115980127800327, 1.2229517515590018, 1.377809239557851]
Training Loss (progress: 0.32), 0.22506997003838064, [0.00046531821302638884, 0.0015411211878706005, 0.003704070634957599, 0.002332424442720758, 0.0020987095824033784, 0.004733348254982235], [0.9851305043273048, 1.075257878135245, 1.195497786965591, 1.1166483621807608, 1.2246633899474453, 1.3792015407067355]
Training Loss (progress: 0.40), 0.214282213786972, [0.00043797037203636524, 0.0015367512289386257, 0.003727157308646755, 0.0022268731822855585, 0.0020849672793355825, 0.0047798412361515314], [0.9841420082766754, 1.075269496199145, 1.1958165945560473, 1.1171134335507993, 1.225725587856184, 1.3806064321430072]
Training Loss (progress: 0.48), 0.21397411362519456, [0.00044062365063949775, 0.001539425216925099, 0.0035801309850095157, 0.0023033103869345567, 0.002008053527154541, 0.004626604127676046], [0.9839821137063479, 1.0759689922696694, 1.1965159057599355, 1.1178709095279227, 1.2265939487454827, 1.38205498200394]
Training Loss (progress: 0.56), 0.1997582638667494, [0.00043319344857881115, 0.0016590020940525875, 0.0035775978173942418, 0.0021768669947988687, 0.0021627314688001933, 0.004601642721994012], [0.983121555030779, 1.0758946950547439, 1.1967226340776245, 1.1180457673579907, 1.2275509363933532, 1.3835881685794653]
Training Loss (progress: 0.64), 0.19912810013047536, [0.0004405619894854416, 0.001565131399164842, 0.003744520044153005, 0.002277530457227264, 0.0021645345956447766, 0.004685262977875716], [0.9827246286642973, 1.0764053769814534, 1.1971038734222825, 1.1184336715034013, 1.228996312198033, 1.3852731935694014]
Training Loss (progress: 0.72), 0.21660661904714476, [0.0004190432069123489, 0.0015461152041938743, 0.003715908217274971, 0.0022312709088202977, 0.0021050168755905037, 0.004559926603403333], [0.9818190433167574, 1.0772961670713515, 1.1982208743159233, 1.118558956205224, 1.2295364931574615, 1.3868803556618081]
Training Loss (progress: 0.80), 0.22141999734962656, [0.0004334912375426038, 0.0015685958968502626, 0.0037738304088402366, 0.0021644418197687815, 0.002021457778833001, 0.004566745838181565], [0.9819057561534856, 1.0777942980366326, 1.1982527460214314, 1.119427713482925, 1.2303533299740717, 1.3882541408943962]
Training Loss (progress: 0.88), 0.21545103317883843, [0.0004257573757676859, 0.0016623310424795056, 0.0037318154505196948, 0.0023010833182930237, 0.0019402351477254068, 0.004606330733131997], [0.9814305041000453, 1.078473384744693, 1.1993623311443862, 1.1201560514318931, 1.2316238052882988, 1.3901943156983494]
Training Loss (progress: 0.96), 0.22697601801718817, [0.00044156659254741154, 0.001589304363514305, 0.0037902018993869408, 0.002265756685826188, 0.002075906091811699, 0.004673251846270093], [0.9806058961073895, 1.0792176858616818, 1.1999508657474414, 1.1208342093904329, 1.232490192747834, 1.391658009246896]
Evaluation on validation dataset:
Step 25, mean loss 0.10020794129513136
Step 50, mean loss 0.056441174675159675
Step 75, mean loss 0.09760409122031856
Step 100, mean loss 0.10677100823652805
Step 125, mean loss 0.120119565493441
Step 150, mean loss 0.09725387147067605
Step 175, mean loss 0.14699672225778276
Step 200, mean loss 0.2398596155135862
Step 225, mean loss 0.2776024054099045
Unrolled forward losses 3.690775512761376
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 2.14588e-36, 3.66352e-11, 7.11063e-05, 7.83163e-08, 2.21104e-08, 6.32290e-04
Node: 21 (pos: 0.212): 3.01433e-40, 2.70940e-12, 2.48436e-05, 1.32062e-08, 3.21913e-09, 2.75285e-04
Node: 22 (pos: 0.222): 2.68668e-44, 1.75325e-13, 8.22433e-06, 2.03262e-09, 4.24586e-10, 1.14849e-04
Node: 23 (pos: 0.232): 1.51943e-48, 9.92694e-15, 2.57968e-06, 2.85556e-10, 5.07313e-11, 4.59151e-05
Node: 24 (pos: 0.242): 5.45238e-53, 4.91796e-16, 7.66677e-07, 3.66168e-11, 5.49125e-12, 1.75899e-05
Node: 25 (pos: 0.253): 1.24146e-57, 2.13183e-17, 2.15893e-07, 4.28574e-12, 5.38456e-13, 6.45729e-06
-
Node: 26 (pos: 0.263): 1.79356e-62, 8.08574e-19, 5.76027e-08, 4.57852e-13, 4.78315e-14, 2.27153e-06
Node: 27 (pos: 0.273): 1.64416e-67, 2.68340e-20, 1.45622e-08, 4.46458e-14, 3.84912e-15, 7.65714e-07
Node: 28 (pos: 0.283): 9.56333e-73, 7.79201e-22, 3.48814e-09, 3.97366e-15, 2.80604e-16, 2.47340e-07
Node: 29 (pos: 0.293): 3.52952e-78, 1.97976e-23, 7.91659e-10, 3.22817e-16, 1.85314e-17, 7.65603e-08
Node: 30 (pos: 0.303): 8.26536e-84, 4.40123e-25, 1.70240e-10, 2.39374e-17, 1.10869e-18, 2.27087e-08
Node: 31 (pos: 0.313): 1.22814e-89, 8.56118e-27, 3.46870e-11, 1.62014e-18, 6.00888e-20, 6.45449e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 1.98310e-17, 1.35528e-05, 1.25964e-02, 5.00913e-04, 2.91415e-04, 3.79145e-02
Node: 08 (pos: 0.081): 5.84576e-15, 7.19525e-05, 2.47172e-02, 1.56792e-03, 1.00221e-03, 6.46103e-02
Node: 09 (pos: 0.091): 1.09340e-12, 3.34242e-04, 4.59548e-02, 4.47961e-03, 3.12241e-03, 1.05506e-01
Node: 10 (pos: 0.101): 1.29764e-10, 1.35855e-03, 8.09548e-02, 1.16818e-02, 8.81264e-03, 1.65095e-01
Node: 11 (pos: 0.111): 9.77178e-09, 4.83157e-03, 1.35125e-01, 2.78060e-02, 2.25323e-02, 2.47555e-01
Node: 12 (pos: 0.121): 4.66908e-07, 1.50349e-02, 2.13701e-01, 6.04115e-02, 5.21904e-02, 3.55704e-01
-
Node: 00 (pos: 0.000): 3.01433e-40, 2.70940e-12, 2.48436e-05, 1.32062e-08, 3.21913e-09, 2.75285e-04
Node: 01 (pos: 0.010): 2.14588e-36, 3.66352e-11, 7.11063e-05, 7.83163e-08, 2.21104e-08, 6.32290e-04
Node: 02 (pos: 0.020): 9.69308e-33, 4.33435e-10, 1.92833e-04, 4.23919e-07, 1.37575e-07, 1.39165e-03
Node: 03 (pos: 0.030): 2.77816e-29, 4.48691e-09, 4.95490e-04, 2.09444e-06, 7.75470e-07, 2.93511e-03
Node: 04 (pos: 0.040): 5.05236e-26, 4.06415e-08, 1.20633e-03, 9.44516e-06, 3.95982e-06, 5.93198e-03
Node: 05 (pos: 0.051): 5.83002e-23, 3.22100e-07, 2.78279e-03, 3.88781e-05, 1.83177e-05, 1.14883e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.07610378210978443
Step 50, mean loss 0.0442675568846383
Step 75, mean loss 0.06241798808987552
Step 100, mean loss 0.07960666485115017
Step 125, mean loss 0.08353620329368189
Step 150, mean loss 0.14543214633451407
Step 175, mean loss 0.1617770556287341
Step 200, mean loss 0.21080196403616464
Step 225, mean loss 0.1660675646431084
Unrolled forward losses 2.976103269123298
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.21226359155022184, [0.0004460237375609878, 0.0015130275270087191, 0.0037921534124019155, 0.0022655398571552895, 0.0023305090259180435, 0.004739835991179635], [0.9799730068339357, 1.0794914588293612, 1.200114309114153, 1.1214681583996906, 1.2330795249456907, 1.3924191031089639]
Training Loss (progress: 0.08), 0.20230040956883907, [0.00047270730824536906, 0.0014829597690559216, 0.003711074959619104, 0.0020648108692793484, 0.0020689311859173583, 0.004719178577773594], [0.9787177730455475, 1.0798977175850653, 1.2008492161613582, 1.1214341260302791, 1.233748415550422, 1.3938317191887297]
Training Loss (progress: 0.16), 0.2162895293896298, [0.0005002791619731365, 0.0015201269691433666, 0.0037119774371482885, 0.0022043413225018645, 0.0020442724471382073, 0.004735572834212097], [0.9789297823213009, 1.0806845003383605, 1.2015801073388561, 1.1222765393939278, 1.2342974787819274, 1.3954120693403322]
Training Loss (progress: 0.24), 0.2182100421394506, [0.00041941497654105755, 0.001542539288636895, 0.0038478860232806725, 0.002171698135913937, 0.001999719456710406, 0.00469867533633122], [0.9780546973154044, 1.0809641139371169, 1.2019222101709348, 1.1233512976303777, 1.2361294274230124, 1.3967348363565404]
Training Loss (progress: 0.32), 0.19272223801184124, [0.0004932225327428137, 0.0016191035409387315, 0.003769956137465919, 0.0022726879232937763, 0.0019588832750035874, 0.004742535284112825], [0.9771040309107359, 1.0815249620400067, 1.2026854434878367, 1.1238657640420073, 1.2364101156226501, 1.3979785581793207]
Training Loss (progress: 0.40), 0.1919709070221362, [0.00048531055035901577, 0.0015076777827125612, 0.0038923349508617647, 0.0021953482840417083, 0.002068608341632303, 0.004739855043573665], [0.9766313400177669, 1.0816927966024172, 1.203170291935867, 1.1241775409989634, 1.2374234484978603, 1.3993996273873166]
Training Loss (progress: 0.48), 0.20327285105740817, [0.00045973592210457777, 0.0015972519803175715, 0.0038148445382142843, 0.0022390124219879262, 0.001980527731616004, 0.004686260338957297], [0.9762386768816191, 1.0824768447802051, 1.2034396378515075, 1.1248502657103288, 1.23849132777423, 1.4006866308658958]
Training Loss (progress: 0.56), 0.1919756504476604, [0.0004681440045184351, 0.0015602231038617277, 0.003912905575428576, 0.0022930494554409377, 0.00213572846440071, 0.004727329845108927], [0.9750413293573753, 1.0829453274746856, 1.2041827078181768, 1.1253938570805904, 1.239268406761766, 1.4020171075515069]
Training Loss (progress: 0.64), 0.204925528777404, [0.00045749891897726335, 0.001599444415700022, 0.0037010541051392073, 0.002170110769251664, 0.0020735933485687102, 0.0045932729195032294], [0.9741856607537933, 1.0829049997720503, 1.204435216083426, 1.1259284968930046, 1.2399719443242807, 1.4034284726481527]
Training Loss (progress: 0.72), 0.1846591054397984, [0.00044393633895367684, 0.0016499106818971682, 0.0037266641067965826, 0.002214135275213223, 0.002094074024315843, 0.004752555265843108], [0.9740759861352994, 1.0831691031985171, 1.2044857689375752, 1.126414570099337, 1.2405538799925042, 1.4048622229038854]
Training Loss (progress: 0.80), 0.20152826812523483, [0.0004872847427602705, 0.0015896459486810519, 0.0038049761388546863, 0.0021996238573619544, 0.0019944558900448577, 0.00452264149025818], [0.9727547419348869, 1.083327246309667, 1.2046383872375668, 1.1270259603355561, 1.2412132723932725, 1.406368779533558]
Training Loss (progress: 0.88), 0.1995658185677927, [0.00044453678553221776, 0.00164286700954735, 0.0038552372561900146, 0.0022024624738497386, 0.002069436126582094, 0.004751104489209745], [0.972212032376736, 1.0841559261198284, 1.2054928367557014, 1.1273195563354554, 1.242271293440762, 1.4076807975031962]
Training Loss (progress: 0.96), 0.20137892077250508, [0.00047973466210561344, 0.001512008534926667, 0.003637327130245175, 0.0022200371085277105, 0.0020661325861557676, 0.004562726945704697], [0.9718340038803358, 1.0846915019411913, 1.2055676764707999, 1.1276580056123862, 1.2432434608228973, 1.4090089391853975]
Evaluation on validation dataset:
Step 25, mean loss 0.08740538776784099
Step 50, mean loss 0.03846065175172167
Step 75, mean loss 0.08110712899595238
Step 100, mean loss 0.0724922804725818
Step 125, mean loss 0.10541842021486372
Step 150, mean loss 0.08853728308400327
Step 175, mean loss 0.12158068015855188
Step 200, mean loss 0.2610612273741273
Step 225, mean loss 0.2680262746365386
Unrolled forward losses 3.0139659853486025
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 9.04990e-36, 8.25328e-11, 6.07695e-05, 5.89155e-08, 8.36100e-08, 5.51597e-04
Node: 21 (pos: 0.212): 1.48648e-39, 6.65955e-12, 2.08639e-05, 9.62771e-09, 1.40411e-08, 2.36320e-04
Node: 22 (pos: 0.222): 1.56170e-43, 4.72283e-13, 6.78106e-06, 1.43375e-09, 2.15184e-09, 9.69399e-05
Node: 23 (pos: 0.232): 1.04945e-47, 2.94374e-14, 2.08636e-06, 1.94571e-10, 3.00940e-10, 3.80738e-05
Node: 24 (pos: 0.242): 4.51074e-52, 1.61264e-15, 6.07673e-07, 2.40624e-11, 3.84074e-11, 1.43176e-05
Node: 25 (pos: 0.253): 1.24011e-56, 7.76447e-17, 1.67549e-07, 2.71179e-12, 4.47315e-12, 5.15513e-06
-
Node: 26 (pos: 0.263): 2.18069e-61, 3.28570e-18, 4.37325e-08, 2.78503e-13, 4.75418e-13, 1.77717e-06
Node: 27 (pos: 0.273): 2.45274e-66, 1.22203e-19, 1.08058e-08, 2.60651e-14, 4.61107e-14, 5.86598e-07
Node: 28 (pos: 0.283): 1.76455e-71, 3.99463e-21, 2.52755e-09, 2.22303e-15, 4.08124e-15, 1.85385e-07
Node: 29 (pos: 0.293): 8.11970e-77, 1.14765e-22, 5.59671e-10, 1.72778e-16, 3.29644e-16, 5.60957e-08
Node: 30 (pos: 0.303): 2.38985e-82, 2.89789e-24, 1.17316e-10, 1.22373e-17, 2.42976e-17, 1.62520e-08
Node: 31 (pos: 0.313): 4.49908e-88, 6.43124e-26, 2.32793e-11, 7.89840e-19, 1.63435e-18, 4.50824e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 3.87216e-17, 1.98813e-05, 1.17332e-02, 4.39792e-04, 5.45678e-04, 3.58020e-02
Node: 08 (pos: 0.081): 1.03254e-14, 9.98164e-05, 2.32830e-02, 1.40458e-03, 1.71253e-03, 6.16428e-02
Node: 09 (pos: 0.091): 1.76109e-12, 4.40452e-04, 4.37371e-02, 4.08792e-03, 4.90463e-03, 1.01620e-01
Node: 10 (pos: 0.101): 1.92123e-10, 1.70819e-03, 7.77772e-02, 1.08421e-02, 1.28185e-02, 1.60398e-01
Node: 11 (pos: 0.111): 1.34061e-08, 5.82252e-03, 1.30932e-01, 2.62048e-02, 3.05725e-02, 2.42403e-01
Node: 12 (pos: 0.121): 5.98344e-07, 1.74432e-02, 2.08654e-01, 5.77171e-02, 6.65409e-02, 3.50753e-01
-
Node: 00 (pos: 0.000): 1.48648e-39, 6.65955e-12, 2.08639e-05, 9.62771e-09, 1.40411e-08, 2.36320e-04
Node: 01 (pos: 0.010): 9.04990e-36, 8.25328e-11, 6.07695e-05, 5.89155e-08, 8.36100e-08, 5.51597e-04
Node: 02 (pos: 0.020): 3.52413e-32, 8.98975e-10, 1.67558e-04, 3.28543e-07, 4.54337e-07, 1.23272e-03
Node: 03 (pos: 0.030): 8.77778e-29, 8.60614e-09, 4.37356e-04, 1.66960e-06, 2.25301e-06, 2.63772e-03
Node: 04 (pos: 0.040): 1.39843e-25, 7.24116e-08, 1.08068e-03, 7.73190e-06, 1.01955e-05, 5.40400e-03
Node: 05 (pos: 0.051): 1.42502e-22, 5.35485e-07, 2.52782e-03, 3.26300e-05, 4.21039e-05, 1.06004e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.06758226036975382
Step 50, mean loss 0.03407249170013938
Step 75, mean loss 0.047529689492711254
Step 100, mean loss 0.05961708215832854
Step 125, mean loss 0.06721725295438252
Step 150, mean loss 0.1257459237053501
Step 175, mean loss 0.14408056653086948
Step 200, mean loss 0.16389120256706527
Step 225, mean loss 0.16914702285096211
Unrolled forward losses 2.1979399260937704
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.17602997944125393, [0.00042514683163160895, 0.0015786602224240579, 0.0038731292871257827, 0.0021894015352088283, 0.002076484878000809, 0.004689702092071869], [0.9714570280877671, 1.0852656442262083, 1.2060731582166369, 1.1279577426725595, 1.2434091932751752, 1.409645192965216]
Training Loss (progress: 0.08), 0.18397795300098646, [0.00045831416971057516, 0.001508801069092474, 0.003871413223783312, 0.002206412655411863, 0.002088468018305894, 0.004601924981278222], [0.9713842172823968, 1.085505399447801, 1.2065536950583113, 1.1285132158447455, 1.2441497814917528, 1.4106261572221275]
Training Loss (progress: 0.16), 0.16501504997854777, [0.0004498001565548264, 0.0014746726729974791, 0.0038194573300288186, 0.002193462507072344, 0.002036463368344361, 0.0045888259985357085], [0.9712530295244749, 1.085783671711663, 1.2071012202525615, 1.1285884460006919, 1.2449723601291156, 1.41145851524213]
Training Loss (progress: 0.24), 0.17259338872097305, [0.0004734245993196054, 0.0014922666281333137, 0.003712442175637379, 0.0021852142592735896, 0.0020112753487803786, 0.004620340584147072], [0.9713109789696053, 1.0862128657197208, 1.2074769391917826, 1.1288823824991983, 1.2455231431154064, 1.412485657584648]
Training Loss (progress: 0.32), 0.1927042317314245, [0.0004534350876511001, 0.001543462585382303, 0.003840182164444938, 0.0021952553033756698, 0.0021235570582439378, 0.004619401195537299], [0.9710798277617027, 1.0865508838502667, 1.2081167095987877, 1.1290312224212222, 1.246231542399795, 1.413435010884967]
Training Loss (progress: 0.40), 0.15674611763148658, [0.00045768498655202863, 0.0015174703913186237, 0.003659719748849262, 0.002138836708165739, 0.0021867277011495376, 0.0045322859354575175], [0.9706512909687095, 1.0866778294439674, 1.2080082230884266, 1.1293044945211006, 1.2470498063203883, 1.4141102607844702]
Training Loss (progress: 0.48), 0.17033017225491495, [0.00045053136828304246, 0.0015190518152707587, 0.0037082369062154067, 0.002170445631435701, 0.0021460953815519213, 0.004555909887225625], [0.970537146231219, 1.0871823866417492, 1.208569709014288, 1.1292607106640833, 1.2473226322796647, 1.4150688519596653]
Training Loss (progress: 0.56), 0.16671176593123893, [0.0004582290924603787, 0.001591420647869575, 0.0037628336373930257, 0.0021641601478362073, 0.0020780617665557043, 0.004580683143724987], [0.9704995472354059, 1.0871821591104434, 1.208990425813738, 1.1298080427905497, 1.2477098705411593, 1.415850202713161]
Training Loss (progress: 0.64), 0.18475226993607266, [0.00047749328272462746, 0.0015072255428794507, 0.003713345423054295, 0.0021398411373819708, 0.0021071833599040487, 0.004586243689036186], [0.9702098536932907, 1.0872510618310034, 1.2093457714630642, 1.129881660760498, 1.248229892870624, 1.4166135848969492]
Training Loss (progress: 0.72), 0.16229235116418303, [0.0004681749638537663, 0.0014759858635202837, 0.003745480966372094, 0.0020844136568422362, 0.0020763399419827526, 0.004600456280750463], [0.9700193334236218, 1.0873360112315045, 1.2098343260127784, 1.129827994488468, 1.2486089912717189, 1.417332517883579]
Training Loss (progress: 0.80), 0.15912016194539988, [0.00047844595279664576, 0.0015226389443214984, 0.0036478193008929534, 0.0022046581419030375, 0.002100784715337319, 0.00459522549409481], [0.9700935608121111, 1.0879009013290633, 1.2099538633799252, 1.129908971241834, 1.2490576657397534, 1.4181837220791804]
Training Loss (progress: 0.88), 0.1561442741753646, [0.00044740816969258615, 0.0015161640681655676, 0.0037296503607012923, 0.0022087242975392146, 0.002089401909241297, 0.004544019215820083], [0.9698953453067283, 1.088147220818536, 1.2102897104472417, 1.1300539713176088, 1.2496146204669887, 1.4189226498115608]
Training Loss (progress: 0.96), 0.1621436609535987, [0.00043746336399969304, 0.0015233277131809378, 0.003789839855342251, 0.0021827516523155828, 0.0020990770870692277, 0.004531805426460708], [0.9695729377197908, 1.0883361760054233, 1.2107033487910748, 1.1305152035543944, 1.2498704906328848, 1.4198088152211858]
Evaluation on validation dataset:
Step 25, mean loss 0.07504093664367835
Step 50, mean loss 0.03316960447731852
Step 75, mean loss 0.06419365344571458
Step 100, mean loss 0.06129467807666984
Step 125, mean loss 0.08594563955850626
Step 150, mean loss 0.06767470076660381
Step 175, mean loss 0.09683913959119422
Step 200, mean loss 0.18303437573082848
Step 225, mean loss 0.22123139291810426
Unrolled forward losses 2.5951753718665618
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 8.35473e-35, 1.33649e-11, 6.65575e-05, 6.27426e-08, 2.36010e-08, 3.78269e-04
Node: 21 (pos: 0.212): 1.74506e-38, 8.85571e-13, 2.30664e-05, 1.03205e-08, 3.45531e-09, 1.55466e-04
Node: 22 (pos: 0.222): 2.36029e-42, 5.10545e-14, 7.57117e-06, 1.54755e-09, 4.58407e-10, 6.10471e-05
Node: 23 (pos: 0.232): 2.06726e-46, 2.56092e-15, 2.35367e-06, 2.11537e-10, 5.51092e-11, 2.29029e-05
Node: 24 (pos: 0.242): 1.17247e-50, 1.11766e-16, 6.92989e-07, 2.63592e-11, 6.00351e-12, 8.20946e-06
Node: 25 (pos: 0.253): 4.30608e-55, 4.24401e-18, 1.93244e-07, 2.99420e-12, 5.92644e-13, 2.81147e-06
-
Node: 26 (pos: 0.263): 1.02409e-59, 1.40215e-19, 5.10371e-08, 3.10049e-13, 5.30140e-14, 9.19921e-07
Node: 27 (pos: 0.273): 1.57715e-64, 4.03054e-21, 1.27663e-08, 2.92673e-14, 4.29730e-15, 2.87583e-07
Node: 28 (pos: 0.283): 1.57283e-69, 1.00806e-22, 3.02442e-09, 2.51847e-15, 3.15652e-16, 8.58960e-08
Node: 29 (pos: 0.293): 1.01570e-74, 2.19360e-24, 6.78608e-10, 1.97557e-16, 2.10102e-17, 2.45120e-08
Node: 30 (pos: 0.303): 4.24743e-80, 4.15320e-26, 1.44210e-10, 1.41270e-17, 1.26724e-18, 6.68316e-09
Node: 31 (pos: 0.313): 1.15017e-85, 6.84162e-28, 2.90249e-11, 9.20894e-19, 6.92621e-20, 1.74093e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 1.09510e-16, 8.49174e-06, 1.22709e-02, 4.53489e-04, 3.02663e-04, 3.01251e-02
Node: 08 (pos: 0.081): 2.50327e-14, 4.83727e-05, 2.42041e-02, 1.44225e-03, 1.03719e-03, 5.32687e-02
Node: 09 (pos: 0.091): 3.70541e-12, 2.39748e-04, 4.52166e-02, 4.18137e-03, 3.22082e-03, 8.99935e-02
Node: 10 (pos: 0.101): 3.55173e-10, 1.03386e-03, 8.00031e-02, 1.10509e-02, 9.06320e-03, 1.45260e-01
Node: 11 (pos: 0.111): 2.20455e-08, 3.87900e-03, 1.34065e-01, 2.66243e-02, 2.31103e-02, 2.24016e-01
Node: 12 (pos: 0.121): 8.86085e-07, 1.26628e-02, 2.12776e-01, 5.84737e-02, 5.33995e-02, 3.30072e-01
-
Node: 00 (pos: 0.000): 1.74506e-38, 8.85571e-13, 2.30664e-05, 1.03205e-08, 3.45531e-09, 1.55466e-04
Node: 01 (pos: 0.010): 8.35473e-35, 1.33649e-11, 6.65575e-05, 6.27426e-08, 2.36010e-08, 3.78269e-04
Node: 02 (pos: 0.020): 2.59018e-31, 1.75492e-10, 1.81892e-04, 3.47716e-07, 1.46077e-07, 8.79355e-04
Node: 03 (pos: 0.030): 5.20000e-28, 2.00494e-09, 4.70790e-04, 1.75667e-06, 8.19296e-07, 1.95310e-03
Node: 04 (pos: 0.040): 6.76009e-25, 1.99296e-08, 1.15409e-03, 8.09013e-06, 4.16398e-06, 4.14458e-03
Node: 05 (pos: 0.051): 5.69086e-22, 1.72364e-07, 2.67950e-03, 3.39644e-05, 1.91771e-05, 8.40298e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.05751397363005502
Step 50, mean loss 0.02971406916535721
Step 75, mean loss 0.03670768572474208
Step 100, mean loss 0.04842854351158977
Step 125, mean loss 0.0606144840061079
Step 150, mean loss 0.1313839131901243
Step 175, mean loss 0.10998055830110298
Step 200, mean loss 0.17880433085275924
Step 225, mean loss 0.13299275216926632
Unrolled forward losses 1.9778076253140022
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.15026614988911768, [0.0004470370502270653, 0.0014764075539534175, 0.0037486270808714463, 0.0022003209108956935, 0.0020524018074578603, 0.004467053375216139], [0.9697160500749812, 1.0886007314663102, 1.210997050987133, 1.130617200690824, 1.2498384019244153, 1.4201424021024691]
Training Loss (progress: 0.08), 0.1596287800710776, [0.00046361034583923864, 0.0015148674239511264, 0.0036930812990693326, 0.002177795211113184, 0.002079428938981742, 0.004496661697918148], [0.9695076094763554, 1.0886779678649565, 1.2113238983146297, 1.1308401305174407, 1.2505133867598146, 1.4209745600634784]
Training Loss (progress: 0.16), 0.1594497305810364, [0.0004611340582799605, 0.0014980991047863653, 0.0036278804763557886, 0.002175329754088245, 0.0020134666685332247, 0.00452708837549953], [0.9693263703219722, 1.088829891084977, 1.2115368302817127, 1.1310263239309526, 1.250568458202646, 1.4217324056311393]
Training Loss (progress: 0.24), 0.1458519595899898, [0.0004503316157376018, 0.0015761186453922469, 0.003657230468484214, 0.0020851333994056907, 0.0019946097605214918, 0.004489215686466315], [0.9692456286925074, 1.0892038295849449, 1.2116143846270184, 1.1310814684777264, 1.25111263715677, 1.4224645390318758]
Training Loss (progress: 0.32), 0.1692112289439492, [0.0004581177461331103, 0.0014912449152193474, 0.0038038167902415963, 0.0022113945881061764, 0.002095523205363147, 0.004571410705783407], [0.9689398724250315, 1.0893915445830038, 1.212293420093671, 1.1314244977296637, 1.2514199378381061, 1.4230908917364815]
Training Loss (progress: 0.40), 0.16663728857547905, [0.0004564755058651133, 0.0014904956032534417, 0.003711302959587858, 0.0022056312811324238, 0.002030411659861918, 0.004483653758336044], [0.9688319189730309, 1.0894508552673308, 1.2125400568483344, 1.1314025528958225, 1.2518858973002411, 1.4236679196339155]
Training Loss (progress: 0.48), 0.15650445797352538, [0.0004225422370765684, 0.0014761702940982461, 0.0037456078414549974, 0.002266104426287786, 0.0020124055810292834, 0.004494762713674562], [0.9684054205101239, 1.089609344014641, 1.2131131964759791, 1.1317438207391672, 1.2521467679977765, 1.4245387964372218]
Training Loss (progress: 0.56), 0.1515911649355654, [0.0004628121149469994, 0.0015307967091994586, 0.003721666978750063, 0.002164088970255465, 0.002096314369425113, 0.004440667382330396], [0.968216811211796, 1.089870190248599, 1.2134779505517452, 1.1317943924900482, 1.2529788020158104, 1.4252102005921976]
Training Loss (progress: 0.64), 0.17631462358187872, [0.00043077055972844504, 0.0015907980130596025, 0.0037260732112028953, 0.002170195427621317, 0.0020710593915922856, 0.0044845480858587946], [0.9679969720719817, 1.0901239295483827, 1.2136062052791752, 1.1321978552772045, 1.2533893690447584, 1.4259251244611033]
Training Loss (progress: 0.72), 0.16357071147154686, [0.0004541094784302198, 0.001513622652204375, 0.0036570819158214312, 0.002167952680622765, 0.0021134618739077574, 0.004459235512867675], [0.9680453882904099, 1.0902694435416422, 1.213752188027587, 1.1325042097124827, 1.253743005956909, 1.4263990340747195]
Training Loss (progress: 0.80), 0.15644443215836434, [0.0004555123407033002, 0.001530080582756968, 0.003709893110217613, 0.0021390660341921437, 0.002087402360568213, 0.00442615347290323], [0.9677069318389118, 1.0906978152462299, 1.2141117757217785, 1.1325619599829975, 1.2542429752927893, 1.4271820451831387]
Training Loss (progress: 0.88), 0.15794598034491153, [0.0004295604767762838, 0.001470182057036924, 0.0037012781964591156, 0.002174711227202003, 0.0020354954750661245, 0.004454333416076236], [0.9676297649608938, 1.090894646014626, 1.2143234579176214, 1.1325151361355328, 1.2545035969276355, 1.4278937592970344]
Training Loss (progress: 0.96), 0.14826727612959206, [0.0004609413733729797, 0.0015092833139341965, 0.00371142634779393, 0.002216860937734799, 0.0020638065023177283, 0.004458602404593216], [0.9672884179474256, 1.0911550933603, 1.2146580784931604, 1.1328341222967218, 1.2550224160116454, 1.4287234862595053]
Evaluation on validation dataset:
Step 25, mean loss 0.0720131154384843
Step 50, mean loss 0.028229392716762836
Step 75, mean loss 0.06110571499187392
Step 100, mean loss 0.059918451096143945
Step 125, mean loss 0.08013366709484963
Step 150, mean loss 0.06537138766107774
Step 175, mean loss 0.09458306132790206
Step 200, mean loss 0.20174390540116602
Step 225, mean loss 0.24139285433875052
Unrolled forward losses 2.2689102399738674
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 1.13338e-36, 2.48747e-11, 5.43619e-05, 6.55011e-08, 3.03374e-08, 3.77781e-04
Node: 21 (pos: 0.212): 1.48806e-40, 1.76219e-12, 1.84263e-05, 1.08220e-08, 4.56157e-09, 1.55137e-04
Node: 22 (pos: 0.222): 1.23538e-44, 1.08991e-13, 5.90861e-06, 1.63030e-09, 6.22376e-10, 6.08654e-05
Node: 23 (pos: 0.232): 6.48507e-49, 5.88526e-15, 1.79241e-06, 2.23938e-10, 7.70535e-11, 2.28141e-05
Node: 24 (pos: 0.242): 2.15261e-53, 2.77449e-16, 5.14393e-07, 2.80471e-11, 8.65634e-12, 8.16986e-06
Node: 25 (pos: 0.253): 4.51804e-58, 1.14194e-17, 1.39655e-07, 3.20295e-12, 8.82425e-13, 2.79514e-06
-
Node: 26 (pos: 0.263): 5.99614e-63, 4.10337e-19, 3.58694e-08, 3.33512e-13, 8.16250e-14, 9.13633e-07
Node: 27 (pos: 0.273): 5.03186e-68, 1.28730e-20, 8.71558e-09, 3.16646e-14, 6.85126e-15, 2.85310e-07
Node: 28 (pos: 0.283): 2.67006e-73, 3.52583e-22, 2.00342e-09, 2.74117e-15, 5.21819e-16, 8.51220e-08
Node: 29 (pos: 0.293): 8.95880e-79, 8.43108e-24, 4.35666e-10, 2.16371e-16, 3.60637e-17, 2.42630e-08
Node: 30 (pos: 0.303): 1.90070e-84, 1.76013e-25, 8.96272e-11, 1.55727e-17, 2.26164e-18, 6.60732e-09
Node: 31 (pos: 0.313): 2.54984e-90, 3.20811e-27, 1.74434e-11, 1.02194e-18, 1.28700e-19, 1.71903e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 1.46070e-17, 1.13721e-05, 1.11799e-02, 4.63236e-04, 3.41193e-04, 3.02082e-02
Node: 08 (pos: 0.081): 4.49643e-15, 6.20629e-05, 2.23680e-02, 1.46908e-03, 1.14942e-03, 5.34438e-02
Node: 09 (pos: 0.091): 8.75203e-13, 2.95708e-04, 4.23371e-02, 4.24807e-03, 3.51363e-03, 9.03331e-02
Node: 10 (pos: 0.101): 1.07717e-10, 1.23008e-03, 7.58091e-02, 1.12005e-02, 9.74623e-03, 1.45873e-01
Node: 11 (pos: 0.111): 8.38296e-09, 4.46732e-03, 1.28418e-01, 2.69266e-02, 2.45312e-02, 2.25051e-01
Node: 12 (pos: 0.121): 4.12520e-07, 1.41645e-02, 2.05795e-01, 5.90239e-02, 5.60277e-02, 3.31716e-01
-
Node: 00 (pos: 0.000): 1.48806e-40, 1.76219e-12, 1.84263e-05, 1.08220e-08, 4.56157e-09, 1.55137e-04
Node: 01 (pos: 0.010): 1.13338e-36, 2.48747e-11, 5.43619e-05, 6.55011e-08, 3.03374e-08, 3.77781e-04
Node: 02 (pos: 0.020): 5.45844e-33, 3.06551e-10, 1.51725e-04, 3.61485e-07, 1.83081e-07, 8.78904e-04
Node: 03 (pos: 0.030): 1.66225e-29, 3.29829e-09, 4.00611e-04, 1.81899e-06, 1.00256e-06, 1.95354e-03
Node: 04 (pos: 0.040): 3.20081e-26, 3.09825e-08, 1.00068e-03, 8.34591e-06, 4.98174e-06, 4.14840e-03
Node: 05 (pos: 0.051): 3.89725e-23, 2.54088e-07, 2.36467e-03, 3.49153e-05, 2.24622e-05, 8.41622e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.0549560916399904
Step 50, mean loss 0.02542523192800581
Step 75, mean loss 0.03492779747540187
Step 100, mean loss 0.051395423243930274
Step 125, mean loss 0.061399628819416206
Step 150, mean loss 0.10983842878071771
Step 175, mean loss 0.1099408137006164
Step 200, mean loss 0.15119005611710956
Step 225, mean loss 0.12267787840350003
Unrolled forward losses 1.703433307319815
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.16393776994268608, [0.00045657158930812987, 0.0014895582864556786, 0.003765403623360894, 0.0022209232277144494, 0.002105079665896789, 0.004464523162503116], [0.9671660591645819, 1.0912033067855484, 1.2147888707603687, 1.1329855522165546, 1.2552488249907319, 1.4291588551932224]
Training Loss (progress: 0.08), 0.16237333957207845, [0.00044537628675330647, 0.0015342994304818024, 0.0036964563811173537, 0.0021599420208435597, 0.0021201961662396514, 0.004562394701231564], [0.967130335262964, 1.091493499043682, 1.2148498969816657, 1.1331622449899463, 1.255520968141346, 1.4297117243252833]
Training Loss (progress: 0.16), 0.16240826472357514, [0.0004502901254893813, 0.001576389920322621, 0.0036143351730913206, 0.002195869162076505, 0.0020377716606509327, 0.0044950927414387715], [0.966688531789408, 1.0916165720089843, 1.2152279484665867, 1.1332148670362907, 1.2559396578871442, 1.4303527990671232]
Training Loss (progress: 0.24), 0.15783036980616955, [0.0004446833425831798, 0.0015406928939355694, 0.0036852407609100327, 0.0021956057265827356, 0.001997862869815743, 0.004465354950399053], [0.9664169250195086, 1.091993771841632, 1.215534079746183, 1.1332788034596495, 1.256176485698457, 1.4308188298876858]
Training Loss (progress: 0.32), 0.14719410753819176, [0.0004587590186724999, 0.0015206592886710252, 0.0037393042746280236, 0.0022089931357110494, 0.002168438266559925, 0.004587084869708653], [0.9662074437196121, 1.092084028257652, 1.2158076488593448, 1.1334967258444972, 1.2567509717954766, 1.431433624240824]
Training Loss (progress: 0.40), 0.16785824145842318, [0.00044264202445154103, 0.0014765626473128657, 0.0037516065637836424, 0.002217090229782192, 0.002018474272215105, 0.004520559568249437], [0.9658695402496249, 1.0924623806934541, 1.2160177888352857, 1.1336408242913496, 1.2571403472979954, 1.4322938677662955]
Training Loss (progress: 0.48), 0.15890736791597038, [0.00043721035919883837, 0.001521270442705261, 0.003687193769125183, 0.0021856440567410407, 0.0020468813030905457, 0.004502319646277611], [0.9657579844177554, 1.0926014224672618, 1.2162609551118335, 1.134069942028477, 1.2572254320660143, 1.432942892933403]
Training Loss (progress: 0.56), 0.15169892651424408, [0.00041363478159482826, 0.001473517877203565, 0.0036784708892505977, 0.002213054646638157, 0.002058217828862256, 0.004445617656917112], [0.9656991107359989, 1.0930215890302488, 1.2165618675081606, 1.133968393902989, 1.2575552888439252, 1.4334781145549882]
Training Loss (progress: 0.64), 0.13805550333860886, [0.00044171657110977214, 0.0015161806945950171, 0.003700509063460017, 0.0022118076320976304, 0.0020285694642023675, 0.004487110488407218], [0.9654878183241574, 1.0932045874789424, 1.216703353006067, 1.134195272766751, 1.2580140162167195, 1.433982625115533]
Training Loss (progress: 0.72), 0.14422111469385424, [0.0004333839119566752, 0.0015377159667087298, 0.003707262119492408, 0.002130861512242981, 0.002084699372728851, 0.00440594363991291], [0.96533839317488, 1.093371312248076, 1.2170428465011023, 1.1343421675326706, 1.2583221612833564, 1.4346884759365413]
Training Loss (progress: 0.80), 0.15251008155300805, [0.00045304112870747334, 0.0014971805938794548, 0.003705156672162503, 0.002161169657640811, 0.0021364466111704846, 0.004464617421170557], [0.9651143692183276, 1.0936812917889702, 1.2173418402857163, 1.1344929395772994, 1.2587331778025668, 1.4352487652279808]
Training Loss (progress: 0.88), 0.15261322784721776, [0.0004397025515760202, 0.0015231493191579816, 0.0036701104737791473, 0.0021216901664025305, 0.0021390011872340843, 0.004491393255121733], [0.9648909058735035, 1.0937501053591425, 1.2173262805221614, 1.134906825577601, 1.2591716688523065, 1.4360261580704399]
Training Loss (progress: 0.96), 0.15864257162516954, [0.0004438496027200103, 0.0014945045153032148, 0.0036686324358381024, 0.002176861301213602, 0.0021215544873106145, 0.004399566571122504], [0.9646985516766472, 1.093978550279154, 1.217475122133263, 1.134867284386776, 1.2598330005417215, 1.4366740819092083]
Evaluation on validation dataset:
Step 25, mean loss 0.06981255421200372
Step 50, mean loss 0.027929557282591194
Step 75, mean loss 0.05597232279174827
Step 100, mean loss 0.05312194832687895
Step 125, mean loss 0.07481837877839839
Step 150, mean loss 0.061573348001923864
Step 175, mean loss 0.0934805168578737
Step 200, mean loss 0.20447495825919249
Step 225, mean loss 0.21885310882713407
Unrolled forward losses 2.2491160479128682
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 5.90418e-37, 4.19970e-11, 4.67403e-05, 4.14890e-08, 1.96689e-08, 3.16473e-04
Node: 21 (pos: 0.212): 7.22666e-41, 3.14748e-12, 1.55826e-05, 6.52359e-09, 2.82109e-09, 1.27423e-04
Node: 22 (pos: 0.222): 5.57299e-45, 2.06539e-13, 4.91050e-06, 9.32905e-10, 3.66272e-10, 4.89664e-05
Node: 23 (pos: 0.232): 2.70778e-49, 1.18668e-14, 1.46267e-06, 1.21335e-10, 4.30468e-11, 1.79592e-05
Node: 24 (pos: 0.242): 8.28915e-54, 5.96983e-16, 4.11816e-07, 1.43527e-11, 4.57962e-12, 6.28661e-06
Node: 25 (pos: 0.253): 1.59875e-58, 2.62957e-17, 1.09596e-07, 1.54410e-12, 4.41030e-13, 2.10031e-06
-
Node: 26 (pos: 0.263): 1.94279e-63, 1.01415e-18, 2.75692e-08, 1.51084e-13, 3.84465e-14, 6.69716e-07
Node: 27 (pos: 0.273): 1.48745e-68, 3.42462e-20, 6.55525e-09, 1.34449e-14, 3.03387e-15, 2.03815e-07
Node: 28 (pos: 0.283): 7.17518e-74, 1.01255e-21, 1.47329e-09, 1.08816e-15, 2.16714e-16, 5.91999e-08
Node: 29 (pos: 0.293): 2.18070e-79, 2.62131e-23, 3.12986e-10, 8.00992e-17, 1.40129e-17, 1.64114e-08
Node: 30 (pos: 0.303): 4.17574e-85, 5.94174e-25, 6.28488e-11, 5.36241e-18, 8.20199e-19, 4.34218e-09
Node: 31 (pos: 0.313): 5.03783e-91, 1.17924e-26, 1.19290e-11, 3.26505e-19, 4.34571e-20, 1.09650e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 1.07481e-17, 1.45526e-05, 1.04292e-02, 3.74423e-04, 2.79078e-04, 2.78861e-02
Node: 08 (pos: 0.081): 3.46071e-15, 7.66052e-05, 2.10888e-02, 1.22572e-03, 9.69043e-04, 4.99632e-02
Node: 09 (pos: 0.091): 7.02058e-13, 3.53078e-04, 4.03078e-02, 3.64938e-03, 3.04587e-03, 8.54380e-02
Node: 10 (pos: 0.101): 8.97334e-11, 1.42488e-03, 7.28220e-02, 9.88199e-03, 8.66623e-03, 1.39441e-01
Node: 11 (pos: 0.111): 7.22617e-09, 5.03477e-03, 1.24358e-01, 2.43370e-02, 2.23203e-02, 2.17205e-01
Node: 12 (pos: 0.121): 3.66637e-07, 1.55767e-02, 2.00732e-01, 5.45114e-02, 5.20379e-02, 3.22915e-01
-
Node: 00 (pos: 0.000): 7.22666e-41, 3.14748e-12, 1.55826e-05, 6.52359e-09, 2.82109e-09, 1.27423e-04
Node: 01 (pos: 0.010): 5.90418e-37, 4.19970e-11, 4.67403e-05, 4.14890e-08, 1.96689e-08, 3.16473e-04
Node: 02 (pos: 0.020): 3.03917e-33, 4.90647e-10, 1.32519e-04, 2.39981e-07, 1.24135e-07, 7.50178e-04
Node: 03 (pos: 0.030): 9.85652e-30, 5.01896e-09, 3.55141e-04, 1.26246e-06, 7.09186e-07, 1.69719e-03
Node: 04 (pos: 0.040): 2.01403e-26, 4.49525e-08, 8.99621e-04, 6.04030e-06, 3.66754e-06, 3.66469e-03
Node: 05 (pos: 0.051): 2.59287e-23, 3.52524e-07, 2.15404e-03, 2.62842e-05, 1.71689e-05, 7.55234e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.05419181827844358
Step 50, mean loss 0.025461938272713966
Step 75, mean loss 0.033037764597751595
Step 100, mean loss 0.04715666805097922
Step 125, mean loss 0.05533195431499533
Step 150, mean loss 0.11093189493141364
Step 175, mean loss 0.0942161402115477
Step 200, mean loss 0.16238492025789794
Step 225, mean loss 0.12550912299352643
Unrolled forward losses 1.7325816063069923
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.15254332495462353, [0.0004370561194309755, 0.001473425636690374, 0.0037839378149399157, 0.0021662540906155748, 0.0020573576832178036, 0.004447486684493096], [0.9643740065827987, 1.0940349779113543, 1.217544631855046, 1.1349943731253858, 1.2598141937640455, 1.4370467107633909]
Training Loss (progress: 0.08), 0.15591635867166412, [0.00044103701237824873, 0.001523826567337397, 0.003638729726006033, 0.0021452747414779706, 0.0021265286203966975, 0.004546139223941597], [0.964056600637047, 1.094457152241857, 1.2179244481284905, 1.135170817238134, 1.2602269190238147, 1.4377109260947882]
Training Loss (progress: 0.16), 0.1583178514005071, [0.00043962932326528707, 0.0014525013916778654, 0.003735316716195674, 0.0021942771754775428, 0.002046274911483626, 0.004453775533276838], [0.9639468905395308, 1.0946657684877603, 1.2182585729867117, 1.1353746795423094, 1.2605945999216315, 1.4382188513007297]
Training Loss (progress: 0.24), 0.1525782324872311, [0.0004545023345761001, 0.001461189869050136, 0.003666909580072541, 0.0021765546216087157, 0.002104274110139557, 0.004465306971635255], [0.9636132400245219, 1.0949891323212446, 1.2185343719168615, 1.135391873941312, 1.2606735251859613, 1.438871433092993]
Training Loss (progress: 0.32), 0.1427029256125079, [0.00043792683308243506, 0.0014985069647214689, 0.0036448784724509376, 0.00216062284636304, 0.0020651767751017993, 0.004431965026098426], [0.9633542400147974, 1.0951635247978442, 1.2187328308861733, 1.1355493772493823, 1.261094313244773, 1.4392188465711724]
Training Loss (progress: 0.40), 0.15216214661787472, [0.00045579405754051904, 0.0014991095777269084, 0.0036714154413047765, 0.002211150490024686, 0.0021002954463362747, 0.004475940438787542], [0.963152813911904, 1.0954363504125246, 1.2190734945252213, 1.1356955475914063, 1.2615378941532287, 1.4399671609022147]
Training Loss (progress: 0.48), 0.1642570410679832, [0.0004489870693179205, 0.0015011460148938482, 0.0037185653359215333, 0.0021795310125535296, 0.001994699994096656, 0.004493415215760764], [0.9630871297231608, 1.095779602162581, 1.2191335617254844, 1.1357633016139859, 1.2618821078732603, 1.4405803988768364]
Training Loss (progress: 0.56), 0.16407045232338097, [0.0004536395929456218, 0.0015188792521591895, 0.0037011864385349123, 0.002148800577351675, 0.002176232083198796, 0.0045246092861544384], [0.9626922549870417, 1.095593172532182, 1.2192378126267924, 1.1359613285026153, 1.2623337693018513, 1.4409341723867966]
Training Loss (progress: 0.64), 0.14763836281869255, [0.0004479815512575506, 0.0014867598316536871, 0.003679457028991089, 0.0021811608675722963, 0.0020710586976127134, 0.004490757071297222], [0.9625974710126292, 1.0958142848707082, 1.2196015661115436, 1.1359832835134103, 1.2628621509208175, 1.4415665053230926]
Training Loss (progress: 0.72), 0.1596117502014235, [0.0004556305879755872, 0.0014703002177979046, 0.0036733247548972397, 0.0022169960945104903, 0.0020987877984832487, 0.004523235448153668], [0.9622453996542931, 1.0963737404334952, 1.2198991880591765, 1.136106981197651, 1.2631204821992577, 1.4420559503427255]
Training Loss (progress: 0.80), 0.15159543450303697, [0.0004414631202893754, 0.0014464316610565955, 0.003688951169585142, 0.0022066928143831257, 0.002113793332982317, 0.004499739693598811], [0.9619620344940879, 1.0965667730488844, 1.2200863195152136, 1.1363366777712036, 1.263565223314038, 1.4425068535088008]
Training Loss (progress: 0.88), 0.14934535310514505, [0.0004106644171625789, 0.0015284342547084886, 0.003724425554867071, 0.0022232884111801146, 0.00210092620719344, 0.004468409240586531], [0.96178431017989, 1.096676282351921, 1.2201140113107518, 1.1367722605151434, 1.2636717860037914, 1.4431500938700061]
Training Loss (progress: 0.96), 0.1553926717699106, [0.00043625997314346955, 0.0015295455109996883, 0.003734054671320213, 0.002189166045977458, 0.0020588493428712763, 0.00451671672257367], [0.961230635508603, 1.0971317842155528, 1.2204017579260695, 1.1366072708995303, 1.2638737854149114, 1.443887930521931]
Evaluation on validation dataset:
Step 25, mean loss 0.06068578313897004
Step 50, mean loss 0.02717864674879851
Step 75, mean loss 0.06049748239932884
Step 100, mean loss 0.05906173366311417
Step 125, mean loss 0.07915470795790758
Step 150, mean loss 0.0643609956052123
Step 175, mean loss 0.0908217024426837
Step 200, mean loss 0.2075449542434542
Step 225, mean loss 0.1914404305358242
Unrolled forward losses 2.273362193401715
Unrolled forward base losses 2.565701273852575
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.14846718517161847, [0.00044855311048369004, 0.0014760011953001766, 0.0037436152724789587, 0.0021540080094629363, 0.0020741335034859367, 0.004412500902862192], [0.9612443472802389, 1.097107278424513, 1.2206041737118434, 1.1368743060487647, 1.2641986585374319, 1.4442493435077983]
Training Loss (progress: 0.08), 0.15045634040396114, [0.00044173432598584037, 0.0014488047838379392, 0.0036747892425964134, 0.0021646412056874308, 0.0019939908244803006, 0.0044271603160394015], [0.9611233801019702, 1.0973592411610145, 1.2207137484890913, 1.1368825645770573, 1.2645902020616242, 1.444735085121753]
Training Loss (progress: 0.16), 0.15584535511264597, [0.0004634309902249838, 0.0014298830004600496, 0.003625289533712606, 0.0022055353524029118, 0.0020951012186083864, 0.004479189144769089], [0.9607826943057223, 1.0975277668630898, 1.2209547909676366, 1.1369497342568466, 1.2648828456622032, 1.4453934121864298]
Training Loss (progress: 0.24), 0.15820541010314787, [0.0004700246605711443, 0.0014425488672468543, 0.0037510812754592386, 0.002179563563729517, 0.0019680888891187224, 0.004413973775833432], [0.9606394821509182, 1.097922845156154, 1.221200007739754, 1.1372898336532145, 1.2653250470184882, 1.4459260248617567]
Training Loss (progress: 0.32), 0.15340563323450127, [0.00045710528757270075, 0.0015053366136845631, 0.003647414666104299, 0.0021885967126936095, 0.00211148424279702, 0.004537870251989524], [0.9602943245763056, 1.0979962056259431, 1.2213998790170062, 1.1371904658179333, 1.265699706951647, 1.446611233845331]
Training Loss (progress: 0.40), 0.15348010820961747, [0.0004522924553859413, 0.001507012290177292, 0.0037308122312914066, 0.0022114498569604886, 0.0020211246176119403, 0.004537055240891274], [0.9601076242132123, 1.0981483328391453, 1.2215326716064694, 1.1376951948115046, 1.265921910256186, 1.4471361726518928]
Training Loss (progress: 0.48), 0.15348420850998715, [0.00045356712761912755, 0.0014873203386020716, 0.00364568260644261, 0.002153033755407844, 0.002048343631010511, 0.004459897463801949], [0.9598497522713273, 1.098391279870972, 1.2216514808429064, 1.1379034180061587, 1.2662828783268398, 1.4475637419290917]
Training Loss (progress: 0.56), 0.15447830804003848, [0.0004569979516795316, 0.0014735750165382785, 0.003684623689191269, 0.002183389298000457, 0.002098558894079196, 0.004422993335307658], [0.9595676550037169, 1.0985378138056483, 1.2217084407598109, 1.1380996385798925, 1.2664181186359427, 1.4481306978098754]
Training Loss (progress: 0.64), 0.14194954565750165, [0.00044144888209157426, 0.0014378738221665125, 0.003768149034201753, 0.0022066507284800624, 0.0020846664930109712, 0.004471373740743481], [0.9594454944821493, 1.0986218257823412, 1.2220043499959108, 1.1381602039673926, 1.2667487307570582, 1.448724758108077]
Training Loss (progress: 0.72), 0.1609532470197314, [0.00046673022541039266, 0.0015233183189635358, 0.0036914762354098257, 0.002187815005271132, 0.002094749390139203, 0.004492479360150187], [0.9590078245132038, 1.0989628731267873, 1.2221892271882386, 1.1381423395448849, 1.267100689702562, 1.4491549367098362]
Training Loss (progress: 0.80), 0.150746006852527, [0.00045115301045831074, 0.0015644903250942943, 0.0037178213266948713, 0.002145330168615301, 0.0021049900085568195, 0.004422924796699636], [0.9589907776015604, 1.0991907248714343, 1.2225012673073938, 1.138103304503932, 1.26749328924987, 1.4497169998977735]
Training Loss (progress: 0.88), 0.1484949667332797, [0.0004825365896794903, 0.0015492813736635192, 0.003735892636225038, 0.002181400987556721, 0.0020865383395731693, 0.004491440876579911], [0.9583973413102153, 1.09918285631028, 1.2227677462606612, 1.1383905048346084, 1.2677068130338165, 1.4501659138905396]
Training Loss (progress: 0.96), 0.16251570551380162, [0.00044949457129647713, 0.0014998332484118955, 0.003616577095414267, 0.0021639413356021532, 0.0021427344365293303, 0.004473012574239057], [0.9582669399670869, 1.0992362331548042, 1.222698003979726, 1.13853638231605, 1.2679145264078462, 1.4505589963857932]
Evaluation on validation dataset:
Step 25, mean loss 0.06059645436016904
Step 50, mean loss 0.024430217523394034
Step 75, mean loss 0.05466722686342279
Step 100, mean loss 0.060878987758158226
Step 125, mean loss 0.07499928039306758
Step 150, mean loss 0.05774911280945946
Step 175, mean loss 0.08479877539581371
Step 200, mean loss 0.18238168844687452
Step 225, mean loss 0.22998150138186363
Unrolled forward losses 2.208259377525864
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 3.69053e-35, 7.23869e-12, 5.75771e-05, 5.13892e-08, 4.24426e-08, 3.84947e-04
Node: 21 (pos: 0.212): 7.06641e-39, 4.48420e-13, 1.96234e-05, 8.26626e-09, 6.61010e-09, 1.58143e-04
Node: 22 (pos: 0.222): 8.72264e-43, 2.40859e-14, 6.32887e-06, 1.21074e-09, 9.35833e-10, 6.20710e-05
Node: 23 (pos: 0.232): 6.94123e-47, 1.12174e-15, 1.93154e-06, 1.61471e-10, 1.20441e-10, 2.32763e-05
Node: 24 (pos: 0.242): 3.56093e-51, 4.52976e-17, 5.57840e-07, 1.96086e-11, 1.40907e-11, 8.33923e-06
Node: 25 (pos: 0.253): 1.17769e-55, 1.58603e-18, 1.52455e-07, 2.16821e-12, 1.49858e-12, 2.85447e-06
-
Node: 26 (pos: 0.263): 2.51093e-60, 4.81502e-20, 3.94276e-08, 2.18303e-13, 1.44880e-13, 9.33495e-07
Node: 27 (pos: 0.273): 3.45128e-65, 1.26747e-21, 9.64909e-09, 2.00135e-14, 1.27328e-14, 2.91666e-07
Node: 28 (pos: 0.283): 3.05818e-70, 2.89289e-23, 2.23460e-09, 1.67067e-15, 1.01724e-15, 8.70656e-08
Node: 29 (pos: 0.293): 1.74697e-75, 5.72502e-25, 4.89710e-10, 1.26988e-16, 7.38768e-17, 2.48310e-08
Node: 30 (pos: 0.303): 6.43349e-81, 9.82371e-27, 1.01556e-10, 8.78901e-18, 4.87728e-18, 6.76597e-09
Node: 31 (pos: 0.313): 1.52738e-86, 1.46159e-28, 1.99296e-11, 5.53887e-19, 2.92706e-19, 1.76138e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 7.42241e-17, 6.40640e-06, 1.15257e-02, 4.14615e-04, 4.01469e-04, 3.07205e-02
Node: 08 (pos: 0.081): 1.79394e-14, 3.81028e-05, 2.29790e-02, 1.33764e-03, 1.32233e-03, 5.43361e-02
Node: 09 (pos: 0.091): 2.79517e-12, 1.96495e-04, 4.33533e-02, 3.92951e-03, 3.95927e-03, 9.18197e-02
Node: 10 (pos: 0.101): 2.80769e-10, 8.78619e-04, 7.73998e-02, 1.05109e-02, 1.07764e-02, 1.48242e-01
Node: 11 (pos: 0.111): 1.81815e-08, 3.40644e-03, 1.30763e-01, 2.56005e-02, 2.66635e-02, 2.28661e-01
Node: 12 (pos: 0.121): 7.59010e-07, 1.14513e-02, 2.09053e-01, 5.67756e-02, 5.99715e-02, 3.36977e-01
-
Node: 00 (pos: 0.000): 7.06641e-39, 4.48420e-13, 1.96234e-05, 8.26626e-09, 6.61010e-09, 1.58143e-04
Node: 01 (pos: 0.010): 3.69053e-35, 7.23869e-12, 5.75771e-05, 5.13892e-08, 4.24426e-08, 3.84947e-04
Node: 02 (pos: 0.020): 1.24256e-31, 1.01318e-10, 1.59865e-04, 2.90897e-07, 2.47732e-07, 8.95235e-04
Node: 03 (pos: 0.030): 2.69702e-28, 1.22961e-09, 4.20031e-04, 1.49938e-06, 1.31446e-06, 1.98912e-03
Node: 04 (pos: 0.040): 3.77391e-25, 1.29390e-08, 1.04433e-03, 7.03702e-06, 6.34009e-06, 4.22253e-03
Node: 05 (pos: 0.051): 3.40437e-22, 1.18055e-07, 2.45709e-03, 3.00725e-05, 2.77990e-05, 8.56388e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.04700650131137851
Step 50, mean loss 0.023163067510767618
Step 75, mean loss 0.03493285230796207
Step 100, mean loss 0.04772806898363342
Step 125, mean loss 0.06099867019306708
Step 150, mean loss 0.10052789466350348
Step 175, mean loss 0.10224361281978135
Step 200, mean loss 0.1790990497877215
Step 225, mean loss 0.12344851310000837
Unrolled forward losses 1.7618244609148976
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00), 0.13820139403690337, [0.00045956292802371744, 0.0014594338973584783, 0.0037285704472181463, 0.0022160366361731495, 0.0021498215420402184, 0.0044674225130481695], [0.9581236262652486, 1.0994601428710087, 1.2229497644191487, 1.1387051110971844, 1.268270554263523, 1.4508446574969829]
Training Loss (progress: 0.08), 0.1386046398509879, [0.0004483487680973235, 0.0014888296241257451, 0.0036648009613524783, 0.0021759129044551817, 0.0021097060031532414, 0.004432633001393964], [0.9581302285586503, 1.0995843275285546, 1.223050671163497, 1.1388519229188654, 1.2684340960306049, 1.4510950296883076]
Training Loss (progress: 0.16), 0.1336672980101679, [0.0004538661147139797, 0.0014489531289667511, 0.0036541543641405412, 0.0021943191151422813, 0.002122561978034182, 0.004489564779965246], [0.9581022993923962, 1.0996997644306732, 1.2232927573719452, 1.1388980795076535, 1.2685151745877645, 1.4513968467068352]
Training Loss (progress: 0.24), 0.1355176634957271, [0.00046510697924885997, 0.0014538627665503748, 0.003671333231982005, 0.00221193718381156, 0.0020712336151290285, 0.004490256260940079], [0.9581408106821601, 1.0998608608369462, 1.2234313917257884, 1.1388949886336956, 1.2686787954367038, 1.4516808648102117]
Training Loss (progress: 0.32), 0.13858887754834093, [0.0004456591428008047, 0.00147427324414585, 0.0036942711726311414, 0.0021846315085383753, 0.002082702213454623, 0.004462061826923222], [0.9580639802565014, 1.0999132258212607, 1.2236671194945097, 1.1391195602083064, 1.268852807264497, 1.451993903887835]
Training Loss (progress: 0.40), 0.14272324014551174, [0.0004503435362520618, 0.0014831441099088156, 0.0037000610127605614, 0.0021840768571103632, 0.002128547144181463, 0.00446620327043376], [0.9578608657711826, 1.1000886169155173, 1.2237881345702721, 1.1390377073329057, 1.269051660176089, 1.4523605324029645]
Training Loss (progress: 0.48), 0.13775809326960037, [0.00043907335567652025, 0.001509072969042194, 0.0036846622171490635, 0.0021790392038258735, 0.0020629615907347323, 0.004470156825805144], [0.9577804633713561, 1.1001938766209665, 1.2239045121138334, 1.1391447855607506, 1.269290796529584, 1.4527080691114984]
Training Loss (progress: 0.56), 0.1421143668328661, [0.00044923981731711, 0.0014939157738122855, 0.0037155113735380676, 0.0021884161716364528, 0.0020987164112542915, 0.0044573685370647926], [0.9577457898627075, 1.1003729393624018, 1.2240302525954463, 1.1391244520396941, 1.269431522962086, 1.4530191026128074]
Training Loss (progress: 0.64), 0.1455796673986914, [0.0004482831622694023, 0.0014658239755249382, 0.0036635571236904563, 0.002203913881026521, 0.0021020754887435484, 0.004446883937756559], [0.9576966683387329, 1.1003099036732003, 1.2241087070945997, 1.1391864710096735, 1.26958175535821, 1.4533098364855166]
Training Loss (progress: 0.72), 0.12706102964919172, [0.0004559818890714693, 0.001461948401630193, 0.0036785941729948926, 0.0021907589367801783, 0.0021240507912942924, 0.004445098395178663], [0.9576578541914808, 1.1004095506956928, 1.2242847493394124, 1.1394316702954697, 1.269799510060877, 1.4535544392458253]
Training Loss (progress: 0.80), 0.12745267578533806, [0.0004580255070291145, 0.0014925938589005184, 0.003725323239295856, 0.002189565724836636, 0.0020849132908918656, 0.00447816625492441], [0.9575735869907497, 1.100457252946113, 1.2244090607313303, 1.1394522174229729, 1.2700534423903653, 1.4539153489428036]
Training Loss (progress: 0.88), 0.14970290169964895, [0.0004384347760675748, 0.001448657744885062, 0.0037078933467750127, 0.0022003673978399406, 0.002067707859287541, 0.0044715186164730105], [0.9575689961597021, 1.1006198997972216, 1.2245671430660807, 1.1395388865331098, 1.2701350560136364, 1.4542264331797943]
Training Loss (progress: 0.96), 0.13495017972630532, [0.00044109452037116505, 0.0014607292179923267, 0.0036620446062593406, 0.0021995380828115437, 0.002107294693167669, 0.004446543664767217], [0.9576564599875433, 1.1007339323688348, 1.2247491777845678, 1.1395894152760249, 1.270319874741483, 1.4544994830192948]
Evaluation on validation dataset:
Step 25, mean loss 0.05161176054048017
Step 50, mean loss 0.02245007721871174
Step 75, mean loss 0.05193689754335881
Step 100, mean loss 0.05081021748159214
Step 125, mean loss 0.06554369749079667
Step 150, mean loss 0.05619154808641033
Step 175, mean loss 0.0786378231759155
Step 200, mean loss 0.1777578456731443
Step 225, mean loss 0.19615305095105634
Unrolled forward losses 1.9457382952156568
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 8.05429e-37, 1.61009e-11, 5.07916e-05, 4.81042e-08, 4.05996e-08, 3.57924e-04
Node: 21 (pos: 0.212): 1.02026e-40, 1.08724e-12, 1.70750e-05, 7.68214e-09, 6.29167e-09, 1.45849e-04
Node: 22 (pos: 0.222): 8.15702e-45, 6.39404e-14, 5.42816e-06, 1.11667e-09, 8.86102e-10, 5.67571e-05
Node: 23 (pos: 0.232): 4.11614e-49, 3.27490e-15, 1.63179e-06, 1.47745e-10, 1.13416e-10, 2.10932e-05
Node: 24 (pos: 0.242): 1.31095e-53, 1.46081e-16, 4.63873e-07, 1.77927e-11, 1.31930e-11, 7.48639e-06
Node: 25 (pos: 0.253): 2.63524e-58, 5.67497e-18, 1.24697e-07, 1.95036e-12, 1.39470e-12, 2.53751e-06
-
Node: 26 (pos: 0.263): 3.34343e-63, 1.92002e-19, 3.16980e-08, 1.94595e-13, 1.33997e-13, 8.21387e-07
Node: 27 (pos: 0.273): 2.67733e-68, 5.65746e-21, 7.61958e-09, 1.76723e-14, 1.17000e-14, 2.53918e-07
Node: 28 (pos: 0.283): 1.35316e-73, 1.45181e-22, 1.73201e-09, 1.46082e-15, 9.28426e-16, 7.49629e-08
Node: 29 (pos: 0.293): 4.31651e-79, 3.24468e-24, 3.72300e-10, 1.09912e-16, 6.69551e-17, 2.11351e-08
Node: 30 (pos: 0.303): 8.69070e-85, 6.31550e-26, 7.56756e-11, 7.52725e-18, 4.38828e-18, 5.69072e-09
Node: 31 (pos: 0.313): 1.10437e-90, 1.07057e-27, 1.45459e-11, 4.69214e-19, 2.61384e-19, 1.46331e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 1.23827e-17, 9.32020e-06, 1.08774e-02, 4.02163e-04, 3.93562e-04, 2.97331e-02
Node: 08 (pos: 0.081): 3.90028e-15, 5.24518e-05, 2.18780e-02, 1.30349e-03, 1.30043e-03, 5.28650e-02
Node: 09 (pos: 0.091): 7.75378e-13, 2.57081e-04, 4.16112e-02, 3.84553e-03, 3.90513e-03, 8.97640e-02
Node: 10 (pos: 0.101): 9.72901e-11, 1.09737e-03, 7.48401e-02, 1.03264e-02, 1.06576e-02, 1.45560e-01
Node: 11 (pos: 0.111): 7.70480e-09, 4.07949e-03, 1.27286e-01, 2.52398e-02, 2.64335e-02, 2.25417e-01
Node: 12 (pos: 0.121): 3.85116e-07, 1.32079e-02, 2.04714e-01, 5.61520e-02, 5.95834e-02, 3.33379e-01
-
Node: 00 (pos: 0.000): 1.02026e-40, 1.08724e-12, 1.70750e-05, 7.68214e-09, 6.29167e-09, 1.45849e-04
Node: 01 (pos: 0.010): 8.05429e-37, 1.61009e-11, 5.07916e-05, 4.81042e-08, 4.05996e-08, 3.57924e-04
Node: 02 (pos: 0.020): 4.01311e-33, 2.07656e-10, 1.42871e-04, 2.74175e-07, 2.38096e-07, 8.38850e-04
Node: 03 (pos: 0.030): 1.26204e-29, 2.33246e-09, 3.80030e-04, 1.42238e-06, 1.26898e-06, 1.87752e-03
Node: 04 (pos: 0.040): 2.50497e-26, 2.28170e-08, 9.55900e-04, 6.71655e-06, 6.14659e-06, 4.01319e-03
Node: 05 (pos: 0.051): 3.13812e-23, 1.94390e-07, 2.27368e-03, 2.88683e-05, 2.70574e-05, 8.19220e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.03983963362842418
Step 50, mean loss 0.02118939953190708
Step 75, mean loss 0.02972528024373246
Step 100, mean loss 0.04553413833562758
Step 125, mean loss 0.05460776334125875
Step 150, mean loss 0.09491679475937374
Step 175, mean loss 0.08545947117705424
Step 200, mean loss 0.15034866226821358
Step 225, mean loss 0.10811437498655202
Unrolled forward losses 1.638400103906586
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00), 0.1364465885494971, [0.0004608823584119424, 0.0014886349322625844, 0.0036583857303738123, 0.002189735876009251, 0.00208576896366979, 0.004433570219157098], [0.9576319835068502, 1.1007790705152334, 1.2247781565300233, 1.1396641751192398, 1.2704243679906586, 1.4546567813635214]
Training Loss (progress: 0.08), 0.12476936293504602, [0.0004399036753828947, 0.0014902077968873498, 0.0036616567374460067, 0.0021723764574972087, 0.0021145690667143677, 0.00444052975635879], [0.9575611661212624, 1.1007834816841808, 1.2250083706572261, 1.1398526415041228, 1.270547145292099, 1.4549435945180538]
Training Loss (progress: 0.16), 0.13381981398491827, [0.00044368348869453775, 0.0014788555034153778, 0.0036983371102710565, 0.002179229666939411, 0.002087683473423159, 0.004457718356676788], [0.95732675776555, 1.1009733087520763, 1.2252217077538923, 1.1398355416299284, 1.2707836479214247, 1.4552361753937575]
Training Loss (progress: 0.24), 0.1431682149206074, [0.0004590070750706877, 0.0014610290200522346, 0.0036989527895611362, 0.0021819994178147333, 0.00210796719255826, 0.004482421248007061], [0.9573921713738446, 1.1011481073472478, 1.2253042932164044, 1.1398909184637287, 1.2709896541516172, 1.4555364128143757]
Training Loss (progress: 0.32), 0.14923712103811548, [0.00043514340744770755, 0.0014757020283824593, 0.0036816825262388536, 0.0021857901579527654, 0.0021036282661442834, 0.004461997700950766], [0.9572366330554409, 1.1012813584547674, 1.2253463928094388, 1.139961076675519, 1.2712037839770725, 1.4558622252950577]
Training Loss (progress: 0.40), 0.14696619243523423, [0.00043958177864131666, 0.001477882322351755, 0.0036856488454090706, 0.0022298500145164304, 0.002064440695224024, 0.004460302826990996], [0.9571371482062442, 1.1013806906394639, 1.2255102041188155, 1.1398712875123886, 1.2714080297586483, 1.4560845507556652]
Training Loss (progress: 0.48), 0.14822152256365434, [0.0004353677701930108, 0.0014939909905948064, 0.003655694584509096, 0.002195293759788519, 0.0020600201116909855, 0.004472579619722782], [0.9571123079524383, 1.1014820127697738, 1.2255684735430912, 1.1399440274840753, 1.2716141670122176, 1.456332187937408]
Training Loss (progress: 0.56), 0.129302309220076, [0.0004549447430716164, 0.0014621379170495794, 0.003646604512654273, 0.0021657735284043127, 0.0020886958473786774, 0.004457445896184752], [0.957030146271297, 1.101526616529597, 1.2257017331148137, 1.1400350272752133, 1.2718168662146285, 1.4566743681480712]
Training Loss (progress: 0.64), 0.1394035721568053, [0.00045511107172973604, 0.0014504044986294777, 0.003639064529408689, 0.0021578243188474845, 0.0020702080755484876, 0.004476395051248266], [0.956861438951335, 1.101619819866249, 1.2257887606911224, 1.1401405748291644, 1.2719401786177416, 1.4569792834873851]
Training Loss (progress: 0.72), 0.13873237576957684, [0.00044923588060455686, 0.001489207928352852, 0.003668442762599667, 0.0021995616297656, 0.0020995342020337774, 0.00445918358909433], [0.9567981839826478, 1.101770726424243, 1.2260406496048493, 1.1400919356033068, 1.2722373437239962, 1.457283561918771]
Training Loss (progress: 0.80), 0.14351225816858632, [0.00044543921058453294, 0.0014596582510267779, 0.0037047826252943235, 0.0021760659668005828, 0.002067353367283354, 0.004444229629136269], [0.9567526446111466, 1.101876899295252, 1.2262206962879614, 1.140216248327607, 1.272386163207576, 1.457540845943788]
Training Loss (progress: 0.88), 0.13399055913841032, [0.0004461340648996805, 0.0014787098585982378, 0.0036450314723464284, 0.002173349763676687, 0.0021252899584412797, 0.0044352692558323895], [0.9567574253829013, 1.1020367800573545, 1.226205205091491, 1.1403984455498049, 1.2724934727378403, 1.457810276237383]
Training Loss (progress: 0.96), 0.13307076162359172, [0.00045529331852506397, 0.001491139485934085, 0.0036314677563554303, 0.002182747118690343, 0.0021489991600141772, 0.004424962557330983], [0.9567241883592965, 1.1020762177312744, 1.2262468363054533, 1.1404020949234237, 1.272626529134315, 1.4581056087444957]
Evaluation on validation dataset:
Step 25, mean loss 0.05323315028369327
Step 50, mean loss 0.02465734388601641
Step 75, mean loss 0.056335653151791704
Step 100, mean loss 0.05272406563345103
Step 125, mean loss 0.06587018089538452
Step 150, mean loss 0.056597496920659296
Step 175, mean loss 0.07999461613989281
Step 200, mean loss 0.1847901862126881
Step 225, mean loss 0.1940149853485889
Unrolled forward losses 2.1511830026200887
Unrolled forward base losses 2.565701273852575
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00), 0.1356450555384414, [0.00044742988704260045, 0.0014743502511847311, 0.0036595106162031865, 0.002180222977222979, 0.002109573511525906, 0.004488919877948618], [0.9566339660368333, 1.1020902076255128, 1.2263428100817428, 1.1404027907265963, 1.2726953096006055, 1.458243656255181]
Training Loss (progress: 0.08), 0.12676088766252075, [0.00045523415620566575, 0.001493472718798655, 0.003638424938545044, 0.0021977691045872915, 0.0020765333099230757, 0.004469277738566701], [0.9565806894977773, 1.1021703583414324, 1.2264739291605316, 1.1404203405639706, 1.2728297598021654, 1.4584259953798573]
Training Loss (progress: 0.16), 0.13327217103399971, [0.0004531424702075708, 0.0014591305237388783, 0.003638565627295226, 0.002179885332008097, 0.0021137582471124107, 0.004448290097039498], [0.9564741694965901, 1.1022988850817397, 1.2267430693871682, 1.1405003562939526, 1.2729992033377004, 1.45870925502183]
Training Loss (progress: 0.24), 0.13724293602313037, [0.0004513096429112297, 0.0014464412735980673, 0.003668248358934636, 0.002175323456803167, 0.002093146337601919, 0.004463585144424459], [0.9564197662025725, 1.1024958395837094, 1.2268376942845296, 1.1406531404377849, 1.2731674440737073, 1.459015674777092]
Training Loss (progress: 0.32), 0.13580677392547866, [0.0004383089408239472, 0.0014617705962974464, 0.0036491637545217324, 0.0021554028668082353, 0.002151861288866847, 0.004480984354834273], [0.9564176681015161, 1.102569744163247, 1.2270904921216397, 1.1407001994801582, 1.2733864827478878, 1.4592335977703381]
Training Loss (progress: 0.40), 0.13830120922546973, [0.00044290166453788077, 0.0014553860341032323, 0.0036490742449111083, 0.0021604323555746503, 0.0020446512442652918, 0.004450688415907716], [0.9563224313601416, 1.1025478243308353, 1.2272108356390556, 1.1407428378212618, 1.2735385155167418, 1.4595657413330685]
Training Loss (progress: 0.48), 0.12985509531239858, [0.00044814110599770176, 0.0014744520637769752, 0.0036470540350513193, 0.0021449330399850985, 0.0021054381188537297, 0.0044539627017878315], [0.9562117928507757, 1.102632831164654, 1.227266813938178, 1.1408518476141258, 1.2738180991316792, 1.45981070955054]
Training Loss (progress: 0.56), 0.13769695493092984, [0.0004471427664952861, 0.001436199249055069, 0.0036427212574957108, 0.0021926150540771774, 0.002103090828421688, 0.004469922675054919], [0.9560835302470246, 1.1027025441471174, 1.2273114411576422, 1.1408384619642753, 1.273868096143614, 1.460112229553376]
Training Loss (progress: 0.64), 0.12666367036192466, [0.0004628506652664799, 0.001476707646550328, 0.0036026255443804113, 0.00219477827733881, 0.0020580477779798636, 0.0044369758840250954], [0.9561016824719087, 1.102815989172096, 1.2275183228384665, 1.140922363295782, 1.2739596999230631, 1.460348128114033]
Training Loss (progress: 0.72), 0.1384104705807581, [0.0004352448950839721, 0.0014651516826431382, 0.003608986898890878, 0.002188541934975198, 0.0020789019902968907, 0.004449358734107969], [0.9558823555808917, 1.1029381851289077, 1.2275620647759184, 1.1409588294954667, 1.2740290209174017, 1.4607027455932196]
Training Loss (progress: 0.80), 0.1360906257515519, [0.0004469084693813965, 0.0014713998875336416, 0.0036638866530325034, 0.0021961767286699622, 0.002138266141504963, 0.004459872091491677], [0.9559136225402135, 1.1030323568072167, 1.2277026159342306, 1.1410317169836708, 1.2742308625169692, 1.4609194948888824]
Training Loss (progress: 0.88), 0.12909035470655428, [0.0004519893247192249, 0.0014568878465024404, 0.0036881278060591203, 0.0021891786250808737, 0.0021019994715743675, 0.004394045654175331], [0.955736194355443, 1.103105532486502, 1.2279261614441646, 1.1411158327739415, 1.2744705337404119, 1.461082171156291]
Training Loss (progress: 0.96), 0.137380865368165, [0.0004423317128766784, 0.0014662443184136594, 0.003648870390169286, 0.0022043807781389983, 0.002103477334302046, 0.004490271721265093], [0.9556784442910375, 1.1031950712682699, 1.2279350483542644, 1.1411286457344356, 1.274619760398387, 1.4613656306379195]
Evaluation on validation dataset:
Step 25, mean loss 0.05158270845167738
Step 50, mean loss 0.024045312379525605
Step 75, mean loss 0.0525761646791163
Step 100, mean loss 0.04966055669307131
Step 125, mean loss 0.06698273818267651
Step 150, mean loss 0.05524076761749919
Step 175, mean loss 0.07877691991347313
Step 200, mean loss 0.16930931399695162
Step 225, mean loss 0.1907595349400478
Unrolled forward losses 2.1065673031192134
Unrolled forward base losses 2.565701273852575
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00), 0.13317382045114057, [0.0004559653609645224, 0.001417099309269649, 0.0036705072106921854, 0.002178243419812849, 0.0021482876240730055, 0.0044615558430652555], [0.9557399069598712, 1.1032078822525901, 1.2280073956920792, 1.1411613519297295, 1.2747450888837544, 1.461504677777248]
Training Loss (progress: 0.08), 0.135463543115188, [0.00043891779674709965, 0.0014718175028049021, 0.003645887657835118, 0.002177292018276092, 0.002108188539950674, 0.004469624423685148], [0.9556378750246186, 1.103326371857432, 1.2281235843426304, 1.1412518983428561, 1.2748821582871668, 1.4618353891502]
Training Loss (progress: 0.16), 0.13522559541917475, [0.0004284974464643085, 0.0014526349440788244, 0.0036374428017841797, 0.0021649037871646947, 0.0021518308012023653, 0.004461167072220198], [0.9555919075474927, 1.1033994975144232, 1.2282461386419286, 1.1412268207476615, 1.2750444881924399, 1.4621574697456334]
Training Loss (progress: 0.24), 0.1434341870483109, [0.00044546821001082354, 0.0014785881617503213, 0.0036670633955098427, 0.0022100855385431654, 0.002070728194780076, 0.004460332726704014], [0.9555327503202109, 1.103532535978371, 1.2284833599319833, 1.141216506624404, 1.2750783757259443, 1.4624409669965184]
Training Loss (progress: 0.32), 0.1378408884138851, [0.00044023917472337665, 0.0014162971116309527, 0.0036623545535322223, 0.002171427517413581, 0.002088899588065479, 0.004439028207584642], [0.9554068242016035, 1.1035675509499474, 1.2284708604830301, 1.1412235152140129, 1.2751756617634784, 1.4626403349681918]
Training Loss (progress: 0.40), 0.13759249680551505, [0.00043413393897001596, 0.0014483464636650249, 0.0036382531061470305, 0.002189699648864978, 0.00208466655446244, 0.004415129929463463], [0.955467281240417, 1.1035975932943138, 1.2285663012507753, 1.1413690361586282, 1.2752790347926115, 1.4628859816532114]
Training Loss (progress: 0.48), 0.13367149121131106, [0.0004567396575751044, 0.001444708042637481, 0.0036973515733782544, 0.0021569547601601406, 0.0021361414842433852, 0.004411121989650616], [0.9554192428992052, 1.1038414422444505, 1.228763785795011, 1.141419164017434, 1.275469044552555, 1.4632185230038144]
Training Loss (progress: 0.56), 0.13339565764030192, [0.00044237983106228877, 0.0014598121888004536, 0.0036708942891983255, 0.0021635925389256283, 0.0021116161078060867, 0.0044358373538881495], [0.9553862406451212, 1.1039156299491413, 1.2287584918258694, 1.1415200316307694, 1.275755238041211, 1.463493523919456]
Training Loss (progress: 0.64), 0.12921787318091013, [0.00044697961367219056, 0.0014474209271738525, 0.0036699309180980282, 0.002152564153488794, 0.0020689333915249767, 0.004456243471683095], [0.9552095741453487, 1.1039749807028831, 1.2289858095432162, 1.141605099438631, 1.2757874065677277, 1.4637866424134418]
Training Loss (progress: 0.72), 0.1412298047463852, [0.0004361966507349025, 0.0014469641899753545, 0.0036197006313553387, 0.0021922969444212285, 0.0021074414843907374, 0.0044545146981044515], [0.9551465761299569, 1.1040391195209356, 1.228998371982242, 1.141745269464935, 1.276017120314665, 1.4639814666210171]
Training Loss (progress: 0.80), 0.14096056734642468, [0.00045085542253761265, 0.0014647703015878265, 0.0036361194906256223, 0.002187356918301833, 0.0021199574745681994, 0.004451762961605674], [0.9550845798154664, 1.104188148107979, 1.2292299184272335, 1.1417819739477557, 1.2760555301458096, 1.4642907873178126]
Training Loss (progress: 0.88), 0.138396425819416, [0.00043851661944632124, 0.0014603793468179354, 0.0036754688389495985, 0.00220648761601211, 0.00207701953046616, 0.00445863824608459], [0.9548994940310062, 1.1041955047953778, 1.2293342692011724, 1.14183695520815, 1.2761105064615834, 1.4645224267689838]
Training Loss (progress: 0.96), 0.12911265862041726, [0.0004452530715993335, 0.0014492045581829432, 0.0036160266380428413, 0.002193444992708258, 0.0020956086239611355, 0.004439661266121277], [0.9549167678504985, 1.1042856080465377, 1.22938375459219, 1.1419300780475725, 1.276386008680073, 1.4647477120939325]
Evaluation on validation dataset:
Step 25, mean loss 0.04870204339373636
Step 50, mean loss 0.020962748955589944
Step 75, mean loss 0.050556589872825464
Step 100, mean loss 0.051155361906714956
Step 125, mean loss 0.06365350269479084
Step 150, mean loss 0.05461078793963615
Step 175, mean loss 0.07516260163808111
Step 200, mean loss 0.1709141038598023
Step 225, mean loss 0.20117356791462573
Unrolled forward losses 1.8676281561916819
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 1.29572e-37, 8.39960e-12, 5.04030e-05, 6.30285e-08, 4.00382e-08, 3.43635e-04
Node: 21 (pos: 0.212): 1.34771e-41, 5.28511e-13, 1.69233e-05, 1.03614e-08, 6.19219e-09, 1.39306e-04
Node: 22 (pos: 0.222): 8.75853e-46, 2.88569e-14, 5.37289e-06, 1.55272e-09, 8.70250e-10, 5.39177e-05
Node: 23 (pos: 0.232): 3.55642e-50, 1.36724e-15, 1.61296e-06, 2.12107e-10, 1.11141e-10, 1.99244e-05
Node: 24 (pos: 0.242): 9.02285e-55, 5.62134e-17, 4.57861e-07, 2.64122e-11, 1.28982e-11, 7.02957e-06
Node: 25 (pos: 0.253): 1.43028e-59, 2.00555e-18, 1.22896e-07, 2.99809e-12, 1.36025e-12, 2.36790e-06
-
Node: 26 (pos: 0.263): 1.41661e-64, 6.20911e-20, 3.11914e-08, 3.10222e-13, 1.30357e-13, 7.61534e-07
Node: 27 (pos: 0.273): 8.76644e-70, 1.66810e-21, 7.48560e-09, 2.92610e-14, 1.13522e-14, 2.33833e-07
Node: 28 (pos: 0.283): 3.38958e-75, 3.88882e-23, 1.69868e-09, 2.51591e-15, 8.98369e-16, 6.85510e-08
Node: 29 (pos: 0.293): 8.18873e-81, 7.86704e-25, 3.64494e-10, 1.97192e-16, 6.46040e-17, 1.91872e-08
Node: 30 (pos: 0.303): 1.23605e-86, 1.38104e-26, 7.39543e-11, 1.40888e-17, 4.22175e-18, 5.12745e-09
Node: 31 (pos: 0.313): 1.16574e-92, 2.10377e-28, 1.41883e-11, 9.17585e-19, 2.50700e-19, 1.30822e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 5.25654e-18, 6.88462e-06, 1.08606e-02, 4.56880e-04, 3.91983e-04, 2.92804e-02
Node: 08 (pos: 0.081): 1.87867e-15, 4.05399e-05, 2.18616e-02, 1.45359e-03, 1.29688e-03, 5.22325e-02
Node: 09 (pos: 0.091): 4.19515e-13, 2.07150e-04, 4.16105e-02, 4.21569e-03, 3.89911e-03, 8.89602e-02
Node: 10 (pos: 0.101): 5.85320e-11, 9.18518e-04, 7.48891e-02, 1.11451e-02, 1.06527e-02, 1.44658e-01
Node: 11 (pos: 0.111): 5.10255e-09, 3.53419e-03, 1.27446e-01, 2.68590e-02, 2.64472e-02, 2.24584e-01
Node: 12 (pos: 0.121): 2.77926e-07, 1.18003e-02, 2.05083e-01, 5.90044e-02, 5.96666e-02, 3.32895e-01
-
Node: 00 (pos: 0.000): 1.34771e-41, 5.28511e-13, 1.69233e-05, 1.03614e-08, 6.19219e-09, 1.39306e-04
Node: 01 (pos: 0.010): 1.29572e-37, 8.39960e-12, 5.04030e-05, 6.30285e-08, 4.00382e-08, 3.43635e-04
Node: 02 (pos: 0.020): 7.78344e-34, 1.15841e-10, 1.41946e-04, 3.49496e-07, 2.35252e-07, 8.09314e-04
Node: 03 (pos: 0.030): 2.92134e-30, 1.38633e-09, 3.77990e-04, 1.76659e-06, 1.25609e-06, 1.81981e-03
Node: 04 (pos: 0.040): 6.85077e-27, 1.43969e-08, 9.51773e-04, 8.13990e-06, 6.09451e-06, 3.90686e-03
Node: 05 (pos: 0.051): 1.00379e-23, 1.29740e-07, 2.26610e-03, 3.41894e-05, 2.68711e-05, 8.00793e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.03848931671271607
Step 50, mean loss 0.02027836273726672
Step 75, mean loss 0.030334611601273362
Step 100, mean loss 0.044353132788512134
Step 125, mean loss 0.05361898059204538
Step 150, mean loss 0.08312259628786972
Step 175, mean loss 0.07905352210496144
Step 200, mean loss 0.1648921932900777
Step 225, mean loss 0.10776281190646438
Unrolled forward losses 1.6017142022503075
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00), 0.1270717166805688, [0.00044668425576237204, 0.0014071217347374906, 0.0036503460298677425, 0.0021951877772097292, 0.0021260055158367768, 0.004436208771041491], [0.9549648990999978, 1.104311920646874, 1.2295279262110743, 1.1418983073902809, 1.276376164677827, 1.4649077885039736]
Training Loss (progress: 0.08), 0.1214321108209228, [0.00043318793116244926, 0.0014570453185234996, 0.003613495905327845, 0.0021789184718103627, 0.0020844330550537672, 0.004425224861912439], [0.9547539477699225, 1.1043709360194607, 1.2296881506594837, 1.1420621656111043, 1.2764678686152084, 1.4651839779014348]
Training Loss (progress: 0.16), 0.11995033919734525, [0.00044115834911637967, 0.0014622890534868233, 0.003658504333186733, 0.0022034099545747065, 0.0021409824261715013, 0.004407129668803948], [0.9546961508602289, 1.1043586833719605, 1.229737786077916, 1.1419796491917522, 1.2766123422607079, 1.4654346730660859]
Training Loss (progress: 0.24), 0.1388317303920462, [0.00043439816509183783, 0.0014394542940488798, 0.0036593629851399893, 0.002194591462115861, 0.002147972258891115, 0.004454230289627646], [0.9545653034618217, 1.1045447923485248, 1.2298901737491879, 1.142069854175207, 1.2768888540188454, 1.4656709604854996]
Training Loss (progress: 0.32), 0.1340758657151306, [0.00044174326615970075, 0.0014571653751279505, 0.0036908728515751, 0.002182883440502306, 0.0020999271637818745, 0.004468038261286692], [0.9544537955081387, 1.1046639831227736, 1.2299993088230143, 1.142195249344275, 1.2770439501873914, 1.4659213976328194]
Training Loss (progress: 0.40), 0.14032423209428824, [0.0004508761323299703, 0.0014574145234885658, 0.0036306139959683377, 0.002187880217938812, 0.0020849189668491717, 0.0044726339051215], [0.9544463085678381, 1.1047440394275565, 1.2300834220413488, 1.1422984351667882, 1.2771749464127946, 1.4662840375393724]
Training Loss (progress: 0.48), 0.1320154272731099, [0.0004384362171573428, 0.0014348845700386758, 0.003630837757029587, 0.002158736559232227, 0.002114348657172241, 0.004413182090935167], [0.9542914542415055, 1.1048079655982503, 1.2301904439619895, 1.1424191773433412, 1.2773989670412114, 1.4664755851522935]
Training Loss (progress: 0.56), 0.12876840037558082, [0.00044605813582147884, 0.0014370647330972485, 0.0036657277768505515, 0.002171172148404105, 0.002102547263045461, 0.004425963102005896], [0.9542538995993106, 1.1048056105477544, 1.230304539931371, 1.142447977446077, 1.2774593490802246, 1.4667698159648515]
Training Loss (progress: 0.64), 0.13041259370925384, [0.00044263494489412016, 0.0014477669180257618, 0.003630131741642777, 0.002173722066372414, 0.002112365212598998, 0.004436264332436984], [0.9541147082469928, 1.104946558544714, 1.2303572842012025, 1.1425437780536893, 1.277582601020933, 1.467056218107778]
Training Loss (progress: 0.72), 0.1287019543907376, [0.00043392016325938596, 0.001465429450652096, 0.0036616582356238285, 0.0021505887412840916, 0.002115122373553397, 0.004431730649878165], [0.9540934015903187, 1.105045465281449, 1.2305605639199744, 1.1424165962473147, 1.277765307183361, 1.4672423296973691]
Training Loss (progress: 0.80), 0.12610773217645926, [0.00044747597407550317, 0.0014623071060322899, 0.0036252849118970742, 0.002172820201487904, 0.002136074543969411, 0.00445780049443686], [0.9540057632221345, 1.1050838997594843, 1.2306429891752788, 1.142526310459606, 1.2779463154791995, 1.4675463200390002]
Training Loss (progress: 0.88), 0.12356521391996214, [0.0004505317785482849, 0.0014433862026981116, 0.003628009687951387, 0.0021488510532962483, 0.0021227447996207786, 0.004404956590357234], [0.9540022334566617, 1.1050980185993033, 1.230710006415935, 1.142500702336204, 1.277926675359157, 1.467710238066387]
Training Loss (progress: 0.96), 0.12379104266915449, [0.00043911752809760904, 0.0014344180676962499, 0.0036101092079460404, 0.002232010073215008, 0.0021510855621408214, 0.004473890052254321], [0.9538885801516717, 1.1051354203942703, 1.2308152357368942, 1.1426951534398153, 1.2781908950892211, 1.467970115660502]
Evaluation on validation dataset:
Step 25, mean loss 0.04611858471472481
Step 50, mean loss 0.02157380822744039
Step 75, mean loss 0.05201853021715988
Step 100, mean loss 0.046172308997502395
Step 125, mean loss 0.06192640607866452
Step 150, mean loss 0.05197783478860886
Step 175, mean loss 0.07440426316230336
Step 200, mean loss 0.16541020082159397
Step 225, mean loss 0.18756618709679057
Unrolled forward losses 1.9297154852516356
Unrolled forward base losses 2.565701273852575
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00), 0.1306772962570809, [0.0004390006284623287, 0.001461445281929476, 0.0036381698033793606, 0.0021817896804514915, 0.0021267787995626133, 0.004424451992376452], [0.9538340350457807, 1.1051650978437877, 1.2308413235849331, 1.1427141795993496, 1.2782514005610586, 1.4680593364130519]
Training Loss (progress: 0.08), 0.1256833860694267, [0.0004440744939325795, 0.0014511721204608316, 0.003621366701854639, 0.0021751711189311345, 0.0021110593835911022, 0.004425472736363317], [0.9538360595364704, 1.1052532505347885, 1.230948163743016, 1.1427027680880282, 1.2783102223254728, 1.4682030994171298]
Training Loss (progress: 0.16), 0.12946004369821246, [0.0004496200426878797, 0.0014799736261956072, 0.0036438850076524793, 0.002184624066300211, 0.0021217964949236993, 0.004433258039975017], [0.9538381386765221, 1.1053399903982983, 1.2309988826976777, 1.1427209528302387, 1.2783850588165067, 1.4683237500239752]
Training Loss (progress: 0.24), 0.12914420606441124, [0.0004460222456693777, 0.0014477204812626758, 0.0036267391354316432, 0.0021926834214128026, 0.0021225366679816227, 0.004434364018104207], [0.9538141578292797, 1.1053453279543002, 1.2310534672688822, 1.1427857242935329, 1.2784641617658148, 1.468439092910154]
Training Loss (progress: 0.32), 0.12743168715846964, [0.000449543580468871, 0.0014258331360981213, 0.0036176139363817807, 0.0022028126365503057, 0.002148230566605873, 0.004462568216757781], [0.9538145136076631, 1.1054244744858681, 1.2310901555145923, 1.142839601566962, 1.2785453836247804, 1.4685934306679362]
Training Loss (progress: 0.40), 0.12778963482984587, [0.0004500239155911332, 0.00146490545381447, 0.0036188649959732456, 0.0021887134098014824, 0.002101860530340811, 0.004447229093490301], [0.953735071588103, 1.105458740277979, 1.231184878499798, 1.1428329287904486, 1.2785145464390328, 1.4687094146193587]
Training Loss (progress: 0.48), 0.1215730047258437, [0.0004400894859236652, 0.0014396582395704359, 0.0036171413956189494, 0.0021701638229569696, 0.002114121283794789, 0.004445195264867166], [0.9537738591841481, 1.10551922094896, 1.2312589351485042, 1.1428469083757595, 1.2785950662182795, 1.4688716086197608]
Training Loss (progress: 0.56), 0.12140347007242222, [0.0004474950396104923, 0.0014654197753586487, 0.003647291867118007, 0.0021816547240941578, 0.00209751107596084, 0.0044586112239387915], [0.9537522426275323, 1.1055284762414652, 1.2313128846464403, 1.14289576587068, 1.278702675732755, 1.4689732878551622]
Training Loss (progress: 0.64), 0.11301885131959682, [0.0004406299780946579, 0.001449943384519943, 0.0036312843374032406, 0.002198478950406906, 0.0020978868550890015, 0.0044432255120810385], [0.9536905097074194, 1.1056095843698626, 1.231308319876334, 1.1428822182820972, 1.2787676736976967, 1.4691177503490616]
Training Loss (progress: 0.72), 0.12100934241281808, [0.00043805796559126596, 0.001471903089500454, 0.0036198630764573483, 0.0021739541000802996, 0.0021128955125335022, 0.004439642574308344], [0.9536793328355219, 1.1057070687096946, 1.2313873318733353, 1.1428774629360505, 1.2788447483235537, 1.4692597921221855]
Training Loss (progress: 0.80), 0.12544357775717194, [0.0004342984705191383, 0.001445505930167277, 0.003639416351174347, 0.0021924851608874623, 0.002137215162737478, 0.0044189810366387396], [0.9536366635138919, 1.105725387334455, 1.2314677405150025, 1.1429529579057505, 1.2789361739748037, 1.4693596516538523]
Training Loss (progress: 0.88), 0.12165760771725226, [0.0004428663921791082, 0.0014630339158506135, 0.0036609018597221887, 0.002181185139040101, 0.002099911317178948, 0.0044315456256266775], [0.9535756736214879, 1.1058026395813632, 1.231510583266068, 1.1429941389973821, 1.2789884332657624, 1.4695141882227845]
Training Loss (progress: 0.96), 0.1270336819752873, [0.00043855566332726316, 0.0014598150346614902, 0.0036291116749173555, 0.002165330557696625, 0.002104706328122423, 0.004431597732303541], [0.9535779045310177, 1.1058379184947742, 1.2315541920562048, 1.1430140681563339, 1.279058321120349, 1.4696223809165936]
Evaluation on validation dataset:
Step 25, mean loss 0.04427649333648973
Step 50, mean loss 0.02026402493831376
Step 75, mean loss 0.05009598952124973
Step 100, mean loss 0.04622247078500398
Step 125, mean loss 0.06148440928190535
Step 150, mean loss 0.04971710178631611
Step 175, mean loss 0.07104938000703112
Step 200, mean loss 0.1641684514965034
Step 225, mean loss 0.18267079548048648
Unrolled forward losses 1.847019189506063
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 6.19673e-37, 1.06268e-11, 5.07148e-05, 5.26234e-08, 2.98181e-08, 3.55415e-04
Node: 21 (pos: 0.212): 7.63384e-41, 6.85749e-13, 1.70362e-05, 8.48304e-09, 4.46604e-09, 1.44556e-04
Node: 22 (pos: 0.222): 5.92708e-45, 3.84495e-14, 5.41145e-06, 1.24531e-09, 6.06848e-10, 5.61434e-05
Node: 23 (pos: 0.232): 2.90038e-49, 1.87318e-15, 1.62540e-06, 1.66477e-10, 7.48087e-11, 2.08222e-05
Node: 24 (pos: 0.242): 8.94514e-54, 7.92920e-17, 4.61647e-07, 2.02667e-11, 8.36642e-12, 7.37426e-06
Node: 25 (pos: 0.253): 1.73874e-58, 2.91637e-18, 1.23984e-07, 2.24680e-12, 8.48872e-13, 2.49387e-06
-
Node: 26 (pos: 0.263): 2.13010e-63, 9.32002e-20, 3.14865e-08, 2.26830e-13, 7.81375e-14, 8.05367e-07
Node: 27 (pos: 0.273): 1.64469e-68, 2.58794e-21, 7.56115e-09, 2.08539e-14, 6.52517e-15, 2.48358e-07
Node: 28 (pos: 0.283): 8.00355e-74, 6.24386e-23, 1.71695e-09, 1.74593e-15, 4.94355e-16, 7.31351e-08
Node: 29 (pos: 0.293): 2.45470e-79, 1.30892e-24, 3.68663e-10, 1.33112e-16, 3.39783e-17, 2.05654e-08
Node: 30 (pos: 0.303): 4.74496e-85, 2.38418e-26, 7.48525e-11, 9.24193e-18, 2.11875e-18, 5.52223e-09
Node: 31 (pos: 0.313): 5.78073e-91, 3.77333e-28, 1.43710e-11, 5.84331e-19, 1.19859e-19, 1.41597e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 1.09278e-17, 7.69178e-06, 1.09020e-02, 4.20093e-04, 3.41854e-04, 2.97978e-02
Node: 08 (pos: 0.081): 3.50407e-15, 4.45655e-05, 2.19382e-02, 1.35344e-03, 1.15452e-03, 5.30437e-02
Node: 09 (pos: 0.091): 7.08154e-13, 2.24354e-04, 4.17445e-02, 3.97088e-03, 3.53737e-03, 9.01668e-02
Node: 10 (pos: 0.101): 9.01986e-11, 9.81363e-04, 7.51108e-02, 1.06093e-02, 9.83271e-03, 1.46360e-01
Node: 11 (pos: 0.111): 7.24083e-09, 3.72982e-03, 1.27794e-01, 2.58130e-02, 2.47959e-02, 2.26864e-01
Node: 12 (pos: 0.121): 3.66349e-07, 1.23171e-02, 2.05599e-01, 5.71930e-02, 5.67287e-02, 3.35792e-01
-
Node: 00 (pos: 0.000): 7.63384e-41, 6.85749e-13, 1.70362e-05, 8.48304e-09, 4.46604e-09, 1.44556e-04
Node: 01 (pos: 0.010): 6.19673e-37, 1.06268e-11, 5.07148e-05, 5.26234e-08, 2.98181e-08, 3.55415e-04
Node: 02 (pos: 0.020): 3.17029e-33, 1.43087e-10, 1.42759e-04, 2.97275e-07, 1.80614e-07, 8.34450e-04
Node: 03 (pos: 0.030): 1.02224e-29, 1.67402e-09, 3.79992e-04, 1.52930e-06, 9.92522e-07, 1.87081e-03
Node: 04 (pos: 0.040): 2.07741e-26, 1.70170e-08, 9.56424e-04, 7.16434e-06, 4.94815e-06, 4.00518e-03
Node: 05 (pos: 0.051): 2.66078e-23, 1.50304e-07, 2.27631e-03, 3.05642e-05, 2.23800e-05, 8.18802e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.03506152439718689
Step 50, mean loss 0.01889765606148499
Step 75, mean loss 0.02833765003175833
Step 100, mean loss 0.041210235583219054
Step 125, mean loss 0.05057756642947755
Step 150, mean loss 0.08381557470511414
Step 175, mean loss 0.07764527167900873
Step 200, mean loss 0.1754878005605504
Step 225, mean loss 0.10666952579759996
Unrolled forward losses 1.5137488211068895
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00), 0.11811075988949443, [0.0004427593645811553, 0.0014539679001890102, 0.0036435750041636504, 0.002177455637328082, 0.0021266308581759296, 0.004422138166383468], [0.9535733195845013, 1.1058994396292205, 1.2316264942967854, 1.1430097323282047, 1.2791580364764805, 1.469676160020168]
Training Loss (progress: 0.08), 0.13415898485585168, [0.00043923568629451097, 0.0014602709379173092, 0.0035995105331641454, 0.002177641433832942, 0.0021075678712673103, 0.004427530613438767], [0.9535853298781024, 1.1059425558128577, 1.2316936067912363, 1.1430749741006812, 1.2792096054528144, 1.4698238028111388]
Training Loss (progress: 0.16), 0.11353804278237496, [0.00044881005912333525, 0.0014307343693073548, 0.0036138761943017884, 0.0021827021408549127, 0.0021506495054136637, 0.004428797485176396], [0.9535327459423993, 1.1059146604710324, 1.2317468625693506, 1.1431093932961303, 1.2792724378157159, 1.469957375779494]
Training Loss (progress: 0.24), 0.12784716013020156, [0.00044023724358541324, 0.001456907261588975, 0.003621848974925902, 0.002179126036167883, 0.002119313256799403, 0.004443635509612356], [0.9535108892985454, 1.1060186022742708, 1.231754517262179, 1.1431511840186415, 1.2792769375639614, 1.470108218365984]
Training Loss (progress: 0.32), 0.1282488032202804, [0.00044163871392496185, 0.0014417526766264542, 0.003607571904566916, 0.002168394677894908, 0.0021225136203982826, 0.004431238046286782], [0.9534992650574022, 1.1060270581506688, 1.231774546996107, 1.1430755717448693, 1.2793222265734894, 1.4702434648741338]
Training Loss (progress: 0.40), 0.128480647544649, [0.0004406627141219652, 0.0014412975847574868, 0.0036302834561728657, 0.002206111321420194, 0.0021270556541752765, 0.004442545740713601], [0.9534352815901597, 1.1060393520623817, 1.2318697911305463, 1.1431353235100787, 1.2794154671196054, 1.47037532993171]
Training Loss (progress: 0.48), 0.12350780693157959, [0.00044247648135724424, 0.001458571079427991, 0.003616153999687195, 0.0022069847585749827, 0.002143689793744298, 0.004410722457294752], [0.9534676858362992, 1.1061185133919407, 1.2319534060141057, 1.1431733752324997, 1.2794525857466268, 1.4704725612586376]
Training Loss (progress: 0.56), 0.12266083504646765, [0.0004410854311229744, 0.0014684791711651656, 0.003650281419190744, 0.0021728732781135115, 0.0020915689101007216, 0.004415748377440396], [0.9534017466119764, 1.1062123418742127, 1.2320228827954502, 1.1431488442633433, 1.2795298705624003, 1.4705963229269376]
Training Loss (progress: 0.64), 0.13027819464041632, [0.0004479595046181855, 0.0014597747795916341, 0.0036208557552329587, 0.002182165037745017, 0.002120138835647707, 0.004400572263055161], [0.9533866766798604, 1.1062248772004732, 1.232078403655277, 1.1432356337352358, 1.279612768437181, 1.4706964340347384]
Training Loss (progress: 0.72), 0.12814934603925446, [0.0004449219713319956, 0.0014533381018464815, 0.003583769152970606, 0.002155771055747827, 0.0021314218867330256, 0.004395743140909479], [0.9532831113797927, 1.1062464869406117, 1.232106261709512, 1.1432706194404918, 1.2797599827768005, 1.4708180351180813]
Training Loss (progress: 0.80), 0.10226168570629894, [0.0004463040701321595, 0.0014535474685819277, 0.003623029695510915, 0.0021425250194000915, 0.002101320361014537, 0.00442514494966429], [0.9532586713298783, 1.106281755552948, 1.2322224680170242, 1.143218040583498, 1.2797710565677922, 1.47098695632581]
Training Loss (progress: 0.88), 0.12152719903767081, [0.0004446488419283194, 0.0014256950536233283, 0.003612083436856428, 0.002189523825884386, 0.0021235395733073844, 0.004401641773335602], [0.9532451702958988, 1.106278325292345, 1.232258947597345, 1.1432882150846837, 1.2798396414016247, 1.4711206218520727]
Training Loss (progress: 0.96), 0.1394526779379795, [0.00044060028651925166, 0.0014507003919558574, 0.003611774240633939, 0.002175123612787944, 0.0021179911874144477, 0.004420355420351166], [0.9532562809275669, 1.1063287928839223, 1.232317477774625, 1.1432782615610981, 1.279835300340686, 1.4712206531412586]
Evaluation on validation dataset:
Step 25, mean loss 0.04568669676297701
Step 50, mean loss 0.020133279302829155
Step 75, mean loss 0.049816097777782814
Step 100, mean loss 0.047627003861035855
Step 125, mean loss 0.06405531180316962
Step 150, mean loss 0.04881504249025238
Step 175, mean loss 0.07076842046860561
Step 200, mean loss 0.16915291600837268
Step 225, mean loss 0.18311301637853838
Unrolled forward losses 1.8377692468495028
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 2.95214e-37, 1.06280e-11, 4.61169e-05, 5.78903e-08, 3.58253e-08, 3.62418e-04
Node: 21 (pos: 0.212): 3.35693e-41, 6.85804e-13, 1.53324e-05, 9.42853e-09, 5.47290e-09, 1.47698e-04
Node: 22 (pos: 0.222): 2.39598e-45, 3.84513e-14, 4.81763e-06, 1.39915e-09, 7.59278e-10, 5.74838e-05
Node: 23 (pos: 0.232): 1.07339e-49, 1.87320e-15, 1.43064e-06, 1.89175e-10, 9.56618e-11, 2.13661e-05
Node: 24 (pos: 0.242): 3.01831e-54, 7.92897e-17, 4.01516e-07, 2.33049e-11, 1.09454e-11, 7.58427e-06
Node: 25 (pos: 0.253): 5.32727e-59, 2.91616e-18, 1.06500e-07, 2.61584e-12, 1.13731e-12, 2.57105e-06
-
Node: 26 (pos: 0.263): 5.90173e-64, 9.31898e-20, 2.66975e-08, 2.67520e-13, 1.07321e-13, 8.32370e-07
Node: 27 (pos: 0.273): 4.10381e-69, 2.58754e-21, 6.32508e-09, 2.49277e-14, 9.19693e-15, 2.57354e-07
Node: 28 (pos: 0.283): 1.79114e-74, 6.24261e-23, 1.41623e-09, 2.11637e-15, 7.15743e-16, 7.59893e-08
Node: 29 (pos: 0.293): 4.90688e-80, 1.30860e-24, 2.99695e-10, 1.63712e-16, 5.05856e-17, 2.14281e-08
Node: 30 (pos: 0.303): 8.43751e-86, 2.38347e-26, 5.99373e-11, 1.15386e-17, 3.24677e-18, 5.77062e-09
Node: 31 (pos: 0.313): 9.10662e-92, 3.77202e-28, 1.13289e-11, 7.40975e-19, 1.89248e-19, 1.48412e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 7.72156e-18, 7.69392e-06, 1.04310e-02, 4.39327e-04, 3.72637e-04, 3.00888e-02
Node: 08 (pos: 0.081): 2.60636e-15, 4.45789e-05, 2.11299e-02, 1.40611e-03, 1.24264e-03, 5.34934e-02
Node: 09 (pos: 0.091): 5.52201e-13, 2.24425e-04, 4.04522e-02, 4.10047e-03, 3.76322e-03, 9.08246e-02
Node: 10 (pos: 0.101): 7.34335e-11, 9.81694e-04, 7.31916e-02, 1.08950e-02, 1.03497e-02, 1.47270e-01
Node: 11 (pos: 0.111): 6.12949e-09, 3.73114e-03, 1.25157e-01, 2.63757e-02, 2.58497e-02, 2.28053e-01
Node: 12 (pos: 0.121): 3.21135e-07, 1.23217e-02, 2.02266e-01, 5.81785e-02, 5.86320e-02, 3.37260e-01
-
Node: 00 (pos: 0.000): 3.35693e-41, 6.85804e-13, 1.53324e-05, 9.42853e-09, 5.47290e-09, 1.47698e-04
Node: 01 (pos: 0.010): 2.95214e-37, 1.06280e-11, 4.61169e-05, 5.78903e-08, 3.58253e-08, 3.62418e-04
Node: 02 (pos: 0.020): 1.62954e-33, 1.43108e-10, 1.31095e-04, 3.23854e-07, 2.12970e-07, 8.49287e-04
Node: 03 (pos: 0.030): 5.64579e-30, 1.67432e-09, 3.52196e-04, 1.65072e-06, 1.14974e-06, 1.90067e-03
Node: 04 (pos: 0.040): 1.22778e-26, 1.70205e-08, 8.94249e-04, 7.66620e-06, 5.63689e-06, 4.06228e-03
Node: 05 (pos: 0.051): 1.67590e-23, 1.50338e-07, 2.14588e-03, 3.24390e-05, 2.50977e-05, 8.29162e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.03600160458453158
Step 50, mean loss 0.018714984403124538
Step 75, mean loss 0.028081058768344345
Step 100, mean loss 0.04282320860877197
Step 125, mean loss 0.05065319796514753
Step 150, mean loss 0.08040932313247129
Step 175, mean loss 0.07502139218114433
Step 200, mean loss 0.16470945329422765
Step 225, mean loss 0.10374773495861138
Unrolled forward losses 1.4952957802061912
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00), 0.12774629572036073, [0.00044334087380939964, 0.0014550043719871219, 0.003601592531807444, 0.0021955681381209194, 0.0020937343398763513, 0.00442405405106485], [0.9532411513928244, 1.1063687469318186, 1.23235538681272, 1.1432357429020468, 1.279888576388058, 1.4712847023068956]
Training Loss (progress: 0.08), 0.13005480749565385, [0.0004388598331239878, 0.0014623701084851954, 0.0035918693919117163, 0.002181836951053814, 0.0021376163724945276, 0.004437030825888944], [0.953207195556588, 1.1064303886145326, 1.2323713254147437, 1.1432798299462341, 1.2799927010110237, 1.4714164954715685]
Training Loss (progress: 0.16), 0.11598093161224472, [0.0004428559625392834, 0.0014517479958772543, 0.003634428852289693, 0.0021760898498017025, 0.0021045491483108495, 0.004423356322065384], [0.953198993021027, 1.1064319580940074, 1.2324543092355835, 1.1433119955041593, 1.2800067778480015, 1.4715473426434658]
Training Loss (progress: 0.24), 0.12720158698347525, [0.0004445236862119858, 0.0014383852513441646, 0.0036250162812232847, 0.0021801321620604666, 0.002128505631691351, 0.004423339738916212], [0.9532109918616339, 1.1064167813162018, 1.2325239445638225, 1.143387578541954, 1.2800370910251777, 1.471630064432654]
Training Loss (progress: 0.32), 0.13002659270570918, [0.0004396110036585232, 0.0014357653599551888, 0.0036098860052889937, 0.0021803252426856527, 0.002145333937449607, 0.004414046724310303], [0.953165806503021, 1.1065062167353044, 1.2326059336935153, 1.1434040190734045, 1.280159690159364, 1.4717885915791942]
Training Loss (progress: 0.40), 0.12128545807929375, [0.0004492410493141492, 0.001447754354161327, 0.0036217101931733074, 0.0021987329688429725, 0.0021192777113603154, 0.004439080454333629], [0.9531088690481129, 1.106589729355271, 1.2326350113922369, 1.1434591070738993, 1.2801884423094396, 1.4718942701045057]
Training Loss (progress: 0.48), 0.12412398196276173, [0.0004418291321501417, 0.0014453546620961065, 0.0036074805667880815, 0.0021805266525837014, 0.002118935312265896, 0.004433967984738315], [0.9531311179771504, 1.106585328724624, 1.2326798910285819, 1.1434883732209082, 1.2802663248200308, 1.472027384872252]
Training Loss (progress: 0.56), 0.12382603783942049, [0.0004373714168326526, 0.0014405447259652148, 0.0036371195629528803, 0.002172877945074294, 0.0021241814835458897, 0.0044328872778788215], [0.9530938357772045, 1.1066175489949452, 1.2327391106963763, 1.1434948072913063, 1.2803498878353186, 1.4721389574291397]
Training Loss (progress: 0.64), 0.11788875565944136, [0.0004403594077020935, 0.001456154888525572, 0.0036202528816555715, 0.0021604390183799136, 0.0021078003664713484, 0.004423392385131678], [0.9530691222191532, 1.1066359164493027, 1.232802512515859, 1.1434692707351097, 1.2804150158558758, 1.4722417735382087]
Training Loss (progress: 0.72), 0.1303155765749905, [0.0004458147039598858, 0.0014570416432788224, 0.0036282751036506734, 0.002173566964528833, 0.0021243390217906225, 0.004442648408533381], [0.9530557754577071, 1.1066878072573845, 1.232841647503298, 1.1435350125784272, 1.2804951544161942, 1.4723933196099361]
Training Loss (progress: 0.80), 0.11472617169538414, [0.00044473454354689176, 0.0014605660662002913, 0.003608754080194651, 0.0021701242139330525, 0.0021398618497827635, 0.0044193271421804365], [0.9530162937493613, 1.106714922886479, 1.2328607255854525, 1.1435235958809535, 1.2805508409975839, 1.472521715196034]
Training Loss (progress: 0.88), 0.11774068347335015, [0.0004405217851787802, 0.0014653614899779583, 0.003602401885631464, 0.002181830922550171, 0.0021052858321838814, 0.004419173294879758], [0.9529581652773889, 1.1066908346291207, 1.2329415913876907, 1.1435276905562777, 1.28063877819245, 1.4726298418160197]
Training Loss (progress: 0.96), 0.12444818165086295, [0.0004416378091790218, 0.001456463831905689, 0.0036244001385184817, 0.0021771158113921166, 0.0021230829918176815, 0.004426949794355752], [0.9529383739491606, 1.1067022119882393, 1.2330063490175736, 1.1435821379071647, 1.2806918383299377, 1.4727483141506872]
Evaluation on validation dataset:
Step 25, mean loss 0.043530511729334656
Step 50, mean loss 0.02029030986870536
Step 75, mean loss 0.0499446965203758
Step 100, mean loss 0.04591976383703583
Step 125, mean loss 0.061479008522579134
Step 150, mean loss 0.05069857304619267
Step 175, mean loss 0.07018282878082821
Step 200, mean loss 0.16097086755083526
Step 225, mean loss 0.18792832756172245
Unrolled forward losses 1.9699731918495398
Unrolled forward base losses 2.565701273852575
Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00), 0.13672541977621716, [0.00043649978980942985, 0.0014521408560584693, 0.0036062396213438, 0.002176560113580984, 0.002143945895662595, 0.004434795572551654], [0.9529736513677178, 1.1067517175505612, 1.2329847285820328, 1.1436176688247892, 1.2807359155813325, 1.472800277990291]
Training Loss (progress: 0.08), 0.13316868017849925, [0.00044737658453105716, 0.0014373835167121097, 0.003617311806139965, 0.0021867308885960457, 0.0021186412376100762, 0.004425855394342126], [0.9528984050216626, 1.106822262778462, 1.2330523695429145, 1.1436066734243795, 1.2808402850151364, 1.4729498610549783]
Training Loss (progress: 0.16), 0.12660360246067123, [0.0004437689348861061, 0.0014456722675409571, 0.0036399112210294487, 0.002182292306871691, 0.0021163717363061165, 0.004431122189196397], [0.9528809301033029, 1.1069154887516373, 1.233118171434476, 1.1436698196004194, 1.2808798572098674, 1.473093396726784]
Training Loss (progress: 0.24), 0.1243631976503985, [0.00044343189552095984, 0.0014603624740634176, 0.003607420908540193, 0.0022008927186265128, 0.0021054151885745915, 0.004426530442575448], [0.9528596576855858, 1.1069948415170785, 1.2331682827433341, 1.1436833485209499, 1.2809228365091, 1.4731958598593475]
Training Loss (progress: 0.32), 0.13929915974247395, [0.0004376952716425088, 0.0014616290650296636, 0.0036042096778127887, 0.002159177856548202, 0.0021236628062454624, 0.00440562187596938], [0.9528178722320035, 1.1070894910219327, 1.233177420326649, 1.143641182852215, 1.2809569185324219, 1.4733468899245985]
Training Loss (progress: 0.40), 0.1326947943372337, [0.0004429080892467067, 0.0014438882079650373, 0.0036125066781223423, 0.0021744042076392066, 0.002139859983660067, 0.004444938237284245], [0.9527984244111682, 1.1070681796493707, 1.2332484847467768, 1.1436751120658797, 1.2810517121357148, 1.4734775213608478]
Training Loss (progress: 0.48), 0.13013108868031537, [0.0004442701812385406, 0.0014471775052323605, 0.0036247177975134042, 0.002177698147030594, 0.0021216119516712603, 0.004429064186014782], [0.9527905825391201, 1.1071165196249693, 1.2333248640739385, 1.1437243406145687, 1.2810614951175912, 1.4736200145397662]
Training Loss (progress: 0.56), 0.12782888012732366, [0.0004467845067331808, 0.001453279502815924, 0.0036159776294515666, 0.002175366711140661, 0.002097201814120334, 0.004431375637816911], [0.9527267122381439, 1.10714055221262, 1.2333793286046892, 1.1437558058725987, 1.2811419530352712, 1.473709080867211]
Training Loss (progress: 0.64), 0.12313869087965054, [0.000443468090911131, 0.0014554763048373776, 0.00363360121253719, 0.0021661325302247767, 0.0021185287207336296, 0.004417864938318798], [0.9527309437162432, 1.1071736211782879, 1.233513346872613, 1.1437649682684166, 1.2812473972946299, 1.4738541641062393]
Training Loss (progress: 0.72), 0.12122281373181162, [0.00044043626876697823, 0.0014539439164321785, 0.003600914077244028, 0.002192299299677273, 0.0021370870541356952, 0.004435847194489134], [0.9527169335301934, 1.1072063673604668, 1.2335249948044487, 1.14382036002513, 1.281392906680894, 1.474011153302702]
Training Loss (progress: 0.80), 0.12903088497438808, [0.0004410021368717344, 0.0014616856172706687, 0.003620274386089042, 0.002171075538345107, 0.002141947777141116, 0.004424706537991185], [0.9526372349222709, 1.107214241600808, 1.2335579565499022, 1.1438075625954482, 1.281420384415194, 1.474124551476645]
Training Loss (progress: 0.88), 0.12248075367252324, [0.0004434453902959675, 0.0014330299583708945, 0.003611269355903268, 0.0021765532247347416, 0.0021444325098627717, 0.004417740419786007], [0.9526930035517562, 1.1072187723007945, 1.2336293235022529, 1.1438499699637665, 1.2814863252957112, 1.4742534285029034]
Training Loss (progress: 0.96), 0.1355373552466419, [0.00044320136842203697, 0.00144608644464677, 0.0036199622649326596, 0.0021787364666922527, 0.0021403313593509367, 0.0044170835643265625], [0.952608294828838, 1.1073434869514325, 1.2336962370081446, 1.143883720275151, 1.2815790604653357, 1.474394545460326]
Evaluation on validation dataset:
Step 25, mean loss 0.043277736884332424
Step 50, mean loss 0.019624743769564718
Step 75, mean loss 0.050319697668389264
Step 100, mean loss 0.04569922108493776
Step 125, mean loss 0.06120435953815908
Step 150, mean loss 0.04992858252300945
Step 175, mean loss 0.07053613723979099
Step 200, mean loss 0.1632058254279271
Step 225, mean loss 0.1886202198400545
Unrolled forward losses 1.8125616929894062
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 20 (pos: 0.202): 8.75914e-37, 1.30500e-11, 4.70680e-05, 4.61435e-08, 3.84953e-08, 3.45819e-04
Node: 21 (pos: 0.212): 1.12028e-40, 8.60899e-13, 1.56813e-05, 7.33302e-09, 5.92578e-09, 1.40188e-04
Node: 22 (pos: 0.222): 9.04784e-45, 4.94022e-14, 4.93809e-06, 1.06045e-09, 8.28719e-10, 5.42583e-05
Node: 23 (pos: 0.232): 4.61440e-49, 2.46601e-15, 1.46979e-06, 1.39550e-10, 1.05292e-10, 2.00498e-05
Node: 24 (pos: 0.242): 1.48606e-53, 1.07077e-16, 4.13500e-07, 1.67112e-11, 1.21536e-11, 7.07369e-06
Node: 25 (pos: 0.253): 3.02212e-58, 4.04437e-18, 1.09955e-07, 1.82103e-12, 1.27451e-12, 2.38271e-06
-
Node: 26 (pos: 0.263): 3.88095e-63, 1.32880e-19, 2.76360e-08, 1.80577e-13, 1.21424e-13, 7.66280e-07
Node: 27 (pos: 0.273): 3.14714e-68, 3.79769e-21, 6.56532e-09, 1.62945e-14, 1.05098e-14, 2.35285e-07
Node: 28 (pos: 0.283): 1.61156e-73, 9.44136e-23, 1.47420e-09, 1.33799e-15, 8.26428e-16, 6.89748e-08
Node: 29 (pos: 0.293): 5.21109e-79, 2.04175e-24, 3.12882e-10, 9.99775e-17, 5.90394e-17, 1.93054e-08
Node: 30 (pos: 0.303): 1.06405e-84, 3.84083e-26, 6.27659e-11, 6.79806e-18, 3.83181e-18, 5.15888e-09
Node: 31 (pos: 0.313): 1.37199e-90, 6.28492e-28, 1.19011e-11, 4.20632e-19, 2.25939e-19, 1.31621e-09
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 07 (pos: 0.071): 1.28428e-17, 8.47394e-06, 1.05372e-02, 3.95185e-04, 3.85665e-04, 2.94690e-02
Node: 08 (pos: 0.081): 4.02031e-15, 4.84081e-05, 2.13165e-02, 1.28490e-03, 1.27982e-03, 5.25697e-02
Node: 09 (pos: 0.091): 7.94713e-13, 2.40549e-04, 4.07594e-02, 3.80166e-03, 3.85843e-03, 8.95354e-02
Node: 10 (pos: 0.101): 9.92003e-11, 1.03978e-03, 7.36646e-02, 1.02356e-02, 1.05681e-02, 1.45595e-01
Node: 11 (pos: 0.111): 7.81931e-09, 3.90964e-03, 1.25838e-01, 2.50775e-02, 2.62973e-02, 2.26040e-01
Node: 12 (pos: 0.121): 3.89202e-07, 1.27874e-02, 2.03181e-01, 5.59101e-02, 5.94495e-02, 3.35056e-01
-
Node: 00 (pos: 0.000): 1.12028e-40, 8.60899e-13, 1.56813e-05, 7.33302e-09, 5.92578e-09, 1.40188e-04
Node: 01 (pos: 0.010): 8.75914e-37, 1.30500e-11, 4.70680e-05, 4.61435e-08, 3.84953e-08, 3.45819e-04
Node: 02 (pos: 0.020): 4.32462e-33, 1.72077e-10, 1.33534e-04, 2.64224e-07, 2.27194e-07, 8.14470e-04
Node: 03 (pos: 0.030): 1.34830e-29, 1.97374e-09, 3.58077e-04, 1.37680e-06, 1.21817e-06, 1.83144e-03
Node: 04 (pos: 0.040): 2.65446e-26, 1.96928e-08, 9.07576e-04, 6.52831e-06, 5.93399e-06, 3.93188e-03
Node: 05 (pos: 0.051): 3.30004e-23, 1.70915e-07, 2.17425e-03, 2.81687e-05, 2.62609e-05, 8.05932e-03
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.03428805009640511
Step 50, mean loss 0.017639090663550752
Step 75, mean loss 0.02730697209265953
Step 100, mean loss 0.0419874252240651
Step 125, mean loss 0.05085923966945094
Step 150, mean loss 0.08286972067682201
Step 175, mean loss 0.07588877606712295
Step 200, mean loss 0.16422657523541287
Step 225, mean loss 0.10327442734215658
Unrolled forward losses 1.4789234050388884
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_euclidean_CE_E1_xresolution100-200_lr0.0001_n100_s0.01_tw25_unrolling2_time6811.tar

Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00), 0.11728243475768968, [0.0004432760618304508, 0.0014391205970657576, 0.003609978253212818, 0.002164679069228773, 0.002149140705507912, 0.00440093283695733], [0.9525911011000822, 1.1073133447931882, 1.233722764168379, 1.143906112439822, 1.2815997033382716, 1.4744373129104593]
Training Loss (progress: 0.08), 0.14053964171956446, [0.00044574354352231935, 0.001452410704469437, 0.0036343719955189316, 0.0021842735520012837, 0.0021343865190705004, 0.004428095563642345], [0.9525762466543832, 1.107329740108258, 1.2337828186196498, 1.143921081182534, 1.2816735047709744, 1.474543429380403]
Training Loss (progress: 0.16), 0.12853197095004812, [0.00044060526347967823, 0.001459634781398899, 0.003636093521626583, 0.002174068531246637, 0.002135017965949686, 0.004418127595703322], [0.9525548945668239, 1.1073482688369916, 1.2338518949606112, 1.143993999404104, 1.2817259659254376, 1.47464215090151]
Training Loss (progress: 0.24), 0.13113111247289252, [0.0004337534288787269, 0.0014216173052225389, 0.003617294756658098, 0.0021695238766100203, 0.002142302117703771, 0.004442864477060584], [0.9524924569804363, 1.1073167827653632, 1.233881458525392, 1.1440355255819339, 1.281790925853848, 1.4747978295622814]
Training Loss (progress: 0.32), 0.12310015944946515, [0.0004440327485415753, 0.00147394212517308, 0.003602151160643575, 0.002162873215523408, 0.0021400345747446606, 0.004431387069676995], [0.9523852924746358, 1.1074378802879883, 1.233940958135107, 1.143980350203063, 1.2818567020761489, 1.4749377260380692]
Training Loss (progress: 0.40), 0.1291822736199862, [0.00044592875633876853, 0.0014545339561022076, 0.0036258806043907832, 0.002173945981496992, 0.002129822409116407, 0.004439595142167316], [0.9523718452342521, 1.107483050528274, 1.2340219187640318, 1.1439949432522158, 1.2819154018018, 1.4750567554352891]
Training Loss (progress: 0.48), 0.1303452274660293, [0.00044785736703133704, 0.0014336711932239174, 0.0036357517702574438, 0.002164427452431833, 0.0021323411498759435, 0.004413651984686552], [0.9523740803628004, 1.1075432342614269, 1.2340438274512722, 1.1440646505476526, 1.281966796069449, 1.4751572213407085]
Training Loss (progress: 0.56), 0.1254234163379591, [0.00043714385049372506, 0.0014489078942267752, 0.0036272727515611427, 0.002173509009298325, 0.0021401731126028476, 0.00442311694381781], [0.9523438681720238, 1.1075694648790475, 1.2341309994906517, 1.1440728801425273, 1.2820318178815457, 1.4752741771257767]
Training Loss (progress: 0.64), 0.12325805548360791, [0.0004394081701353217, 0.001445290115899292, 0.003595764671388589, 0.002184215306682941, 0.002133012239915638, 0.004410216681491077], [0.952342339866796, 1.10761138957477, 1.2341565325396844, 1.1441609479195498, 1.2821298932575815, 1.475386436298975]
Training Loss (progress: 0.72), 0.11707214014585034, [0.0004467272027307365, 0.001451697315002936, 0.0036249366191489275, 0.002169742082150156, 0.002125997659749814, 0.0044257973294852876], [0.9522654231817049, 1.1076414142850397, 1.2342267833165494, 1.1441218486718778, 1.2822736641172783, 1.4755022486961338]
Training Loss (progress: 0.80), 0.13121307753428232, [0.0004449147249963717, 0.0014664862020451416, 0.0036261836111053875, 0.0021799011792115247, 0.0021137941445131974, 0.004429556306228408], [0.9522122082527924, 1.1076038937809745, 1.2342869115293946, 1.144149428832447, 1.2823208319508344, 1.4756433126751027]
Training Loss (progress: 0.88), 0.13098489568917487, [0.0004383906433758366, 0.0014418713795180207, 0.003617032258871339, 0.0021684830554761724, 0.0021366881131445743, 0.004408137379266856], [0.9522330503968963, 1.107657281001137, 1.2343805101213745, 1.1441704840008315, 1.2823178149445191, 1.4757405255588778]
Training Loss (progress: 0.96), 0.13144098531441922, [0.00043678785410150247, 0.001459344632147358, 0.0036012154835220874, 0.002182945331313993, 0.0021450378650468335, 0.004416068579145693], [0.9521781066938872, 1.1076890581201504, 1.2343826434107859, 1.1441629092620076, 1.2823878892998306, 1.4758719933262228]
Evaluation on validation dataset:
Step 25, mean loss 0.04423133550699637
Step 50, mean loss 0.019991888953270424
Step 75, mean loss 0.049993072829903305
Step 100, mean loss 0.045777898393811176
Step 125, mean loss 0.06170353382429487
Step 150, mean loss 0.04952815698482307
Step 175, mean loss 0.07063282886270136
Step 200, mean loss 0.16161164138761838
Step 225, mean loss 0.18524843564352617
Unrolled forward losses 1.8694069428514632
Unrolled forward base losses 2.565701273852575
Test loss: 1.4789234050388884
