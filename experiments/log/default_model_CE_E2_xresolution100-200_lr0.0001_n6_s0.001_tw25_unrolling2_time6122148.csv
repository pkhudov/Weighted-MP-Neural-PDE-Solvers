Training on dataset data/CE_train_E2.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_default_model_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time6122148.tar
Beta parameter added to the GNN solver
Number of parameters: 1033777
Saved initial model at models/init6122148.pt
Epoch 0
Starting epoch 0...
Training Loss (progress: 0.00), 1.1851697558909122, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.2354410986124592, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.17672490835060445, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.14773189623559296, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.13682523558940846, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.1260560116206982, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.1114841446588402, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.11297964627671328, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.10066085940278988, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.09168472418758912, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.09034547336285546, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.08980095276911818, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.08065630138839783, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.05143060445185166
Step 50, mean loss 0.045400754069212235
Step 75, mean loss 0.05213262571198554
Step 100, mean loss 0.05417703852177138
Step 125, mean loss 0.07671920475723829
Step 150, mean loss 0.0742347339459722
Step 175, mean loss 0.0959646023505813
Step 200, mean loss 0.1202462667000018
Step 225, mean loss 0.15248770802329276
Unrolled forward losses 12.596993219214198
Unrolled forward base losses 1.1720234445357585
Evaluation on test dataset:
Step 25, mean loss 0.044424057807588874
Step 50, mean loss 0.04379800983440578
Step 75, mean loss 0.05473011205169638
Step 100, mean loss 0.07100745231497702
Step 125, mean loss 0.09062616048845434
Step 150, mean loss 0.13134631122428786
Step 175, mean loss 0.1432878322824469
Step 200, mean loss 0.1533108567423375
Step 225, mean loss 0.19209054865857883
Unrolled forward losses 11.790907884772466
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_default_model_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time6122148.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.20352639189948754, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.18004047823336672, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.18271461653822246, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.15982328545522342, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1992061570745115, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.1660238287403065, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.1611059121338409, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.16392955832828376, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.1608950397399434, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.15313953366954014, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.15371271655674923, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.14591466711175052, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.13385580475572267, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.06429120855171269
Step 50, mean loss 0.03661774526863937
Step 75, mean loss 0.04339119474853794
Step 100, mean loss 0.05190908764825289
Step 125, mean loss 0.07145771245810031
Step 150, mean loss 0.0828089505658664
Step 175, mean loss 0.08455602434772454
Step 200, mean loss 0.10136528280803335
Step 225, mean loss 0.11892176223391437
Unrolled forward losses 3.444175158934738
Unrolled forward base losses 1.1720234445357585
Evaluation on test dataset:
Step 25, mean loss 0.05968140171640181
Step 50, mean loss 0.03761662082780612
Step 75, mean loss 0.04721662073901806
Step 100, mean loss 0.06162418286499228
Step 125, mean loss 0.07697510673493727
Step 150, mean loss 0.12546452677767617
Step 175, mean loss 0.13822207628972666
Step 200, mean loss 0.12595028119413004
Step 225, mean loss 0.1861881400242013
Unrolled forward losses 4.012448185823764
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_default_model_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time6122148.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.18610497957713557, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.1997736853771974, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.18738510159850164, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.19240973829902472, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1869546072152997, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.19221136613010562, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.19302145400597773, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.1752794092880576, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.19577043956520945, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.1675873440678812, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.1630580472230343, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.17157871556133553, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.16438843578567774, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.051716691916292946
Step 50, mean loss 0.020858486292854056
Step 75, mean loss 0.02522340785548797
Step 100, mean loss 0.030491728083984388
Step 125, mean loss 0.0422161918075457
Step 150, mean loss 0.05097897729651438
Step 175, mean loss 0.0543763238794948
Step 200, mean loss 0.07265596504231216
Step 225, mean loss 0.09631723114899485
Unrolled forward losses 2.292333771527577
Unrolled forward base losses 1.1720234445357585
Evaluation on test dataset:
Step 25, mean loss 0.04749997272183572
Step 50, mean loss 0.02097814740497965
Step 75, mean loss 0.024929842474007556
Step 100, mean loss 0.03660701571305018
Step 125, mean loss 0.04785454468156184
Step 150, mean loss 0.08117758458033189
Step 175, mean loss 0.09638801768296813
Step 200, mean loss 0.10261282612331202
Step 225, mean loss 0.13569109623615333
Unrolled forward losses 2.163200173697622
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_default_model_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time6122148.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.15985938420066112, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.17699206153471705, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.1811951885651923, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.16660777395565168, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1805880424692604, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.16493887748077454, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.1539602620455943, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.15991462635501943, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.14737351436358206, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.1732455615722107, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.14913900575176267, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.14941790020784465, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.1571562539343251, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.043344233817818933
Step 50, mean loss 0.022522293327902558
Step 75, mean loss 0.029084740366567344
Step 100, mean loss 0.038898824807537716
Step 125, mean loss 0.05170890912937514
Step 150, mean loss 0.05903878520076061
Step 175, mean loss 0.06478668004549486
Step 200, mean loss 0.07961042993945747
Step 225, mean loss 0.0932221531514725
Unrolled forward losses 2.413611574483803
Unrolled forward base losses 1.1720234445357585
Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.16238343972996033, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.15238546642229517, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.15707792158142625, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.1426711185141442, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1362385034117936, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.14932463985457686, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.14408759581037967, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.14266694148986023, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.15978317258233937, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.1548281629158987, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.16078840653672472, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.15941105146437134, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.13391850593419413, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.03862653451092503
Step 50, mean loss 0.017238928251216732
Step 75, mean loss 0.02350630044552783
Step 100, mean loss 0.030632360077361472
Step 125, mean loss 0.04420982868079006
Step 150, mean loss 0.04586632232462812
Step 175, mean loss 0.0505063392564897
Step 200, mean loss 0.07080962210310185
Step 225, mean loss 0.08930506888877841
Unrolled forward losses 2.619792415999236
Unrolled forward base losses 1.1720234445357585
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.1402029259755824, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.13384234753251487, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.11138576974458371, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.1256092895382034, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.11662727823793566, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.13785670876118858, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.1282847971204769, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.11965451156893343, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.11556718901033076, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.11793678574061121, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.11888753612311308, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.12032999387908513, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.10668387672100568, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.02970820798690848
Step 50, mean loss 0.012191392490181847
Step 75, mean loss 0.0170186667765117
Step 100, mean loss 0.021093202803146388
Step 125, mean loss 0.029279446197584175
Step 150, mean loss 0.03335689053342213
Step 175, mean loss 0.04112893223161898
Step 200, mean loss 0.056903844261483705
Step 225, mean loss 0.07140569488517323
Unrolled forward losses 1.7276320441186055
Unrolled forward base losses 1.1720234445357585
Evaluation on test dataset:
Step 25, mean loss 0.027663596213147623
Step 50, mean loss 0.012705993486583992
Step 75, mean loss 0.016525589473369108
Step 100, mean loss 0.02381021301170566
Step 125, mean loss 0.031383409464397376
Step 150, mean loss 0.058848455199304844
Step 175, mean loss 0.06854536851819096
Step 200, mean loss 0.07737541455952085
Step 225, mean loss 0.10248918180629699
Unrolled forward losses 1.7261805859488097
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_default_model_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time6122148.tar

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.11074546832987188, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.11410464717276068, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.11627743992300225, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.12323376155732448, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.10073545896432623, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.11757317109017228, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.12240075386591011, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.12380997087693331, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.1179749112258309, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.12149968303001678, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.1280609647422436, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.11191335521762032, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.10050886925510233, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.026487702238617388
Step 50, mean loss 0.011392148426262955
Step 75, mean loss 0.015519953177764627
Step 100, mean loss 0.02015096630574671
Step 125, mean loss 0.027800199028801657
Step 150, mean loss 0.03477281230787549
Step 175, mean loss 0.037718260727776086
Step 200, mean loss 0.05483820106658694
Step 225, mean loss 0.06947300513153323
Unrolled forward losses 1.6063369724485057
Unrolled forward base losses 1.1720234445357585
Evaluation on test dataset:
Step 25, mean loss 0.02781155294969985
Step 50, mean loss 0.01343657975574622
Step 75, mean loss 0.015587653222707899
Step 100, mean loss 0.023574630043725866
Step 125, mean loss 0.028551564698545293
Step 150, mean loss 0.05302579963750865
Step 175, mean loss 0.0643740114915643
Step 200, mean loss 0.0709769152398933
Step 225, mean loss 0.10422719937796512
Unrolled forward losses 1.5731136006052593
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_default_model_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time6122148.tar

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.11703326445275906, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.09923957906762794, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.12909184571800936, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.11891774324437013, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1129987800472367, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.11311622351274311, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.11245887875483364, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.12347936210291806, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.11322280162997564, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.11102248859936066, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.11895285742452655, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.12365932013024654, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.11053865710890491, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.024413674212500482
Step 50, mean loss 0.009675880116948313
Step 75, mean loss 0.01635976115586552
Step 100, mean loss 0.021511009558027674
Step 125, mean loss 0.029781106158396138
Step 150, mean loss 0.034441273471234574
Step 175, mean loss 0.039167212530366195
Step 200, mean loss 0.053369563831284335
Step 225, mean loss 0.07264483862171228
Unrolled forward losses 1.504494719285629
Unrolled forward base losses 1.1720234445357585
Evaluation on test dataset:
Step 25, mean loss 0.02337580768776689
Step 50, mean loss 0.011073969487254826
Step 75, mean loss 0.016186006027365068
Step 100, mean loss 0.025516368070033813
Step 125, mean loss 0.03144536163649533
Step 150, mean loss 0.05410055643110839
Step 175, mean loss 0.06647312710339416
Step 200, mean loss 0.07312558729060417
Step 225, mean loss 0.09617541865639548
Unrolled forward losses 1.603889665763424
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_default_model_CE_E2_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time6122148.tar

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.11824023226990414, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.10987934524677018, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.1068038476856307, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.11291218910878716, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1029309290864719, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.10879327526584462, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.11024817018807191, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.12807270145681293, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.113415773502658, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.1152556386552364, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.11012581666712064, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.11397685169507484, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.11647433884345226, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.02328494383524477
Step 50, mean loss 0.009604840661644643
Step 75, mean loss 0.013924479156566867
Step 100, mean loss 0.018263685251757596
Step 125, mean loss 0.02561060230790226
Step 150, mean loss 0.02998552165787261
Step 175, mean loss 0.03610465377773061
Step 200, mean loss 0.05002724928303635
Step 225, mean loss 0.06578559486218144
Unrolled forward losses 1.530499976471197
Unrolled forward base losses 1.1720234445357585
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.11175088891987112, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.11173693155584262, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.10524819149232494, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.10685139431895806, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.11561037727899463, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.11213037248830268, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.10995540078879078, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.12087179419313936, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.10888680164267114, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.10658753036413335, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.11341370403429477, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
