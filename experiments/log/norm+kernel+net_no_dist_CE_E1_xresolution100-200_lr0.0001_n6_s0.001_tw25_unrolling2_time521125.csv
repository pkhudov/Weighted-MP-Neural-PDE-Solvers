Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar
Number of parameters: 1031645
Saved initial model at models/init521125.pt
Epoch 0
Starting epoch 0...
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Training Loss (progress: 0.00), 1.3466396017200162, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.2774132264448517, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.21485499809717196, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.17243993954087478, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.16342368827240603, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.14443265767289473, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.13464148235971796, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.1222564354993964, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.11776668743943583, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.10888912971207532, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.10672567154404913, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.10677150878450636, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.09372745754682135, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.07184986685674406
Step 50, mean loss 0.06662324409688247
Step 75, mean loss 0.08168966491022506
Step 100, mean loss 0.21955826595878464
Step 125, mean loss 0.13640582398680146
Step 150, mean loss 0.13016595421538862
Step 175, mean loss 0.25628877668926564
Step 200, mean loss 0.5305945282262232
Step 225, mean loss 0.4125167484341824
Unrolled forward losses 10.621693955092613
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.062236614479925574
Step 50, mean loss 0.051023121850833665
Step 75, mean loss 0.07726769013901091
Step 100, mean loss 0.09713789728961074
Step 125, mean loss 0.2518864812467704
Step 150, mean loss 0.15189047798306374
Step 175, mean loss 0.346950969401558
Step 200, mean loss 0.31134444933813077
Step 225, mean loss 0.19362489059433707
Unrolled forward losses 9.081841687568039
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.22599438481961678, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.2158015854055958, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.2039916251197143, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.19741499943013793, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.19822101265675143, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.19649493827188583, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.17147569681706054, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.17711014112142393, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.15795440671642633, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.16359945640119727, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.16322778120136458, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.1453713277888685, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.16555462903195248, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.09013003676238092
Step 50, mean loss 0.07502170962165683
Step 75, mean loss 0.08742197384825165
Step 100, mean loss 0.12020718049418089
Step 125, mean loss 0.12932093181744125
Step 150, mean loss 0.1193465079598585
Step 175, mean loss 0.17618523017735366
Step 200, mean loss 0.44427243299183206
Step 225, mean loss 0.3113942780305719
Unrolled forward losses 7.2222814246299585
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.06965583770157374
Step 50, mean loss 0.058221647113766116
Step 75, mean loss 0.08211534016484312
Step 100, mean loss 0.09099512710433577
Step 125, mean loss 0.17767363622163512
Step 150, mean loss 0.13763280907218328
Step 175, mean loss 0.1819055645159508
Step 200, mean loss 0.2603446404031199
Step 225, mean loss 0.17208806617927885
Unrolled forward losses 6.133564451491529
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.19833768892494277, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.20111778037991473, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.21271542363714263, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.2137133423472174, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.20053524273349008, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.19186604586376785, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.18655560181081093, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.18659943057418854, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.22430530004903776, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.16775703778516715, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.2058707317748159, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.19336376154264476, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.1918402083632642, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.07206835528573309
Step 50, mean loss 0.03273641956002921
Step 75, mean loss 0.05353253339648059
Step 100, mean loss 0.07057553394726757
Step 125, mean loss 0.08498718643703589
Step 150, mean loss 0.07876489304795359
Step 175, mean loss 0.11946348646176125
Step 200, mean loss 0.3260830878492365
Step 225, mean loss 0.29282606954544066
Unrolled forward losses 3.200061382161331
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.05760001813945011
Step 50, mean loss 0.025455218784423146
Step 75, mean loss 0.04151981632900568
Step 100, mean loss 0.050987787849788926
Step 125, mean loss 0.08430579282644518
Step 150, mean loss 0.09269073277126458
Step 175, mean loss 0.12793846333816786
Step 200, mean loss 0.1695710116635336
Step 225, mean loss 0.12934527659007594
Unrolled forward losses 3.0195858395036863
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.16821988470072388, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.17416313090695387, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.18228224722108313, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.19595493179539625, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1794642167238417, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.16927909879185563, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.17393206676567566, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.18186493657129127, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.18296309086143833, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.1580661807521282, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.19489196834658745, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.15544481311065567, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.18963827739045686, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.059879934290944
Step 50, mean loss 0.02757990050755532
Step 75, mean loss 0.04008500325125011
Step 100, mean loss 0.0554121688401762
Step 125, mean loss 0.06258050418836304
Step 150, mean loss 0.059823342042541916
Step 175, mean loss 0.09086295542771289
Step 200, mean loss 0.286004325435549
Step 225, mean loss 0.25063669569260266
Unrolled forward losses 2.2661388628655676
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.049326851932471716
Step 50, mean loss 0.022573577068351353
Step 75, mean loss 0.0335804011936965
Step 100, mean loss 0.04243589844132187
Step 125, mean loss 0.07614251323750645
Step 150, mean loss 0.0730871183292468
Step 175, mean loss 0.11675387693445434
Step 200, mean loss 0.17749027341773738
Step 225, mean loss 0.10758818998037449
Unrolled forward losses 2.2502240754549296
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.16478025333613208, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.1712532916958125, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.16567720435874275, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.14520742070594317, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.18105363368548813, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.16484774838402372, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.1670352605315398, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.16881137873702, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.1782579578500818, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.15592094647992935, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.16001227644343902, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.16953162377656178, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.1622572850483606, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.05310442409956432
Step 50, mean loss 0.03105966917887703
Step 75, mean loss 0.04000290948415951
Step 100, mean loss 0.054727443230326425
Step 125, mean loss 0.06502913178948848
Step 150, mean loss 0.07088313552778841
Step 175, mean loss 0.10611570243308853
Step 200, mean loss 0.2666776939703929
Step 225, mean loss 0.2596346836640925
Unrolled forward losses 2.521240014062938
Unrolled forward base losses 2.565701273852575
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.14610344469342018, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.1499304789762382, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.14305784445240488, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.12076821485983441, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1451224259384861, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.13851647115150595, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.14350018155855868, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.13289091341128126, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.1230025960685252, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.13075444253952226, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.1284893224611036, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.1450140886152718, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.1480446444320064, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.044433275592966545
Step 50, mean loss 0.02040186421281854
Step 75, mean loss 0.028065973270162185
Step 100, mean loss 0.04750722103837247
Step 125, mean loss 0.044935575579742947
Step 150, mean loss 0.044861093061624904
Step 175, mean loss 0.0688904592062171
Step 200, mean loss 0.22372216137117748
Step 225, mean loss 0.2361788364538895
Unrolled forward losses 1.8358452181385139
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.03518774909698208
Step 50, mean loss 0.015442567075272256
Step 75, mean loss 0.026801914537302757
Step 100, mean loss 0.03146815476194213
Step 125, mean loss 0.06503783990938432
Step 150, mean loss 0.05135682740530652
Step 175, mean loss 0.08491146512408493
Step 200, mean loss 0.13215440889779362
Step 225, mean loss 0.08721096368233243
Unrolled forward losses 1.7259685861424443
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.12570138393831395, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.1359022305736107, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.13142850874152057, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.13132549809767852, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.14176997182929008, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.1316794126536118, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.1231579204556266, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.13364383846670144, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.145720255197106, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.1388546741893194, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.1339929488181677, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.12637113649182619, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.12497614031364802, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.04350868640215262
Step 50, mean loss 0.01829044521882492
Step 75, mean loss 0.02934812433218289
Step 100, mean loss 0.04777055288865775
Step 125, mean loss 0.04325328952739008
Step 150, mean loss 0.043991546677562623
Step 175, mean loss 0.06778811830789047
Step 200, mean loss 0.18353788745256963
Step 225, mean loss 0.23075073228577558
Unrolled forward losses 2.1142386325452964
Unrolled forward base losses 2.565701273852575
Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.13843503628101336, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.12841206689940818, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.13332663826750077, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.12808480048519508, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.14123159755430864, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.1354588002434311, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.13328224087254995, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.12243875326550276, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.1257334294631618, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.13282354110530165, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.12965179134911844, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.12659576156080915, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.13583856314836248, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.037218898641568535
Step 50, mean loss 0.01730015370941445
Step 75, mean loss 0.026992457654010094
Step 100, mean loss 0.04073493219621099
Step 125, mean loss 0.041087293267783855
Step 150, mean loss 0.043796241208175365
Step 175, mean loss 0.066865195759786
Step 200, mean loss 0.19744378632855053
Step 225, mean loss 0.2122913172416306
Unrolled forward losses 1.6725957905873772
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.031808389179233974
Step 50, mean loss 0.014449153491533518
Step 75, mean loss 0.025151931662836614
Step 100, mean loss 0.028789969674958053
Step 125, mean loss 0.0604276493157372
Step 150, mean loss 0.05182086291759168
Step 175, mean loss 0.07521752604491258
Step 200, mean loss 0.1265746971342728
Step 225, mean loss 0.08445544586056287
Unrolled forward losses 1.6920944481858418
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.12377605186230892, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.11735358586786214, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.1325910241366459, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.11519133123948969, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.13217742370664756, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.11379779311750225, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.1293008608555599, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.13100839202980205, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.11959945648151994, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.13446143450996154, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.12262476846827537, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.1238507277174889, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.11947807943631662, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.033571528829456514
Step 50, mean loss 0.017107838742811028
Step 75, mean loss 0.027310258215668612
Step 100, mean loss 0.03727628220456562
Step 125, mean loss 0.038182504482828714
Step 150, mean loss 0.04261718987366877
Step 175, mean loss 0.06804303751012514
Step 200, mean loss 0.20703115907435704
Step 225, mean loss 0.23931472980186624
Unrolled forward losses 1.6803406751167786
Unrolled forward base losses 2.565701273852575
Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.1250806356404531, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.12793906389776863, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.1266361942081855, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.11657574824780605, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.12275683290559414, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.1230229676395137, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.12533310473629306, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.12160761213358265, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.10668564640169725, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.12505598007022894, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.12604462440283562, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.1257866956820124, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.12063843855264622, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.03220772164120675
Step 50, mean loss 0.01609988715624895
Step 75, mean loss 0.023891313349137556
Step 100, mean loss 0.03597497717406169
Step 125, mean loss 0.03586954625125818
Step 150, mean loss 0.03874654635163925
Step 175, mean loss 0.060935714110728956
Step 200, mean loss 0.16747061783074355
Step 225, mean loss 0.19394760819981566
Unrolled forward losses 1.6752346776511458
Unrolled forward base losses 2.565701273852575
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00), 0.11258156105734822, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.11470993120939985, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.11707921975643679, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.10712886263935525, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1124418139636473, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.11546599524509832, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.11268559294836442, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.10921013104973745, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.12145083020048213, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.10647308451087863, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.11494325015298355, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.11747592495434178, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.11286668821421394, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.029747523090874268
Step 50, mean loss 0.01429702477977583
Step 75, mean loss 0.022919294497843405
Step 100, mean loss 0.031774304680423686
Step 125, mean loss 0.03273637970074128
Step 150, mean loss 0.03554883304694083
Step 175, mean loss 0.05644554042033082
Step 200, mean loss 0.1738728474541363
Step 225, mean loss 0.2096514884642096
Unrolled forward losses 1.538080156862429
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.02421819177464053
Step 50, mean loss 0.011477521929631626
Step 75, mean loss 0.020078677977478327
Step 100, mean loss 0.024621894469437505
Step 125, mean loss 0.04146836486573065
Step 150, mean loss 0.04176008820261781
Step 175, mean loss 0.06253537695841493
Step 200, mean loss 0.12076346463032912
Step 225, mean loss 0.07256370302940798
Unrolled forward losses 1.4967039163093823
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00), 0.10338423035516424, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.10794462704638945, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.09948604635177247, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.11615071025920898, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.1057052743821199, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.11436022755547633, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.11247525036004925, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.10413972334483793, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.11065951102661296, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.11500560967079619, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.09884554120820838, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.10474371545248781, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.10845110771592455, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.028106701605613897
Step 50, mean loss 0.014289293006044302
Step 75, mean loss 0.022193255389402686
Step 100, mean loss 0.031332723677709354
Step 125, mean loss 0.032635854924326316
Step 150, mean loss 0.03475788933064902
Step 175, mean loss 0.053619756978220356
Step 200, mean loss 0.1671176950826103
Step 225, mean loss 0.20320665475719385
Unrolled forward losses 1.6070355281683728
Unrolled forward base losses 2.565701273852575
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00), 0.10602782109313905, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.11082238376835465, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.12049830083046643, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.09964758123964118, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.10320955089668338, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.10947394914182307, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.10626852068547711, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.10534987504638652, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.10937491055366468, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.10121074356952978, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.10589862298205405, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.12543099648895442, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.10493848096347257, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.029942832549557968
Step 50, mean loss 0.014417689439089509
Step 75, mean loss 0.023511180010617777
Step 100, mean loss 0.03129795250319953
Step 125, mean loss 0.03251258813873978
Step 150, mean loss 0.03375509007487588
Step 175, mean loss 0.055128398821943314
Step 200, mean loss 0.16132114774000855
Step 225, mean loss 0.20683829800753323
Unrolled forward losses 1.5885521399103486
Unrolled forward base losses 2.565701273852575
Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00), 0.11578099367859411, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.11236477414324265, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.11323198461111082, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.10466029124877307, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.10540152854060938, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.10737352100395742, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.09695398930397814, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.11402723781871589, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.10545165533942012, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.10773113590843053, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.11585502611120202, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.11092137197865085, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.09949659995753841, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.02981395890992018
Step 50, mean loss 0.015212610711278846
Step 75, mean loss 0.02187062942363442
Step 100, mean loss 0.03132778112732735
Step 125, mean loss 0.03220772255098925
Step 150, mean loss 0.03487183445512082
Step 175, mean loss 0.054863142158577724
Step 200, mean loss 0.1548483326219904
Step 225, mean loss 0.19747426416465258
Unrolled forward losses 1.6171588607302958
Unrolled forward base losses 2.565701273852575
Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00), 0.10969080538950109, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.09820532763721695, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.09901058924468038, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.10734800229840315, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.11301969533855329, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.10523369407986721, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.10895325390927843, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.11094179570110434, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.11273508485222156, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.1181479415291545, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.11499154369018738, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.1037953127188894, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.10506659604346687, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.025590308177886465
Step 50, mean loss 0.012962379978886038
Step 75, mean loss 0.0226851532236321
Step 100, mean loss 0.03300446545880001
Step 125, mean loss 0.030768477384654283
Step 150, mean loss 0.033909920429381436
Step 175, mean loss 0.05242040685177493
Step 200, mean loss 0.14762929590708562
Step 225, mean loss 0.1944634308292957
Unrolled forward losses 1.489330326948744
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.021055175932888824
Step 50, mean loss 0.010395754568840513
Step 75, mean loss 0.019652069585631753
Step 100, mean loss 0.023887694866172638
Step 125, mean loss 0.041496169615955356
Step 150, mean loss 0.038603546583842935
Step 175, mean loss 0.05696188465666096
Step 200, mean loss 0.11568475650645348
Step 225, mean loss 0.0700313339158325
Unrolled forward losses 1.4941147835825315
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar

Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00), 0.11174114475848577, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.10899775136188097, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.11167419487340152, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.10354341215893371, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.11042081977186576, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.10304733073298063, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.10436548328319, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.10093979275785207, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.1066170963528888, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.11199084434485101, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.10718631269331823, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.10942518273186315, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.10070324460306697, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.025254517070048936
Step 50, mean loss 0.013155361647644186
Step 75, mean loss 0.02169153422057688
Step 100, mean loss 0.030583544560818302
Step 125, mean loss 0.030316596209427418
Step 150, mean loss 0.032632986759491625
Step 175, mean loss 0.0522978913917916
Step 200, mean loss 0.1489425494336781
Step 225, mean loss 0.19740712618310347
Unrolled forward losses 1.5299955892269024
Unrolled forward base losses 2.565701273852575
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00), 0.09761166813509065, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.10960114141126125, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.1023541715595178, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.10506116930853754, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.10407733916824786, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.0983480965595369, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.10912193182033715, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.10514798537792917, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.10526052675154782, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.09343424912278157, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.10148849216156337, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.10037836362311306, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.10749017516667493, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.024715257184768465
Step 50, mean loss 0.012758136512518146
Step 75, mean loss 0.021776628084493793
Step 100, mean loss 0.03169552443752994
Step 125, mean loss 0.030328636652696268
Step 150, mean loss 0.03290097974524603
Step 175, mean loss 0.05095297155455483
Step 200, mean loss 0.14575498596477968
Step 225, mean loss 0.1960784992949628
Unrolled forward losses 1.552876798579661
Unrolled forward base losses 2.565701273852575
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00), 0.10496046665145398, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.10100500420160712, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.09707377645747449, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.09845753477839045, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.10538953194831138, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.10244615343827977, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.09793530908135253, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.09449329954842828, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.1038070390024114, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.09995605605037063, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.10445595554650038, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.10765389834985385, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.1000395780436376, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.024457191121653375
Step 50, mean loss 0.012842654893658368
Step 75, mean loss 0.022015687100666773
Step 100, mean loss 0.03052872017015268
Step 125, mean loss 0.029647066689168163
Step 150, mean loss 0.03192261591023535
Step 175, mean loss 0.052132847317048286
Step 200, mean loss 0.14783405931634802
Step 225, mean loss 0.18922342952482496
Unrolled forward losses 1.470314923278543
Unrolled forward base losses 2.565701273852575
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 01 (pos: 0.010): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 02 (pos: 0.020): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 03 (pos: 0.030): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 04 (pos: 0.040): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
-
Node: 07 (pos: 0.071): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 08 (pos: 0.081): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 09 (pos: 0.091): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 10 (pos: 0.101): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 11 (pos: 0.111): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 12 (pos: 0.121): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 58 (pos: 0.586): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 59 (pos: 0.596): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 60 (pos: 0.606): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 61 (pos: 0.616): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 50 (pos: 0.505): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
-
Node: 51 (pos: 0.515): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 52 (pos: 0.525): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 53 (pos: 0.535): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 54 (pos: 0.545): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 55 (pos: 0.556): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 62 (pos: 0.626): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.02015536512174743
Step 50, mean loss 0.01018373933087598
Step 75, mean loss 0.021035137498767238
Step 100, mean loss 0.023508482313661466
Step 125, mean loss 0.03953322301273416
Step 150, mean loss 0.037825493935246014
Step 175, mean loss 0.05415332555133727
Step 200, mean loss 0.11277793298749092
Step 225, mean loss 0.06977581163153321
Unrolled forward losses 1.4463108450325977
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+kernel+net_no_dist_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time521125.tar

Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00), 0.10285589594104884, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.10606069750480929, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.10094728017747466, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.10119849492681486, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.08894215319127297, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.096833865868662, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.09298266048306789, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.10599943474576856, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.09574795386352375, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.10022333326393437, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.10199693315641753, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.10649068502114772, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.10293840690563437, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.023588416236604924
Step 50, mean loss 0.012595220078382239
Step 75, mean loss 0.02112920316723231
Step 100, mean loss 0.030652201995628937
Step 125, mean loss 0.02916469087712174
Step 150, mean loss 0.03211719568994734
Step 175, mean loss 0.05057969842370866
Step 200, mean loss 0.14517814287492725
Step 225, mean loss 0.1917794169721689
Unrolled forward losses 1.4787957373320455
Unrolled forward base losses 2.565701273852575
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00), 0.1148118023054895, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.08), 0.09522236331576395, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.16), 0.0980131819325537, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.24), 0.10109888969295396, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.32), 0.0958101138020196, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.40), 0.10617499769545424, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.48), 0.10485960039985384, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.56), 0.09482697885008073, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.64), 0.10445781299277422, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.72), 0.09178965038966731, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.80), 0.10041327525385312, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.88), 0.10355079955218882, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Training Loss (progress: 0.96), 0.10058634856515009, [0.001, 0.001, 0.001, 0.001, 0.001, 0.001], [1, 1, 1, 1, 1, 1]
Evaluation on validation dataset:
Step 25, mean loss 0.022945790820257005
Step 50, mean loss 0.012495276493249156
Step 75, mean loss 0.021410287956438886
Step 100, mean loss 0.03020020220375962
Step 125, mean loss 0.0286910100569341
Step 150, mean loss 0.03201162221544521
Step 175, mean loss 0.050769176969891146
Step 200, mean loss 0.14555426845708022
Step 225, mean loss 0.19407233607001134
Unrolled forward losses 1.4957873339141872
Unrolled forward base losses 2.565701273852575
Test loss: 1.4463108450325977
