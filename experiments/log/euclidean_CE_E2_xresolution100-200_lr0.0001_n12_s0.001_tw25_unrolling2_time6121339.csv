Training on dataset data/CE_train_E2.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n12_s0.001_tw25_unrolling2_time6121339.tar
Beta parameter added to the GNN solver
Number of parameters: 1033789.0
Saved initial model at models/init6121339.pt
Epoch 0
Starting epoch 0...
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 13 (pos: 0.131): 3.70575e-05, 3.70575e-05, 3.70575e-05, 3.70575e-05, 3.70575e-05, 3.70575e-05
Node: 14 (pos: 0.141): 4.34850e-06, 4.34850e-06, 4.34850e-06, 4.34850e-06, 4.34850e-06, 4.34850e-06
Node: 15 (pos: 0.152): 4.16084e-07, 4.16084e-07, 4.16084e-07, 4.16084e-07, 4.16084e-07, 4.16084e-07
Node: 00 (pos: 0.000): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 01 (pos: 0.010): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 02 (pos: 0.020): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
-
Node: 03 (pos: 0.030): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 05 (pos: 0.051): 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01, 9.03002e-01
Node: 06 (pos: 0.061): 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01, 6.64898e-01
Node: 07 (pos: 0.071): 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01, 3.99208e-01
Node: 08 (pos: 0.081): 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01, 1.95443e-01
Node: 09 (pos: 0.091): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 35 (pos: 0.354): 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02, 7.80223e-02
Node: 36 (pos: 0.364): 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02, 2.53978e-02
Node: 37 (pos: 0.374): 6.74139e-03, 6.74139e-03, 6.74139e-03, 6.74139e-03, 6.74139e-03, 6.74139e-03
Node: 38 (pos: 0.384): 1.45908e-03, 1.45908e-03, 1.45908e-03, 1.45908e-03, 1.45908e-03, 1.45908e-03
Node: 39 (pos: 0.394): 2.57507e-04, 2.57507e-04, 2.57507e-04, 2.57507e-04, 2.57507e-04, 2.57507e-04
Node: 40 (pos: 0.404): 3.70575e-05, 3.70575e-05, 3.70575e-05, 3.70575e-05, 3.70575e-05, 3.70575e-05
-
Node: 41 (pos: 0.414): 4.34850e-06, 4.34850e-06, 4.34850e-06, 4.34850e-06, 4.34850e-06, 4.34850e-06
Node: 42 (pos: 0.424): 4.16084e-07, 4.16084e-07, 4.16084e-07, 4.16084e-07, 4.16084e-07, 4.16084e-07
Node: 19 (pos: 0.192): 4.34850e-06, 4.34850e-06, 4.34850e-06, 4.34850e-06, 4.34850e-06, 4.34850e-06
Node: 20 (pos: 0.202): 3.70575e-05, 3.70575e-05, 3.70575e-05, 3.70575e-05, 3.70575e-05, 3.70575e-05
Node: 21 (pos: 0.212): 2.57507e-04, 2.57507e-04, 2.57507e-04, 2.57507e-04, 2.57507e-04, 2.57507e-04
Node: 22 (pos: 0.222): 1.45908e-03, 1.45908e-03, 1.45908e-03, 1.45908e-03, 1.45908e-03, 1.45908e-03
=========================================================================================================
Training Loss (progress: 0.00), 1.1662783341343044, [0.0019380753971909484, 0.01040392935865313, 0.010778336438469921, 0.009272557143795627, 0.011207935800494914, 0.011028105706517074], [1.0085189829370058, 1.014407068787103, 1.0139881075239603, 1.012380993148865, 1.013387273687893, 1.0132904699779655]
Training Loss (progress: 0.08), 0.19783402590942797, [0.000911618386369488, 0.0007192905071278834, 0.002643203408557015, 0.0010737896996693794, 0.02164065677651342, 0.008193379483530992], [1.03300208778909, 1.0410901162653716, 1.0334953842049461, 1.0412796527616994, 1.0338766412282756, 1.0428808496038635]
Training Loss (progress: 0.16), 0.14511348202810143, [0.0008027745456537217, 0.0006200699889532854, 0.002777231147215611, 0.000923622456610089, 0.024275524262471274, 0.007472966982721866], [1.0351279892975833, 1.0486320615848626, 1.0343709308525428, 1.0480855869037908, 1.0380898531320428, 1.0486697423277715]
Training Loss (progress: 0.24), 0.1327948355800778, [0.0008468636371022434, 0.0005219902276193108, 0.0030360730456738382, 0.001057341537873111, 0.02685716346534031, 0.007752219781668253], [1.037589661999865, 1.0543810689116948, 1.0353664188284826, 1.0522420295011572, 1.0416148968696448, 1.0537199816440084]
Training Loss (progress: 0.32), 0.12347394703193769, [0.0011022196792675922, 0.0005602124785851583, 0.0034392499044588317, 0.0009591461710506955, 0.028786156926009353, 0.008336680385124565], [1.0394660200056125, 1.06076416567958, 1.0373620466379365, 1.056904359347204, 1.0446915064685103, 1.0582035535147458]
Training Loss (progress: 0.40), 0.11118659936513269, [0.0008621589503956418, 0.0004618008580440514, 0.003353719681492431, 0.0011558418655319247, 0.030292711911683253, 0.008569448683661014], [1.0404440064884426, 1.069051003300718, 1.0399036493950455, 1.0613288027207493, 1.047334886302511, 1.0612381136827784]
Training Loss (progress: 0.48), 0.11026972481599798, [0.0008293424964615001, 0.000510208693417384, 0.003379589482584034, 0.0012841057191935157, 0.03400541120851625, 0.009157378116451753], [1.0408301167839293, 1.0763592520789877, 1.0441688377836353, 1.0664193504702477, 1.0512498498775125, 1.0652144482231023]
Training Loss (progress: 0.56), 0.09791331724292754, [0.0008552833653665652, 0.00040128340093649565, 0.0032546221527784036, 0.0013213809083724235, 0.036832406757516034, 0.009545282753502644], [1.0401552661224958, 1.082246512674084, 1.0469381462353422, 1.0711527926628355, 1.053647323498427, 1.0690885306229059]
Training Loss (progress: 0.64), 0.0900023645923357, [0.0007579282657883704, 0.0005453930736155, 0.0035557860905964843, 0.0013197804111740733, 0.03915062040157112, 0.009773176646107683], [1.0396948976926927, 1.088878891342838, 1.0500340987402086, 1.076359088117234, 1.0559151259020279, 1.0711920638104675]
Training Loss (progress: 0.72), 0.09003531615971513, [0.00083718621198795, 0.0005322899959899585, 0.003292619761478257, 0.0012473439640817302, 0.041573151215278145, 0.00981563199449425], [1.0380310126498682, 1.0943537182603567, 1.0524599217376738, 1.081077425289054, 1.0575957559131002, 1.0736359569951752]
Training Loss (progress: 0.80), 0.08955783181071275, [0.0008425808219373478, 0.0004355577285580962, 0.003064395124412492, 0.001355371493953439, 0.043882207997037445, 0.009971764034091946], [1.0368776723122415, 1.0977877659343733, 1.0561832994485478, 1.0859353657833768, 1.060053844909029, 1.0757457535657087]
Training Loss (progress: 0.88), 0.08943979401957859, [0.0009017011755850758, 0.0003921916379571186, 0.0032344761427672273, 0.0012988963561649477, 0.04685260509386807, 0.010035306261999019], [1.0347026951013156, 1.101920484150321, 1.0598423150573681, 1.0906065565211014, 1.062150778806481, 1.0783074526675978]
Training Loss (progress: 0.96), 0.08258776566487146, [0.0008245348343327469, 0.0004976581531808338, 0.003358308092317915, 0.00131663034448975, 0.049341783008155164, 0.010343465089649579], [1.034332071558366, 1.106287531147335, 1.0632779795353917, 1.0942108072857948, 1.0635357879317417, 1.0801408167077509]
Evaluation on validation dataset:
Step 25, mean loss 0.06706496444715009
Step 50, mean loss 0.06501173314462401
Step 75, mean loss 0.07719066054871136
Step 100, mean loss 0.08487025610560711
Step 125, mean loss 0.10159343805145832
Step 150, mean loss 0.10220295604338822
Step 175, mean loss 0.11340084610000523
Step 200, mean loss 0.1316713853767885
Step 225, mean loss 0.1858107123580961
Unrolled forward losses 15.229815852123256
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 13 (pos: 0.131): 3.45991e-07, 2.63018e-09, 4.00274e-02, 5.37163e-04, 8.67067e-01, 3.88515e-01
Node: 14 (pos: 0.141): 1.51115e-08, 4.06243e-11, 2.00986e-02, 1.08391e-04, 8.30659e-01, 3.13376e-01
Node: 15 (pos: 0.152): 4.89832e-10, 4.21785e-13, 9.45099e-03, 1.87792e-05, 7.92536e-01, 2.47649e-01
Node: 00 (pos: 0.000): 9.50820e-02, 4.62153e-02, 6.29692e-01, 3.24013e-01, 1.02937e+00, 9.17849e-01
Node: 01 (pos: 0.010): 2.69992e-01, 1.85575e-01, 7.92244e-01, 5.52416e-01, 1.04420e+00, 9.86018e-01
Node: 02 (pos: 0.020): 5.68988e-01, 5.00907e-01, 9.33459e-01, 8.08667e-01, 1.05492e+00, 1.03779e+00
-
Node: 03 (pos: 0.030): 8.89927e-01, 9.08866e-01, 1.03000e+00, 1.01642e+00, 1.06140e+00, 1.07015e+00
Node: 05 (pos: 0.051): 8.89927e-01, 9.08866e-01, 1.03000e+00, 1.01642e+00, 1.06140e+00, 1.07015e+00
Node: 06 (pos: 0.061): 5.68988e-01, 5.00907e-01, 9.33459e-01, 8.08667e-01, 1.05492e+00, 1.03779e+00
Node: 07 (pos: 0.071): 2.69992e-01, 1.85575e-01, 7.92244e-01, 5.52416e-01, 1.04420e+00, 9.86018e-01
Node: 08 (pos: 0.081): 9.50820e-02, 4.62153e-02, 6.29692e-01, 3.24013e-01, 1.02937e+00, 9.17849e-01
Node: 09 (pos: 0.091): 2.48510e-02, 7.73672e-03, 4.68708e-01, 1.63176e-01, 1.01062e+00, 8.37082e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 35 (pos: 0.354): 2.48510e-02, 7.73672e-03, 4.68708e-01, 1.63176e-01, 1.01062e+00, 8.37082e-01
Node: 36 (pos: 0.364): 4.82048e-03, 8.70629e-04, 3.26725e-01, 7.05584e-02, 9.88165e-01, 7.47954e-01
Node: 37 (pos: 0.374): 6.93961e-04, 6.58589e-05, 2.13289e-01, 2.61963e-02, 9.62269e-01, 6.54776e-01
Node: 38 (pos: 0.384): 7.41445e-05, 3.34888e-06, 1.30394e-01, 8.35084e-03, 9.33232e-01, 5.61591e-01
Node: 39 (pos: 0.394): 5.87926e-06, 1.14470e-07, 7.46544e-02, 2.28570e-03, 9.01381e-01, 4.71909e-01
Node: 40 (pos: 0.404): 3.45991e-07, 2.63018e-09, 4.00274e-02, 5.37163e-04, 8.67067e-01, 3.88515e-01
-
Node: 41 (pos: 0.414): 1.51115e-08, 4.06243e-11, 2.00986e-02, 1.08391e-04, 8.30659e-01, 3.13376e-01
Node: 42 (pos: 0.424): 4.89832e-10, 4.21785e-13, 9.45099e-03, 1.87792e-05, 7.92536e-01, 2.47649e-01
Node: 19 (pos: 0.192): 1.51115e-08, 4.06243e-11, 2.00986e-02, 1.08391e-04, 8.30659e-01, 3.13376e-01
Node: 20 (pos: 0.202): 3.45991e-07, 2.63018e-09, 4.00274e-02, 5.37163e-04, 8.67067e-01, 3.88515e-01
Node: 21 (pos: 0.212): 5.87926e-06, 1.14470e-07, 7.46544e-02, 2.28570e-03, 9.01381e-01, 4.71909e-01
Node: 22 (pos: 0.222): 7.41445e-05, 3.34888e-06, 1.30394e-01, 8.35084e-03, 9.33232e-01, 5.61591e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.05324936850045443
Step 50, mean loss 0.05765414688786939
Step 75, mean loss 0.07437505725529656
Step 100, mean loss 0.0953449845052966
Step 125, mean loss 0.11767041049568731
Step 150, mean loss 0.156565038434953
Step 175, mean loss 0.16923864741122419
Step 200, mean loss 0.2122856280994533
Step 225, mean loss 0.26595759625449517
Unrolled forward losses 15.585094379058651
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n12_s0.001_tw25_unrolling2_time6121339.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.19621797120004703, [0.0007786069201178726, 0.00046564974285260235, 0.0036532520841543407, 0.0013433184444009878, 0.050323198620592834, 0.009900071142229905], [1.0332672280048614, 1.1082602255427063, 1.0649704468325112, 1.09770866864648, 1.0637255628597906, 1.0810766820422872]
Training Loss (progress: 0.08), 0.19274145120091518, [0.001023097509659273, 0.0005395910192590849, 0.003986673974083626, 0.0014346843036305186, 0.05610783165053517, 0.01107067905119154], [1.0312065744611585, 1.1092042458402087, 1.066539422385015, 1.1033453172557257, 1.066960652135312, 1.0837160797861425]
Training Loss (progress: 0.16), 0.180051356556236, [0.001027044348706015, 0.0006208561146296345, 0.004268019384298329, 0.0014836783242958716, 0.05939217166860192, 0.0111469692952724], [1.029159317334851, 1.1102830925360212, 1.0691843142289505, 1.107659726390946, 1.0682072719157896, 1.0859304498434184]
Training Loss (progress: 0.24), 0.18542207882650605, [0.0011373818795439956, 0.000664611324548952, 0.004760055790642839, 0.001649643291308413, 0.06310209665019988, 0.011398388943263777], [1.0274613449969965, 1.1107177693218413, 1.0732501478968075, 1.112014376265061, 1.0697820120818626, 1.0879255591743433]
Training Loss (progress: 0.32), 0.1568488901043042, [0.0009080118465852728, 0.0006272653780055787, 0.0044352354563139485, 0.0016089266949210691, 0.0671481639330973, 0.011071130654319233], [1.0265819080320915, 1.112159946153081, 1.0762949053003807, 1.116899586777345, 1.0717329244895744, 1.0895667675600196]
Training Loss (progress: 0.40), 0.1702897135173364, [0.001091232071415937, 0.0006650390566322644, 0.004541145253523751, 0.0015482095515268574, 0.06971520782631248, 0.011712064588300711], [1.0247427518361791, 1.1126223412058738, 1.0808145180752344, 1.1209504170040898, 1.0729188701214594, 1.0918450193275564]
Training Loss (progress: 0.48), 0.1534257061357934, [0.0009853535997759932, 0.0006243460337883669, 0.004421839784113342, 0.0016414069824435807, 0.07208245122729454, 0.01141529162869031], [1.0223548788080452, 1.1140950488036674, 1.0837748144231492, 1.1241550822019803, 1.0732481600533261, 1.093098237259492]
Training Loss (progress: 0.56), 0.15916824540268895, [0.0012000412491878626, 0.0007272270766052546, 0.004163034543570508, 0.0016544392565619158, 0.07479211586865048, 0.011576272331346355], [1.0205194827066133, 1.1149647970548726, 1.0878335592458903, 1.1286277218439564, 1.074138804609621, 1.0952294195393013]
Training Loss (progress: 0.64), 0.16807435578259095, [0.0010945697943754997, 0.0007698319270886905, 0.004626361673123673, 0.0015415159757473868, 0.07691386358047161, 0.011274829975992261], [1.0181765519763735, 1.1152799714290789, 1.09086224788533, 1.1327733230226014, 1.0750525097089203, 1.0976860471632306]
Training Loss (progress: 0.72), 0.1459982460532383, [0.0010408969731266313, 0.0006175775320473031, 0.004691780630431259, 0.001582818508724294, 0.08001104748342804, 0.011259971717679236], [1.016051790372549, 1.1149735625539585, 1.094449978130046, 1.1358792771472108, 1.0766906292228904, 1.0989554551541953]
Training Loss (progress: 0.80), 0.1529877142858425, [0.001278317521361013, 0.0006157950729512474, 0.004415282593304903, 0.001552175734877099, 0.08155854267765775, 0.011066155162559734], [1.0147203779892882, 1.1174309453087388, 1.0981419872090064, 1.1399207823382138, 1.0774443609633955, 1.1005245863568693]
Training Loss (progress: 0.88), 0.14727032172529045, [0.0014079567588835941, 0.0007657680103526465, 0.004205568393389478, 0.0015868769116633116, 0.08409585042712983, 0.011288109175702922], [1.0119115635443372, 1.115445739960572, 1.1006010585591592, 1.1418930176126998, 1.078286265999209, 1.1031739803840133]
Training Loss (progress: 0.96), 0.1535212621706004, [0.001292883516557949, 0.0008131693072346636, 0.004487717639561304, 0.001465179115155435, 0.08666504273481589, 0.011763974409244581], [1.0095583472727414, 1.1180931272708363, 1.1049786017210077, 1.144441975343593, 1.0793186091383224, 1.104723228070486]
Evaluation on validation dataset:
Step 25, mean loss 0.11250590821677733
Step 50, mean loss 0.06268803602347098
Step 75, mean loss 0.0700100971957904
Step 100, mean loss 0.07594906170269143
Step 125, mean loss 0.08619175168993018
Step 150, mean loss 0.1042898690424727
Step 175, mean loss 0.10896184470725578
Step 200, mean loss 0.1312039195208064
Step 225, mean loss 0.15699852640590184
Unrolled forward losses 5.675376775081343
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 13 (pos: 0.131): 1.12411e-04, 2.10279e-08, 1.08729e-01, 1.68222e-03, 9.60731e-01, 4.44305e-01
Node: 14 (pos: 0.141): 1.66212e-05, 5.01694e-10, 6.67997e-02, 4.27457e-04, 9.37498e-01, 3.66936e-01
Node: 15 (pos: 0.152): 2.04859e-06, 8.38632e-12, 3.91789e-02, 9.53312e-05, 9.12695e-01, 2.97568e-01
Node: 00 (pos: 0.000): 2.35177e-01, 6.48968e-02, 7.63200e-01, 4.03506e-01, 1.05957e+00, 9.55089e-01
Node: 01 (pos: 0.010): 4.44743e-01, 2.25429e-01, 8.97765e-01, 6.37061e-01, 1.06825e+00, 1.01798e+00
Node: 02 (pos: 0.020): 7.01073e-01, 5.48636e-01, 1.00818e+00, 8.82766e-01, 1.07450e+00, 1.06543e+00
-
Node: 03 (pos: 0.030): 9.21204e-01, 9.35513e-01, 1.08084e+00, 1.07360e+00, 1.07826e+00, 1.09495e+00
Node: 05 (pos: 0.051): 9.21204e-01, 9.35513e-01, 1.08084e+00, 1.07360e+00, 1.07826e+00, 1.09495e+00
Node: 06 (pos: 0.061): 7.01073e-01, 5.48636e-01, 1.00818e+00, 8.82766e-01, 1.07450e+00, 1.06543e+00
Node: 07 (pos: 0.071): 4.44743e-01, 2.25429e-01, 8.97765e-01, 6.37061e-01, 1.06825e+00, 1.01798e+00
Node: 08 (pos: 0.081): 2.35177e-01, 6.48968e-02, 7.63200e-01, 4.03506e-01, 1.05957e+00, 9.55089e-01
Node: 09 (pos: 0.091): 1.03661e-01, 1.30896e-02, 6.19390e-01, 2.24313e-01, 1.04851e+00, 8.79900e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 35 (pos: 0.354): 1.03661e-01, 1.30896e-02, 6.19390e-01, 2.24313e-01, 1.04851e+00, 8.79900e-01
Node: 36 (pos: 0.364): 3.80872e-02, 1.84979e-03, 4.79889e-01, 1.09444e-01, 1.03515e+00, 7.95994e-01
Node: 37 (pos: 0.374): 1.16648e-02, 1.83149e-04, 3.54950e-01, 4.68666e-02, 1.01958e+00, 7.07087e-01
Node: 38 (pos: 0.384): 2.97795e-03, 1.27051e-05, 2.50636e-01, 1.76145e-02, 1.00191e+00, 6.16769e-01
Node: 39 (pos: 0.394): 6.33715e-04, 6.17508e-07, 1.68955e-01, 5.81045e-03, 9.82248e-01, 5.28273e-01
Node: 40 (pos: 0.404): 1.12411e-04, 2.10279e-08, 1.08729e-01, 1.68222e-03, 9.60731e-01, 4.44305e-01
-
Node: 41 (pos: 0.414): 1.66212e-05, 5.01694e-10, 6.67997e-02, 4.27457e-04, 9.37498e-01, 3.66936e-01
Node: 42 (pos: 0.424): 2.04859e-06, 8.38632e-12, 3.91789e-02, 9.53312e-05, 9.12695e-01, 2.97568e-01
Node: 19 (pos: 0.192): 1.66212e-05, 5.01694e-10, 6.67997e-02, 4.27457e-04, 9.37498e-01, 3.66936e-01
Node: 20 (pos: 0.202): 1.12411e-04, 2.10279e-08, 1.08729e-01, 1.68222e-03, 9.60731e-01, 4.44305e-01
Node: 21 (pos: 0.212): 6.33715e-04, 6.17508e-07, 1.68955e-01, 5.81045e-03, 9.82248e-01, 5.28273e-01
Node: 22 (pos: 0.222): 2.97795e-03, 1.27051e-05, 2.50636e-01, 1.76145e-02, 1.00191e+00, 6.16769e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.09906161843314973
Step 50, mean loss 0.057189609062980845
Step 75, mean loss 0.06214461345437705
Step 100, mean loss 0.0847660484949925
Step 125, mean loss 0.10306049801571279
Step 150, mean loss 0.15365680385766523
Step 175, mean loss 0.16477902467088681
Step 200, mean loss 0.1878762068004664
Step 225, mean loss 0.24288063483101724
Unrolled forward losses 5.68237036515813
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n12_s0.001_tw25_unrolling2_time6121339.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.21913711268521746, [0.0012664442414807777, 0.0006283102077240033, 0.004833733965833571, 0.0017234112650124811, 0.08763701839582512, 0.0112270544409586], [1.0091928714245146, 1.1174941257542492, 1.1067018691655084, 1.1464310203501127, 1.0796132618570176, 1.1051316237796682]
Training Loss (progress: 0.08), 0.1856771662189762, [0.0012730397992564055, 0.0005562976913826401, 0.004808248994852602, 0.001673825436080804, 0.08912127079029965, 0.011788835200548712], [1.009109124327431, 1.1175429513711082, 1.1109240028356129, 1.1473882263283548, 1.0809069017421027, 1.1075454484752247]
Training Loss (progress: 0.16), 0.2080807401779594, [0.0011261539890487916, 0.0006717385070226519, 0.004939608040782789, 0.0017307730327304105, 0.09110066257516823, 0.011991047767523492], [1.008891192893902, 1.1180522225612735, 1.1123203163940747, 1.147745138792371, 1.0824380924860248, 1.1095550653814972]
Training Loss (progress: 0.24), 0.19735061727315084, [0.0013270262115921976, 0.0006760459922082518, 0.004870402926090795, 0.0018174877439061333, 0.09230071318838619, 0.011782351637740551], [1.0085216203174385, 1.1171371150877483, 1.1151257520131537, 1.1490136040087757, 1.0831504584635498, 1.1107505734416874]
Training Loss (progress: 0.32), 0.19196900964144648, [0.0012422991324798325, 0.0007194557404401356, 0.0048687719241113135, 0.001752229280125645, 0.0932503059428469, 0.012115655599242266], [1.008255533651803, 1.1168830509787282, 1.1169442711428819, 1.1484241238616673, 1.0840168364462799, 1.1124065483738697]
Training Loss (progress: 0.40), 0.19784282144813553, [0.001261158800407751, 0.0006735106225238542, 0.005025800722277305, 0.0018039677517556825, 0.0950713552471656, 0.012109353012761875], [1.0078188642579717, 1.1177631674310873, 1.1185240030822994, 1.149686858696572, 1.0852317748075906, 1.1140632806441944]
Training Loss (progress: 0.48), 0.19149134520842392, [0.00126135091763536, 0.0006454747523526458, 0.004885077814026187, 0.0017956781082735485, 0.09619888297156176, 0.01215742901381307], [1.0073225092541063, 1.1176388370668107, 1.120471522439524, 1.1500404343228812, 1.0862666749519077, 1.1156239852564513]
Training Loss (progress: 0.56), 0.19988666157056925, [0.0012635860403363015, 0.0007020924682573795, 0.004980778450796637, 0.0017474909058718075, 0.09780783448534322, 0.012223651045539734], [1.0074144254529283, 1.118135713998448, 1.123727294062947, 1.150962236677694, 1.0872523656182151, 1.1168387179985233]
Training Loss (progress: 0.64), 0.16622022202490272, [0.0012725817407322562, 0.0006690231096516897, 0.004851181545139271, 0.0017870687320769524, 0.0988887364478694, 0.012131435368027027], [1.007388777843022, 1.1182695432546739, 1.1250650314597392, 1.1520387595520745, 1.0878567173180584, 1.117972578573741]
Training Loss (progress: 0.72), 0.1918222798828148, [0.0012399621966695021, 0.0006969760808438052, 0.0050179669910646926, 0.0018370739043254598, 0.10019862941807182, 0.01228814153596686], [1.006654871442721, 1.1183165771160872, 1.1271497513905646, 1.1528189084215499, 1.088734232351842, 1.1190160402419669]
Training Loss (progress: 0.80), 0.1646991932856454, [0.00130516022332822, 0.0007294341286752062, 0.004835644739956562, 0.0018027305312835042, 0.10143440433561797, 0.012647571531486806], [1.0065210269590632, 1.1186430529983735, 1.1292387709326768, 1.1528842579337855, 1.0896424643481706, 1.120368341817671]
Training Loss (progress: 0.88), 0.17326756771179433, [0.0013476651929405956, 0.0006811115816312871, 0.004956298570961843, 0.00181593925608673, 0.1024616310840025, 0.012665915510150125], [1.0056464393338471, 1.1194449987273358, 1.1309527200780238, 1.1539904184458756, 1.0900499375735873, 1.1215921864624705]
Training Loss (progress: 0.96), 0.18256000744996143, [0.0012097703845933001, 0.0007863610891065347, 0.005129721027660538, 0.001861679172224817, 0.10351898030930069, 0.012540348283689925], [1.005370615005871, 1.1196446335609553, 1.1321373658308083, 1.153867370314789, 1.0907301981222086, 1.1225864694046601]
Evaluation on validation dataset:
Step 25, mean loss 0.04787278267557454
Step 50, mean loss 0.024718530791274618
Step 75, mean loss 0.030736515561253196
Step 100, mean loss 0.03585611906963219
Step 125, mean loss 0.04543979699329551
Step 150, mean loss 0.05281128712507988
Step 175, mean loss 0.059427147392454624
Step 200, mean loss 0.08203728863838838
Step 225, mean loss 0.11905589537919056
Unrolled forward losses 2.272403646937427
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 13 (pos: 0.131): 1.66646e-04, 1.57016e-07, 1.46450e-01, 3.81852e-03, 9.88454e-01, 4.93635e-01
Node: 14 (pos: 0.141): 2.67873e-05, 5.71228e-09, 9.53080e-02, 1.15089e-03, 9.68206e-01, 4.15383e-01
Node: 15 (pos: 0.152): 3.61789e-06, 1.51570e-10, 5.95388e-02, 3.09434e-04, 9.46505e-01, 3.43838e-01
Node: 00 (pos: 0.000): 2.49610e-01, 8.96367e-02, 8.16464e-01, 4.62741e-01, 1.07377e+00, 9.84535e-01
Node: 01 (pos: 0.010): 4.59076e-01, 2.70519e-01, 9.42159e-01, 6.90174e-01, 1.08121e+00, 1.04284e+00
Node: 02 (pos: 0.020): 7.09415e-01, 5.95455e-01, 1.04362e+00, 9.18276e-01, 1.08655e+00, 1.08658e+00
-
Node: 03 (pos: 0.030): 9.21107e-01, 9.55959e-01, 1.10967e+00, 1.08989e+00, 1.08976e+00, 1.11371e+00
Node: 05 (pos: 0.051): 9.21107e-01, 9.55959e-01, 1.10967e+00, 1.08989e+00, 1.08976e+00, 1.11371e+00
Node: 06 (pos: 0.061): 7.09415e-01, 5.95455e-01, 1.04362e+00, 9.18276e-01, 1.08655e+00, 1.08658e+00
Node: 07 (pos: 0.071): 4.59076e-01, 2.70519e-01, 9.42159e-01, 6.90174e-01, 1.08121e+00, 1.04284e+00
Node: 08 (pos: 0.081): 2.49610e-01, 8.96367e-02, 8.16464e-01, 4.62741e-01, 1.07377e+00, 9.84535e-01
Node: 09 (pos: 0.091): 1.14034e-01, 2.16627e-02, 6.79176e-01, 2.76766e-01, 1.06429e+00, 9.14338e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 35 (pos: 0.354): 1.14034e-01, 2.16627e-02, 6.79176e-01, 2.76766e-01, 1.06429e+00, 9.14338e-01
Node: 36 (pos: 0.364): 4.37722e-02, 3.81839e-03, 5.42325e-01, 1.47666e-01, 1.05281e+00, 8.35303e-01
Node: 37 (pos: 0.374): 1.41175e-02, 4.90894e-04, 4.15689e-01, 7.02818e-02, 1.03941e+00, 7.50659e-01
Node: 38 (pos: 0.384): 3.82569e-03, 4.60292e-05, 3.05851e-01, 2.98400e-02, 1.02416e+00, 6.63594e-01
Node: 39 (pos: 0.394): 8.71075e-04, 3.14789e-06, 2.16015e-01, 1.13019e-02, 1.00714e+00, 5.77063e-01
Node: 40 (pos: 0.404): 1.66646e-04, 1.57016e-07, 1.46450e-01, 3.81852e-03, 9.88454e-01, 4.93635e-01
-
Node: 41 (pos: 0.414): 2.67873e-05, 5.71228e-09, 9.53080e-02, 1.15089e-03, 9.68206e-01, 4.15383e-01
Node: 42 (pos: 0.424): 3.61789e-06, 1.51570e-10, 5.95388e-02, 3.09434e-04, 9.46505e-01, 3.43838e-01
Node: 19 (pos: 0.192): 2.67873e-05, 5.71228e-09, 9.53080e-02, 1.15089e-03, 9.68206e-01, 4.15383e-01
Node: 20 (pos: 0.202): 1.66646e-04, 1.57016e-07, 1.46450e-01, 3.81852e-03, 9.88454e-01, 4.93635e-01
Node: 21 (pos: 0.212): 8.71075e-04, 3.14789e-06, 2.16015e-01, 1.13019e-02, 1.00714e+00, 5.77063e-01
Node: 22 (pos: 0.222): 3.82569e-03, 4.60292e-05, 3.05851e-01, 2.98400e-02, 1.02416e+00, 6.63594e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.045309484616313116
Step 50, mean loss 0.02637080451781663
Step 75, mean loss 0.03182044077926792
Step 100, mean loss 0.04611082960165645
Step 125, mean loss 0.058250044970865424
Step 150, mean loss 0.0875406939658975
Step 175, mean loss 0.09339332169446696
Step 200, mean loss 0.13039127474858866
Step 225, mean loss 0.17367274363208496
Unrolled forward losses 2.8296579399260846
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n12_s0.001_tw25_unrolling2_time6121339.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.154791559061952, [0.0013378192162498811, 0.0007519148506453117, 0.005014126261195961, 0.0018943895843695558, 0.1036805725903164, 0.012265321243224537], [1.004792111924203, 1.119152334171904, 1.1330711759853942, 1.154002900620391, 1.0909215813518414, 1.122861858571091]
Training Loss (progress: 0.08), 0.17579275714929143, [0.0012811304223710501, 0.0006646630336479311, 0.005006292189496946, 0.0018055716820241747, 0.10484932742534452, 0.012658233298889746], [1.0050785868522425, 1.1195685964472535, 1.1347491977598256, 1.1547784696755448, 1.0917056940728014, 1.1241620508039234]
Training Loss (progress: 0.16), 0.15697050359666248, [0.0013145598166793143, 0.0006865835577913656, 0.00515026874486441, 0.0017601467081560375, 0.10616034904611703, 0.012620984892303216], [1.0037660715619718, 1.119567020749921, 1.1366918555295513, 1.1552845869230202, 1.0923346784698982, 1.1251892988993935]
Training Loss (progress: 0.24), 0.17838947160183977, [0.0012478373748105967, 0.0007074716951026702, 0.005041897397358487, 0.0018993107580112596, 0.1073796954165487, 0.01272809129242666], [1.0036106991443394, 1.1199033125625495, 1.13839058297898, 1.1563326987182199, 1.0931165030266938, 1.1265580415319798]
Training Loss (progress: 0.32), 0.18582305065010565, [0.001295392915756752, 0.000704586062483109, 0.00525967374652967, 0.0019225546979961129, 0.10818947848375898, 0.01256205030731674], [1.0036487146798332, 1.1198531501175992, 1.140583417853858, 1.156473546731334, 1.0937092468091925, 1.127443346527983]
Training Loss (progress: 0.40), 0.15435816939538152, [0.0012838767575224376, 0.0006831977686695313, 0.005061830065432065, 0.0018559907702253163, 0.10900347867093572, 0.012704289368411791], [1.002846400528742, 1.1200599964205125, 1.1421117796170837, 1.1568430748389844, 1.0941206376124315, 1.128635947400394]
Training Loss (progress: 0.48), 0.18535022498752604, [0.0012925111740830528, 0.0006944815556919469, 0.005174512034418787, 0.0018402385740727426, 0.11022286785269529, 0.012662912552707021], [1.0018891363080225, 1.1198383607670603, 1.1440177977723234, 1.158040693053132, 1.0949906783230443, 1.1298613841981044]
Training Loss (progress: 0.56), 0.16615759796196664, [0.0013386375207730607, 0.000766271643164793, 0.005207701776446063, 0.0019166505995317992, 0.11106680694241036, 0.012802656791376358], [1.0012805069789723, 1.1196117143172057, 1.1454275849220026, 1.1588349443648545, 1.0952187393268846, 1.1309123137868442]
Training Loss (progress: 0.64), 0.15070960694822505, [0.00137574001231857, 0.0006919731039902686, 0.0050328507985636685, 0.0018586852408816361, 0.11203712166632288, 0.012610093768644736], [1.0009866588474774, 1.1199705923276564, 1.146514013946868, 1.1596027588067677, 1.0957523115140178, 1.1312622517256514]
Training Loss (progress: 0.72), 0.1606577724953401, [0.0013688615469183004, 0.0008845482345000962, 0.005315106303736793, 0.001764085127961589, 0.1130919032534305, 0.012777808912154605], [1.0000149404315304, 1.1199015788038538, 1.148414340407048, 1.1594570656768246, 1.0964160982468572, 1.1328328305973832]
Training Loss (progress: 0.80), 0.16036232814668014, [0.0013319168968871434, 0.0006639887812010213, 0.005372971313039528, 0.001888973749208305, 0.11424542628042546, 0.012711081274109077], [0.9992540296299721, 1.1195273113961317, 1.1500966261610057, 1.1602466700519272, 1.0969261584773442, 1.134039774112213]
Training Loss (progress: 0.88), 0.1685334666860487, [0.0014005570790982143, 0.000719549147568319, 0.0053702058876116615, 0.00193463357872774, 0.11529828707102162, 0.012775612658977361], [0.9986415895007081, 1.1192021456862, 1.1516197174711347, 1.1606186809846557, 1.0974525175231393, 1.1352284334692964]
Training Loss (progress: 0.96), 0.16761303475990216, [0.0013719186235610773, 0.0007166707425109743, 0.00526619472586859, 0.001891411440373389, 0.11644092036898193, 0.012669138745466157], [0.998217018674727, 1.1192247122240788, 1.1533901243075888, 1.1604684254590074, 1.0979677453351198, 1.1359769401594668]
Evaluation on validation dataset:
Step 25, mean loss 0.04419105266312875
Step 50, mean loss 0.01697050573150236
Step 75, mean loss 0.02619642244551929
Step 100, mean loss 0.034307513093788725
Step 125, mean loss 0.03980869946163856
Step 150, mean loss 0.046129531736037205
Step 175, mean loss 0.04997688862773281
Step 200, mean loss 0.06900536447472264
Step 225, mean loss 0.09201583159532715
Unrolled forward losses 2.082053362938167
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 13 (pos: 0.131): 3.39161e-04, 5.96196e-08, 1.74146e-01, 6.55861e-03, 1.00635e+00, 5.04664e-01
Node: 14 (pos: 0.141): 6.33803e-05, 1.76967e-09, 1.17063e-01, 2.21170e-03, 9.88062e-01, 4.25574e-01
Node: 15 (pos: 0.152): 1.00955e-05, 3.75770e-11, 7.57697e-02, 6.72484e-04, 9.68413e-01, 3.53100e-01
Node: 00 (pos: 0.000): 2.78106e-01, 7.68019e-02, 8.52888e-01, 5.07166e-01, 1.08295e+00, 9.97956e-01
Node: 01 (pos: 0.010): 4.86438e-01, 2.48049e-01, 9.73621e-01, 7.28638e-01, 1.08959e+00, 1.05630e+00
Node: 02 (pos: 0.020): 7.25217e-01, 5.73095e-01, 1.07019e+00, 9.43871e-01, 1.09436e+00, 1.10005e+00
-
Node: 03 (pos: 0.030): 9.21579e-01, 9.47197e-01, 1.13267e+00, 1.10244e+00, 1.09723e+00, 1.12717e+00
Node: 05 (pos: 0.051): 9.21579e-01, 9.47197e-01, 1.13267e+00, 1.10244e+00, 1.09723e+00, 1.12717e+00
Node: 06 (pos: 0.061): 7.25217e-01, 5.73095e-01, 1.07019e+00, 9.43871e-01, 1.09436e+00, 1.10005e+00
Node: 07 (pos: 0.071): 4.86438e-01, 2.48049e-01, 9.73621e-01, 7.28638e-01, 1.08959e+00, 1.05630e+00
Node: 08 (pos: 0.081): 2.78106e-01, 7.68019e-02, 8.52888e-01, 5.07166e-01, 1.08295e+00, 9.97956e-01
Node: 09 (pos: 0.091): 1.35524e-01, 1.70110e-02, 7.19392e-01, 3.18294e-01, 1.07447e+00, 9.27653e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 35 (pos: 0.354): 1.35524e-01, 1.70110e-02, 7.19392e-01, 3.18294e-01, 1.07447e+00, 9.27653e-01
Node: 36 (pos: 0.364): 5.62921e-02, 2.69534e-03, 5.84267e-01, 1.80113e-01, 1.06420e+00, 8.48417e-01
Node: 37 (pos: 0.374): 1.99297e-02, 3.05507e-04, 4.56908e-01, 9.18973e-02, 1.05219e+00, 7.63454e-01
Node: 38 (pos: 0.384): 6.01421e-03, 2.47715e-05, 3.44047e-01, 4.22766e-02, 1.03849e+00, 6.75937e-01
Node: 39 (pos: 0.394): 1.54696e-03, 1.43684e-06, 2.49448e-01, 1.75362e-02, 1.02319e+00, 5.88816e-01
Node: 40 (pos: 0.404): 3.39161e-04, 5.96196e-08, 1.74146e-01, 6.55861e-03, 1.00635e+00, 5.04664e-01
-
Node: 41 (pos: 0.414): 6.33803e-05, 1.76967e-09, 1.17063e-01, 2.21170e-03, 9.88062e-01, 4.25574e-01
Node: 42 (pos: 0.424): 1.00955e-05, 3.75770e-11, 7.57697e-02, 6.72484e-04, 9.68413e-01, 3.53100e-01
Node: 19 (pos: 0.192): 6.33803e-05, 1.76967e-09, 1.17063e-01, 2.21170e-03, 9.88062e-01, 4.25574e-01
Node: 20 (pos: 0.202): 3.39161e-04, 5.96196e-08, 1.74146e-01, 6.55861e-03, 1.00635e+00, 5.04664e-01
Node: 21 (pos: 0.212): 1.54696e-03, 1.43684e-06, 2.49448e-01, 1.75362e-02, 1.02319e+00, 5.88816e-01
Node: 22 (pos: 0.222): 6.01421e-03, 2.47715e-05, 3.44047e-01, 4.22766e-02, 1.03849e+00, 6.75937e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.04164276398607124
Step 50, mean loss 0.01932560223825211
Step 75, mean loss 0.027323943439101474
Step 100, mean loss 0.03795922058867421
Step 125, mean loss 0.046787952871964335
Step 150, mean loss 0.0662327419608564
Step 175, mean loss 0.07646814913378133
Step 200, mean loss 0.09755366208891751
Step 225, mean loss 0.1427025044869355
Unrolled forward losses 2.610844757267291
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n12_s0.001_tw25_unrolling2_time6121339.tar

Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.17159714964765044, [0.001314160536585288, 0.0006694268723892825, 0.005392751721681787, 0.0019688995522048613, 0.11683868654689711, 0.012662902785239842], [0.9981870817076554, 1.1196096637485784, 1.1545324269118409, 1.1609746483968113, 1.098184311777165, 1.136513237414152]
Training Loss (progress: 0.08), 0.1682618800296979, [0.0013140844197541566, 0.0007370497412736265, 0.005338718629688128, 0.0018836074876449483, 0.11792921436619849, 0.01278842236776293], [0.9970933752144966, 1.1191204781667972, 1.1554982860609793, 1.1615221729449907, 1.0987504127330163, 1.1376758345099804]
Training Loss (progress: 0.16), 0.15702022904063714, [0.001318135425277903, 0.0006636701500146334, 0.00522560903115147, 0.0018563680085710971, 0.11874967670839427, 0.012804182603383727], [0.9963498187767015, 1.120145517342414, 1.1566457356283857, 1.1621398369697409, 1.0990412192151864, 1.1388742082972827]
Training Loss (progress: 0.24), 0.17286419493029662, [0.0013342711021966805, 0.000660578222472138, 0.00547189755730526, 0.0019182523061596047, 0.11958841800663195, 0.012685672937007597], [0.9960291883266923, 1.1193394463399904, 1.1577979590745207, 1.1623268544347674, 1.099464989362759, 1.1396182625498235]
Training Loss (progress: 0.32), 0.16608115730521228, [0.0013727030751147793, 0.0008563961654974987, 0.00544137336599198, 0.0018362320928278358, 0.12083787333425008, 0.012832592999430882], [0.9953146636794318, 1.1191125575530319, 1.1592014581458574, 1.1638062183430142, 1.100112640946515, 1.1407325424966748]
Training Loss (progress: 0.40), 0.15880632217040416, [0.0012600962010663706, 0.000684811470486808, 0.005219165785879109, 0.00193464520044134, 0.12146381356783247, 0.012777858469836364], [0.9945771181530485, 1.1191685421560846, 1.1606204629224122, 1.1632419121238995, 1.1003564033635689, 1.141752997501901]
Training Loss (progress: 0.48), 0.14811360505561985, [0.0013387499196187657, 0.0007612875244255875, 0.00552779475129062, 0.0019365973312388343, 0.12243254782064412, 0.012607706791794902], [0.9942992871015113, 1.1193076236280084, 1.1619696598407745, 1.1641288760571387, 1.1006825750497802, 1.1423626020312971]
Training Loss (progress: 0.56), 0.1498897302372231, [0.0013655150902201567, 0.0007948952907001505, 0.005424759708197471, 0.0019149123433057475, 0.12383703023001903, 0.012808261500324204], [0.9934131922385452, 1.1194634048053966, 1.1636661592446285, 1.164284613172455, 1.1010293040674017, 1.1438049256079856]
Training Loss (progress: 0.64), 0.1588137424570172, [0.001398670532131656, 0.000695316214285047, 0.00573847403395994, 0.0019476925644308558, 0.12474252051014792, 0.012687151165629771], [0.9934689266528602, 1.1194863650484792, 1.1647473017748786, 1.164575267533159, 1.101497732102289, 1.1447177037321365]
Training Loss (progress: 0.72), 0.15549263422764054, [0.0013458667786284536, 0.000652002619180791, 0.005411899876361223, 0.0019861847163439405, 0.1257818128179753, 0.012792102840239863], [0.9925705435157443, 1.119391412290156, 1.1660171233186118, 1.1655292789915774, 1.1016231965228889, 1.145533029508184]
Training Loss (progress: 0.80), 0.17272997068570364, [0.001384831220754026, 0.0006895564767668142, 0.0056097889602872856, 0.0019178413418495226, 0.12680809505728552, 0.012877627499156353], [0.9917079622106449, 1.119296505797398, 1.1682108424162045, 1.1652032908435757, 1.1021172830727892, 1.1464740177973782]
Training Loss (progress: 0.88), 0.16594049899335064, [0.0013364574933061053, 0.0007334292681936888, 0.005370115989651153, 0.0019361984640874491, 0.1277989234709376, 0.01292316929788822], [0.9911060550342905, 1.1187229915797163, 1.1692337574507186, 1.1653898632653445, 1.1024877807039748, 1.1477575055031553]
Training Loss (progress: 0.96), 0.15094758780659476, [0.0012780147185061422, 0.0006324113468047773, 0.0055103589965754, 0.00197100372528517, 0.12894978347818112, 0.013019489020231584], [0.9902813036698683, 1.118793993072684, 1.1702040315943212, 1.1656049089104294, 1.1029227724548236, 1.1483858009105394]
Evaluation on validation dataset:
Step 25, mean loss 0.04540746951969857
Step 50, mean loss 0.030141982996974973
Step 75, mean loss 0.030635470970456255
Step 100, mean loss 0.03431712732056673
Step 125, mean loss 0.03956970187847262
Step 150, mean loss 0.046280590836232705
Step 175, mean loss 0.051658280556892505
Step 200, mean loss 0.06982186151278806
Step 225, mean loss 0.09700490998506398
Unrolled forward losses 2.591120199846488
Unrolled forward base losses 1.1720234445357585
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.1246279850534986, [0.0013184598546191416, 0.0006959200688838881, 0.00556305305573369, 0.0019356853008792945, 0.12966710841920331, 0.013048275453402832], [0.9896588939272828, 1.1185728472513643, 1.1711621295899513, 1.166124117923876, 1.103212101810628, 1.1491433972543497]
Training Loss (progress: 0.08), 0.1371948168479885, [0.0013390674783654978, 0.0007314127827697211, 0.0054340070374515465, 0.0018921920695744844, 0.13013318444911143, 0.013009214250393473], [0.9896405681168265, 1.1186926705909797, 1.1725098606801065, 1.166232386402969, 1.103616908188192, 1.1499495835457507]
Training Loss (progress: 0.16), 0.13434034068188236, [0.0013295957169011886, 0.0007061434143558397, 0.005489690451735661, 0.00196307145177466, 0.13059952720587314, 0.012934508130658561], [0.9897556647116902, 1.1187748265875617, 1.173279257007805, 1.1664607359176196, 1.1040117782525416, 1.150598138228093]
Training Loss (progress: 0.24), 0.14145148149299394, [0.0013410004808191902, 0.0007175971670512265, 0.005537693132633073, 0.0019490790858479189, 0.13095133295948264, 0.013098432748483378], [0.9899291754154387, 1.118843176948071, 1.174061706023436, 1.1663198868554299, 1.1043169916083004, 1.151350738695461]
Training Loss (progress: 0.32), 0.1287060522699891, [0.0012940116040228726, 0.000752541321048273, 0.005606608765850727, 0.001959985466545071, 0.13126240097211747, 0.013056835187911887], [0.9896124485291478, 1.1191497118540694, 1.1751853557944316, 1.1668257422047486, 1.1047209141971748, 1.1522018942962469]
Training Loss (progress: 0.40), 0.13752069252411947, [0.0013316904374399343, 0.0006973935362607213, 0.00544850293449011, 0.0020046100451675294, 0.13156178188414794, 0.013043128525441114], [0.9895591119974948, 1.119139652931037, 1.175880898614974, 1.1668897030983387, 1.1049951110222893, 1.15280968196133]
Training Loss (progress: 0.48), 0.1271325859177684, [0.0013174913810172668, 0.000681022914216834, 0.005483624324478813, 0.0019731861719664103, 0.13197788644890387, 0.013030555166271336], [0.9893429970496503, 1.1190519777543806, 1.1765298324311209, 1.1669238767990135, 1.1052616952495735, 1.1535308826148332]
Training Loss (progress: 0.56), 0.1406886446577091, [0.0012676713660709563, 0.0007231819929419133, 0.005554764492061853, 0.001986148448393225, 0.1322450902139758, 0.01322394068121568], [0.9893684756201281, 1.1188891666681782, 1.1773687737095504, 1.1670030309082722, 1.1056472959522672, 1.154344649816154]
Training Loss (progress: 0.64), 0.13006645419749757, [0.0013119970475986666, 0.0006859827286833702, 0.0055504310228106915, 0.0019925253334001384, 0.13239196791374627, 0.013028530535904598], [0.9892108433967377, 1.1189066969989645, 1.1781603253764248, 1.167218424234806, 1.1057085102323225, 1.154713419277543]
Training Loss (progress: 0.72), 0.1318588629877916, [0.001335543921151048, 0.0007185916093866455, 0.005467347287640971, 0.001954928799889759, 0.1329282228570025, 0.01317085724263859], [0.9890794457646258, 1.1187534129160621, 1.1791202489887047, 1.1672746629838997, 1.1060327130988223, 1.1556832223486446]
Training Loss (progress: 0.80), 0.12757130687585785, [0.0013113269570884144, 0.00068234577052326, 0.0056211871244504375, 0.0020103913049103754, 0.13317774734093965, 0.013071462418112752], [0.9889593140103747, 1.1190475530533008, 1.1799182376145212, 1.1673127742824267, 1.1061889600505665, 1.156223994151951]
Training Loss (progress: 0.88), 0.13098188838949812, [0.0012829098046153616, 0.0006567422131167101, 0.005593107279491683, 0.0020117285125249855, 0.13344873310888758, 0.013100083672579857], [0.988769972265422, 1.1190989399149587, 1.1803699211942185, 1.1675471997539062, 1.1064163119899044, 1.1569013103695127]
Training Loss (progress: 0.96), 0.12426148030273097, [0.0013732962729927853, 0.0007057216989322811, 0.0055811716079916295, 0.0019468378805262499, 0.13385639019039516, 0.013102080717612912], [0.9886773131612624, 1.1190760632597885, 1.1812497592423108, 1.1678386332669906, 1.106756218513151, 1.1576519926863205]
Evaluation on validation dataset:
Step 25, mean loss 0.032738497273408045
Step 50, mean loss 0.017184159026103592
Step 75, mean loss 0.02209950306067
Step 100, mean loss 0.02765595027688337
Step 125, mean loss 0.030941938039148506
Step 150, mean loss 0.03895250989321973
Step 175, mean loss 0.04330334930606196
Step 200, mean loss 0.06066796435383452
Step 225, mean loss 0.08688677517307311
Unrolled forward losses 1.93080192370427
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 13 (pos: 0.131): 3.75296e-04, 8.36713e-07, 1.96111e-01, 6.50798e-03, 1.02564e+00, 5.30244e-01
Node: 14 (pos: 0.141): 7.17889e-05, 4.32581e-08, 1.34497e-01, 2.18836e-03, 1.00936e+00, 4.50043e-01
Node: 15 (pos: 0.152): 1.17309e-05, 1.68668e-09, 8.89869e-02, 6.63306e-04, 9.91833e-01, 3.76053e-01
Node: 00 (pos: 0.000): 2.80310e-01, 1.17116e-01, 8.86457e-01, 5.09040e-01, 1.09341e+00, 1.02180e+00
Node: 01 (pos: 0.010): 4.86493e-01, 3.14377e-01, 1.00520e+00, 7.32028e-01, 1.09926e+00, 1.07921e+00
Node: 02 (pos: 0.020): 7.21281e-01, 6.36448e-01, 1.09964e+00, 9.48909e-01, 1.10346e+00, 1.12218e+00
-
Node: 03 (pos: 0.030): 9.13526e-01, 9.71740e-01, 1.16051e+00, 1.10877e+00, 1.10598e+00, 1.14878e+00
Node: 05 (pos: 0.051): 9.13526e-01, 9.71740e-01, 1.16051e+00, 1.10877e+00, 1.10598e+00, 1.14878e+00
Node: 06 (pos: 0.061): 7.21281e-01, 6.36448e-01, 1.09964e+00, 9.48909e-01, 1.10346e+00, 1.12218e+00
Node: 07 (pos: 0.071): 4.86493e-01, 3.14377e-01, 1.00520e+00, 7.32028e-01, 1.09926e+00, 1.07921e+00
Node: 08 (pos: 0.081): 2.80310e-01, 1.17116e-01, 8.86457e-01, 5.09040e-01, 1.09341e+00, 1.02180e+00
Node: 09 (pos: 0.091): 1.37971e-01, 3.29044e-02, 7.54159e-01, 3.19079e-01, 1.08594e+00, 9.52446e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 35 (pos: 0.354): 1.37971e-01, 3.29044e-02, 7.54159e-01, 3.19079e-01, 1.08594e+00, 9.52446e-01
Node: 36 (pos: 0.364): 5.80133e-02, 6.97216e-03, 6.18969e-01, 1.80287e-01, 1.07688e+00, 8.74045e-01
Node: 37 (pos: 0.374): 2.08380e-02, 1.11418e-03, 4.90090e-01, 9.18234e-02, 1.06627e+00, 7.89667e-01
Node: 38 (pos: 0.384): 6.39400e-03, 1.34283e-04, 3.74355e-01, 4.21563e-02, 1.05416e+00, 7.02378e-01
Node: 39 (pos: 0.394): 1.67602e-03, 1.22057e-05, 2.75862e-01, 1.74459e-02, 1.04059e+00, 6.15057e-01
Node: 40 (pos: 0.404): 3.75296e-04, 8.36713e-07, 1.96111e-01, 6.50798e-03, 1.02564e+00, 5.30244e-01
-
Node: 41 (pos: 0.414): 7.17889e-05, 4.32581e-08, 1.34497e-01, 2.18836e-03, 1.00936e+00, 4.50043e-01
Node: 42 (pos: 0.424): 1.17309e-05, 1.68668e-09, 8.89869e-02, 6.63306e-04, 9.91833e-01, 3.76053e-01
Node: 19 (pos: 0.192): 7.17889e-05, 4.32581e-08, 1.34497e-01, 2.18836e-03, 1.00936e+00, 4.50043e-01
Node: 20 (pos: 0.202): 3.75296e-04, 8.36713e-07, 1.96111e-01, 6.50798e-03, 1.02564e+00, 5.30244e-01
Node: 21 (pos: 0.212): 1.67602e-03, 1.22057e-05, 2.75862e-01, 1.74459e-02, 1.04059e+00, 6.15057e-01
Node: 22 (pos: 0.222): 6.39400e-03, 1.34283e-04, 3.74355e-01, 4.21563e-02, 1.05416e+00, 7.02378e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.03374601293891822
Step 50, mean loss 0.017403590033108846
Step 75, mean loss 0.01985125550801555
Step 100, mean loss 0.02944545090807555
Step 125, mean loss 0.0343301801287999
Step 150, mean loss 0.053136070795945206
Step 175, mean loss 0.0649006657508786
Step 200, mean loss 0.0828182143757357
Step 225, mean loss 0.11278800626177941
Unrolled forward losses 2.140276539254807
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n12_s0.001_tw25_unrolling2_time6121339.tar

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.11908732205486135, [0.0013266058078019423, 0.0007113541920281532, 0.005590873687775901, 0.0019896567170289195, 0.13395533847314467, 0.013041375786567461], [0.9884338781380473, 1.1190007417336427, 1.1814595456793033, 1.1678484240451283, 1.106837425897646, 1.157832132775735]
Training Loss (progress: 0.08), 0.1386025996440503, [0.0013094545028124167, 0.0006990670158023472, 0.005713944865582872, 0.001962474868917686, 0.13434752567649583, 0.013244467788400535], [0.9883098294739283, 1.1191679199195064, 1.1820919561079055, 1.168085220883001, 1.1071556697463258, 1.1588363884554789]
Training Loss (progress: 0.16), 0.12045954941766047, [0.0013386647683154146, 0.0006980455046543438, 0.00574910081190843, 0.0019754861077032593, 0.1345960518725529, 0.013167239426964681], [0.988339295874177, 1.119344792790814, 1.1830971013307756, 1.1679802078867336, 1.1073265253727727, 1.159267705738614]
Training Loss (progress: 0.24), 0.1279432209349976, [0.001292626713710074, 0.0007026086607134712, 0.005699054950319452, 0.002022769627915582, 0.13497111131076908, 0.013114669028510257], [0.9880580360359231, 1.1191531372903856, 1.183539789259385, 1.16786718226495, 1.1075387510745143, 1.1596396616568376]
Training Loss (progress: 0.32), 0.12767571467431385, [0.001333387107739717, 0.0006694701803097422, 0.005568161921146933, 0.001989865482041571, 0.1353931888439752, 0.013205709050367899], [0.9878491721457119, 1.1192219036138695, 1.1841100397184234, 1.1680489924723787, 1.1079158559853584, 1.1605087121634066]
Training Loss (progress: 0.40), 0.12664533135135905, [0.001329133438985985, 0.0006604151114423228, 0.005641339180648491, 0.001990177592110044, 0.13570375729516265, 0.01311940778413028], [0.9878201212525467, 1.11923613752154, 1.1848869386297642, 1.1682326714343452, 1.1080826619118254, 1.160902944646501]
Training Loss (progress: 0.48), 0.11639644161074038, [0.0013238878980718891, 0.0006817943056229997, 0.005716759112849732, 0.002013185289828936, 0.13603606103265517, 0.013154424711102838], [0.9875798722908016, 1.1191223462333848, 1.185487561839608, 1.168188481501243, 1.1082867216655174, 1.1616152524849308]
Training Loss (progress: 0.56), 0.11520782488739992, [0.0013251607301538295, 0.000722320261276252, 0.005786710757470707, 0.001980027669703194, 0.13647154544724652, 0.01309025972860798], [0.9871726940972262, 1.1190763441220186, 1.186329098182813, 1.1683743718305675, 1.1086288623414686, 1.1621112174087451]
Training Loss (progress: 0.64), 0.13311248983056276, [0.0013276706976367235, 0.0006888692539617285, 0.005702609375939666, 0.0020307278819185997, 0.13669951379781398, 0.013141048189073344], [0.9868873660553249, 1.1190219214397787, 1.1868714016849204, 1.1681564923400238, 1.1087902285158406, 1.1627732297163507]
Training Loss (progress: 0.72), 0.12241936812059041, [0.0013246357050752295, 0.0007062104384376142, 0.005793939576210412, 0.002005081018701798, 0.1370950320349646, 0.013154083646507489], [0.98658932866024, 1.119267738291973, 1.1875026186001358, 1.1685705967475892, 1.1089771602177207, 1.1633582351257483]
Training Loss (progress: 0.80), 0.12149220858368298, [0.0013372322843709695, 0.0007358347752075703, 0.005630517367603115, 0.0019577173616260675, 0.13717174234049792, 0.013100782647821928], [0.9864307927197477, 1.1189414552371781, 1.1881007764229978, 1.1684238835855267, 1.1090173722398389, 1.1639113220702733]
Training Loss (progress: 0.88), 0.12413050630649573, [0.0013480991549028676, 0.0007018220885127996, 0.005783578453169226, 0.0020502643562520084, 0.13761262532466423, 0.013098921849379105], [0.9863602364211609, 1.1191693879256928, 1.188904191345112, 1.1685028679901728, 1.1093437671558743, 1.1644504881787319]
Training Loss (progress: 0.96), 0.11207691494314599, [0.0012987771627134574, 0.0006664878187482556, 0.005709499604463262, 0.002009451703850611, 0.13787787182298902, 0.013213633121960352], [0.9862022670596376, 1.1190656496840607, 1.1895277349919002, 1.1685570794409084, 1.1095855429489012, 1.1652609073934572]
Evaluation on validation dataset:
Step 25, mean loss 0.05179790537084462
Step 50, mean loss 0.01493740498502403
Step 75, mean loss 0.02084215184975137
Step 100, mean loss 0.026316382244419276
Step 125, mean loss 0.0288907298706194
Step 150, mean loss 0.03616466599218043
Step 175, mean loss 0.03829452459690326
Step 200, mean loss 0.056030481781797856
Step 225, mean loss 0.08429626606172191
Unrolled forward losses 1.7349633091860857
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 13 (pos: 0.131): 4.52436e-04, 8.63492e-07, 1.94817e-01, 6.52973e-03, 1.03068e+00, 5.34980e-01
Node: 14 (pos: 0.141): 9.00546e-05, 4.49395e-08, 1.33232e-01, 2.19703e-03, 1.01481e+00, 4.54289e-01
Node: 15 (pos: 0.152): 1.53705e-05, 1.76501e-09, 8.78774e-02, 6.66382e-04, 9.97713e-01, 3.79809e-01
Node: 00 (pos: 0.000): 2.88245e-01, 1.17700e-01, 8.90624e-01, 5.09486e-01, 1.09668e+00, 1.02886e+00
Node: 01 (pos: 0.010): 4.93680e-01, 3.15249e-01, 1.01088e+00, 7.32518e-01, 1.10237e+00, 1.08649e+00
Node: 02 (pos: 0.020): 7.25040e-01, 6.37206e-01, 1.10660e+00, 9.49405e-01, 1.10645e+00, 1.12962e+00
-
Node: 03 (pos: 0.030): 9.13087e-01, 9.71976e-01, 1.16832e+00, 1.10926e+00, 1.10890e+00, 1.15631e+00
Node: 05 (pos: 0.051): 9.13087e-01, 9.71976e-01, 1.16832e+00, 1.10926e+00, 1.10890e+00, 1.15631e+00
Node: 06 (pos: 0.061): 7.25040e-01, 6.37206e-01, 1.10660e+00, 9.49405e-01, 1.10645e+00, 1.12962e+00
Node: 07 (pos: 0.071): 4.93680e-01, 3.15249e-01, 1.01088e+00, 7.32518e-01, 1.10237e+00, 1.08649e+00
Node: 08 (pos: 0.081): 2.88245e-01, 1.17700e-01, 8.90624e-01, 5.09486e-01, 1.09668e+00, 1.02886e+00
Node: 09 (pos: 0.091): 1.44315e-01, 3.31627e-02, 7.56785e-01, 3.19442e-01, 1.08941e+00, 9.59239e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 35 (pos: 0.354): 1.44315e-01, 3.31627e-02, 7.56785e-01, 3.19442e-01, 1.08941e+00, 9.59239e-01
Node: 36 (pos: 0.364): 6.19575e-02, 7.05136e-03, 6.20205e-01, 1.80551e-01, 1.08059e+00, 8.80509e-01
Node: 37 (pos: 0.374): 2.28092e-02, 1.13147e-03, 4.90210e-01, 9.19927e-02, 1.07026e+00, 7.95753e-01
Node: 38 (pos: 0.384): 7.20044e-03, 1.37014e-04, 3.73691e-01, 4.22526e-02, 1.05847e+00, 7.08044e-01
Node: 39 (pos: 0.394): 1.94913e-03, 1.25210e-05, 2.74744e-01, 1.74945e-02, 1.04525e+00, 6.20269e-01
Node: 40 (pos: 0.404): 4.52436e-04, 8.63492e-07, 1.94817e-01, 6.52973e-03, 1.03068e+00, 5.34980e-01
-
Node: 41 (pos: 0.414): 9.00546e-05, 4.49395e-08, 1.33232e-01, 2.19703e-03, 1.01481e+00, 4.54289e-01
Node: 42 (pos: 0.424): 1.53705e-05, 1.76501e-09, 8.78774e-02, 6.66382e-04, 9.97713e-01, 3.79809e-01
Node: 19 (pos: 0.192): 9.00546e-05, 4.49395e-08, 1.33232e-01, 2.19703e-03, 1.01481e+00, 4.54289e-01
Node: 20 (pos: 0.202): 4.52436e-04, 8.63492e-07, 1.94817e-01, 6.52973e-03, 1.03068e+00, 5.34980e-01
Node: 21 (pos: 0.212): 1.94913e-03, 1.25210e-05, 2.74744e-01, 1.74945e-02, 1.04525e+00, 6.20269e-01
Node: 22 (pos: 0.222): 7.20044e-03, 1.37014e-04, 3.73691e-01, 4.22526e-02, 1.05847e+00, 7.08044e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.05091979703335383
Step 50, mean loss 0.014678867111726437
Step 75, mean loss 0.01836413261619052
Step 100, mean loss 0.029070588084616735
Step 125, mean loss 0.03408829568678959
Step 150, mean loss 0.05541608829694912
Step 175, mean loss 0.06362885184771669
Step 200, mean loss 0.08609808949138326
Step 225, mean loss 0.11278144243395069
Unrolled forward losses 1.960877569037849
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n12_s0.001_tw25_unrolling2_time6121339.tar

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.12560743785412506, [0.0013588813679339892, 0.0007047130782962311, 0.005698178826119627, 0.001969289574754731, 0.13816853935314305, 0.013124896152100659], [0.9860198639886442, 1.1189208950223546, 1.1897632400972062, 1.1683433281294329, 1.1098024765745, 1.1654089081665246]
Training Loss (progress: 0.08), 0.11751496857195834, [0.0013456901539646688, 0.0006816054377648498, 0.005780319125704192, 0.002061029402674385, 0.13849875230164133, 0.013174897676058872], [0.9859027589458943, 1.1189770116169049, 1.1904900854836435, 1.1684643571720885, 1.1099574054662498, 1.1659310396317075]
Training Loss (progress: 0.16), 0.11756819609343845, [0.0013612042358564578, 0.0007266602351788664, 0.005658281127594435, 0.0020099143698214107, 0.1386013095101443, 0.013095431554582591], [0.9858340001172428, 1.1189880263250302, 1.1910121955429527, 1.1684645190245302, 1.1100071388194512, 1.1665157417727139]
Training Loss (progress: 0.24), 0.10826850177508146, [0.001310172257920287, 0.0007033753712441951, 0.005742559429819917, 0.0020040632626005506, 0.13895070657966124, 0.013248364730312044], [0.985637776714195, 1.1192462244242716, 1.191670352982304, 1.1685636215069708, 1.1101392179873828, 1.1672104338179239]
Training Loss (progress: 0.32), 0.11553002449453151, [0.0013468903480878941, 0.0007484357532107483, 0.005769681303321345, 0.0020264119785017294, 0.13928292408096904, 0.013149946689384366], [0.985516678127455, 1.1192376998285953, 1.192199329237874, 1.1687547011326218, 1.1103513610596856, 1.167463518947897]
Training Loss (progress: 0.40), 0.130349470015758, [0.0013470680491518177, 0.0006938156056186923, 0.0057529375140272345, 0.0020374857261585624, 0.13958529045439366, 0.013248768827169704], [0.9853940255340193, 1.1191904769479368, 1.1931083477634146, 1.1688693890681106, 1.110583328062624, 1.168166410497525]
Training Loss (progress: 0.48), 0.11697663059369509, [0.0013276818615433643, 0.0007267966862326846, 0.005718640329695603, 0.002042784035939473, 0.14007857320874062, 0.013323320451140593], [0.9850379067108239, 1.1195631323114643, 1.1937285632543022, 1.1687404069109797, 1.110954208207035, 1.1687371014190815]
Training Loss (progress: 0.56), 0.12101961346878247, [0.0013190817857297954, 0.000724759274109747, 0.005849829777272142, 0.002050471937881266, 0.14046225567167733, 0.013261547941214424], [0.9848285878456864, 1.1192919594531776, 1.1945546195857362, 1.1688040392787158, 1.1112796187812493, 1.1692642092069276]
Training Loss (progress: 0.64), 0.11648631868638566, [0.001305155010524166, 0.000698459129594374, 0.0058653865700757065, 0.0020424530218466747, 0.14057662343053523, 0.01336770904957468], [0.9848019550337431, 1.119166345266462, 1.1950380476064717, 1.1687545620853437, 1.1113427437754426, 1.1698184105615896]
Training Loss (progress: 0.72), 0.11823555641892962, [0.0013536707194070523, 0.0007996584860923483, 0.005883093046144871, 0.002035301335767805, 0.14100064595923043, 0.013388998042861585], [0.9842424665391248, 1.1191628491560115, 1.1953995581571353, 1.1688130381422108, 1.1115860447032753, 1.17036647610796]
Training Loss (progress: 0.80), 0.11913767230367733, [0.0013292240294608792, 0.0007086436128040514, 0.005841500107540979, 0.0020693819094241023, 0.14128052800768848, 0.01329859525622076], [0.9841886013760872, 1.1192704753105298, 1.1963561292512792, 1.168975789810438, 1.1116714766891005, 1.1708543185840947]
Training Loss (progress: 0.88), 0.12186621836450534, [0.0013031683218910949, 0.0006674104245361794, 0.005766916173264764, 0.0020546705127519145, 0.1415959839640904, 0.013186766707913192], [0.9840079845154276, 1.1193045057957554, 1.1968426672748564, 1.1690208671231939, 1.111879252186637, 1.1711074592550452]
Training Loss (progress: 0.96), 0.11536805408607487, [0.0013312432325102274, 0.0006734805701648653, 0.005901723998459344, 0.0020225537297579093, 0.14192424851013105, 0.013269120444946356], [0.9838578823810463, 1.1191537651362098, 1.1975461949828445, 1.1691508484268622, 1.112047904737508, 1.1718157029954144]
Evaluation on validation dataset:
Step 25, mean loss 0.02597045890053528
Step 50, mean loss 0.012014060054132886
Step 75, mean loss 0.01688741642947452
Step 100, mean loss 0.021659798973129724
Step 125, mean loss 0.0263659289502651
Step 150, mean loss 0.03332815351459349
Step 175, mean loss 0.0374464753825994
Step 200, mean loss 0.05691740760459714
Step 225, mean loss 0.08298138726700582
Unrolled forward losses 1.508910807363994
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 13 (pos: 0.131): 4.23880e-04, 1.20627e-06, 2.05826e-01, 7.98524e-03, 1.03520e+00, 5.42715e-01
Node: 14 (pos: 0.141): 8.32679e-05, 6.73386e-08, 1.42193e-01, 2.80230e-03, 1.01971e+00, 4.61687e-01
Node: 15 (pos: 0.152): 1.40088e-05, 2.85585e-09, 9.48323e-02, 8.90081e-04, 1.00302e+00, 3.86755e-01
Node: 00 (pos: 0.000): 2.84646e-01, 1.24210e-01, 9.03636e-01, 5.26479e-01, 1.09952e+00, 1.03626e+00
Node: 01 (pos: 0.010): 4.89659e-01, 3.25001e-01, 1.02220e+00, 7.46402e-01, 1.10505e+00, 1.09364e+00
Node: 02 (pos: 0.020): 7.21392e-01, 6.46041e-01, 1.11629e+00, 9.57749e-01, 1.10903e+00, 1.13657e+00
-
Node: 03 (pos: 0.030): 9.10202e-01, 9.75632e-01, 1.17686e+00, 1.11229e+00, 1.11142e+00, 1.16313e+00
Node: 05 (pos: 0.051): 9.10202e-01, 9.75632e-01, 1.17686e+00, 1.11229e+00, 1.11142e+00, 1.16313e+00
Node: 06 (pos: 0.061): 7.21392e-01, 6.46041e-01, 1.11629e+00, 9.57749e-01, 1.10903e+00, 1.13657e+00
Node: 07 (pos: 0.071): 4.89659e-01, 3.25001e-01, 1.02220e+00, 7.46402e-01, 1.10505e+00, 1.09364e+00
Node: 08 (pos: 0.081): 2.84646e-01, 1.24210e-01, 9.03636e-01, 5.26479e-01, 1.09952e+00, 1.03626e+00
Node: 09 (pos: 0.091): 1.41712e-01, 3.60646e-02, 7.71179e-01, 3.36108e-01, 1.09244e+00, 9.66879e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 35 (pos: 0.354): 1.41712e-01, 3.60646e-02, 7.71179e-01, 3.36108e-01, 1.09244e+00, 9.66879e-01
Node: 36 (pos: 0.364): 6.04220e-02, 7.95526e-03, 6.35359e-01, 1.94207e-01, 1.08385e+00, 8.88358e-01
Node: 37 (pos: 0.374): 2.20635e-02, 1.33314e-03, 5.05342e-01, 1.01563e-01, 1.07378e+00, 8.03741e-01
Node: 38 (pos: 0.384): 6.89987e-03, 1.69726e-04, 3.88020e-01, 4.80728e-02, 1.06229e+00, 7.16071e-01
Node: 39 (pos: 0.394): 1.84798e-03, 1.64161e-05, 2.87625e-01, 2.05944e-02, 1.04941e+00, 6.28215e-01
Node: 40 (pos: 0.404): 4.23880e-04, 1.20627e-06, 2.05826e-01, 7.98524e-03, 1.03520e+00, 5.42715e-01
-
Node: 41 (pos: 0.414): 8.32679e-05, 6.73386e-08, 1.42193e-01, 2.80230e-03, 1.01971e+00, 4.61687e-01
Node: 42 (pos: 0.424): 1.40088e-05, 2.85585e-09, 9.48323e-02, 8.90081e-04, 1.00302e+00, 3.86755e-01
Node: 19 (pos: 0.192): 8.32679e-05, 6.73386e-08, 1.42193e-01, 2.80230e-03, 1.01971e+00, 4.61687e-01
Node: 20 (pos: 0.202): 4.23880e-04, 1.20627e-06, 2.05826e-01, 7.98524e-03, 1.03520e+00, 5.42715e-01
Node: 21 (pos: 0.212): 1.84798e-03, 1.64161e-05, 2.87625e-01, 2.05944e-02, 1.04941e+00, 6.28215e-01
Node: 22 (pos: 0.222): 6.89987e-03, 1.69726e-04, 3.88020e-01, 4.80728e-02, 1.06229e+00, 7.16071e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.027648294302351578
Step 50, mean loss 0.012651694617411214
Step 75, mean loss 0.01604112962994103
Step 100, mean loss 0.026469443421200174
Step 125, mean loss 0.031285008381992566
Step 150, mean loss 0.04623200073376833
Step 175, mean loss 0.061363279551729814
Step 200, mean loss 0.08128471741716231
Step 225, mean loss 0.11057861536315605
Unrolled forward losses 1.7246731136874
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n12_s0.001_tw25_unrolling2_time6121339.tar

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.12901866756065897, [0.0013560650881221062, 0.0006504570165051362, 0.005880616168231642, 0.0020628794623222856, 0.1422384254027882, 0.01331405073871836], [0.9835263787648338, 1.119351947831724, 1.1978473094819477, 1.1691834044923584, 1.1122741648304033, 1.1721141123930539]
Training Loss (progress: 0.08), 0.10902894189323259, [0.001339449291181198, 0.0006844374849347136, 0.005779332880167324, 0.002049819686071547, 0.14238529580702508, 0.01327725089257927], [0.9834360346025297, 1.1191634906061605, 1.198371211353337, 1.169273520215884, 1.1123690483859832, 1.1726429008194827]
Training Loss (progress: 0.16), 0.1297022120958149, [0.0013220341556666392, 0.0007208281399796743, 0.0058642545558756825, 0.002051748540671432, 0.14271629303368372, 0.0132924269930123], [0.9831881306284278, 1.119259209859263, 1.19910379464149, 1.1693311478719348, 1.1125250613575564, 1.1732470892888032]
Training Loss (progress: 0.24), 0.1342724867054389, [0.0013339654917542288, 0.0007069599899257349, 0.005881209349568087, 0.0020347477529406416, 0.14322935175769572, 0.013295816505352208], [0.9831424813846408, 1.1194262255241374, 1.1999240285165866, 1.1693978723997889, 1.1128664527466097, 1.1737379192611719]
Training Loss (progress: 0.32), 0.10870059067343035, [0.001335216986561255, 0.0007228453812299721, 0.005919246811802255, 0.00207928239305188, 0.1433464152236197, 0.01321589088442346], [0.9827645850912586, 1.1193414264241521, 1.200833102041285, 1.1695005908716591, 1.1128941758655648, 1.174146515224071]
Training Loss (progress: 0.40), 0.12302479412095316, [0.0012965932763721877, 0.0007450810952291218, 0.005960076333036002, 0.00206624586347602, 0.143698071002336, 0.013269154929902978], [0.9822894302318358, 1.1194879605632808, 1.201533193008976, 1.1696756371936212, 1.1131032563561336, 1.1747082628994645]
Training Loss (progress: 0.48), 0.11952100260426796, [0.0013354152808239316, 0.0006783687075495811, 0.005869405430020364, 0.0020484300126126123, 0.14395594302196515, 0.013254607726303496], [0.9821333795541365, 1.1195504861842078, 1.2018903998659487, 1.169738129463278, 1.1132510307801895, 1.1752225357717632]
Training Loss (progress: 0.56), 0.1266233016010416, [0.0012750644157724534, 0.0006961586872430324, 0.0059812125150420095, 0.0020611804597150283, 0.14425739524027587, 0.013329813494071823], [0.9818980077293029, 1.119640871533853, 1.2025905374630237, 1.1696058483884608, 1.1133870763302738, 1.1757586842872843]
Training Loss (progress: 0.64), 0.12645399821213027, [0.0013246906867716067, 0.0007301920553882456, 0.005900418550932614, 0.002070359060465008, 0.14463183647187325, 0.013390758258703958], [0.9816441328692093, 1.1195832864902584, 1.2028010849408637, 1.1696815127030045, 1.1135699974464717, 1.1763339296175477]
Training Loss (progress: 0.72), 0.11884482327652564, [0.0013512400132355495, 0.0007417605367419499, 0.0059101407294441305, 0.0020825904082672677, 0.14503743550648193, 0.013365794632493823], [0.9813301025728812, 1.1196792203061567, 1.2038672098769698, 1.1695950845804186, 1.1137478522648607, 1.1770058103173455]
Training Loss (progress: 0.80), 0.13200078595142303, [0.0013960835148462837, 0.0006762995140142954, 0.005914609707261655, 0.002077189889363132, 0.14543743565828413, 0.013360318254977206], [0.9812148519161065, 1.1198581487369053, 1.2040444135975876, 1.1693560830912768, 1.113989657181541, 1.1773861666171264]
Training Loss (progress: 0.88), 0.11841435888551415, [0.001342676738285233, 0.0007037553214525316, 0.005870922709291828, 0.0020714144870003066, 0.14581716000940553, 0.013455203865360603], [0.9810905564781264, 1.1196827859428855, 1.2049070224854612, 1.1695012022430988, 1.1142425367875126, 1.1781117019635772]
Training Loss (progress: 0.96), 0.12666480108020256, [0.001318881369819599, 0.0007082533789066086, 0.0059266759418173534, 0.002082908201942754, 0.14593496230357775, 0.013429652962618863], [0.9807000675575813, 1.1197134978285004, 1.205361290393624, 1.1696828454339785, 1.1142163773739033, 1.1786546709001562]
Evaluation on validation dataset:
Step 25, mean loss 0.026503820579070754
Step 50, mean loss 0.0107535278987069
Step 75, mean loss 0.016805530679337245
Step 100, mean loss 0.022405459567334127
Step 125, mean loss 0.02543678668296946
Step 150, mean loss 0.03222654858789388
Step 175, mean loss 0.03532881689733952
Step 200, mean loss 0.0516580792539571
Step 225, mean loss 0.07673992036210853
Unrolled forward losses 1.4679525064113417
Unrolled forward base losses 1.1720234445357585
=========================================================================================================

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 13 (pos: 0.131): 4.23713e-04, 1.15012e-06, 2.18919e-01, 8.77428e-03, 1.03913e+00, 5.52194e-01
Node: 14 (pos: 0.141): 8.32772e-05, 6.35612e-08, 1.52997e-01, 3.14045e-03, 1.02400e+00, 4.70894e-01
Node: 15 (pos: 0.152): 1.40182e-05, 2.66609e-09, 1.03339e-01, 1.01924e-03, 1.00768e+00, 3.95519e-01
Node: 00 (pos: 0.000): 2.83957e-01, 1.23294e-01, 9.17670e-01, 5.34675e-01, 1.10193e+00, 1.04415e+00
Node: 01 (pos: 0.010): 4.88390e-01, 3.23687e-01, 1.03408e+00, 7.53060e-01, 1.10733e+00, 1.10108e+00
Node: 02 (pos: 0.020): 7.19436e-01, 6.44974e-01, 1.12616e+00, 9.61772e-01, 1.11120e+00, 1.14364e+00
-
Node: 03 (pos: 0.030): 9.07668e-01, 9.75421e-01, 1.18530e+00, 1.11383e+00, 1.11353e+00, 1.16996e+00
Node: 05 (pos: 0.051): 9.07668e-01, 9.75421e-01, 1.18530e+00, 1.11383e+00, 1.11353e+00, 1.16996e+00
Node: 06 (pos: 0.061): 7.19436e-01, 6.44974e-01, 1.12616e+00, 9.61772e-01, 1.11120e+00, 1.14364e+00
Node: 07 (pos: 0.071): 4.88390e-01, 3.23687e-01, 1.03408e+00, 7.53060e-01, 1.10733e+00, 1.10108e+00
Node: 08 (pos: 0.081): 2.83957e-01, 1.23294e-01, 9.17670e-01, 5.34675e-01, 1.10193e+00, 1.04415e+00
Node: 09 (pos: 0.091): 1.41399e-01, 3.56445e-02, 7.87047e-01, 3.44233e-01, 1.09502e+00, 9.75261e-01
---------------------------------------------------------------------------------------------------------

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 35 (pos: 0.354): 1.41399e-01, 3.56445e-02, 7.87047e-01, 3.44233e-01, 1.09502e+00, 9.75261e-01
Node: 36 (pos: 0.364): 6.03048e-02, 7.82124e-03, 6.52372e-01, 2.00964e-01, 1.08664e+00, 8.97201e-01
Node: 37 (pos: 0.374): 2.20276e-02, 1.30254e-03, 5.22602e-01, 1.06387e-01, 1.07681e+00, 8.12964e-01
Node: 38 (pos: 0.384): 6.89115e-03, 1.64643e-04, 4.04602e-01, 5.10692e-02, 1.06559e+00, 7.25547e-01
Node: 39 (pos: 0.394): 1.84640e-03, 1.57952e-05, 3.02737e-01, 2.22297e-02, 1.05301e+00, 6.37782e-01
Node: 40 (pos: 0.404): 4.23713e-04, 1.15012e-06, 2.18919e-01, 8.77428e-03, 1.03913e+00, 5.52194e-01
-
Node: 41 (pos: 0.414): 8.32772e-05, 6.35612e-08, 1.52997e-01, 3.14045e-03, 1.02400e+00, 4.70894e-01
Node: 42 (pos: 0.424): 1.40182e-05, 2.66609e-09, 1.03339e-01, 1.01924e-03, 1.00768e+00, 3.95519e-01
Node: 19 (pos: 0.192): 8.32772e-05, 6.35612e-08, 1.52997e-01, 3.14045e-03, 1.02400e+00, 4.70894e-01
Node: 20 (pos: 0.202): 4.23713e-04, 1.15012e-06, 2.18919e-01, 8.77428e-03, 1.03913e+00, 5.52194e-01
Node: 21 (pos: 0.212): 1.84640e-03, 1.57952e-05, 3.02737e-01, 2.22297e-02, 1.05301e+00, 6.37782e-01
Node: 22 (pos: 0.222): 6.89115e-03, 1.64643e-04, 4.04602e-01, 5.10692e-02, 1.06559e+00, 7.25547e-01
=========================================================================================================
Evaluation on test dataset:
Step 25, mean loss 0.02720030130593179
Step 50, mean loss 0.011146367095423979
Step 75, mean loss 0.015780579768475585
Step 100, mean loss 0.02529864160083521
Step 125, mean loss 0.030098394036555343
Step 150, mean loss 0.046990510665086534
Step 175, mean loss 0.05732892965972092
Step 200, mean loss 0.07415922752359103
Step 225, mean loss 0.10113522367699151
Unrolled forward losses 1.7147924016478928
Unrolled forward base losses 1.4476105995166209
Saved model at models/GNN_euclidean_CE_E2_xresolution100-200_lr0.0001_n12_s0.001_tw25_unrolling2_time6121339.tar

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.12383284975359693, [0.0013363198556433599, 0.0006909125642759874, 0.005901370623508817, 0.0021028411205192654, 0.1460565308485089, 0.013440540199752384], [0.9807411059100479, 1.1195832939797556, 1.2056115329352375, 1.1696520005796094, 1.1143001303676885, 1.178905691250398]
Training Loss (progress: 0.08), 0.11847871977838677, [0.0013751726303322142, 0.0006944422770808292, 0.0059386342874934925, 0.002071911378329916, 0.14648602304563418, 0.013485884220418604], [0.9805204964831392, 1.1198139155267808, 1.2066254861399694, 1.1697042833843574, 1.1144424003480846, 1.1795528740269703]
Training Loss (progress: 0.16), 0.1156351792700595, [0.0013297567339882643, 0.00066519239694718, 0.005930572377308588, 0.002029413605544929, 0.14679528113190535, 0.013519155860994376], [0.9805265266089004, 1.1197993306162073, 1.207114816956416, 1.1698742182029729, 1.1145516375331963, 1.180142777064229]
Training Loss (progress: 0.24), 0.1233067838207823, [0.0013813120960137276, 0.0007368191819211395, 0.005934519696219021, 0.0020400932055942545, 0.14709229438640806, 0.013428719694022302], [0.9803774653683013, 1.119801686579767, 1.2079076897254464, 1.1698183187806055, 1.1147260901297495, 1.1804786513837133]
Training Loss (progress: 0.32), 0.1162492085855706, [0.0013252065999501447, 0.0007020766704929625, 0.005937854372309686, 0.00205068395811246, 0.14750683730818762, 0.013450593463340679], [0.9799927463792819, 1.1197324038461447, 1.2083784791978622, 1.1701176952991554, 1.1148938713644134, 1.1810779493424726]
Training Loss (progress: 0.40), 0.11512002374554979, [0.0013533045398169742, 0.0007208855388453089, 0.005921633776799759, 0.0021040414864101752, 0.14780269907247218, 0.013506534372590999], [0.9797669079314891, 1.1197988426008558, 1.2089145076727124, 1.1702106097556642, 1.1150740844793305, 1.1816623877329544]
Training Loss (progress: 0.48), 0.1193012927145784, [0.001330085293195098, 0.0006998215452230903, 0.005978001133567732, 0.002114335727213295, 0.14823646104439217, 0.013463204145989874], [0.9794972882855143, 1.1200325735710954, 1.2094662864545564, 1.1701912996543635, 1.115223380362531, 1.1820442917086518]
Training Loss (progress: 0.56), 0.10880739167548466, [0.0013925422274101925, 0.0007203656549014025, 0.00601810962250241, 0.0020925314848857486, 0.1486641320839079, 0.01344242355699811], [0.979119916255461, 1.1201885057070458, 1.2102451890561352, 1.169913403450084, 1.1155616762577576, 1.1825274719367458]
Training Loss (progress: 0.64), 0.11212249624949211, [0.0013318548183105239, 0.0007717994000982925, 0.00590410009603554, 0.0020761678288579617, 0.14887265850548614, 0.013542493587225802], [0.978896261377607, 1.1200187559097035, 1.2107509980312678, 1.169971476526973, 1.1156430559933668, 1.1831675576822434]
Training Loss (progress: 0.72), 0.11167314254332289, [0.0013681863399797706, 0.0007017545947025768, 0.006063734204333717, 0.0020665675843610843, 0.14926100719687393, 0.013555665724879231], [0.9788517905337346, 1.1201135681929528, 1.2112662681157833, 1.1700005646744596, 1.115912248198359, 1.1835840241694768]
Training Loss (progress: 0.80), 0.13815714252594674, [0.001372590180112591, 0.0006730307574815066, 0.006041412033068384, 0.002112130502604708, 0.14962547394858225, 0.01352196890058589], [0.9784841932346264, 1.1201992345376015, 1.2120489053630774, 1.1702244942000835, 1.1160891871374863, 1.1840312239358866]
Training Loss (progress: 0.88), 0.11271092830266857, [0.0013434918255851205, 0.0006949419107293119, 0.005995750936701269, 0.002087272613942905, 0.14994266769677342, 0.013481961836823939], [0.9783119711151657, 1.1202674705494922, 1.2125559254935507, 1.1699952223584351, 1.1161764569921957, 1.1845488500519314]
Training Loss (progress: 0.96), 0.1120873418140667, [0.0013249668650481452, 0.0007045015314354183, 0.005844884008149553, 0.0020770768254781444, 0.15015881539517573, 0.01349562581237966], [0.9780200598197014, 1.1200803853794612, 1.2131766969641646, 1.170076884315497, 1.1162491388199915, 1.185073198065036]
Evaluation on validation dataset:
Step 25, mean loss 0.02493522316081956
Step 50, mean loss 0.012304075696944052
Step 75, mean loss 0.01680698020110909
Step 100, mean loss 0.023307858600005962
Step 125, mean loss 0.027020501671391185
Step 150, mean loss 0.03295732972339268
Step 175, mean loss 0.036430989668016084
Step 200, mean loss 0.05272908891077828
Step 225, mean loss 0.07717879451263195
Unrolled forward losses 1.6808774435010843
Unrolled forward base losses 1.1720234445357585
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00), 0.1029118421394429, [0.0013241540296059133, 0.000696725684227682, 0.006027672115198662, 0.0020933326955864234, 0.1504268722512445, 0.013509763923480241], [0.9779622306521594, 1.120062583724745, 1.2136528932575965, 1.170208846948871, 1.1163907007344211, 1.1853084414834785]
Training Loss (progress: 0.08), 0.10905513949752894, [0.001369813981781181, 0.0006932104957803591, 0.005980268081798421, 0.002092755049157798, 0.1505763217715367, 0.013543959625239806], [0.9779871554664656, 1.1200748353130923, 1.2141318127430067, 1.1702140418932325, 1.1165155848093604, 1.1856784674269825]
Training Loss (progress: 0.16), 0.1081116629629129, [0.0013377435825292327, 0.0007144512712850309, 0.005985883535424202, 0.0021081713772155126, 0.15064725673860047, 0.013512618731337089], [0.9779961957312487, 1.120054061528253, 1.214458761778594, 1.1702572820886064, 1.1166048881836994, 1.1859324324763614]
Training Loss (progress: 0.24), 0.09754436434704102, [0.0013363373467716571, 0.0007023570005182223, 0.006065852947899001, 0.002090454606817489, 0.15086733841183153, 0.013546612035767297], [0.977842248488324, 1.1201652223675482, 1.2148694997333367, 1.1702784027435706, 1.1167814891918952, 1.186348714119917]
