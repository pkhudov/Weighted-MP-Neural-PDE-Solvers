Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514222.tar
Number of parameters: 1035593.0
Epoch 0
Starting epoch 0...
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): -1.30123e-01, -1.45589e-01, -7.36364e-02, 8.05708e-02, 4.62396e-02, -4.17228e-02
Node: 01 (pos: 0.010): -1.29793e-01, -1.46672e-01, -7.51978e-02, 8.06855e-02, 4.54756e-02, -4.16757e-02
Node: 02 (pos: 0.020): -1.29472e-01, -1.47756e-01, -7.67602e-02, 8.07987e-02, 4.47066e-02, -4.16282e-02
Node: 03 (pos: 0.030): -1.29161e-01, -1.48840e-01, -7.83237e-02, 8.09104e-02, 4.39325e-02, -4.15802e-02
Node: 04 (pos: 0.040): -1.28858e-01, -1.49924e-01, -7.98879e-02, 8.10206e-02, 4.31532e-02, -4.15317e-02
Node: 05 (pos: 0.051): -1.28565e-01, -1.51008e-01, -8.14529e-02, 8.11293e-02, 4.23689e-02, -4.14827e-02
-
Node: 07 (pos: 0.071): -1.28565e-01, -1.51008e-01, -8.14529e-02, 8.11293e-02, 4.23689e-02, -4.14827e-02
Node: 08 (pos: 0.081): -1.28858e-01, -1.49924e-01, -7.98879e-02, 8.10206e-02, 4.31532e-02, -4.15317e-02
Node: 09 (pos: 0.091): -1.29161e-01, -1.48840e-01, -7.83237e-02, 8.09104e-02, 4.39325e-02, -4.15802e-02
Node: 10 (pos: 0.101): -1.29472e-01, -1.47756e-01, -7.67602e-02, 8.07987e-02, 4.47066e-02, -4.16282e-02
Node: 11 (pos: 0.111): -1.29793e-01, -1.46672e-01, -7.51978e-02, 8.06855e-02, 4.54756e-02, -4.16757e-02
Node: 12 (pos: 0.121): -1.30123e-01, -1.45589e-01, -7.36364e-02, 8.05708e-02, 4.62396e-02, -4.17228e-02

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.43133e-08, 6.23166e-10, 4.41692e-03, 1.51603e-03, 1.17879e-01, 1.75382e-01
Node: 01 (pos: 0.010): 4.82802e-08, 4.54057e-10, 3.50102e-03, 1.48825e-03, 1.26434e-01, 1.76072e-01
Node: 02 (pos: 0.020): 5.24666e-08, 3.30033e-10, 2.76108e-03, 1.46129e-03, 1.35514e-01, 1.76770e-01
Node: 03 (pos: 0.030): 5.68692e-08, 2.39307e-10, 2.16660e-03, 1.43513e-03, 1.45139e-01, 1.77478e-01
Node: 04 (pos: 0.040): 6.14828e-08, 1.73106e-10, 1.69160e-03, 1.40975e-03, 1.55330e-01, 1.78194e-01
Node: 05 (pos: 0.051): 6.63000e-08, 1.24922e-10, 1.31413e-03, 1.38513e-03, 1.66107e-01, 1.78920e-01
-
Node: 07 (pos: 0.071): 6.63000e-08, 1.24922e-10, 1.31413e-03, 1.38513e-03, 1.66107e-01, 1.78920e-01
Node: 08 (pos: 0.081): 6.14828e-08, 1.73106e-10, 1.69160e-03, 1.40975e-03, 1.55330e-01, 1.78194e-01
Node: 09 (pos: 0.091): 5.68692e-08, 2.39307e-10, 2.16660e-03, 1.43513e-03, 1.45139e-01, 1.77478e-01
Node: 10 (pos: 0.101): 5.24666e-08, 3.30033e-10, 2.76108e-03, 1.46129e-03, 1.35514e-01, 1.76770e-01
Node: 11 (pos: 0.111): 4.82802e-08, 4.54057e-10, 3.50102e-03, 1.48825e-03, 1.26434e-01, 1.76072e-01
Node: 12 (pos: 0.121): 4.43133e-08, 6.23166e-10, 4.41692e-03, 1.51603e-03, 1.17879e-01, 1.75382e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): -1.28565e-01, -1.51008e-01, -8.14529e-02, 8.11293e-02, 4.23689e-02, -4.14827e-02
Node: 01 (pos: 0.010): -1.28858e-01, -1.49924e-01, -7.98879e-02, 8.10206e-02, 4.31532e-02, -4.15317e-02
Node: 02 (pos: 0.020): -1.29161e-01, -1.48840e-01, -7.83237e-02, 8.09104e-02, 4.39325e-02, -4.15802e-02
Node: 03 (pos: 0.030): -1.29472e-01, -1.47756e-01, -7.67602e-02, 8.07987e-02, 4.47066e-02, -4.16282e-02
Node: 04 (pos: 0.040): -1.29793e-01, -1.46672e-01, -7.51978e-02, 8.06855e-02, 4.54756e-02, -4.16757e-02
Node: 05 (pos: 0.051): -1.30123e-01, -1.45589e-01, -7.36364e-02, 8.05708e-02, 4.62396e-02, -4.17228e-02
-
Node: 07 (pos: 0.071): -1.29793e-01, -1.46672e-01, -7.51978e-02, 8.06855e-02, 4.54756e-02, -4.16757e-02
Node: 08 (pos: 0.081): -1.29472e-01, -1.47756e-01, -7.67602e-02, 8.07987e-02, 4.47066e-02, -4.16282e-02
Node: 09 (pos: 0.091): -1.29161e-01, -1.48840e-01, -7.83237e-02, 8.09104e-02, 4.39325e-02, -4.15802e-02
Node: 10 (pos: 0.101): -1.28858e-01, -1.49924e-01, -7.98879e-02, 8.10206e-02, 4.31532e-02, -4.15317e-02
Node: 11 (pos: 0.111): -1.28565e-01, -1.51008e-01, -8.14529e-02, 8.11293e-02, 4.23689e-02, -4.14827e-02
Node: 12 (pos: 0.121): -1.30123e-01, -1.45589e-01, -7.36364e-02, 8.05708e-02, 4.62396e-02, -4.17228e-02

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 6.63000e-08, 1.24922e-10, 1.31413e-03, 1.38513e-03, 1.66107e-01, 1.78920e-01
Node: 58 (pos: 0.586): 6.14828e-08, 1.73106e-10, 1.69160e-03, 1.40975e-03, 1.55330e-01, 1.78194e-01
Node: 59 (pos: 0.596): 5.68692e-08, 2.39307e-10, 2.16660e-03, 1.43513e-03, 1.45139e-01, 1.77478e-01
Node: 60 (pos: 0.606): 5.24666e-08, 3.30033e-10, 2.76108e-03, 1.46129e-03, 1.35514e-01, 1.76770e-01
Node: 61 (pos: 0.616): 4.82802e-08, 4.54057e-10, 3.50102e-03, 1.48825e-03, 1.26434e-01, 1.76072e-01
Node: 50 (pos: 0.505): 4.43133e-08, 6.23166e-10, 4.41692e-03, 1.51603e-03, 1.17879e-01, 1.75382e-01
-
Node: 51 (pos: 0.515): 4.82802e-08, 4.54057e-10, 3.50102e-03, 1.48825e-03, 1.26434e-01, 1.76072e-01
Node: 52 (pos: 0.525): 5.24666e-08, 3.30033e-10, 2.76108e-03, 1.46129e-03, 1.35514e-01, 1.76770e-01
Node: 53 (pos: 0.535): 5.68692e-08, 2.39307e-10, 2.16660e-03, 1.43513e-03, 1.45139e-01, 1.77478e-01
Node: 54 (pos: 0.545): 6.14828e-08, 1.73106e-10, 1.69160e-03, 1.40975e-03, 1.55330e-01, 1.78194e-01
Node: 55 (pos: 0.556): 6.63000e-08, 1.24922e-10, 1.31413e-03, 1.38513e-03, 1.66107e-01, 1.78920e-01
Node: 62 (pos: 0.626): 4.43133e-08, 6.23166e-10, 4.41692e-03, 1.51603e-03, 1.17879e-01, 1.75382e-01
=========================================================================================================
Training Loss (progress: 0.00), 1.327294595077829, -8.305464757686613e-10, -2.6462390892314785e-09, -2.106377357301597e-08, 1.737559788190092e-08, -2.0914978871911124e-08, -2.4783483672575516e-08, [0.000385404807421335, 0.009676387246673872, 0.00015111402995530122, 0.00010910556708183313, 0.00012635960029185275, 0.0006368696879229946]
Training Loss (progress: 0.08), 0.2614623204707742, 2.9790080229166487e-08, 3.180588106390353e-08, -3.0762923128814957e-07, -2.5308640110543446e-06, -5.595195542648363e-08, -4.2696667578309486e-08, [0.0003843925411309942, 0.009469177346280569, 0.00015071665309678272, 0.00010881807125857997, 0.0001260246018000637, 0.0006976152157486334]
Training Loss (progress: 0.16), 0.21091421326905715, -8.441692226874674e-09, -7.076879721095765e-09, -6.027406916098312e-08, 5.3109243745037155e-08, 3.6228241785383506e-08, 1.7620753454268947e-07, [0.00038338675935570125, 0.01035728653377058, 0.00015032229210716885, 0.0001085333409291159, 0.00012570216505671469, 0.0006098263358262404]
Training Loss (progress: 0.24), 0.17407880734414255, -2.044603532290461e-08, -2.2295088037756418e-08, -2.974529050788076e-07, -1.415477852367271e-06, -5.8951513764057095e-08, -6.858189983826799e-08, [0.0003823836156394737, 0.012678848410092725, 0.00014992896299242676, 0.0001082493556170886, 0.0001253956347481619, 0.0005529419388913256]
Training Loss (progress: 0.32), 0.14970567826970813, -2.656379896438032e-08, 2.2850382418148725e-09, -6.263525041725392e-08, 1.431895073414731e-09, 3.3250281975628673e-09, 3.792984798941185e-09, [0.0003813830948464951, 0.018145086987039864, 0.00014953666305567333, 0.00010796611337310649, 0.00012509359484327008, 0.000500098806006614]
Training Loss (progress: 0.40), 0.13983768989262774, -3.006506200228127e-08, 2.7184570840886284e-08, -4.931959538097284e-07, -3.0302488596654635e-06, 4.023582770528872e-08, 4.0664233322298e-07, [0.00038038519635289804, 0.021694895493676473, 0.00014914538961273514, 0.0001076836122528776, 0.00012507147222464674, 0.00046050008531615857]
Training Loss (progress: 0.48), 0.12305497522272987, 2.777797191187713e-08, 1.0624357532707063e-08, -2.0921365589699733e-07, -3.418661753644658e-06, -5.3371802194381104e-08, 5.752069039381106e-09, [0.000379389910266446, 0.024264329186970066, 0.00014875514000789607, 0.00010740185031719937, 0.00012512929972224578, 0.00042199446801540516]
Training Loss (progress: 0.56), 0.12580838704699346, -3.004101471695434e-08, -6.01757144451797e-08, 7.466450934868091e-07, 9.810707041230616e-06, 9.430527492926092e-08, 3.3857584884081316e-07, [0.000378397243878784, 0.026025789899845053, 0.00014836591156528587, 0.00010712082563194109, 0.00012411157974743267, 0.0003940027101850553]
Training Loss (progress: 0.64), 0.12289786695210651, -4.943321815119157e-08, 3.042733685861841e-08, -1.7519045507774098e-07, -5.2033483281301786e-06, -9.944017279848542e-08, -5.855322478011209e-07, [0.00037740716129266256, 0.02914884313693753, 0.00014797770163098455, 0.00010684053626803409, 0.00011978511961390509, 0.0003634270802862997]
Training Loss (progress: 0.72), 0.10907843108261489, -5.462551060498138e-08, 6.305664292128807e-08, -1.6167659533370699e-07, -6.624183607759733e-07, 5.270867734968476e-09, 4.7997834086764587e-08, [0.00037641967851925214, 0.03291307748805269, 0.00014759050750790169, 0.00010656098030145721, 0.00011724023030078995, 0.0003405202088366867]
Training Loss (progress: 0.80), 0.10627413142974004, 1.1367365818586062e-07, -8.776766433773124e-09, -5.970824057220824e-07, -3.2735594531504755e-06, -2.0853503723305898e-08, -8.314570203335354e-08, [0.00037543478974797715, 0.03569930731884991, 0.00014720432657177194, 0.00010628215581322382, 0.00011288225667257673, 0.0003160390571454607]
Training Loss (progress: 0.88), 0.10302881394492609, -7.919309547343735e-08, 4.124193397026854e-08, 3.176555855179234e-07, 6.3007317094606455e-06, 1.0574190557229012e-08, -3.8876632778124006e-07, [0.00037445252102442337, 0.03849999024069924, 0.0001468191561844317, 0.00010600406088936813, 0.00011133592184267209, 0.00030009392287789317]
Training Loss (progress: 0.96), 0.09693786920170232, -7.965718632392e-08, 1.2969316942917226e-08, 1.1590879605545642e-07, 2.331532586209284e-06, -4.220954246759411e-08, -6.975893497016988e-07, [0.00037347290589588876, 0.04118946299944753, 0.0001464349936652116, 0.00010572669362093145, 0.00010930957518295023, 0.00027413268150960137]
Evaluation on validation dataset:
Step 25, mean loss 0.0814619147518795
Step 50, mean loss 0.09624640567551242
Step 75, mean loss 0.11488121788260469
Step 100, mean loss 0.271025139202548
Step 125, mean loss 0.23704953499671283
Step 150, mean loss 0.21533522041429182
Step 175, mean loss 0.32570724495098524
Step 200, mean loss 0.7981545046560982
Step 225, mean loss 0.517307603733035
Unrolled forward losses 14.69731339040873
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): -1.24995e-01, 1.20297e-02, -8.37010e-02, 9.65814e-02, 6.20455e-02, -8.57557e-02
Node: 01 (pos: 0.010): -1.24690e-01, 8.25681e-03, -8.51269e-02, 9.67111e-02, 6.12759e-02, -8.54937e-02
Node: 02 (pos: 0.020): -1.24394e-01, 4.50193e-03, -8.65539e-02, 9.68395e-02, 6.05013e-02, -8.52312e-02
Node: 03 (pos: 0.030): -1.24106e-01, 7.65312e-04, -8.79819e-02, 9.69666e-02, 5.97217e-02, -8.49683e-02
Node: 04 (pos: 0.040): -1.23827e-01, -2.95282e-03, -8.94107e-02, 9.70923e-02, 5.89373e-02, -8.47049e-02
Node: 05 (pos: 0.051): -1.23556e-01, -6.65225e-03, -9.08402e-02, 9.72165e-02, 5.81479e-02, -8.44410e-02
-
Node: 07 (pos: 0.071): -1.23556e-01, -6.65225e-03, -9.08402e-02, 9.72165e-02, 5.81479e-02, -8.44410e-02
Node: 08 (pos: 0.081): -1.23827e-01, -2.95282e-03, -8.94107e-02, 9.70923e-02, 5.89373e-02, -8.47049e-02
Node: 09 (pos: 0.091): -1.24106e-01, 7.65312e-04, -8.79819e-02, 9.69666e-02, 5.97217e-02, -8.49683e-02
Node: 10 (pos: 0.101): -1.24394e-01, 4.50193e-03, -8.65539e-02, 9.68395e-02, 6.05013e-02, -8.52312e-02
Node: 11 (pos: 0.111): -1.24690e-01, 8.25681e-03, -8.51269e-02, 9.67111e-02, 6.12759e-02, -8.54937e-02
Node: 12 (pos: 0.121): -1.24995e-01, 1.20297e-02, -8.37010e-02, 9.65814e-02, 6.20455e-02, -8.57557e-02

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 6.46109e-19, 9.96615e-01, 1.57626e-21, 4.34763e-39, 3.71521e-16, 9.94964e-13
Node: 01 (pos: 0.010): 7.92491e-19, 9.98404e-01, 3.03958e-22, 3.42859e-39, 8.92122e-16, 1.17771e-12
Node: 02 (pos: 0.020): 9.66011e-19, 9.99525e-01, 5.69352e-23, 2.70956e-39, 2.13062e-15, 1.39371e-12
Node: 03 (pos: 0.030): 1.17023e-18, 9.99986e-01, 1.03599e-23, 2.14598e-39, 5.05989e-15, 1.64894e-12
Node: 04 (pos: 0.040): 1.40887e-18, 9.99796e-01, 1.83134e-24, 1.70342e-39, 1.19464e-14, 1.95048e-12
Node: 05 (pos: 0.051): 1.68571e-18, 9.98964e-01, 3.14525e-25, 1.35522e-39, 2.80354e-14, 2.30663e-12
-
Node: 07 (pos: 0.071): 1.68571e-18, 9.98964e-01, 3.14525e-25, 1.35522e-39, 2.80354e-14, 2.30663e-12
Node: 08 (pos: 0.081): 1.40887e-18, 9.99796e-01, 1.83134e-24, 1.70342e-39, 1.19464e-14, 1.95048e-12
Node: 09 (pos: 0.091): 1.17023e-18, 9.99986e-01, 1.03599e-23, 2.14598e-39, 5.05989e-15, 1.64894e-12
Node: 10 (pos: 0.101): 9.66011e-19, 9.99525e-01, 5.69352e-23, 2.70956e-39, 2.13062e-15, 1.39371e-12
Node: 11 (pos: 0.111): 7.92491e-19, 9.98404e-01, 3.03958e-22, 3.42859e-39, 8.92122e-16, 1.17771e-12
Node: 12 (pos: 0.121): 6.46109e-19, 9.96615e-01, 1.57626e-21, 4.34763e-39, 3.71521e-16, 9.94964e-13
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): -1.23556e-01, -6.65225e-03, -9.08402e-02, 9.72165e-02, 5.81479e-02, -8.44410e-02
Node: 01 (pos: 0.010): -1.23827e-01, -2.95282e-03, -8.94107e-02, 9.70923e-02, 5.89373e-02, -8.47049e-02
Node: 02 (pos: 0.020): -1.24106e-01, 7.65312e-04, -8.79819e-02, 9.69666e-02, 5.97217e-02, -8.49683e-02
Node: 03 (pos: 0.030): -1.24394e-01, 4.50193e-03, -8.65539e-02, 9.68395e-02, 6.05013e-02, -8.52312e-02
Node: 04 (pos: 0.040): -1.24690e-01, 8.25681e-03, -8.51269e-02, 9.67111e-02, 6.12759e-02, -8.54937e-02
Node: 05 (pos: 0.051): -1.24995e-01, 1.20297e-02, -8.37010e-02, 9.65814e-02, 6.20455e-02, -8.57557e-02
-
Node: 07 (pos: 0.071): -1.24690e-01, 8.25681e-03, -8.51269e-02, 9.67111e-02, 6.12759e-02, -8.54937e-02
Node: 08 (pos: 0.081): -1.24394e-01, 4.50193e-03, -8.65539e-02, 9.68395e-02, 6.05013e-02, -8.52312e-02
Node: 09 (pos: 0.091): -1.24106e-01, 7.65312e-04, -8.79819e-02, 9.69666e-02, 5.97217e-02, -8.49683e-02
Node: 10 (pos: 0.101): -1.23827e-01, -2.95282e-03, -8.94107e-02, 9.70923e-02, 5.89373e-02, -8.47049e-02
Node: 11 (pos: 0.111): -1.23556e-01, -6.65225e-03, -9.08402e-02, 9.72165e-02, 5.81479e-02, -8.44410e-02
Node: 12 (pos: 0.121): -1.24995e-01, 1.20297e-02, -8.37010e-02, 9.65814e-02, 6.20455e-02, -8.57557e-02

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.68571e-18, 9.98964e-01, 3.14525e-25, 1.35522e-39, 2.80354e-14, 2.30663e-12
Node: 58 (pos: 0.586): 1.40887e-18, 9.99796e-01, 1.83134e-24, 1.70342e-39, 1.19464e-14, 1.95048e-12
Node: 59 (pos: 0.596): 1.17023e-18, 9.99986e-01, 1.03599e-23, 2.14598e-39, 5.05989e-15, 1.64894e-12
Node: 60 (pos: 0.606): 9.66011e-19, 9.99525e-01, 5.69352e-23, 2.70956e-39, 2.13062e-15, 1.39371e-12
Node: 61 (pos: 0.616): 7.92491e-19, 9.98404e-01, 3.03958e-22, 3.42859e-39, 8.92122e-16, 1.17771e-12
Node: 50 (pos: 0.505): 6.46109e-19, 9.96615e-01, 1.57626e-21, 4.34763e-39, 3.71521e-16, 9.94964e-13
-
Node: 51 (pos: 0.515): 7.92491e-19, 9.98404e-01, 3.03958e-22, 3.42859e-39, 8.92122e-16, 1.17771e-12
Node: 52 (pos: 0.525): 9.66011e-19, 9.99525e-01, 5.69352e-23, 2.70956e-39, 2.13062e-15, 1.39371e-12
Node: 53 (pos: 0.535): 1.17023e-18, 9.99986e-01, 1.03599e-23, 2.14598e-39, 5.05989e-15, 1.64894e-12
Node: 54 (pos: 0.545): 1.40887e-18, 9.99796e-01, 1.83134e-24, 1.70342e-39, 1.19464e-14, 1.95048e-12
Node: 55 (pos: 0.556): 1.68571e-18, 9.98964e-01, 3.14525e-25, 1.35522e-39, 2.80354e-14, 2.30663e-12
Node: 62 (pos: 0.626): 6.46109e-19, 9.96615e-01, 1.57626e-21, 4.34763e-39, 3.71521e-16, 9.94964e-13
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 1.6741810454943903e-21), ('0.bias', 9.594166727482973e-20), ('2.weight', 1.1062018603362352e-18), ('2.bias', 3.0341999233629827e-19)] 

GNN_Layer 1 gradients:
[('0.weight', 3.760268809313929e-06), ('0.bias', 7.041599314445235e-05), ('2.weight', 0.0008429755261046048), ('2.bias', 0.0002216948877563442)] 

GNN_Layer 2 gradients:
[('0.weight', 2.029297574024831e-24), ('0.bias', 3.516121305960163e-23), ('2.weight', 4.143449074524103e-22), ('2.bias', 1.0524962765275568e-22)] 

GNN_Layer 3 gradients:
[('0.weight', 5.83089314928363e-41), ('0.bias', 1.4346759242729794e-39), ('2.weight', 1.745344176427651e-38), ('2.bias', 4.7653907962127336e-39)] 

GNN_Layer 4 gradients:
[('0.weight', 5.819448937103398e-17), ('0.bias', 1.913096762516107e-15), ('2.weight', 2.4336142729647343e-14), ('2.bias', 6.4587018394256164e-15)] 

GNN_Layer 5 gradients:
[('0.weight', 2.555372443901207e-14), ('0.bias', 6.694511774292648e-13), ('2.weight', 8.607325524549152e-12), ('2.bias', 2.21117001281746e-12)] 

Evaluation on test dataset:
Step 25, mean loss 0.06279389661486424
Step 50, mean loss 0.07347931429836682
Step 75, mean loss 0.1025331707351231
Step 100, mean loss 0.11920559753625198
Step 125, mean loss 0.31887832100868446
Step 150, mean loss 0.21475383795602046
Step 175, mean loss 0.33137192436441726
Step 200, mean loss 0.25357527754498577
Step 225, mean loss 0.3103572833662348
Unrolled forward losses 14.111582104292037
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+net_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514222.tar

Epoch 1
Starting epoch 1...
