Training on dataset data/CE_train_E1.h5
Specified device: cuda:0
Using NVIDIA A100 80GB PCIe
models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar
Number of parameters: 1034609.0
Epoch 0
Starting epoch 0...
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): -8.94566e-02, -5.84114e-02, 7.02894e-02, -6.28336e-02, 3.61339e-03, -3.73650e-03
Node: 01 (pos: 0.010): -9.01397e-02, -5.79874e-02, 7.17195e-02, -6.25442e-02, 4.22798e-03, -3.69531e-03
Node: 02 (pos: 0.020): -9.08100e-02, -5.75690e-02, 7.31585e-02, -6.22542e-02, 4.84136e-03, -3.65656e-03
Node: 03 (pos: 0.030): -9.14674e-02, -5.71564e-02, 7.46064e-02, -6.19636e-02, 5.45348e-03, -3.62022e-03
Node: 04 (pos: 0.040): -9.21120e-02, -5.67496e-02, 7.60632e-02, -6.16724e-02, 6.06427e-03, -3.58628e-03
Node: 05 (pos: 0.051): -9.27439e-02, -5.63484e-02, 7.75289e-02, -6.13806e-02, 6.67366e-03, -3.55474e-03
-
Node: 07 (pos: 0.071): -9.27439e-02, -5.63484e-02, 7.75289e-02, -6.13806e-02, 6.67366e-03, -3.55474e-03
Node: 08 (pos: 0.081): -9.21120e-02, -5.67496e-02, 7.60632e-02, -6.16724e-02, 6.06427e-03, -3.58628e-03
Node: 09 (pos: 0.091): -9.14674e-02, -5.71564e-02, 7.46064e-02, -6.19636e-02, 5.45348e-03, -3.62022e-03
Node: 10 (pos: 0.101): -9.08100e-02, -5.75690e-02, 7.31585e-02, -6.22542e-02, 4.84136e-03, -3.65656e-03
Node: 11 (pos: 0.111): -9.01397e-02, -5.79874e-02, 7.17195e-02, -6.25442e-02, 4.22798e-03, -3.69531e-03
Node: 12 (pos: 0.121): -8.94566e-02, -5.84114e-02, 7.02894e-02, -6.28336e-02, 3.61339e-03, -3.73650e-03

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.34630e-04, 3.29786e-02, 7.15034e-03, 1.92921e-02, 9.87028e-01, 9.86136e-01
Node: 01 (pos: 0.010): 2.95994e-04, 3.46473e-02, 5.83611e-03, 2.00050e-02, 9.82283e-01, 9.86437e-01
Node: 02 (pos: 0.020): 2.62187e-04, 3.63633e-02, 4.73784e-03, 2.07423e-02, 9.76834e-01, 9.86719e-01
Node: 03 (pos: 0.030): 2.32579e-04, 3.81260e-02, 3.82529e-03, 2.15047e-02, 9.70697e-01, 9.86980e-01
Node: 04 (pos: 0.040): 2.06622e-04, 3.99346e-02, 3.07142e-03, 2.22930e-02, 9.63893e-01, 9.87221e-01
Node: 05 (pos: 0.051): 1.83843e-04, 4.17880e-02, 2.45229e-03, 2.31080e-02, 9.56439e-01, 9.87443e-01
-
Node: 07 (pos: 0.071): 1.83843e-04, 4.17880e-02, 2.45229e-03, 2.31080e-02, 9.56439e-01, 9.87443e-01
Node: 08 (pos: 0.081): 2.06622e-04, 3.99346e-02, 3.07142e-03, 2.22930e-02, 9.63893e-01, 9.87221e-01
Node: 09 (pos: 0.091): 2.32579e-04, 3.81260e-02, 3.82529e-03, 2.15047e-02, 9.70697e-01, 9.86980e-01
Node: 10 (pos: 0.101): 2.62187e-04, 3.63633e-02, 4.73784e-03, 2.07423e-02, 9.76834e-01, 9.86719e-01
Node: 11 (pos: 0.111): 2.95994e-04, 3.46473e-02, 5.83611e-03, 2.00050e-02, 9.82283e-01, 9.86437e-01
Node: 12 (pos: 0.121): 3.34630e-04, 3.29786e-02, 7.15034e-03, 1.92921e-02, 9.87028e-01, 9.86136e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): -9.27439e-02, -5.63484e-02, 7.75289e-02, -6.13806e-02, 6.67366e-03, -3.55474e-03
Node: 01 (pos: 0.010): -9.21120e-02, -5.67496e-02, 7.60632e-02, -6.16724e-02, 6.06427e-03, -3.58628e-03
Node: 02 (pos: 0.020): -9.14674e-02, -5.71564e-02, 7.46064e-02, -6.19636e-02, 5.45348e-03, -3.62022e-03
Node: 03 (pos: 0.030): -9.08100e-02, -5.75690e-02, 7.31585e-02, -6.22542e-02, 4.84136e-03, -3.65656e-03
Node: 04 (pos: 0.040): -9.01397e-02, -5.79874e-02, 7.17195e-02, -6.25442e-02, 4.22798e-03, -3.69531e-03
Node: 05 (pos: 0.051): -8.94566e-02, -5.84114e-02, 7.02894e-02, -6.28336e-02, 3.61339e-03, -3.73650e-03
-
Node: 07 (pos: 0.071): -9.01397e-02, -5.79874e-02, 7.17195e-02, -6.25442e-02, 4.22798e-03, -3.69531e-03
Node: 08 (pos: 0.081): -9.08100e-02, -5.75690e-02, 7.31585e-02, -6.22542e-02, 4.84136e-03, -3.65656e-03
Node: 09 (pos: 0.091): -9.14674e-02, -5.71564e-02, 7.46064e-02, -6.19636e-02, 5.45348e-03, -3.62022e-03
Node: 10 (pos: 0.101): -9.21120e-02, -5.67496e-02, 7.60632e-02, -6.16724e-02, 6.06427e-03, -3.58628e-03
Node: 11 (pos: 0.111): -9.27439e-02, -5.63484e-02, 7.75289e-02, -6.13806e-02, 6.67366e-03, -3.55474e-03
Node: 12 (pos: 0.121): -8.94566e-02, -5.84114e-02, 7.02894e-02, -6.28336e-02, 3.61339e-03, -3.73650e-03

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.83843e-04, 4.17880e-02, 2.45229e-03, 2.31080e-02, 9.56439e-01, 9.87443e-01
Node: 58 (pos: 0.586): 2.06622e-04, 3.99346e-02, 3.07142e-03, 2.22930e-02, 9.63893e-01, 9.87221e-01
Node: 59 (pos: 0.596): 2.32579e-04, 3.81260e-02, 3.82529e-03, 2.15047e-02, 9.70697e-01, 9.86980e-01
Node: 60 (pos: 0.606): 2.62187e-04, 3.63633e-02, 4.73784e-03, 2.07423e-02, 9.76834e-01, 9.86719e-01
Node: 61 (pos: 0.616): 2.95994e-04, 3.46473e-02, 5.83611e-03, 2.00050e-02, 9.82283e-01, 9.86437e-01
Node: 50 (pos: 0.505): 3.34630e-04, 3.29786e-02, 7.15034e-03, 1.92921e-02, 9.87028e-01, 9.86136e-01
-
Node: 51 (pos: 0.515): 2.95994e-04, 3.46473e-02, 5.83611e-03, 2.00050e-02, 9.82283e-01, 9.86437e-01
Node: 52 (pos: 0.525): 2.62187e-04, 3.63633e-02, 4.73784e-03, 2.07423e-02, 9.76834e-01, 9.86719e-01
Node: 53 (pos: 0.535): 2.32579e-04, 3.81260e-02, 3.82529e-03, 2.15047e-02, 9.70697e-01, 9.86980e-01
Node: 54 (pos: 0.545): 2.06622e-04, 3.99346e-02, 3.07142e-03, 2.22930e-02, 9.63893e-01, 9.87221e-01
Node: 55 (pos: 0.556): 1.83843e-04, 4.17880e-02, 2.45229e-03, 2.31080e-02, 9.56439e-01, 9.87443e-01
Node: 62 (pos: 0.626): 3.34630e-04, 3.29786e-02, 7.15034e-03, 1.92921e-02, 9.87028e-01, 9.86136e-01
=========================================================================================================
Training Loss (progress: 0.00), 1.2367890229075602, [0.006295127732705691, 0.0046234088202019505, 0.005025512774659744, 0.004731555799358866, 0.008969247367041758, 0.006548914097165395]
Training Loss (progress: 0.08), 0.2655876404874201, [0.012342572036960457, 0.01221172884897778, 0.0024230652357485312, 0.012527004251547057, 0.02713156903841937, 0.022754113128161033]
Training Loss (progress: 0.16), 0.19813932179422575, [0.017361272873600023, 0.017973520232273728, 0.0007274075370352406, 0.01778383181345503, 0.030795985967600237, 0.02953467101904944]
Training Loss (progress: 0.24), 0.16648669927353985, [0.028465765761014405, 0.027650861128379726, 0.0005469353186606148, 0.0232743584169304, 0.041862243715146255, 0.04132068126488323]
Training Loss (progress: 0.32), 0.15645890148111333, [0.030218535750342633, 0.03687305406240549, 0.0005242116889209946, 0.023521425516818274, 0.049166191592417315, 0.049495823901714704]
Training Loss (progress: 0.40), 0.14070145299429337, [0.04191133346954827, 0.045745262869966975, 0.0006468265024460822, 0.030238356102386735, 0.05583115554854568, 0.055684368162930695]
Training Loss (progress: 0.48), 0.14355135182802706, [0.05202937678450222, 0.05782914803805556, 0.0009238429175488223, 0.03659567841524109, 0.06586947884209961, 0.0555386999249193]
Training Loss (progress: 0.56), 0.11351874885537733, [0.05983391562370687, 0.0670997672440586, 0.0008776503028380127, 0.04196603999502508, 0.07342148298333603, 0.06230035420545868]
Training Loss (progress: 0.64), 0.11077314348020054, [0.06685169013574874, 0.08327293173163543, 0.0008889469814581476, 0.048064988016308166, 0.07755889210098989, 0.06948439591675254]
Training Loss (progress: 0.72), 0.10892157474410316, [0.07823009929448578, 0.09195180038310202, 0.0010510844732346206, 0.060574863286135344, 0.08438411581876394, 0.0795329980663388]
Training Loss (progress: 0.80), 0.10280288240035672, [0.09002389748652581, 0.1010722430791112, 0.0011028255969672334, 0.06284804666685159, 0.08960760643960823, 0.09689590579525187]
Training Loss (progress: 0.88), 0.09921724801888794, [0.09846036859458718, 0.10859114989804972, 0.001183818989403921, 0.07178971859046375, 0.09756340064159054, 0.10505186317917645]
Training Loss (progress: 0.96), 0.09895785539945604, [0.09950535388468226, 0.12040915819630924, 0.0012385675135059345, 0.07757993915760852, 0.10633786879029172, 0.11246112367662958]
Evaluation on validation dataset:
Step 25, mean loss 0.09903137533007475
Step 50, mean loss 0.09168049638936182
Step 75, mean loss 0.10158666712390851
Step 100, mean loss 0.281408891636183
Step 125, mean loss 0.20334380173981578
Step 150, mean loss 0.148318330948722
Step 175, mean loss 0.24592151903051224
Step 200, mean loss 0.631844044591419
Step 225, mean loss 0.4725139249673197
Unrolled forward losses 15.100149083311944
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.68530e-03, -3.46854e-03, -6.07731e-02, -1.35503e-03, -5.15902e-04, -8.71922e-06
Node: 01 (pos: 0.010): 2.14397e-03, -2.52535e-03, -5.20790e-02, -1.28133e-03, -4.42368e-04, 8.64515e-06
Node: 02 (pos: 0.020): 1.61645e-03, -1.58807e-03, -4.31782e-02, -1.20730e-03, -3.69709e-04, 2.37889e-05
Node: 03 (pos: 0.030): 1.10274e-03, -6.56749e-04, -3.40694e-02, -1.13291e-03, -2.97974e-04, 3.67231e-05
Node: 04 (pos: 0.040): 6.02804e-04, 2.68579e-04, -2.47515e-02, -1.05815e-03, -2.27212e-04, 4.74589e-05
Node: 05 (pos: 0.051): 1.16618e-04, 1.18788e-03, -1.52236e-02, -9.83001e-04, -1.57472e-04, 5.60071e-05
-
Node: 07 (pos: 0.071): 1.16618e-04, 1.18788e-03, -1.52236e-02, -9.83001e-04, -1.57472e-04, 5.60071e-05
Node: 08 (pos: 0.081): 6.02804e-04, 2.68579e-04, -2.47515e-02, -1.05815e-03, -2.27212e-04, 4.74589e-05
Node: 09 (pos: 0.091): 1.10274e-03, -6.56749e-04, -3.40694e-02, -1.13291e-03, -2.97974e-04, 3.67231e-05
Node: 10 (pos: 0.101): 1.61645e-03, -1.58807e-03, -4.31782e-02, -1.20730e-03, -3.69709e-04, 2.37889e-05
Node: 11 (pos: 0.111): 2.14397e-03, -2.52535e-03, -5.20790e-02, -1.28133e-03, -4.42368e-04, 8.64515e-06
Node: 12 (pos: 0.121): 2.68530e-03, -3.46854e-03, -6.07731e-02, -1.35503e-03, -5.15902e-04, -8.71922e-06

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 9.99931e-01, 9.99901e-01, 5.09112e-02, 9.99978e-01, 9.99998e-01, 1.00000e+00
Node: 01 (pos: 0.010): 9.99956e-01, 9.99948e-01, 1.12292e-01, 9.99980e-01, 9.99998e-01, 1.00000e+00
Node: 02 (pos: 0.020): 9.99975e-01, 9.99979e-01, 2.22444e-01, 9.99982e-01, 9.99999e-01, 1.00000e+00
Node: 03 (pos: 0.030): 9.99988e-01, 9.99996e-01, 3.92273e-01, 9.99984e-01, 9.99999e-01, 1.00000e+00
Node: 04 (pos: 0.040): 9.99996e-01, 9.99999e-01, 6.10229e-01, 9.99986e-01, 1.00000e+00, 1.00000e+00
Node: 05 (pos: 0.051): 1.00000e+00, 9.99988e-01, 8.29570e-01, 9.99988e-01, 1.00000e+00, 1.00000e+00
-
Node: 07 (pos: 0.071): 1.00000e+00, 9.99988e-01, 8.29570e-01, 9.99988e-01, 1.00000e+00, 1.00000e+00
Node: 08 (pos: 0.081): 9.99996e-01, 9.99999e-01, 6.10229e-01, 9.99986e-01, 1.00000e+00, 1.00000e+00
Node: 09 (pos: 0.091): 9.99988e-01, 9.99996e-01, 3.92273e-01, 9.99984e-01, 9.99999e-01, 1.00000e+00
Node: 10 (pos: 0.101): 9.99975e-01, 9.99979e-01, 2.22444e-01, 9.99982e-01, 9.99999e-01, 1.00000e+00
Node: 11 (pos: 0.111): 9.99956e-01, 9.99948e-01, 1.12292e-01, 9.99980e-01, 9.99998e-01, 1.00000e+00
Node: 12 (pos: 0.121): 9.99931e-01, 9.99901e-01, 5.09112e-02, 9.99978e-01, 9.99998e-01, 1.00000e+00
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.16618e-04, 1.18788e-03, -1.52236e-02, -9.83001e-04, -1.57472e-04, 5.60071e-05
Node: 01 (pos: 0.010): 6.02804e-04, 2.68579e-04, -2.47515e-02, -1.05815e-03, -2.27212e-04, 4.74589e-05
Node: 02 (pos: 0.020): 1.10274e-03, -6.56749e-04, -3.40694e-02, -1.13291e-03, -2.97974e-04, 3.67231e-05
Node: 03 (pos: 0.030): 1.61645e-03, -1.58807e-03, -4.31782e-02, -1.20730e-03, -3.69709e-04, 2.37889e-05
Node: 04 (pos: 0.040): 2.14397e-03, -2.52535e-03, -5.20790e-02, -1.28133e-03, -4.42368e-04, 8.64515e-06
Node: 05 (pos: 0.051): 2.68530e-03, -3.46854e-03, -6.07731e-02, -1.35503e-03, -5.15902e-04, -8.71922e-06
-
Node: 07 (pos: 0.071): 2.14397e-03, -2.52535e-03, -5.20790e-02, -1.28133e-03, -4.42368e-04, 8.64515e-06
Node: 08 (pos: 0.081): 1.61645e-03, -1.58807e-03, -4.31782e-02, -1.20730e-03, -3.69709e-04, 2.37889e-05
Node: 09 (pos: 0.091): 1.10274e-03, -6.56749e-04, -3.40694e-02, -1.13291e-03, -2.97974e-04, 3.67231e-05
Node: 10 (pos: 0.101): 6.02804e-04, 2.68579e-04, -2.47515e-02, -1.05815e-03, -2.27212e-04, 4.74589e-05
Node: 11 (pos: 0.111): 1.16618e-04, 1.18788e-03, -1.52236e-02, -9.83001e-04, -1.57472e-04, 5.60071e-05
Node: 12 (pos: 0.121): 2.68530e-03, -3.46854e-03, -6.07731e-02, -1.35503e-03, -5.15902e-04, -8.71922e-06

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.00000e+00, 9.99988e-01, 8.29570e-01, 9.99988e-01, 1.00000e+00, 1.00000e+00
Node: 58 (pos: 0.586): 9.99996e-01, 9.99999e-01, 6.10229e-01, 9.99986e-01, 1.00000e+00, 1.00000e+00
Node: 59 (pos: 0.596): 9.99988e-01, 9.99996e-01, 3.92273e-01, 9.99984e-01, 9.99999e-01, 1.00000e+00
Node: 60 (pos: 0.606): 9.99975e-01, 9.99979e-01, 2.22444e-01, 9.99982e-01, 9.99999e-01, 1.00000e+00
Node: 61 (pos: 0.616): 9.99956e-01, 9.99948e-01, 1.12292e-01, 9.99980e-01, 9.99998e-01, 1.00000e+00
Node: 50 (pos: 0.505): 9.99931e-01, 9.99901e-01, 5.09112e-02, 9.99978e-01, 9.99998e-01, 1.00000e+00
-
Node: 51 (pos: 0.515): 9.99956e-01, 9.99948e-01, 1.12292e-01, 9.99980e-01, 9.99998e-01, 1.00000e+00
Node: 52 (pos: 0.525): 9.99975e-01, 9.99979e-01, 2.22444e-01, 9.99982e-01, 9.99999e-01, 1.00000e+00
Node: 53 (pos: 0.535): 9.99988e-01, 9.99996e-01, 3.92273e-01, 9.99984e-01, 9.99999e-01, 1.00000e+00
Node: 54 (pos: 0.545): 9.99996e-01, 9.99999e-01, 6.10229e-01, 9.99986e-01, 1.00000e+00, 1.00000e+00
Node: 55 (pos: 0.556): 1.00000e+00, 9.99988e-01, 8.29570e-01, 9.99988e-01, 1.00000e+00, 1.00000e+00
Node: 62 (pos: 0.626): 9.99931e-01, 9.99901e-01, 5.09112e-02, 9.99978e-01, 9.99998e-01, 1.00000e+00
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 0.0005551997859134553), ('0.bias', 0.011616884813049632), ('2.weight', 0.12676214330335858), ('2.bias', 0.03607561512541519)] 

GNN_Layer 1 gradients:
[('0.weight', 6.911105656181253e-05), ('0.bias', 0.0011706894710926655), ('2.weight', 0.014491448156966017), ('2.bias', 0.00390830002188745)] 

GNN_Layer 2 gradients:
[('0.weight', 0.10988858120918579), ('0.bias', 1.41661708163484), ('2.weight', 11.914120601551982), ('2.bias', 3.2009716669890547)] 

GNN_Layer 3 gradients:
[('0.weight', 6.453672083061585e-05), ('0.bias', 0.0009870778608862605), ('2.weight', 0.01249942728315121), ('2.bias', 0.003228853776548006)] 

GNN_Layer 4 gradients:
[('0.weight', 2.7954264571957686e-05), ('0.bias', 0.0005395124649067082), ('2.weight', 0.007219154063305797), ('2.bias', 0.00190400905761865)] 

GNN_Layer 5 gradients:
[('0.weight', 2.570772193459497e-06), ('0.bias', 0.00012172345660672072), ('2.weight', 0.0015604829391196425), ('2.bias', 0.00038546234648941934)] 

Evaluation on test dataset:
Step 25, mean loss 0.08298751103519111
Step 50, mean loss 0.07688285261660843
Step 75, mean loss 0.09701304211990802
Step 100, mean loss 0.1075120970096225
Step 125, mean loss 0.2938602932613145
Step 150, mean loss 0.16186890135740098
Step 175, mean loss 0.29486671442236395
Step 200, mean loss 0.27464076434143647
Step 225, mean loss 0.24625545070166546
Unrolled forward losses 11.780992330703672
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 1
Starting epoch 1...
Training Loss (progress: 0.00), 0.2080853880676329, [0.10440765809594656, 0.12202700994104249, 0.001222595096900058, 0.08220371225285054, 0.11031074260614865, 0.11528826966889787]
Training Loss (progress: 0.08), 0.2079324962366452, [0.11261927492691896, 0.13302078956474953, 0.0015200359161551534, 0.09230237308033402, 0.11330664284594193, 0.12973023790816843]
Training Loss (progress: 0.16), 0.18192550171693334, [0.12041790253690692, 0.1436755848310112, 0.0014343366918479405, 0.11216666276440128, 0.11769252601266955, 0.13749404697242903]
Training Loss (progress: 0.24), 0.19002186451357853, [0.13006022698822411, 0.1467580224316865, 0.0015049764882503669, 0.11199141583477364, 0.12693000141245556, 0.1405917927006732]
Training Loss (progress: 0.32), 0.18870001826436386, [0.14329825702072957, 0.15547219774289442, 0.001606147198566105, 0.1194936657234277, 0.12666729295917023, 0.14805215825369844]
Training Loss (progress: 0.40), 0.17453349019472855, [0.1535807351743591, 0.16129595632603577, 0.001694667665856503, 0.13135653422557636, 0.1350538531231116, 0.16194271343397315]
Training Loss (progress: 0.48), 0.1476356077003368, [0.16686691330910486, 0.16750198796816954, 0.0017109013050396681, 0.13488856709231434, 0.13971040622224903, 0.17094792347066493]
Training Loss (progress: 0.56), 0.1976166010112333, [0.17092653716075953, 0.1711589453758233, 0.0016045469414360397, 0.14460906062461673, 0.14561515957178484, 0.17408665812881854]
Training Loss (progress: 0.64), 0.16019620666236137, [0.18622281180696745, 0.1710951203745937, 0.0018954248954846614, 0.1489208953485166, 0.1505557586592762, 0.17936482690375963]
Training Loss (progress: 0.72), 0.1634153441899459, [0.19249916115338883, 0.17563668189252798, 0.0019756317553615388, 0.1573891178910545, 0.15551363969377266, 0.1854727056518468]
Training Loss (progress: 0.80), 0.1562490441159516, [0.2059044568590972, 0.1768299501732883, 0.0020547605815971876, 0.16340090762533416, 0.1629968095865367, 0.19200439058534272]
Training Loss (progress: 0.88), 0.1443962903248493, [0.21136607617301165, 0.17641376057681554, 0.0021230633208962606, 0.17194258979307225, 0.1739737528420875, 0.19865494981474646]
Training Loss (progress: 0.96), 0.1516150330530608, [0.219023660856739, 0.18300945163061338, 0.0022392806741177726, 0.17465328758808907, 0.1819825986708924, 0.20632029406193952]
Evaluation on validation dataset:
Step 25, mean loss 0.09207444611792667
Step 50, mean loss 0.06455832067360806
Step 75, mean loss 0.11335317268339726
Step 100, mean loss 0.12251100830583811
Step 125, mean loss 0.17060016198583278
Step 150, mean loss 0.14207934915498183
Step 175, mean loss 0.22806912043693178
Step 200, mean loss 0.5813498311871906
Step 225, mean loss 0.3580164094863121
Unrolled forward losses 4.823926537375447
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.23969e-04, -3.24211e-04, -8.23744e-02, -7.56208e-05, 4.32882e-05, -3.44562e-03
Node: 01 (pos: 0.010): -4.39180e-05, -8.59106e-05, -7.08777e-02, -3.11882e-05, 2.70351e-05, -3.41028e-03
Node: 02 (pos: 0.020): -1.99512e-04, 1.47055e-04, -5.89900e-02, 1.35846e-05, 1.01026e-05, -3.37698e-03
Node: 03 (pos: 0.030): -3.42811e-04, 3.74683e-04, -4.67082e-02, 5.87112e-05, -7.55072e-06, -3.34572e-03
Node: 04 (pos: 0.040): -4.73811e-04, 5.96976e-04, -3.40300e-02, 1.04205e-04, -2.59661e-05, -3.31648e-03
Node: 05 (pos: 0.051): -5.92508e-04, 8.13931e-04, -2.09530e-02, 1.50079e-04, -4.51848e-05, -3.28926e-03
-
Node: 07 (pos: 0.071): -5.92508e-04, 8.13931e-04, -2.09530e-02, 1.50079e-04, -4.51848e-05, -3.28926e-03
Node: 08 (pos: 0.081): -4.73811e-04, 5.96976e-04, -3.40300e-02, 1.04205e-04, -2.59661e-05, -3.31648e-03
Node: 09 (pos: 0.091): -3.42811e-04, 3.74683e-04, -4.67082e-02, 5.87112e-05, -7.55072e-06, -3.34572e-03
Node: 10 (pos: 0.101): -1.99512e-04, 1.47055e-04, -5.89900e-02, 1.35846e-05, 1.01026e-05, -3.37698e-03
Node: 11 (pos: 0.111): -4.39180e-05, -8.59106e-05, -7.08777e-02, -3.11882e-05, 2.70351e-05, -3.41028e-03
Node: 12 (pos: 0.121): 1.23969e-04, -3.24211e-04, -8.23744e-02, -7.56208e-05, 4.32882e-05, -3.44562e-03

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.00000e+00, 9.99999e-01, 4.89403e-02, 1.00000e+00, 1.00000e+00, 9.99943e-01
Node: 01 (pos: 0.010): 1.00000e+00, 1.00000e+00, 1.07127e-01, 1.00000e+00, 1.00000e+00, 9.99944e-01
Node: 02 (pos: 0.020): 1.00000e+00, 1.00000e+00, 2.12826e-01, 1.00000e+00, 1.00000e+00, 9.99945e-01
Node: 03 (pos: 0.030): 9.99999e-01, 9.99999e-01, 3.79059e-01, 1.00000e+00, 1.00000e+00, 9.99946e-01
Node: 04 (pos: 0.040): 9.99999e-01, 9.99998e-01, 5.97550e-01, 1.00000e+00, 1.00000e+00, 9.99947e-01
Node: 05 (pos: 0.051): 9.99998e-01, 9.99996e-01, 8.22660e-01, 1.00000e+00, 1.00000e+00, 9.99948e-01
-
Node: 07 (pos: 0.071): 9.99998e-01, 9.99996e-01, 8.22660e-01, 1.00000e+00, 1.00000e+00, 9.99948e-01
Node: 08 (pos: 0.081): 9.99999e-01, 9.99998e-01, 5.97550e-01, 1.00000e+00, 1.00000e+00, 9.99947e-01
Node: 09 (pos: 0.091): 9.99999e-01, 9.99999e-01, 3.79059e-01, 1.00000e+00, 1.00000e+00, 9.99946e-01
Node: 10 (pos: 0.101): 1.00000e+00, 1.00000e+00, 2.12826e-01, 1.00000e+00, 1.00000e+00, 9.99945e-01
Node: 11 (pos: 0.111): 1.00000e+00, 1.00000e+00, 1.07127e-01, 1.00000e+00, 1.00000e+00, 9.99944e-01
Node: 12 (pos: 0.121): 1.00000e+00, 9.99999e-01, 4.89403e-02, 1.00000e+00, 1.00000e+00, 9.99943e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): -5.92508e-04, 8.13931e-04, -2.09530e-02, 1.50079e-04, -4.51848e-05, -3.28926e-03
Node: 01 (pos: 0.010): -4.73811e-04, 5.96976e-04, -3.40300e-02, 1.04205e-04, -2.59661e-05, -3.31648e-03
Node: 02 (pos: 0.020): -3.42811e-04, 3.74683e-04, -4.67082e-02, 5.87112e-05, -7.55072e-06, -3.34572e-03
Node: 03 (pos: 0.030): -1.99512e-04, 1.47055e-04, -5.89900e-02, 1.35846e-05, 1.01026e-05, -3.37698e-03
Node: 04 (pos: 0.040): -4.39180e-05, -8.59106e-05, -7.08777e-02, -3.11882e-05, 2.70351e-05, -3.41028e-03
Node: 05 (pos: 0.051): 1.23969e-04, -3.24211e-04, -8.23744e-02, -7.56208e-05, 4.32882e-05, -3.44562e-03
-
Node: 07 (pos: 0.071): -4.39180e-05, -8.59106e-05, -7.08777e-02, -3.11882e-05, 2.70351e-05, -3.41028e-03
Node: 08 (pos: 0.081): -1.99512e-04, 1.47055e-04, -5.89900e-02, 1.35846e-05, 1.01026e-05, -3.37698e-03
Node: 09 (pos: 0.091): -3.42811e-04, 3.74683e-04, -4.67082e-02, 5.87112e-05, -7.55072e-06, -3.34572e-03
Node: 10 (pos: 0.101): -4.73811e-04, 5.96976e-04, -3.40300e-02, 1.04205e-04, -2.59661e-05, -3.31648e-03
Node: 11 (pos: 0.111): -5.92508e-04, 8.13931e-04, -2.09530e-02, 1.50079e-04, -4.51848e-05, -3.28926e-03
Node: 12 (pos: 0.121): 1.23969e-04, -3.24211e-04, -8.23744e-02, -7.56208e-05, 4.32882e-05, -3.44562e-03

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.99998e-01, 9.99996e-01, 8.22660e-01, 1.00000e+00, 1.00000e+00, 9.99948e-01
Node: 58 (pos: 0.586): 9.99999e-01, 9.99998e-01, 5.97550e-01, 1.00000e+00, 1.00000e+00, 9.99947e-01
Node: 59 (pos: 0.596): 9.99999e-01, 9.99999e-01, 3.79059e-01, 1.00000e+00, 1.00000e+00, 9.99946e-01
Node: 60 (pos: 0.606): 1.00000e+00, 1.00000e+00, 2.12826e-01, 1.00000e+00, 1.00000e+00, 9.99945e-01
Node: 61 (pos: 0.616): 1.00000e+00, 1.00000e+00, 1.07127e-01, 1.00000e+00, 1.00000e+00, 9.99944e-01
Node: 50 (pos: 0.505): 1.00000e+00, 9.99999e-01, 4.89403e-02, 1.00000e+00, 1.00000e+00, 9.99943e-01
-
Node: 51 (pos: 0.515): 1.00000e+00, 1.00000e+00, 1.07127e-01, 1.00000e+00, 1.00000e+00, 9.99944e-01
Node: 52 (pos: 0.525): 1.00000e+00, 1.00000e+00, 2.12826e-01, 1.00000e+00, 1.00000e+00, 9.99945e-01
Node: 53 (pos: 0.535): 9.99999e-01, 9.99999e-01, 3.79059e-01, 1.00000e+00, 1.00000e+00, 9.99946e-01
Node: 54 (pos: 0.545): 9.99999e-01, 9.99998e-01, 5.97550e-01, 1.00000e+00, 1.00000e+00, 9.99947e-01
Node: 55 (pos: 0.556): 9.99998e-01, 9.99996e-01, 8.22660e-01, 1.00000e+00, 1.00000e+00, 9.99948e-01
Node: 62 (pos: 0.626): 1.00000e+00, 9.99999e-01, 4.89403e-02, 1.00000e+00, 1.00000e+00, 9.99943e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 3.3793531419857123e-08), ('0.bias', 6.476740710158795e-05), ('2.weight', 0.0007046416299492355), ('2.bias', 0.00021028681099292165)] 

GNN_Layer 1 gradients:
[('0.weight', 2.8833303913758457e-06), ('0.bias', 0.00020664609994793456), ('2.weight', 0.0025971970039576063), ('2.bias', 0.0007332997977520417)] 

GNN_Layer 2 gradients:
[('0.weight', 0.1418884609179523), ('0.bias', 0.2866103939363238), ('2.weight', 2.27585886440688), ('2.bias', 0.5653911419713555)] 

GNN_Layer 3 gradients:
[('0.weight', 3.5365558665277217e-07), ('0.bias', 2.0773915409173725e-05), ('2.weight', 0.000264796909148257), ('2.bias', 7.126389627734866e-05)] 

GNN_Layer 4 gradients:
[('0.weight', 3.829493636097685e-07), ('0.bias', 2.476387335038951e-05), ('2.weight', 0.0003313530830857575), ('2.bias', 9.151006103960552e-05)] 

GNN_Layer 5 gradients:
[('0.weight', 2.442239931557474e-05), ('0.bias', 0.00018444315820827578), ('2.weight', 0.0024200716937988376), ('2.bias', 0.0006180811371553907)] 

Evaluation on test dataset:
Step 25, mean loss 0.06910579409623085
Step 50, mean loss 0.051099089576287796
Step 75, mean loss 0.08743659969252318
Step 100, mean loss 0.09880348078837145
Step 125, mean loss 0.11682594916506076
Step 150, mean loss 0.152770633622444
Step 175, mean loss 0.2207951152657033
Step 200, mean loss 0.2560717675676009
Step 225, mean loss 0.2209936527154952
Unrolled forward losses 3.632078970596477
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 2
Starting epoch 2...
Training Loss (progress: 0.00), 0.23086575219937422, [0.22323907173528615, 0.1827956706953899, 0.002173981642880113, 0.18295802442424125, 0.18176575496951322, 0.2071832876259176]
Training Loss (progress: 0.08), 0.20300934492408368, [0.2235752490376958, 0.18263156538372954, 0.002126231572486516, 0.18297260692383646, 0.18351867430800545, 0.20966188463335386]
Training Loss (progress: 0.16), 0.1975089946710767, [0.22829539474651805, 0.18405527530141902, 0.002009064729896989, 0.18483844287899998, 0.18331647793951272, 0.21124355629962246]
Training Loss (progress: 0.24), 0.2371683792565344, [0.22954077308858326, 0.1849762194546753, 0.0020896403119909433, 0.18481731019719658, 0.18641374306752828, 0.21355773440235623]
Training Loss (progress: 0.32), 0.18954356448370954, [0.23384916394025135, 0.18795086825495566, 0.0020250557091346347, 0.1872508486182215, 0.18805874499374237, 0.21763353653619086]
Training Loss (progress: 0.40), 0.20656261115149221, [0.23885361634984625, 0.19234585094730236, 0.002143693980156753, 0.19055832532172703, 0.19015379060042675, 0.2212748175710405]
Training Loss (progress: 0.48), 0.20278810297316982, [0.2429145946752101, 0.19343040460074643, 0.002116050373541268, 0.19294291932644564, 0.19363505767935127, 0.22605370970325242]
Training Loss (progress: 0.56), 0.21829450691392585, [0.24502465567923218, 0.1950519666702458, 0.0020625600351346675, 0.1927691666826889, 0.19651393137427473, 0.22826356827064403]
Training Loss (progress: 0.64), 0.20667982826577755, [0.24724066020867524, 0.19639378609338556, 0.0021401190645126333, 0.19429437848903972, 0.20110417539723613, 0.23455965008943605]
Training Loss (progress: 0.72), 0.21317412537504316, [0.2520420594938216, 0.2016751450045281, 0.0021110039710577878, 0.19985597078437858, 0.20405677356215257, 0.23614124178257265]
Training Loss (progress: 0.80), 0.184346916060708, [0.25599036739235786, 0.20300040203580413, 0.002066163748712857, 0.2008346178852811, 0.2041404959346997, 0.23591642300314733]
Training Loss (progress: 0.88), 0.19892636307718464, [0.2587164376198033, 0.20369242569270263, 0.002077417971865351, 0.2006676511566031, 0.20649162813632332, 0.24037251061782533]
Training Loss (progress: 0.96), 0.18999760152780512, [0.26269297133089686, 0.2057523808520305, 0.00212445168931048, 0.202573860363446, 0.20780233715119306, 0.2467851785308571]
Evaluation on validation dataset:
Step 25, mean loss 0.07132341996885577
Step 50, mean loss 0.03720370570787161
Step 75, mean loss 0.04481849241571613
Step 100, mean loss 0.06295881579559343
Step 125, mean loss 0.07310895557745435
Step 150, mean loss 0.07387711563460361
Step 175, mean loss 0.12506383966277113
Step 200, mean loss 0.3310502040667452
Step 225, mean loss 0.19306775975683038
Unrolled forward losses 2.855534195412269
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 3.19903e-05, 1.33910e-04, -8.35099e-02, 1.30167e-05, -2.75186e-05, -5.45446e-05
Node: 01 (pos: 0.010): 2.21534e-06, 9.57687e-05, -7.16714e-02, 1.52579e-05, -1.58946e-05, -1.92152e-05
Node: 02 (pos: 0.020): -1.56674e-05, 5.30322e-05, -5.94170e-02, 1.78560e-05, -4.97536e-06, 1.41221e-05
Node: 03 (pos: 0.030): -2.16459e-05, 5.70754e-06, -4.67435e-02, 2.08241e-05, 5.19986e-06, 4.54763e-05
Node: 04 (pos: 0.040): -1.57078e-05, -4.61976e-05, -3.36483e-02, 2.41746e-05, 1.45920e-05, 7.48560e-05
Node: 05 (pos: 0.051): 2.15896e-06, -1.02675e-04, -2.01289e-02, 2.79201e-05, 2.31621e-05, 1.02270e-04
-
Node: 07 (pos: 0.071): 2.15896e-06, -1.02675e-04, -2.01289e-02, 2.79201e-05, 2.31621e-05, 1.02270e-04
Node: 08 (pos: 0.081): -1.57078e-05, -4.61976e-05, -3.36483e-02, 2.41746e-05, 1.45920e-05, 7.48560e-05
Node: 09 (pos: 0.091): -2.16459e-05, 5.70754e-06, -4.67435e-02, 2.08241e-05, 5.19986e-06, 4.54763e-05
Node: 10 (pos: 0.101): -1.56674e-05, 5.30322e-05, -5.94170e-02, 1.78560e-05, -4.97536e-06, 1.41221e-05
Node: 11 (pos: 0.111): 2.21534e-06, 9.57687e-05, -7.16714e-02, 1.52579e-05, -1.58946e-05, -1.92152e-05
Node: 12 (pos: 0.121): 3.19903e-05, 1.33910e-04, -8.35099e-02, 1.30167e-05, -2.75186e-05, -5.45446e-05

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.00000e+00, 1.00000e+00, 3.50513e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 01 (pos: 0.010): 1.00000e+00, 1.00000e+00, 8.47359e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 02 (pos: 0.020): 1.00000e+00, 1.00000e+00, 1.83354e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 03 (pos: 0.030): 1.00000e+00, 1.00000e+00, 3.49985e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 04 (pos: 0.040): 1.00000e+00, 1.00000e+00, 5.80408e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 05 (pos: 0.051): 1.00000e+00, 1.00000e+00, 8.23094e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 07 (pos: 0.071): 1.00000e+00, 1.00000e+00, 8.23094e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 08 (pos: 0.081): 1.00000e+00, 1.00000e+00, 5.80408e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 09 (pos: 0.091): 1.00000e+00, 1.00000e+00, 3.49985e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 10 (pos: 0.101): 1.00000e+00, 1.00000e+00, 1.83354e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 11 (pos: 0.111): 1.00000e+00, 1.00000e+00, 8.47359e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 12 (pos: 0.121): 1.00000e+00, 1.00000e+00, 3.50513e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 2.15896e-06, -1.02675e-04, -2.01289e-02, 2.79201e-05, 2.31621e-05, 1.02270e-04
Node: 01 (pos: 0.010): -1.57078e-05, -4.61976e-05, -3.36483e-02, 2.41746e-05, 1.45920e-05, 7.48560e-05
Node: 02 (pos: 0.020): -2.16459e-05, 5.70754e-06, -4.67435e-02, 2.08241e-05, 5.19986e-06, 4.54763e-05
Node: 03 (pos: 0.030): -1.56674e-05, 5.30322e-05, -5.94170e-02, 1.78560e-05, -4.97536e-06, 1.41221e-05
Node: 04 (pos: 0.040): 2.21534e-06, 9.57687e-05, -7.16714e-02, 1.52579e-05, -1.58946e-05, -1.92152e-05
Node: 05 (pos: 0.051): 3.19903e-05, 1.33910e-04, -8.35099e-02, 1.30167e-05, -2.75186e-05, -5.45446e-05
-
Node: 07 (pos: 0.071): 2.21534e-06, 9.57687e-05, -7.16714e-02, 1.52579e-05, -1.58946e-05, -1.92152e-05
Node: 08 (pos: 0.081): -1.56674e-05, 5.30322e-05, -5.94170e-02, 1.78560e-05, -4.97536e-06, 1.41221e-05
Node: 09 (pos: 0.091): -2.16459e-05, 5.70754e-06, -4.67435e-02, 2.08241e-05, 5.19986e-06, 4.54763e-05
Node: 10 (pos: 0.101): -1.57078e-05, -4.61976e-05, -3.36483e-02, 2.41746e-05, 1.45920e-05, 7.48560e-05
Node: 11 (pos: 0.111): 2.15896e-06, -1.02675e-04, -2.01289e-02, 2.79201e-05, 2.31621e-05, 1.02270e-04
Node: 12 (pos: 0.121): 3.19903e-05, 1.33910e-04, -8.35099e-02, 1.30167e-05, -2.75186e-05, -5.45446e-05

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.00000e+00, 1.00000e+00, 8.23094e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 58 (pos: 0.586): 1.00000e+00, 1.00000e+00, 5.80408e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 59 (pos: 0.596): 1.00000e+00, 1.00000e+00, 3.49985e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 60 (pos: 0.606): 1.00000e+00, 1.00000e+00, 1.83354e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 61 (pos: 0.616): 1.00000e+00, 1.00000e+00, 8.47359e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 50 (pos: 0.505): 1.00000e+00, 1.00000e+00, 3.50513e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 51 (pos: 0.515): 1.00000e+00, 1.00000e+00, 8.47359e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 52 (pos: 0.525): 1.00000e+00, 1.00000e+00, 1.83354e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 53 (pos: 0.535): 1.00000e+00, 1.00000e+00, 3.49985e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 54 (pos: 0.545): 1.00000e+00, 1.00000e+00, 5.80408e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 55 (pos: 0.556): 1.00000e+00, 1.00000e+00, 8.23094e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 62 (pos: 0.626): 1.00000e+00, 1.00000e+00, 3.50513e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 4.868199095554147e-07), ('0.bias', 8.409629060353458e-06), ('2.weight', 9.226836235965394e-05), ('2.bias', 2.7727578023670595e-05)] 

GNN_Layer 1 gradients:
[('0.weight', 2.6574463899402474e-06), ('0.bias', 5.496009207688148e-05), ('2.weight', 0.0006934244717168382), ('2.bias', 0.0001982421839634481)] 

GNN_Layer 2 gradients:
[('0.weight', 0.13539769735824278), ('0.bias', 1.4105012878738257), ('2.weight', 9.236760834283677), ('2.bias', 2.6555340710914326)] 

GNN_Layer 3 gradients:
[('0.weight', 6.517593100277484e-08), ('0.bias', 2.487473964347821e-06), ('2.weight', 3.175363000345222e-05), ('2.bias', 8.672776799192212e-06)] 

GNN_Layer 4 gradients:
[('0.weight', 4.7549223440520546e-07), ('0.bias', 1.5125491678428313e-05), ('2.weight', 0.00020173822107600199), ('2.bias', 5.6804868513685063e-05)] 

GNN_Layer 5 gradients:
[('0.weight', 2.0395556123606925e-07), ('0.bias', 8.850929406594713e-06), ('2.weight', 0.00011420688991008372), ('2.bias', 2.995294750484333e-05)] 

Evaluation on test dataset:
Step 25, mean loss 0.05476538760825169
Step 50, mean loss 0.025804437622328005
Step 75, mean loss 0.03908734647458484
Step 100, mean loss 0.04480082714170686
Step 125, mean loss 0.06068223636946777
Step 150, mean loss 0.06954609101369537
Step 175, mean loss 0.10533611067418072
Step 200, mean loss 0.12610666025765593
Step 225, mean loss 0.151258758537392
Unrolled forward losses 2.085028989841123
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 3
Starting epoch 3...
Training Loss (progress: 0.00), 0.1994398449609068, [0.26598393264211845, 0.20569576532309755, 0.002116613774309832, 0.20246781307064501, 0.2076935502099406, 0.2466576266024288]
Training Loss (progress: 0.08), 0.17550212419082872, [0.2667524150490455, 0.2058823520597045, 0.0021248648121628667, 0.203907424228914, 0.20846325993852388, 0.2493832828632994]
Training Loss (progress: 0.16), 0.1873135127184935, [0.2701232369608535, 0.208390156936774, 0.002133596537057061, 0.20693381989074947, 0.21108814768888734, 0.25098834059086883]
Training Loss (progress: 0.24), 0.17990086309669392, [0.27540421890849226, 0.21091288509047024, 0.002211616486431285, 0.20975146153823565, 0.21124859558248452, 0.2534728793544717]
Training Loss (progress: 0.32), 0.1820373876560492, [0.2779930098207487, 0.212007499570817, 0.002147200638271842, 0.20968531867789106, 0.21348411267224793, 0.25896423475868896]
Training Loss (progress: 0.40), 0.15917876660833685, [0.2834845071638986, 0.2153525658994001, 0.0020831338650444415, 0.21270544511148767, 0.21682778194563423, 0.26291530409230396]
Training Loss (progress: 0.48), 0.17332927665335554, [0.28808386276628284, 0.2168225839214181, 0.002156638857249062, 0.2142247558263662, 0.21879660235693035, 0.26690529378357253]
Training Loss (progress: 0.56), 0.17659209863836378, [0.2912355967689572, 0.2208042880272125, 0.0021068192596500174, 0.21575062196463718, 0.2231838390424681, 0.2688818992646472]
Training Loss (progress: 0.64), 0.17813086369059716, [0.30034985685011634, 0.22125411533362654, 0.002130598740657275, 0.2181372381955104, 0.2268075781604428, 0.2703163512395559]
Training Loss (progress: 0.72), 0.18299511922954817, [0.3062981800292141, 0.22463096894061055, 0.002111013773639357, 0.21959582977540518, 0.23029979983387153, 0.272784868363424]
Training Loss (progress: 0.80), 0.18122859113380724, [0.30808606111693543, 0.22773379452459505, 0.002226236067416205, 0.22512784280260242, 0.2301840712271062, 0.2782503969417253]
Training Loss (progress: 0.88), 0.1630784501816599, [0.31066171662764125, 0.22755115900333245, 0.002147704067665529, 0.22685705296448944, 0.23356935814792212, 0.27947674254129234]
Training Loss (progress: 0.96), 0.17272714553798085, [0.31489940655398163, 0.22979326186702276, 0.0021419306780404756, 0.23200821679459746, 0.24227330357897098, 0.2826614575765257]
Evaluation on validation dataset:
Step 25, mean loss 0.05812694314228633
Step 50, mean loss 0.03319180472223149
Step 75, mean loss 0.052473832899800565
Step 100, mean loss 0.06360965120685196
Step 125, mean loss 0.10289323852974361
Step 150, mean loss 0.07820436835743702
Step 175, mean loss 0.1235039624172648
Step 200, mean loss 0.3062824242056272
Step 225, mean loss 0.2286352851322555
Unrolled forward losses 3.6475814545124425
Unrolled forward base losses 2.565701273852575
Epoch 4
Starting epoch 4...
Training Loss (progress: 0.00), 0.18070554629300797, [0.31534972447121445, 0.2300619910275953, 0.002183784718770497, 0.23188796668394634, 0.24223960490473387, 0.28459019966110816]
Training Loss (progress: 0.08), 0.16106181630862457, [0.3193415157710688, 0.2334220141479989, 0.0021426561973393906, 0.23443785310002557, 0.2494293361665923, 0.28701079660178264]
Training Loss (progress: 0.16), 0.18141132304991686, [0.3267932944784361, 0.23517797125076195, 0.002135944696635581, 0.237568359201082, 0.2492633417689226, 0.2918529985379593]
Training Loss (progress: 0.24), 0.1603150796644597, [0.32708144856192206, 0.2349367445128527, 0.0021521926277806203, 0.24020253366468577, 0.25357319994910943, 0.295951617897151]
Training Loss (progress: 0.32), 0.17159986499897548, [0.3284580052570805, 0.236792155714174, 0.0020961513120398914, 0.2431401116922533, 0.25333628886780774, 0.29982367411507915]
Training Loss (progress: 0.40), 0.16923798271131812, [0.33104475652698134, 0.23720110911730224, 0.0021664298524888834, 0.2454766052356332, 0.2569104050546111, 0.30167980868285643]
Training Loss (progress: 0.48), 0.16524253107163708, [0.33332959766335135, 0.23983785914923858, 0.0021467531068621146, 0.2472785437547816, 0.25937273122719096, 0.3043912390184983]
Training Loss (progress: 0.56), 0.1637153860818371, [0.33659494224161446, 0.2405566283151448, 0.002087227574064794, 0.24961250665215814, 0.2612447266199059, 0.30920290956423374]
Training Loss (progress: 0.64), 0.17401802932555363, [0.3406672310555428, 0.24337297387545195, 0.0021835519137240675, 0.2530756261392908, 0.2647695031194094, 0.3142444562997063]
Training Loss (progress: 0.72), 0.178525000132419, [0.3430327968327751, 0.24418843890943132, 0.002108900782285959, 0.2550251665427267, 0.26541582723061485, 0.3159457175273354]
Training Loss (progress: 0.80), 0.15225042895281185, [0.3469341426914498, 0.24564679641876647, 0.0021020201152688236, 0.25507525286047456, 0.2668674693113613, 0.3195396788669572]
Training Loss (progress: 0.88), 0.16083493609860045, [0.34958879956394023, 0.24727100844056196, 0.0022093434500439378, 0.2576065088923212, 0.26797473775039476, 0.3235389416099886]
Training Loss (progress: 0.96), 0.16377294213435745, [0.3492229028396916, 0.2493840471601627, 0.0022111437487466064, 0.2588549938161679, 0.27040486676377723, 0.3260596361974145]
Evaluation on validation dataset:
Step 25, mean loss 0.0528616714646435
Step 50, mean loss 0.031234399936493913
Step 75, mean loss 0.04440595106176412
Step 100, mean loss 0.05535893125372729
Step 125, mean loss 0.07420633147316763
Step 150, mean loss 0.06395238710462356
Step 175, mean loss 0.11553917579798205
Step 200, mean loss 0.3206106793155144
Step 225, mean loss 0.22075650196215377
Unrolled forward losses 3.171992498797393
Unrolled forward base losses 2.565701273852575
Epoch 5
Starting epoch 5...
Training Loss (progress: 0.00), 0.12929227580190608, [0.3498260173125446, 0.24926186476383186, 0.002258553164160145, 0.258727710731128, 0.27074987060363676, 0.32700849859745257]
Training Loss (progress: 0.08), 0.1476627057880628, [0.3501928100072131, 0.24919799110403684, 0.0022166558657382668, 0.2586196337939168, 0.2706388174123338, 0.3277879745656954]
Training Loss (progress: 0.16), 0.13593171988081532, [0.35014191488202, 0.24977543305431957, 0.0022080458923804534, 0.25860881709663835, 0.2705254707235314, 0.327652987371668]
Training Loss (progress: 0.24), 0.1480067361260704, [0.35204409042399015, 0.2508262770894345, 0.0021410815394434517, 0.25918022729432916, 0.2707441855088997, 0.32937761812661465]
Training Loss (progress: 0.32), 0.1382830663804393, [0.35408042966259745, 0.2529985979956517, 0.0021643577744681363, 0.2598098788975154, 0.2712290667256047, 0.3308284588132557]
Training Loss (progress: 0.40), 0.12751978553599286, [0.35642449536228116, 0.2542587981802149, 0.002186281293701579, 0.260564030086531, 0.2715883873827977, 0.334592396037258]
Training Loss (progress: 0.48), 0.13515135236232334, [0.3570154886165366, 0.25620104237213376, 0.0021517949966438, 0.26154881752777337, 0.271483376652685, 0.33487500089507866]
Training Loss (progress: 0.56), 0.14693031375792842, [0.3592210479511304, 0.25664471761415414, 0.0021219829264058996, 0.2634024772136957, 0.27250710684405843, 0.3364832701542359]
Training Loss (progress: 0.64), 0.1304072317130938, [0.35907354126231383, 0.25808659106283716, 0.002142865938131634, 0.26474846225432397, 0.27249623163866965, 0.336573936583121]
Training Loss (progress: 0.72), 0.12612270461663355, [0.3603885508705057, 0.2592128489535883, 0.002145066122916632, 0.2663305442549217, 0.2729485990763711, 0.33882796977841945]
Training Loss (progress: 0.80), 0.14484219228291823, [0.361741480649052, 0.25991870170820286, 0.0021379949682354352, 0.2669933728349527, 0.27441319802591846, 0.34061360530429624]
Training Loss (progress: 0.88), 0.13585973282083647, [0.36367295365385083, 0.26080402119290585, 0.002191444571298403, 0.2682583070509284, 0.2749733696140893, 0.3411501299754942]
Training Loss (progress: 0.96), 0.13483603396331964, [0.36479374375851076, 0.26115588668645134, 0.002121282852800683, 0.2688879734446091, 0.27614649649985806, 0.3413320795062099]
Evaluation on validation dataset:
Step 25, mean loss 0.04102953474024709
Step 50, mean loss 0.02261266983688615
Step 75, mean loss 0.0384389911845802
Step 100, mean loss 0.04534362188467106
Step 125, mean loss 0.05706915303203729
Step 150, mean loss 0.053647358758918004
Step 175, mean loss 0.0881540652471541
Step 200, mean loss 0.24727830678051788
Step 225, mean loss 0.1914048191157865
Unrolled forward losses 2.2959019439368697
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): -4.13995e-04, 1.42010e-05, -8.42285e-02, -1.46259e-05, -1.86802e-06, -1.91116e-03
Node: 01 (pos: 0.010): -4.24784e-04, 7.61448e-06, -7.17779e-02, -1.01889e-05, 3.16471e-07, -1.89870e-03
Node: 02 (pos: 0.020): -4.24750e-04, -3.24431e-06, -5.88678e-02, -5.44174e-06, 1.92884e-06, -1.88807e-03
Node: 03 (pos: 0.030): -4.13882e-04, -1.83697e-05, -4.54947e-02, -3.73210e-07, 2.93513e-06, -1.87926e-03
Node: 04 (pos: 0.040): -3.92168e-04, -3.77554e-05, -3.16557e-02, 5.02767e-06, 3.30141e-06, -1.87226e-03
Node: 05 (pos: 0.051): -3.59596e-04, -6.13950e-05, -1.73481e-02, 1.07717e-05, 2.99385e-06, -1.86707e-03
-
Node: 07 (pos: 0.071): -3.59596e-04, -6.13950e-05, -1.73481e-02, 1.07717e-05, 2.99385e-06, -1.86707e-03
Node: 08 (pos: 0.081): -3.92168e-04, -3.77554e-05, -3.16557e-02, 5.02767e-06, 3.30141e-06, -1.87226e-03
Node: 09 (pos: 0.091): -4.13882e-04, -1.83697e-05, -4.54947e-02, -3.73210e-07, 2.93513e-06, -1.87926e-03
Node: 10 (pos: 0.101): -4.24750e-04, -3.24431e-06, -5.88678e-02, -5.44174e-06, 1.92884e-06, -1.88807e-03
Node: 11 (pos: 0.111): -4.24784e-04, 7.61448e-06, -7.17779e-02, -1.01889e-05, 3.16471e-07, -1.89870e-03
Node: 12 (pos: 0.121): -4.13995e-04, 1.42010e-05, -8.42285e-02, -1.46259e-05, -1.86802e-06, -1.91116e-03

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.00000e+00, 1.00000e+00, 3.51750e-02, 1.00000e+00, 1.00000e+00, 9.99989e-01
Node: 01 (pos: 0.010): 1.00000e+00, 1.00000e+00, 8.79543e-02, 1.00000e+00, 1.00000e+00, 9.99989e-01
Node: 02 (pos: 0.020): 1.00000e+00, 1.00000e+00, 1.94931e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 03 (pos: 0.030): 1.00000e+00, 1.00000e+00, 3.76592e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 04 (pos: 0.040): 1.00000e+00, 1.00000e+00, 6.23242e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 05 (pos: 0.051): 1.00000e+00, 1.00000e+00, 8.67618e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
-
Node: 07 (pos: 0.071): 1.00000e+00, 1.00000e+00, 8.67618e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 08 (pos: 0.081): 1.00000e+00, 1.00000e+00, 6.23242e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 09 (pos: 0.091): 1.00000e+00, 1.00000e+00, 3.76592e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 10 (pos: 0.101): 1.00000e+00, 1.00000e+00, 1.94931e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 11 (pos: 0.111): 1.00000e+00, 1.00000e+00, 8.79543e-02, 1.00000e+00, 1.00000e+00, 9.99989e-01
Node: 12 (pos: 0.121): 1.00000e+00, 1.00000e+00, 3.51750e-02, 1.00000e+00, 1.00000e+00, 9.99989e-01
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): -3.59596e-04, -6.13950e-05, -1.73481e-02, 1.07717e-05, 2.99385e-06, -1.86707e-03
Node: 01 (pos: 0.010): -3.92168e-04, -3.77554e-05, -3.16557e-02, 5.02767e-06, 3.30141e-06, -1.87226e-03
Node: 02 (pos: 0.020): -4.13882e-04, -1.83697e-05, -4.54947e-02, -3.73210e-07, 2.93513e-06, -1.87926e-03
Node: 03 (pos: 0.030): -4.24750e-04, -3.24431e-06, -5.88678e-02, -5.44174e-06, 1.92884e-06, -1.88807e-03
Node: 04 (pos: 0.040): -4.24784e-04, 7.61448e-06, -7.17779e-02, -1.01889e-05, 3.16471e-07, -1.89870e-03
Node: 05 (pos: 0.051): -4.13995e-04, 1.42010e-05, -8.42285e-02, -1.46259e-05, -1.86802e-06, -1.91116e-03
-
Node: 07 (pos: 0.071): -4.24784e-04, 7.61448e-06, -7.17779e-02, -1.01889e-05, 3.16471e-07, -1.89870e-03
Node: 08 (pos: 0.081): -4.24750e-04, -3.24431e-06, -5.88678e-02, -5.44174e-06, 1.92884e-06, -1.88807e-03
Node: 09 (pos: 0.091): -4.13882e-04, -1.83697e-05, -4.54947e-02, -3.73210e-07, 2.93513e-06, -1.87926e-03
Node: 10 (pos: 0.101): -3.92168e-04, -3.77554e-05, -3.16557e-02, 5.02767e-06, 3.30141e-06, -1.87226e-03
Node: 11 (pos: 0.111): -3.59596e-04, -6.13950e-05, -1.73481e-02, 1.07717e-05, 2.99385e-06, -1.86707e-03
Node: 12 (pos: 0.121): -4.13995e-04, 1.42010e-05, -8.42285e-02, -1.46259e-05, -1.86802e-06, -1.91116e-03

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.00000e+00, 1.00000e+00, 8.67618e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 58 (pos: 0.586): 1.00000e+00, 1.00000e+00, 6.23242e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 59 (pos: 0.596): 1.00000e+00, 1.00000e+00, 3.76592e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 60 (pos: 0.606): 1.00000e+00, 1.00000e+00, 1.94931e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 61 (pos: 0.616): 1.00000e+00, 1.00000e+00, 8.79543e-02, 1.00000e+00, 1.00000e+00, 9.99989e-01
Node: 50 (pos: 0.505): 1.00000e+00, 1.00000e+00, 3.51750e-02, 1.00000e+00, 1.00000e+00, 9.99989e-01
-
Node: 51 (pos: 0.515): 1.00000e+00, 1.00000e+00, 8.79543e-02, 1.00000e+00, 1.00000e+00, 9.99989e-01
Node: 52 (pos: 0.525): 1.00000e+00, 1.00000e+00, 1.94931e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 53 (pos: 0.535): 1.00000e+00, 1.00000e+00, 3.76592e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 54 (pos: 0.545): 1.00000e+00, 1.00000e+00, 6.23242e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 55 (pos: 0.556): 1.00000e+00, 1.00000e+00, 8.67618e-01, 1.00000e+00, 1.00000e+00, 9.99990e-01
Node: 62 (pos: 0.626): 1.00000e+00, 1.00000e+00, 3.51750e-02, 1.00000e+00, 1.00000e+00, 9.99989e-01
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 3.3981299427648145e-06), ('0.bias', 0.00013913224435579892), ('2.weight', 0.0015254338559210071), ('2.bias', 0.0004775103235960585)] 

GNN_Layer 1 gradients:
[('0.weight', 1.1257393880248419e-08), ('0.bias', 3.1421022026203492e-06), ('2.weight', 3.9660215319523045e-05), ('2.bias', 1.1789237385197992e-05)] 

GNN_Layer 2 gradients:
[('0.weight', 0.03906668177743819), ('0.bias', 0.27335026574191246), ('2.weight', 1.6879674803986318), ('2.bias', 0.5010210638038535)] 

GNN_Layer 3 gradients:
[('0.weight', 2.2025275056502564e-07), ('0.bias', 5.838256260336495e-06), ('2.weight', 7.431621459201672e-05), ('2.bias', 2.118775828553258e-05)] 

GNN_Layer 4 gradients:
[('0.weight', 3.814357559546562e-08), ('0.bias', 7.290527892473359e-07), ('2.weight', 9.67241626936042e-06), ('2.bias', 2.844374315733849e-06)] 

GNN_Layer 5 gradients:
[('0.weight', 1.826195616425202e-05), ('0.bias', 0.00043627289441183553), ('2.weight', 0.005609883961729376), ('2.bias', 0.001529796545453056)] 

Evaluation on test dataset:
Step 25, mean loss 0.03233217951474156
Step 50, mean loss 0.017803080345404322
Step 75, mean loss 0.0284744161805096
Step 100, mean loss 0.035837265603511304
Step 125, mean loss 0.045200674308282715
Step 150, mean loss 0.0548708004066011
Step 175, mean loss 0.07916952817423965
Step 200, mean loss 0.09026634053339483
Step 225, mean loss 0.09716078666472247
Unrolled forward losses 1.8176801106653317
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 6
Starting epoch 6...
Training Loss (progress: 0.00), 0.15293848549307087, [0.3654615128977809, 0.2614659816626345, 0.00213773126261622, 0.26883222401063855, 0.2766256532423006, 0.34207865671220794]
Training Loss (progress: 0.08), 0.13007531234464842, [0.36620782008793945, 0.26269550689125304, 0.0021293282611764414, 0.2696627941934517, 0.2797816172565497, 0.34285777776668375]
Training Loss (progress: 0.16), 0.13068608176326132, [0.36719250996383174, 0.2632281305224666, 0.0021159179046061926, 0.27004882356975246, 0.28058848676616355, 0.3440148671924743]
Training Loss (progress: 0.24), 0.13881089676243125, [0.3686332577884615, 0.26466879463787807, 0.002142156256226094, 0.2718133891009354, 0.28147562134936516, 0.3450952580741006]
Training Loss (progress: 0.32), 0.1281507825649756, [0.3717416144449204, 0.2650683323633524, 0.0021126439412535516, 0.2725377900422727, 0.2829460949243518, 0.3459015832185894]
Training Loss (progress: 0.40), 0.13034695150751566, [0.3717729184712518, 0.2653524678071518, 0.002112362955145305, 0.2730287854929232, 0.284155673362021, 0.34722570572025624]
Training Loss (progress: 0.48), 0.14601607791660656, [0.3742637634005925, 0.2658910307533049, 0.0021486248350042815, 0.2749699016992604, 0.28541518074016947, 0.34708358499739145]
Training Loss (progress: 0.56), 0.12697008453865016, [0.3758099845710897, 0.2657801194695742, 0.002149674317083335, 0.2762726597184759, 0.28654389781554884, 0.34927361075331903]
Training Loss (progress: 0.64), 0.14052201624404947, [0.3768967586713812, 0.2660278638591888, 0.0020725756597548186, 0.27616163445027797, 0.28738789533564707, 0.3491286087919679]
Training Loss (progress: 0.72), 0.1273532403167393, [0.3771561311561263, 0.2667062115225991, 0.002092032516385194, 0.27663432740154437, 0.2882671523559761, 0.35099559948635917]
Training Loss (progress: 0.80), 0.1261088923220899, [0.37859390623014094, 0.26810678610967487, 0.002093779495880884, 0.27808941385077485, 0.29078196762961434, 0.3533747713504542]
Training Loss (progress: 0.88), 0.12347785222032287, [0.3793206288003402, 0.26857776410503104, 0.0021171877194411984, 0.28018028945708295, 0.2917904534056817, 0.35407732363189887]
Training Loss (progress: 0.96), 0.1346649964956256, [0.3800451190752954, 0.2691900898893187, 0.0021144872494583, 0.2811084623612932, 0.29286746614163217, 0.3565825035583847]
Evaluation on validation dataset:
Step 25, mean loss 0.0388728410598983
Step 50, mean loss 0.018984981434948537
Step 75, mean loss 0.035363669020258254
Step 100, mean loss 0.03804870915146054
Step 125, mean loss 0.05066648526198505
Step 150, mean loss 0.04604769032212544
Step 175, mean loss 0.08292300095341018
Step 200, mean loss 0.2271499286370151
Step 225, mean loss 0.18675949722379293
Unrolled forward losses 2.088935512391176
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.44929e-05, -3.26947e-06, -8.25265e-02, 2.17674e-05, -7.62077e-06, -2.92545e-07
Node: 01 (pos: 0.010): -6.09143e-06, -5.48309e-07, -7.00234e-02, 2.13240e-05, -8.90458e-06, 1.66702e-05
Node: 02 (pos: 0.020): -1.60238e-05, -2.05331e-06, -5.70610e-02, 2.11939e-05, -1.07417e-05, 3.18219e-05
Node: 03 (pos: 0.030): -1.52933e-05, -7.77909e-06, -4.36362e-02, 2.13882e-05, -1.31654e-05, 4.51705e-05
Node: 04 (pos: 0.040): -3.88924e-06, -1.77199e-05, -2.97459e-02, 2.19174e-05, -1.62087e-05, 5.67234e-05
Node: 05 (pos: 0.051): 1.81994e-05, -3.18695e-05, -1.53877e-02, 2.27922e-05, -1.99046e-05, 6.64883e-05
-
Node: 07 (pos: 0.071): 1.81994e-05, -3.18695e-05, -1.53877e-02, 2.27922e-05, -1.99046e-05, 6.64883e-05
Node: 08 (pos: 0.081): -3.88924e-06, -1.77199e-05, -2.97459e-02, 2.19174e-05, -1.62087e-05, 5.67234e-05
Node: 09 (pos: 0.091): -1.52933e-05, -7.77909e-06, -4.36362e-02, 2.13882e-05, -1.31654e-05, 4.51705e-05
Node: 10 (pos: 0.101): -1.60238e-05, -2.05331e-06, -5.70610e-02, 2.11939e-05, -1.07417e-05, 3.18219e-05
Node: 11 (pos: 0.111): -6.09143e-06, -5.48309e-07, -7.00234e-02, 2.13240e-05, -8.90458e-06, 1.66702e-05
Node: 12 (pos: 0.121): 1.44929e-05, -3.26947e-06, -8.25265e-02, 2.17674e-05, -7.62077e-06, -2.92545e-07

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.00000e+00, 1.00000e+00, 3.76413e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 01 (pos: 0.010): 1.00000e+00, 1.00000e+00, 9.43101e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 02 (pos: 0.020): 1.00000e+00, 1.00000e+00, 2.08481e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 03 (pos: 0.030): 1.00000e+00, 1.00000e+00, 3.99746e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 04 (pos: 0.040): 1.00000e+00, 1.00000e+00, 6.53062e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 05 (pos: 0.051): 1.00000e+00, 1.00000e+00, 8.92239e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 07 (pos: 0.071): 1.00000e+00, 1.00000e+00, 8.92239e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 08 (pos: 0.081): 1.00000e+00, 1.00000e+00, 6.53062e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 09 (pos: 0.091): 1.00000e+00, 1.00000e+00, 3.99746e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 10 (pos: 0.101): 1.00000e+00, 1.00000e+00, 2.08481e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 11 (pos: 0.111): 1.00000e+00, 1.00000e+00, 9.43101e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 12 (pos: 0.121): 1.00000e+00, 1.00000e+00, 3.76413e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 1.81994e-05, -3.18695e-05, -1.53877e-02, 2.27922e-05, -1.99046e-05, 6.64883e-05
Node: 01 (pos: 0.010): -3.88924e-06, -1.77199e-05, -2.97459e-02, 2.19174e-05, -1.62087e-05, 5.67234e-05
Node: 02 (pos: 0.020): -1.52933e-05, -7.77909e-06, -4.36362e-02, 2.13882e-05, -1.31654e-05, 4.51705e-05
Node: 03 (pos: 0.030): -1.60238e-05, -2.05331e-06, -5.70610e-02, 2.11939e-05, -1.07417e-05, 3.18219e-05
Node: 04 (pos: 0.040): -6.09143e-06, -5.48309e-07, -7.00234e-02, 2.13240e-05, -8.90458e-06, 1.66702e-05
Node: 05 (pos: 0.051): 1.44929e-05, -3.26947e-06, -8.25265e-02, 2.17674e-05, -7.62077e-06, -2.92545e-07
-
Node: 07 (pos: 0.071): -6.09143e-06, -5.48309e-07, -7.00234e-02, 2.13240e-05, -8.90458e-06, 1.66702e-05
Node: 08 (pos: 0.081): -1.60238e-05, -2.05331e-06, -5.70610e-02, 2.11939e-05, -1.07417e-05, 3.18219e-05
Node: 09 (pos: 0.091): -1.52933e-05, -7.77909e-06, -4.36362e-02, 2.13882e-05, -1.31654e-05, 4.51705e-05
Node: 10 (pos: 0.101): -3.88924e-06, -1.77199e-05, -2.97459e-02, 2.19174e-05, -1.62087e-05, 5.67234e-05
Node: 11 (pos: 0.111): 1.81994e-05, -3.18695e-05, -1.53877e-02, 2.27922e-05, -1.99046e-05, 6.64883e-05
Node: 12 (pos: 0.121): 1.44929e-05, -3.26947e-06, -8.25265e-02, 2.17674e-05, -7.62077e-06, -2.92545e-07

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.00000e+00, 1.00000e+00, 8.92239e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 58 (pos: 0.586): 1.00000e+00, 1.00000e+00, 6.53062e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 59 (pos: 0.596): 1.00000e+00, 1.00000e+00, 3.99746e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 60 (pos: 0.606): 1.00000e+00, 1.00000e+00, 2.08481e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 61 (pos: 0.616): 1.00000e+00, 1.00000e+00, 9.43101e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 50 (pos: 0.505): 1.00000e+00, 1.00000e+00, 3.76413e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 51 (pos: 0.515): 1.00000e+00, 1.00000e+00, 9.43101e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 52 (pos: 0.525): 1.00000e+00, 1.00000e+00, 2.08481e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 53 (pos: 0.535): 1.00000e+00, 1.00000e+00, 3.99746e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 54 (pos: 0.545): 1.00000e+00, 1.00000e+00, 6.53062e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 55 (pos: 0.556): 1.00000e+00, 1.00000e+00, 8.92239e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 62 (pos: 0.626): 1.00000e+00, 1.00000e+00, 3.76413e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 5.0397825287267835e-08), ('0.bias', 6.639040461167928e-07), ('2.weight', 7.2331668831803535e-06), ('2.bias', 2.2914867771838568e-06)] 

GNN_Layer 1 gradients:
[('0.weight', 1.7256811628544755e-08), ('0.bias', 7.721350731900322e-07), ('2.weight', 9.759418812036855e-06), ('2.bias', 2.914969124142756e-06)] 

GNN_Layer 2 gradients:
[('0.weight', 0.07409121161847904), ('0.bias', 0.295771155069051), ('2.weight', 1.7940601108467593), ('2.bias', 0.4932852715007767)] 

GNN_Layer 3 gradients:
[('0.weight', 2.38901965749989e-07), ('0.bias', 2.756975164937527e-06), ('2.weight', 3.507068108303785e-05), ('2.bias', 1.0068535031048112e-05)] 

GNN_Layer 4 gradients:
[('0.weight', 2.1399095163737782e-07), ('0.bias', 1.0982401532887347e-06), ('2.weight', 1.4422225263986055e-05), ('2.bias', 4.285527867380602e-06)] 

GNN_Layer 5 gradients:
[('0.weight', 4.892522024995981e-07), ('0.bias', 1.3760111323172342e-05), ('2.weight', 0.00017704435938751444), ('2.bias', 4.858944432130489e-05)] 

Evaluation on test dataset:
Step 25, mean loss 0.03012661770891524
Step 50, mean loss 0.01456227819941829
Step 75, mean loss 0.02521139489474926
Step 100, mean loss 0.031055860653170154
Step 125, mean loss 0.03985003833660273
Step 150, mean loss 0.04962853531392364
Step 175, mean loss 0.07154520627317323
Step 200, mean loss 0.09168995573089081
Step 225, mean loss 0.08555980191944909
Unrolled forward losses 1.585394088398179
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 7
Starting epoch 7...
Training Loss (progress: 0.00), 0.12194908681622027, [0.37996551350218855, 0.26928616085792745, 0.0020759224789407096, 0.28128662044525055, 0.2933154435334874, 0.3565081787756034]
Training Loss (progress: 0.08), 0.1251928897695404, [0.3806532166682827, 0.2702382190845496, 0.0020834132201451357, 0.28237579193257767, 0.29437457947399953, 0.3569650714031184]
Training Loss (progress: 0.16), 0.1289734144321964, [0.38243641204991874, 0.2713262657627183, 0.002048978821957098, 0.2824629624236195, 0.2954799452179546, 0.35927287961045795]
Training Loss (progress: 0.24), 0.11983608161920246, [0.3829888360500648, 0.27202432122466563, 0.002060207784669339, 0.2840534408513092, 0.2975859041945402, 0.3606373073751064]
Training Loss (progress: 0.32), 0.13783387450553744, [0.38368033130800033, 0.2726678532619773, 0.002068495528622148, 0.28532194395087995, 0.29843956492969553, 0.3607447714354037]
Training Loss (progress: 0.40), 0.12606278971753745, [0.3842377920541426, 0.27257161620573234, 0.0020509718450665527, 0.28705254439647354, 0.2990176001494873, 0.3622422641200145]
Training Loss (progress: 0.48), 0.11994317052638448, [0.3857773171667478, 0.2733978418670128, 0.002079581599297296, 0.2894304591482184, 0.2993789749316548, 0.3637635130055566]
Training Loss (progress: 0.56), 0.13398303835657685, [0.38640173556780627, 0.2745415243453021, 0.0020829687729774326, 0.28931218757308147, 0.2996378828011362, 0.36582015024582965]
Training Loss (progress: 0.64), 0.12584832876230975, [0.38668928221823134, 0.27519394155919513, 0.0020760815687619495, 0.28977802862937957, 0.2995124513575153, 0.36833510821415183]
Training Loss (progress: 0.72), 0.11839234142281535, [0.38711356210347597, 0.27691500942712216, 0.002066718433252097, 0.2901370453250044, 0.299855169521122, 0.3700692325870899]
Training Loss (progress: 0.80), 0.11830810170679641, [0.3883568172931171, 0.27812194921061856, 0.002066261325296285, 0.2901249699752965, 0.3023136596197168, 0.3704667971792385]
Training Loss (progress: 0.88), 0.1266772551183093, [0.38995322415675365, 0.2788059774649717, 0.002023720549512129, 0.2911163209961552, 0.30239636736660197, 0.37153670985969134]
Training Loss (progress: 0.96), 0.11909889951559914, [0.3904142281358107, 0.2795545314021031, 0.0020752294769200144, 0.2917433020933847, 0.3033126890625655, 0.3735269357947083]
Evaluation on validation dataset:
Step 25, mean loss 0.035897067115313944
Step 50, mean loss 0.01995494323943316
Step 75, mean loss 0.03231676915655668
Step 100, mean loss 0.03450921790366164
Step 125, mean loss 0.044079068130353775
Step 150, mean loss 0.04188375926655465
Step 175, mean loss 0.07396542911356738
Step 200, mean loss 0.20749832484790987
Step 225, mean loss 0.15598959914428726
Unrolled forward losses 1.962159259298858
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.22963e-05, 8.84382e-04, -8.24815e-02, 1.16878e-05, -2.44052e-04, -6.58157e-05
Node: 01 (pos: 0.010): -1.36166e-05, 8.56788e-04, -6.99930e-02, 1.52819e-05, -2.49719e-04, -3.98479e-05
Node: 02 (pos: 0.020): -2.90519e-05, 8.25096e-04, -5.70466e-02, 1.91783e-05, -2.55925e-04, -1.56511e-05
Node: 03 (pos: 0.030): -3.39995e-05, 7.89311e-04, -4.36390e-02, 2.33878e-05, -2.62705e-04, 6.78218e-06
Node: 04 (pos: 0.040): -2.84491e-05, 7.49441e-04, -2.97672e-02, 2.79207e-05, -2.70089e-04, 2.74592e-05
Node: 05 (pos: 0.051): -1.23904e-05, 7.05492e-04, -1.54288e-02, 3.27876e-05, -2.78110e-04, 4.63872e-05
-
Node: 07 (pos: 0.071): -1.23904e-05, 7.05492e-04, -1.54288e-02, 3.27876e-05, -2.78110e-04, 4.63872e-05
Node: 08 (pos: 0.081): -2.84491e-05, 7.49441e-04, -2.97672e-02, 2.79207e-05, -2.70089e-04, 2.74592e-05
Node: 09 (pos: 0.091): -3.39995e-05, 7.89311e-04, -4.36390e-02, 2.33878e-05, -2.62705e-04, 6.78218e-06
Node: 10 (pos: 0.101): -2.90519e-05, 8.25096e-04, -5.70466e-02, 1.91783e-05, -2.55925e-04, -1.56511e-05
Node: 11 (pos: 0.111): -1.36166e-05, 8.56788e-04, -6.99930e-02, 1.52819e-05, -2.49719e-04, -3.98479e-05
Node: 12 (pos: 0.121): 1.22963e-05, 8.84382e-04, -8.24815e-02, 1.16878e-05, -2.44052e-04, -6.58157e-05

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.00000e+00, 9.99997e-01, 3.71002e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 01 (pos: 0.010): 1.00000e+00, 9.99997e-01, 9.32822e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 02 (pos: 0.020): 1.00000e+00, 9.99998e-01, 2.06852e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 03 (pos: 0.030): 1.00000e+00, 9.99998e-01, 3.97683e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 04 (pos: 0.040): 1.00000e+00, 9.99998e-01, 6.51129e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 05 (pos: 0.051): 1.00000e+00, 9.99998e-01, 8.91132e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 07 (pos: 0.071): 1.00000e+00, 9.99998e-01, 8.91132e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 08 (pos: 0.081): 1.00000e+00, 9.99998e-01, 6.51129e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 09 (pos: 0.091): 1.00000e+00, 9.99998e-01, 3.97683e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 10 (pos: 0.101): 1.00000e+00, 9.99998e-01, 2.06852e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 11 (pos: 0.111): 1.00000e+00, 9.99997e-01, 9.32822e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 12 (pos: 0.121): 1.00000e+00, 9.99997e-01, 3.71002e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): -1.23904e-05, 7.05492e-04, -1.54288e-02, 3.27876e-05, -2.78110e-04, 4.63872e-05
Node: 01 (pos: 0.010): -2.84491e-05, 7.49441e-04, -2.97672e-02, 2.79207e-05, -2.70089e-04, 2.74592e-05
Node: 02 (pos: 0.020): -3.39995e-05, 7.89311e-04, -4.36390e-02, 2.33878e-05, -2.62705e-04, 6.78218e-06
Node: 03 (pos: 0.030): -2.90519e-05, 8.25096e-04, -5.70466e-02, 1.91783e-05, -2.55925e-04, -1.56511e-05
Node: 04 (pos: 0.040): -1.36166e-05, 8.56788e-04, -6.99930e-02, 1.52819e-05, -2.49719e-04, -3.98479e-05
Node: 05 (pos: 0.051): 1.22963e-05, 8.84382e-04, -8.24815e-02, 1.16878e-05, -2.44052e-04, -6.58157e-05
-
Node: 07 (pos: 0.071): -1.36166e-05, 8.56788e-04, -6.99930e-02, 1.52819e-05, -2.49719e-04, -3.98479e-05
Node: 08 (pos: 0.081): -2.90519e-05, 8.25096e-04, -5.70466e-02, 1.91783e-05, -2.55925e-04, -1.56511e-05
Node: 09 (pos: 0.091): -3.39995e-05, 7.89311e-04, -4.36390e-02, 2.33878e-05, -2.62705e-04, 6.78218e-06
Node: 10 (pos: 0.101): -2.84491e-05, 7.49441e-04, -2.97672e-02, 2.79207e-05, -2.70089e-04, 2.74592e-05
Node: 11 (pos: 0.111): -1.23904e-05, 7.05492e-04, -1.54288e-02, 3.27876e-05, -2.78110e-04, 4.63872e-05
Node: 12 (pos: 0.121): 1.22963e-05, 8.84382e-04, -8.24815e-02, 1.16878e-05, -2.44052e-04, -6.58157e-05

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.00000e+00, 9.99998e-01, 8.91132e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 58 (pos: 0.586): 1.00000e+00, 9.99998e-01, 6.51129e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 59 (pos: 0.596): 1.00000e+00, 9.99998e-01, 3.97683e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 60 (pos: 0.606): 1.00000e+00, 9.99998e-01, 2.06852e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 61 (pos: 0.616): 1.00000e+00, 9.99997e-01, 9.32822e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 50 (pos: 0.505): 1.00000e+00, 9.99997e-01, 3.71002e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 51 (pos: 0.515): 1.00000e+00, 9.99997e-01, 9.32822e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 52 (pos: 0.525): 1.00000e+00, 9.99998e-01, 2.06852e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 53 (pos: 0.535): 1.00000e+00, 9.99998e-01, 3.97683e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 54 (pos: 0.545): 1.00000e+00, 9.99998e-01, 6.51129e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 55 (pos: 0.556): 1.00000e+00, 9.99998e-01, 8.91132e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 62 (pos: 0.626): 1.00000e+00, 9.99997e-01, 3.71002e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 3.6769300634458944e-07), ('0.bias', 1.1751198439444838e-05), ('2.weight', 0.00012914096820758702), ('2.bias', 4.0851549557740656e-05)] 

GNN_Layer 1 gradients:
[('0.weight', 1.1413920582850961e-05), ('0.bias', 0.00025339075743785163), ('2.weight', 0.0032091386224442917), ('2.bias', 0.0009624496950770871)] 

GNN_Layer 2 gradients:
[('0.weight', 0.017212856855594764), ('0.bias', 0.15869057092630612), ('2.weight', 0.9584674716990883), ('2.bias', 0.2891783224932354)] 

GNN_Layer 3 gradients:
[('0.weight', 3.0293139041382444e-07), ('0.bias', 6.391446460050229e-06), ('2.weight', 8.138069370467824e-05), ('2.bias', 2.349149676845233e-05)] 

GNN_Layer 4 gradients:
[('0.weight', 2.3804585451312297e-06), ('0.bias', 3.828356194116372e-05), ('2.weight', 0.0005070078136714163), ('2.bias', 0.00015115209415274264)] 

GNN_Layer 5 gradients:
[('0.weight', 3.4222198334089354e-07), ('0.bias', 1.8204512610137406e-07), ('2.weight', 4.824565890338195e-06), ('2.bias', 3.5201906915814085e-07)] 

Evaluation on test dataset:
Step 25, mean loss 0.027540156278409396
Step 50, mean loss 0.013251488914715632
Step 75, mean loss 0.022225036696848145
Step 100, mean loss 0.027398729702609356
Step 125, mean loss 0.03625281619143663
Step 150, mean loss 0.045288887028454766
Step 175, mean loss 0.0577894667602732
Step 200, mean loss 0.0753449093930586
Step 225, mean loss 0.07343045255357794
Unrolled forward losses 1.471032639948001
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 8
Starting epoch 8...
Training Loss (progress: 0.00), 0.14270942750472002, [0.39068283557495204, 0.2796887236174083, 0.0020607890704273787, 0.2916822257950338, 0.30325713326178066, 0.3734504629275659]
Training Loss (progress: 0.08), 0.12732565113323646, [0.3920018229652267, 0.2804835121539554, 0.0020992787794298267, 0.2920554693826856, 0.3046476070160618, 0.37411307393284027]
Training Loss (progress: 0.16), 0.12226265257269114, [0.3934841737528384, 0.281021622816277, 0.0020756818269769776, 0.2935823681367423, 0.3064603041104411, 0.3763531842820311]
Training Loss (progress: 0.24), 0.12191862929274985, [0.3945779371287403, 0.28110472358479804, 0.00205592059221098, 0.2940590895597761, 0.30699454840697604, 0.37760788176942073]
Training Loss (progress: 0.32), 0.12264252531443631, [0.3957970752928415, 0.28242015088006805, 0.0020402818468387104, 0.2949821725885911, 0.307496351224147, 0.3799914210043124]
Training Loss (progress: 0.40), 0.11504121731198574, [0.396429059207886, 0.2843255149485442, 0.0020915404743013484, 0.29525743124338377, 0.3080802483450312, 0.38037806807547964]
Training Loss (progress: 0.48), 0.12817685571623336, [0.39698725967960785, 0.2849805887678061, 0.002033496759747177, 0.29602077461110077, 0.3085779225913774, 0.38095005061352516]
Training Loss (progress: 0.56), 0.11035172165056818, [0.39761044950571794, 0.28659468049814624, 0.0020447581828410603, 0.29645649830381937, 0.3092856224735517, 0.38278972859330174]
Training Loss (progress: 0.64), 0.12419294466317163, [0.39989469760051227, 0.2869733722586079, 0.0020740483407306947, 0.29633496950966015, 0.30915612810243076, 0.38505706006091567]
Training Loss (progress: 0.72), 0.13160984750527024, [0.40098654767734665, 0.28685314842551546, 0.0020937962372328993, 0.2977791693452145, 0.31070212061079927, 0.3867048323473188]
Training Loss (progress: 0.80), 0.11682456844685908, [0.40285249568325066, 0.2872568895675326, 0.0020717600929652962, 0.2985851865779949, 0.3122560986588113, 0.3882608893719364]
Training Loss (progress: 0.88), 0.13047207921644244, [0.403396954149622, 0.28731704962004634, 0.0020099738767239946, 0.2994770411322201, 0.313825411547733, 0.38880594842109445]
Training Loss (progress: 0.96), 0.11007912966153503, [0.4058521065480132, 0.2877563896512898, 0.002042005794224553, 0.3004655643582106, 0.3145131259376697, 0.39030252173290025]
Evaluation on validation dataset:
Step 25, mean loss 0.03297976695037223
Step 50, mean loss 0.018608759142542144
Step 75, mean loss 0.030161340308134874
Step 100, mean loss 0.0328242651243648
Step 125, mean loss 0.03862956841719592
Step 150, mean loss 0.03843224578615716
Step 175, mean loss 0.06609457900814288
Step 200, mean loss 0.21813913269752175
Step 225, mean loss 0.17066603570130304
Unrolled forward losses 1.882471740796958
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 4.40288e-05, 2.50927e-05, -8.19258e-02, 8.26257e-04, 6.92506e-04, -2.83857e-05
Node: 01 (pos: 0.010): 2.70919e-05, 2.84621e-05, -6.94261e-02, 8.51171e-04, 6.92115e-04, -1.24258e-05
Node: 02 (pos: 0.020): 2.04747e-05, 2.77433e-05, -5.64690e-02, 8.76369e-04, 6.91197e-04, 1.77989e-06
Node: 03 (pos: 0.030): 2.41876e-05, 2.29414e-05, -4.30513e-02, 9.01864e-04, 6.89721e-04, 1.42386e-05
Node: 04 (pos: 0.040): 3.82413e-05, 1.40618e-05, -2.91702e-02, 9.27663e-04, 6.87655e-04, 2.49578e-05
Node: 05 (pos: 0.051): 6.26463e-05, 1.11040e-06, -1.48230e-02, 9.53779e-04, 6.84969e-04, 3.39446e-05
-
Node: 07 (pos: 0.071): 6.26463e-05, 1.11040e-06, -1.48230e-02, 9.53779e-04, 6.84969e-04, 3.39446e-05
Node: 08 (pos: 0.081): 3.82413e-05, 1.40618e-05, -2.91702e-02, 9.27663e-04, 6.87655e-04, 2.49578e-05
Node: 09 (pos: 0.091): 2.41876e-05, 2.29414e-05, -4.30513e-02, 9.01864e-04, 6.89721e-04, 1.42386e-05
Node: 10 (pos: 0.101): 2.04747e-05, 2.77433e-05, -5.64690e-02, 8.76369e-04, 6.91197e-04, 1.77989e-06
Node: 11 (pos: 0.111): 2.70919e-05, 2.84621e-05, -6.94261e-02, 8.51171e-04, 6.92115e-04, -1.24258e-05
Node: 12 (pos: 0.121): 4.40288e-05, 2.50927e-05, -8.19258e-02, 8.26257e-04, 6.92506e-04, -2.83857e-05

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.00000e+00, 1.00000e+00, 3.51228e-02, 9.99998e-01, 9.99998e-01, 1.00000e+00
Node: 01 (pos: 0.010): 1.00000e+00, 1.00000e+00, 9.02697e-02, 9.99998e-01, 9.99998e-01, 1.00000e+00
Node: 02 (pos: 0.020): 1.00000e+00, 1.00000e+00, 2.03713e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 03 (pos: 0.030): 1.00000e+00, 1.00000e+00, 3.96621e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 04 (pos: 0.040): 1.00000e+00, 1.00000e+00, 6.54057e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 05 (pos: 0.051): 1.00000e+00, 1.00000e+00, 8.96164e-01, 9.99997e-01, 9.99999e-01, 1.00000e+00
-
Node: 07 (pos: 0.071): 1.00000e+00, 1.00000e+00, 8.96164e-01, 9.99997e-01, 9.99999e-01, 1.00000e+00
Node: 08 (pos: 0.081): 1.00000e+00, 1.00000e+00, 6.54057e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 09 (pos: 0.091): 1.00000e+00, 1.00000e+00, 3.96621e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 10 (pos: 0.101): 1.00000e+00, 1.00000e+00, 2.03713e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 11 (pos: 0.111): 1.00000e+00, 1.00000e+00, 9.02697e-02, 9.99998e-01, 9.99998e-01, 1.00000e+00
Node: 12 (pos: 0.121): 1.00000e+00, 1.00000e+00, 3.51228e-02, 9.99998e-01, 9.99998e-01, 1.00000e+00
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 6.26463e-05, 1.11040e-06, -1.48230e-02, 9.53779e-04, 6.84969e-04, 3.39446e-05
Node: 01 (pos: 0.010): 3.82413e-05, 1.40618e-05, -2.91702e-02, 9.27663e-04, 6.87655e-04, 2.49578e-05
Node: 02 (pos: 0.020): 2.41876e-05, 2.29414e-05, -4.30513e-02, 9.01864e-04, 6.89721e-04, 1.42386e-05
Node: 03 (pos: 0.030): 2.04747e-05, 2.77433e-05, -5.64690e-02, 8.76369e-04, 6.91197e-04, 1.77989e-06
Node: 04 (pos: 0.040): 2.70919e-05, 2.84621e-05, -6.94261e-02, 8.51171e-04, 6.92115e-04, -1.24258e-05
Node: 05 (pos: 0.051): 4.40288e-05, 2.50927e-05, -8.19258e-02, 8.26257e-04, 6.92506e-04, -2.83857e-05
-
Node: 07 (pos: 0.071): 2.70919e-05, 2.84621e-05, -6.94261e-02, 8.51171e-04, 6.92115e-04, -1.24258e-05
Node: 08 (pos: 0.081): 2.04747e-05, 2.77433e-05, -5.64690e-02, 8.76369e-04, 6.91197e-04, 1.77989e-06
Node: 09 (pos: 0.091): 2.41876e-05, 2.29414e-05, -4.30513e-02, 9.01864e-04, 6.89721e-04, 1.42386e-05
Node: 10 (pos: 0.101): 3.82413e-05, 1.40618e-05, -2.91702e-02, 9.27663e-04, 6.87655e-04, 2.49578e-05
Node: 11 (pos: 0.111): 6.26463e-05, 1.11040e-06, -1.48230e-02, 9.53779e-04, 6.84969e-04, 3.39446e-05
Node: 12 (pos: 0.121): 4.40288e-05, 2.50927e-05, -8.19258e-02, 8.26257e-04, 6.92506e-04, -2.83857e-05

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.00000e+00, 1.00000e+00, 8.96164e-01, 9.99997e-01, 9.99999e-01, 1.00000e+00
Node: 58 (pos: 0.586): 1.00000e+00, 1.00000e+00, 6.54057e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 59 (pos: 0.596): 1.00000e+00, 1.00000e+00, 3.96621e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 60 (pos: 0.606): 1.00000e+00, 1.00000e+00, 2.03713e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 61 (pos: 0.616): 1.00000e+00, 1.00000e+00, 9.02697e-02, 9.99998e-01, 9.99998e-01, 1.00000e+00
Node: 50 (pos: 0.505): 1.00000e+00, 1.00000e+00, 3.51228e-02, 9.99998e-01, 9.99998e-01, 1.00000e+00
-
Node: 51 (pos: 0.515): 1.00000e+00, 1.00000e+00, 9.02697e-02, 9.99998e-01, 9.99998e-01, 1.00000e+00
Node: 52 (pos: 0.525): 1.00000e+00, 1.00000e+00, 2.03713e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 53 (pos: 0.535): 1.00000e+00, 1.00000e+00, 3.96621e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 54 (pos: 0.545): 1.00000e+00, 1.00000e+00, 6.54057e-01, 9.99997e-01, 9.99998e-01, 1.00000e+00
Node: 55 (pos: 0.556): 1.00000e+00, 1.00000e+00, 8.96164e-01, 9.99997e-01, 9.99999e-01, 1.00000e+00
Node: 62 (pos: 0.626): 1.00000e+00, 1.00000e+00, 3.51228e-02, 9.99998e-01, 9.99998e-01, 1.00000e+00
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 4.4733841894254577e-07), ('0.bias', 4.955945039540954e-07), ('2.weight', 7.80846560496596e-06), ('2.bias', 1.5906220937545887e-06)] 

GNN_Layer 1 gradients:
[('0.weight', 3.3840076760915316e-07), ('0.bias', 5.14948083746253e-06), ('2.weight', 6.536915419757958e-05), ('2.bias', 1.9677278419998487e-05)] 

GNN_Layer 2 gradients:
[('0.weight', 0.10511479750832933), ('0.bias', 0.11903139427290307), ('2.weight', 0.9810635440834933), ('2.bias', 0.12927378651752264)] 

GNN_Layer 3 gradients:
[('0.weight', 1.4771657663638763e-05), ('0.bias', 0.00020682175599927508), ('2.weight', 0.002632866111196065), ('2.bias', 0.0007649809173907082)] 

GNN_Layer 4 gradients:
[('0.weight', 4.324125946753667e-06), ('0.bias', 2.9062667205325765e-05), ('2.weight', 0.00040537606842691625), ('2.bias', 0.0001155839353398346)] 

GNN_Layer 5 gradients:
[('0.weight', 5.100322220844461e-07), ('0.bias', 6.010839695161433e-06), ('2.weight', 7.727688192982578e-05), ('2.bias', 2.1414553711176094e-05)] 

Evaluation on test dataset:
Step 25, mean loss 0.026035648956990093
Step 50, mean loss 0.012891801380960672
Step 75, mean loss 0.021787547022256132
Step 100, mean loss 0.026033120705060194
Step 125, mean loss 0.033825881585150375
Step 150, mean loss 0.044024532572846706
Step 175, mean loss 0.05633881455257886
Step 200, mean loss 0.06748941083979272
Step 225, mean loss 0.07416233445023195
Unrolled forward losses 1.5642993912106413
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 9
Starting epoch 9...
Training Loss (progress: 0.00), 0.1267504150194955, [0.40580665181596665, 0.2876963099690018, 0.0020295377235544023, 0.30130433222720227, 0.31541611780963863, 0.39022100868705306]
Training Loss (progress: 0.08), 0.12373714580304344, [0.407120557388628, 0.28789745779387466, 0.002021943844059553, 0.3034989748268326, 0.31654193984622786, 0.3915419335256466]
Training Loss (progress: 0.16), 0.12637676623664934, [0.40870312738150205, 0.28906703668436595, 0.0020590705296020064, 0.3058979978138136, 0.3176963833025867, 0.39250222949317115]
Training Loss (progress: 0.24), 0.12694027806696273, [0.4100566104702562, 0.2900555139325909, 0.0020324572300933342, 0.3064381516335661, 0.31948625515329293, 0.39475784175161316]
Training Loss (progress: 0.32), 0.10706595843347026, [0.4124369189435514, 0.290618242779776, 0.0020369489382782565, 0.3073026691824453, 0.32085783600580403, 0.39702507217556066]
Training Loss (progress: 0.40), 0.1151427249539831, [0.413235148109699, 0.29154572885906416, 0.0020434617187892108, 0.30718476027325936, 0.32489226216096306, 0.39729711623175695]
Training Loss (progress: 0.48), 0.11997941443511743, [0.41429793587938807, 0.29144555383990495, 0.0020231492683134913, 0.30878912796850216, 0.32601505138252457, 0.3998529177344081]
Training Loss (progress: 0.56), 0.11911443391835573, [0.41453542069620164, 0.29197079594794656, 0.0020366063148593043, 0.3089020200750434, 0.3263790329636833, 0.40184684993044645]
Training Loss (progress: 0.64), 0.12374986698262948, [0.41582021140111736, 0.29260723903677865, 0.001983380010344902, 0.3091540715445229, 0.3277978070999766, 0.4030390036144565]
Training Loss (progress: 0.72), 0.1295433159165392, [0.4161901864911718, 0.2933512386109774, 0.0020447043470991524, 0.30902466540451, 0.32897748664914844, 0.4051511816303373]
Training Loss (progress: 0.80), 0.12334874211564957, [0.4179812266452632, 0.2944747482316962, 0.0020673612669026083, 0.3092243042029912, 0.33061884225883165, 0.4049886620864508]
Training Loss (progress: 0.88), 0.1143814774036959, [0.41919627853294944, 0.2956782834501965, 0.002032368980431269, 0.31018249464980313, 0.33255664491718934, 0.40656326879851146]
Training Loss (progress: 0.96), 0.11331357115932326, [0.42042851207470655, 0.29696332245880636, 0.00203913366067404, 0.3118397298428878, 0.3326031022433386, 0.4078398471587452]
Evaluation on validation dataset:
Step 25, mean loss 0.03331744760201319
Step 50, mean loss 0.01889907920699766
Step 75, mean loss 0.029464241616775067
Step 100, mean loss 0.032101412939160884
Step 125, mean loss 0.03977150281415856
Step 150, mean loss 0.035832249024495715
Step 175, mean loss 0.05905189192718889
Step 200, mean loss 0.20830103539187866
Step 225, mean loss 0.15209780096653497
Unrolled forward losses 2.119003724725718
Unrolled forward base losses 2.565701273852575
Epoch 10
Starting epoch 10...
Training Loss (progress: 0.00), 0.10315002570653097, [0.4206479422471199, 0.29770207205732035, 0.0020299401458069343, 0.3121342952676182, 0.333402212929473, 0.4091615471083807]
Training Loss (progress: 0.08), 0.10862476339155445, [0.4209711133579619, 0.29775191818496183, 0.00202795770015442, 0.312082274995, 0.3333491354786655, 0.4091118147233895]
Training Loss (progress: 0.16), 0.10225195278455687, [0.4216258604601864, 0.29816847243531197, 0.0020057134880192133, 0.3121671146928357, 0.3332932935602294, 0.4094213049484706]
Training Loss (progress: 0.24), 0.09913706816773266, [0.4220149395698626, 0.298776387929338, 0.002007409548712134, 0.3125950706011922, 0.33340628440976516, 0.4093661722509968]
Training Loss (progress: 0.32), 0.1084255738356074, [0.422823773845253, 0.299269207367279, 0.0020155304609538534, 0.31280954315434534, 0.3336291677630966, 0.41005654470871816]
Training Loss (progress: 0.40), 0.10295223121686095, [0.4229871498866907, 0.299420384979901, 0.0019902744148197864, 0.3134501672153734, 0.3336769347387981, 0.41051428953276026]
Training Loss (progress: 0.48), 0.10795554106620199, [0.4234634297764597, 0.29942490731955895, 0.0020009041828399155, 0.3135907989439718, 0.3339501231988456, 0.4112185956186923]
Training Loss (progress: 0.56), 0.10907549920416056, [0.42339405092656085, 0.2997011113857486, 0.0020110970223406626, 0.3135611882715307, 0.33465720439499197, 0.4119207395243306]
Training Loss (progress: 0.64), 0.11749337146585427, [0.4240636686447031, 0.3003023908299131, 0.001997769269640846, 0.31359337972486645, 0.33520349788018194, 0.41310131450660453]
Training Loss (progress: 0.72), 0.10332848511786998, [0.4242472889712585, 0.3005394178511418, 0.001991190891698394, 0.3137881680743141, 0.33533468336024846, 0.41334204813245595]
Training Loss (progress: 0.80), 0.10567987076631209, [0.4247965321191397, 0.3008656082221459, 0.0020053273340481337, 0.3142524693778239, 0.33567201310714645, 0.41368073078103185]
Training Loss (progress: 0.88), 0.11714315675540984, [0.42538371843838646, 0.30148769457771013, 0.0019950012007408885, 0.31474808732483545, 0.3356694216301997, 0.4141028845972639]
Training Loss (progress: 0.96), 0.11649361228508236, [0.4256362897590759, 0.30191315426602694, 0.001992645515836549, 0.31504005909358157, 0.3360452862146112, 0.4145520747283094]
Evaluation on validation dataset:
Step 25, mean loss 0.028524031294348468
Step 50, mean loss 0.01543108387391109
Step 75, mean loss 0.028599508534383054
Step 100, mean loss 0.0289506175526429
Step 125, mean loss 0.037172473733351814
Step 150, mean loss 0.035726398904124275
Step 175, mean loss 0.06307971632485534
Step 200, mean loss 0.192740163060679
Step 225, mean loss 0.16061174297622666
Unrolled forward losses 1.698361246589441
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 5.97452e-05, -4.04927e-05, -8.07998e-02, -2.38834e-07, -4.84311e-06, 6.25854e-06
Node: 01 (pos: 0.010): 3.31569e-05, -2.57522e-05, -6.83065e-02, -1.07399e-06, -4.24634e-06, 1.53357e-05
Node: 02 (pos: 0.020): 1.66530e-05, -1.50229e-05, -5.53591e-02, -1.62202e-06, -4.16538e-06, 2.26751e-05
Node: 03 (pos: 0.030): 1.02430e-05, -8.30008e-06, -4.19543e-02, -1.87287e-06, -4.63084e-06, 2.82840e-05
Node: 04 (pos: 0.040): 1.39366e-05, -5.57879e-06, -2.80894e-02, -1.81658e-06, -5.67328e-06, 3.21693e-05
Node: 05 (pos: 0.051): 2.77435e-05, -6.85359e-06, -1.37619e-02, -1.44335e-06, -7.32321e-06, 3.43384e-05
-
Node: 07 (pos: 0.071): 2.77435e-05, -6.85359e-06, -1.37619e-02, -1.44335e-06, -7.32321e-06, 3.43384e-05
Node: 08 (pos: 0.081): 1.39366e-05, -5.57879e-06, -2.80894e-02, -1.81658e-06, -5.67328e-06, 3.21693e-05
Node: 09 (pos: 0.091): 1.02430e-05, -8.30008e-06, -4.19543e-02, -1.87287e-06, -4.63084e-06, 2.82840e-05
Node: 10 (pos: 0.101): 1.66530e-05, -1.50229e-05, -5.53591e-02, -1.62202e-06, -4.16538e-06, 2.26751e-05
Node: 11 (pos: 0.111): 3.31569e-05, -2.57522e-05, -6.83065e-02, -1.07399e-06, -4.24634e-06, 1.53357e-05
Node: 12 (pos: 0.121): 5.97452e-05, -4.04927e-05, -8.07998e-02, -2.38834e-07, -4.84311e-06, 6.25854e-06

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.00000e+00, 1.00000e+00, 3.70157e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 01 (pos: 0.010): 1.00000e+00, 1.00000e+00, 9.48139e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 02 (pos: 0.020): 1.00000e+00, 1.00000e+00, 2.12803e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 03 (pos: 0.030): 1.00000e+00, 1.00000e+00, 4.11173e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 04 (pos: 0.040): 1.00000e+00, 1.00000e+00, 6.71401e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 05 (pos: 0.051): 1.00000e+00, 1.00000e+00, 9.08804e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 07 (pos: 0.071): 1.00000e+00, 1.00000e+00, 9.08804e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 08 (pos: 0.081): 1.00000e+00, 1.00000e+00, 6.71401e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 09 (pos: 0.091): 1.00000e+00, 1.00000e+00, 4.11173e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 10 (pos: 0.101): 1.00000e+00, 1.00000e+00, 2.12803e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 11 (pos: 0.111): 1.00000e+00, 1.00000e+00, 9.48139e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 12 (pos: 0.121): 1.00000e+00, 1.00000e+00, 3.70157e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 2.77435e-05, -6.85359e-06, -1.37619e-02, -1.44335e-06, -7.32321e-06, 3.43384e-05
Node: 01 (pos: 0.010): 1.39366e-05, -5.57879e-06, -2.80894e-02, -1.81658e-06, -5.67328e-06, 3.21693e-05
Node: 02 (pos: 0.020): 1.02430e-05, -8.30008e-06, -4.19543e-02, -1.87287e-06, -4.63084e-06, 2.82840e-05
Node: 03 (pos: 0.030): 1.66530e-05, -1.50229e-05, -5.53591e-02, -1.62202e-06, -4.16538e-06, 2.26751e-05
Node: 04 (pos: 0.040): 3.31569e-05, -2.57522e-05, -6.83065e-02, -1.07399e-06, -4.24634e-06, 1.53357e-05
Node: 05 (pos: 0.051): 5.97452e-05, -4.04927e-05, -8.07998e-02, -2.38834e-07, -4.84311e-06, 6.25854e-06
-
Node: 07 (pos: 0.071): 3.31569e-05, -2.57522e-05, -6.83065e-02, -1.07399e-06, -4.24634e-06, 1.53357e-05
Node: 08 (pos: 0.081): 1.66530e-05, -1.50229e-05, -5.53591e-02, -1.62202e-06, -4.16538e-06, 2.26751e-05
Node: 09 (pos: 0.091): 1.02430e-05, -8.30008e-06, -4.19543e-02, -1.87287e-06, -4.63084e-06, 2.82840e-05
Node: 10 (pos: 0.101): 1.39366e-05, -5.57879e-06, -2.80894e-02, -1.81658e-06, -5.67328e-06, 3.21693e-05
Node: 11 (pos: 0.111): 2.77435e-05, -6.85359e-06, -1.37619e-02, -1.44335e-06, -7.32321e-06, 3.43384e-05
Node: 12 (pos: 0.121): 5.97452e-05, -4.04927e-05, -8.07998e-02, -2.38834e-07, -4.84311e-06, 6.25854e-06

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.00000e+00, 1.00000e+00, 9.08804e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 58 (pos: 0.586): 1.00000e+00, 1.00000e+00, 6.71401e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 59 (pos: 0.596): 1.00000e+00, 1.00000e+00, 4.11173e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 60 (pos: 0.606): 1.00000e+00, 1.00000e+00, 2.12803e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 61 (pos: 0.616): 1.00000e+00, 1.00000e+00, 9.48139e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 50 (pos: 0.505): 1.00000e+00, 1.00000e+00, 3.70157e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 51 (pos: 0.515): 1.00000e+00, 1.00000e+00, 9.48139e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 52 (pos: 0.525): 1.00000e+00, 1.00000e+00, 2.12803e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 53 (pos: 0.535): 1.00000e+00, 1.00000e+00, 4.11173e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 54 (pos: 0.545): 1.00000e+00, 1.00000e+00, 6.71401e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 55 (pos: 0.556): 1.00000e+00, 1.00000e+00, 9.08804e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 62 (pos: 0.626): 1.00000e+00, 1.00000e+00, 3.70157e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 1.70784240046356e-06), ('0.bias', 3.0172541312419353e-05), ('2.weight', 0.000333354515763812), ('2.bias', 0.00010649332423446581)] 

GNN_Layer 1 gradients:
[('0.weight', 2.574894327885125e-07), ('0.bias', 4.768081410396154e-06), ('2.weight', 6.049153146387532e-05), ('2.bias', 1.8380298852054794e-05)] 

GNN_Layer 2 gradients:
[('0.weight', 0.0569885937147593), ('0.bias', 0.09823125706533753), ('2.weight', 0.7242131875502212), ('2.bias', 0.18172655984178832)] 

GNN_Layer 3 gradients:
[('0.weight', 3.636487346893061e-08), ('0.bias', 5.937561100569848e-07), ('2.weight', 7.563382770094358e-06), ('2.bias', 2.215555821352288e-06)] 

GNN_Layer 4 gradients:
[('0.weight', 2.086787244145048e-09), ('0.bias', 9.373811824745856e-07), ('2.weight', 1.2542819670958936e-05), ('2.bias', 3.7612595986671436e-06)] 

GNN_Layer 5 gradients:
[('0.weight', 3.9065216942438844e-07), ('0.bias', 1.1218602490448063e-05), ('2.weight', 0.00014451071464386853), ('2.bias', 4.050413660765694e-05)] 

Evaluation on test dataset:
Step 25, mean loss 0.022443978074158176
Step 50, mean loss 0.010831509099520504
Step 75, mean loss 0.019924381372086256
Step 100, mean loss 0.02391208030557495
Step 125, mean loss 0.029874081263846487
Step 150, mean loss 0.03896791069190871
Step 175, mean loss 0.05164735541991272
Step 200, mean loss 0.07169365724100375
Step 225, mean loss 0.07324761182176338
Unrolled forward losses 1.315440803506172
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 11
Starting epoch 11...
Training Loss (progress: 0.00), 0.11176369425389411, [0.42566910729438384, 0.301894290946399, 0.0019952835322786704, 0.31504156151791823, 0.3360181414369597, 0.4145182654212579]
Training Loss (progress: 0.08), 0.10809965382499295, [0.42635096358149893, 0.3020837610866932, 0.002004390452125506, 0.3155215586062809, 0.3364790013263059, 0.41519329735071353]
Training Loss (progress: 0.16), 0.10084516136157737, [0.42638935867812733, 0.30245737173214265, 0.0020137321878154163, 0.31547720615470926, 0.3369051318428914, 0.41551649283198516]
Training Loss (progress: 0.24), 0.10622998127103986, [0.4273346476914716, 0.30269254218735514, 0.0019848013526043984, 0.315424315975589, 0.3372780888899855, 0.416073987059901]
Training Loss (progress: 0.32), 0.10664479691075222, [0.42807830362610144, 0.3027250479358294, 0.001975862604391356, 0.3157384931269458, 0.3372537479645328, 0.41704890068624556]
Training Loss (progress: 0.40), 0.10603796421038743, [0.4284070946364622, 0.3030381156623312, 0.001986234876586582, 0.3162379131819384, 0.3378093290330357, 0.41736531509906727]
Training Loss (progress: 0.48), 0.11301529194166589, [0.42931034977021876, 0.3030043678024972, 0.001980010413540965, 0.3166083972829406, 0.33844983178141447, 0.4174832067494545]
Training Loss (progress: 0.56), 0.11030349833902509, [0.4296304127020307, 0.30365961883609166, 0.0019848620717924197, 0.3168435284243765, 0.3388684115007949, 0.4180303719678294]
Training Loss (progress: 0.64), 0.11491062692942482, [0.4303391495365099, 0.30403956866715504, 0.001990850694705437, 0.3169044731547164, 0.3395039548761959, 0.41853710147199835]
Training Loss (progress: 0.72), 0.10616567869779726, [0.43078819753501885, 0.3046435009136414, 0.001996680270912237, 0.3168540179938255, 0.340458874636602, 0.41919897508509657]
Training Loss (progress: 0.80), 0.10412352174400223, [0.43137074443917617, 0.3046142930158835, 0.0019679948496393847, 0.31685395552799206, 0.3405291876454006, 0.419354155121789]
Training Loss (progress: 0.88), 0.09874809220528236, [0.43175837035240916, 0.3051679969892198, 0.0019628153062884804, 0.3171274908778758, 0.34147274730469224, 0.42007443291294494]
Training Loss (progress: 0.96), 0.10218446972747522, [0.432359817674189, 0.3056716908747548, 0.001985388726462359, 0.31731794095710353, 0.3422839592165637, 0.4200108543052599]
Evaluation on validation dataset:
Step 25, mean loss 0.027315031213613984
Step 50, mean loss 0.015502057126435537
Step 75, mean loss 0.026632181327063388
Step 100, mean loss 0.028969584615017217
Step 125, mean loss 0.0349240444832116
Step 150, mean loss 0.034534551864981985
Step 175, mean loss 0.059087794669845116
Step 200, mean loss 0.18738881637646101
Step 225, mean loss 0.15263211291145887
Unrolled forward losses 1.7117502003712617
Unrolled forward base losses 2.565701273852575
Epoch 12
Starting epoch 12...
Training Loss (progress: 0.00), 0.10502875061913385, [0.4328102329892872, 0.3058419482027388, 0.0019917911716538133, 0.3173092572900943, 0.3426559962152578, 0.4199938854135269]
Training Loss (progress: 0.08), 0.11211436051099122, [0.43327054588945746, 0.30607125549157715, 0.0019825340391703165, 0.3172561475939368, 0.34364919575264447, 0.4205087794587649]
Training Loss (progress: 0.16), 0.10897305900276, [0.43395929675656114, 0.30651924998995866, 0.0019519157851467762, 0.3173713493284235, 0.3439665926816765, 0.42064458074517636]
Training Loss (progress: 0.24), 0.10107159337489359, [0.43420534050114323, 0.3064702571030557, 0.0019647990615487775, 0.3176636503606781, 0.34455946801793275, 0.4213867286441414]
Training Loss (progress: 0.32), 0.10996416934472152, [0.43455736303517395, 0.3066187351167191, 0.0019542266567143386, 0.31791754844083275, 0.3452649079059252, 0.42205537200861926]
Training Loss (progress: 0.40), 0.09984931097333276, [0.4351852949996177, 0.306783999495994, 0.001952860490511579, 0.3183420395155697, 0.3459326121242585, 0.4228288447340971]
Training Loss (progress: 0.48), 0.10377152962160113, [0.43532509756331994, 0.30710602493176137, 0.0019631733056571584, 0.3188067727923262, 0.3460762073078959, 0.4235403355160004]
Training Loss (progress: 0.56), 0.1083031098734236, [0.4359619669184311, 0.307063664517885, 0.001971552977113617, 0.319143349852683, 0.34602155886428726, 0.4237669119322721]
Training Loss (progress: 0.64), 0.10726800943438511, [0.4358908308281071, 0.30757253213295865, 0.0019744189596942827, 0.3191326611111229, 0.34655289290373664, 0.4242920462167153]
Training Loss (progress: 0.72), 0.10467045392057929, [0.43621256324874286, 0.30762263120252636, 0.0019573005229962287, 0.31925660935808137, 0.3466829471600228, 0.42439348199110905]
Training Loss (progress: 0.80), 0.10565631143666736, [0.43677510139906933, 0.30784939010149903, 0.001943201478847064, 0.31964083586918013, 0.34772123461057736, 0.4252617954742587]
Training Loss (progress: 0.88), 0.10419508031363427, [0.43722257612933757, 0.3084489354125194, 0.0019447876550204627, 0.31958759545519444, 0.34834466690128196, 0.425923277326827]
Training Loss (progress: 0.96), 0.10427597185365782, [0.43731242535217113, 0.30916900634776046, 0.0019559625046241744, 0.31996369048702605, 0.3490277286960866, 0.42651675675830647]
Evaluation on validation dataset:
Step 25, mean loss 0.025260069975988876
Step 50, mean loss 0.014597062085853003
Step 75, mean loss 0.026185906675542478
Step 100, mean loss 0.02719571946172684
Step 125, mean loss 0.034899832887508205
Step 150, mean loss 0.0331558117269926
Step 175, mean loss 0.05620974274896735
Step 200, mean loss 0.1890917434742742
Step 225, mean loss 0.1529059473146465
Unrolled forward losses 1.6724354101015009
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 8.78568e-04, -4.33598e-04, -8.01192e-02, 2.90875e-05, -8.39762e-04, -4.53657e-05
Node: 01 (pos: 0.010): 8.60632e-04, -4.18757e-04, -6.76617e-02, 3.81219e-05, -8.31927e-04, -3.59599e-05
Node: 02 (pos: 0.020): 8.52679e-04, -4.07871e-04, -5.47542e-02, 4.74358e-05, -8.24608e-04, -2.82698e-05
Node: 03 (pos: 0.030): 8.54720e-04, -4.00936e-04, -4.13935e-02, 5.70391e-05, -8.17835e-04, -2.22885e-05
Node: 04 (pos: 0.040): 8.66763e-04, -3.97947e-04, -2.75769e-02, 6.69417e-05, -8.11639e-04, -1.80087e-05
Node: 05 (pos: 0.051): 8.88820e-04, -3.98898e-04, -1.33020e-02, 7.71531e-05, -8.06050e-04, -1.54237e-05
-
Node: 07 (pos: 0.071): 8.88820e-04, -3.98898e-04, -1.33020e-02, 7.71531e-05, -8.06050e-04, -1.54237e-05
Node: 08 (pos: 0.081): 8.66763e-04, -3.97947e-04, -2.75769e-02, 6.69417e-05, -8.11639e-04, -1.80087e-05
Node: 09 (pos: 0.091): 8.54720e-04, -4.00936e-04, -4.13935e-02, 5.70391e-05, -8.17835e-04, -2.22885e-05
Node: 10 (pos: 0.101): 8.52679e-04, -4.07871e-04, -5.47542e-02, 4.74358e-05, -8.24608e-04, -2.82698e-05
Node: 11 (pos: 0.111): 8.60632e-04, -4.18757e-04, -6.76617e-02, 3.81219e-05, -8.31927e-04, -3.59599e-05
Node: 12 (pos: 0.121): 8.78568e-04, -4.33598e-04, -8.01192e-02, 2.90875e-05, -8.39762e-04, -4.53657e-05

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 9.99998e-01, 9.99999e-01, 3.69982e-02, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 01 (pos: 0.010): 9.99998e-01, 9.99999e-01, 9.52408e-02, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 02 (pos: 0.020): 9.99998e-01, 9.99999e-01, 2.14423e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 03 (pos: 0.030): 9.99998e-01, 9.99999e-01, 4.14773e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 04 (pos: 0.040): 9.99998e-01, 9.99999e-01, 6.76657e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 05 (pos: 0.051): 9.99998e-01, 9.99999e-01, 9.13128e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
-
Node: 07 (pos: 0.071): 9.99998e-01, 9.99999e-01, 9.13128e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 08 (pos: 0.081): 9.99998e-01, 9.99999e-01, 6.76657e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 09 (pos: 0.091): 9.99998e-01, 9.99999e-01, 4.14773e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 10 (pos: 0.101): 9.99998e-01, 9.99999e-01, 2.14423e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 11 (pos: 0.111): 9.99998e-01, 9.99999e-01, 9.52408e-02, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 12 (pos: 0.121): 9.99998e-01, 9.99999e-01, 3.69982e-02, 1.00000e+00, 9.99998e-01, 1.00000e+00
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 8.88820e-04, -3.98898e-04, -1.33020e-02, 7.71531e-05, -8.06050e-04, -1.54237e-05
Node: 01 (pos: 0.010): 8.66763e-04, -3.97947e-04, -2.75769e-02, 6.69417e-05, -8.11639e-04, -1.80087e-05
Node: 02 (pos: 0.020): 8.54720e-04, -4.00936e-04, -4.13935e-02, 5.70391e-05, -8.17835e-04, -2.22885e-05
Node: 03 (pos: 0.030): 8.52679e-04, -4.07871e-04, -5.47542e-02, 4.74358e-05, -8.24608e-04, -2.82698e-05
Node: 04 (pos: 0.040): 8.60632e-04, -4.18757e-04, -6.76617e-02, 3.81219e-05, -8.31927e-04, -3.59599e-05
Node: 05 (pos: 0.051): 8.78568e-04, -4.33598e-04, -8.01192e-02, 2.90875e-05, -8.39762e-04, -4.53657e-05
-
Node: 07 (pos: 0.071): 8.60632e-04, -4.18757e-04, -6.76617e-02, 3.81219e-05, -8.31927e-04, -3.59599e-05
Node: 08 (pos: 0.081): 8.52679e-04, -4.07871e-04, -5.47542e-02, 4.74358e-05, -8.24608e-04, -2.82698e-05
Node: 09 (pos: 0.091): 8.54720e-04, -4.00936e-04, -4.13935e-02, 5.70391e-05, -8.17835e-04, -2.22885e-05
Node: 10 (pos: 0.101): 8.66763e-04, -3.97947e-04, -2.75769e-02, 6.69417e-05, -8.11639e-04, -1.80087e-05
Node: 11 (pos: 0.111): 8.88820e-04, -3.98898e-04, -1.33020e-02, 7.71531e-05, -8.06050e-04, -1.54237e-05
Node: 12 (pos: 0.121): 8.78568e-04, -4.33598e-04, -8.01192e-02, 2.90875e-05, -8.39762e-04, -4.53657e-05

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 9.99998e-01, 9.99999e-01, 9.13128e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 58 (pos: 0.586): 9.99998e-01, 9.99999e-01, 6.76657e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 59 (pos: 0.596): 9.99998e-01, 9.99999e-01, 4.14773e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 60 (pos: 0.606): 9.99998e-01, 9.99999e-01, 2.14423e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 61 (pos: 0.616): 9.99998e-01, 9.99999e-01, 9.52408e-02, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 50 (pos: 0.505): 9.99998e-01, 9.99999e-01, 3.69982e-02, 1.00000e+00, 9.99998e-01, 1.00000e+00
-
Node: 51 (pos: 0.515): 9.99998e-01, 9.99999e-01, 9.52408e-02, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 52 (pos: 0.525): 9.99998e-01, 9.99999e-01, 2.14423e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 53 (pos: 0.535): 9.99998e-01, 9.99999e-01, 4.14773e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 54 (pos: 0.545): 9.99998e-01, 9.99999e-01, 6.76657e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 55 (pos: 0.556): 9.99998e-01, 9.99999e-01, 9.13128e-01, 1.00000e+00, 9.99998e-01, 1.00000e+00
Node: 62 (pos: 0.626): 9.99998e-01, 9.99999e-01, 3.69982e-02, 1.00000e+00, 9.99998e-01, 1.00000e+00
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 4.700205322231478e-06), ('0.bias', 0.00011340989882072104), ('2.weight', 0.0012505519200927413), ('2.bias', 0.0004022483690371446)] 

GNN_Layer 1 gradients:
[('0.weight', 1.4981880809623023e-06), ('0.bias', 4.21515689692366e-05), ('2.weight', 0.0005340918639801537), ('2.bias', 0.00016329496271779765)] 

GNN_Layer 2 gradients:
[('0.weight', 0.025329617847086518), ('0.bias', 0.05556829037769047), ('2.weight', 0.35588147275343185), ('2.bias', 0.08507491688480417)] 

GNN_Layer 3 gradients:
[('0.weight', 1.2788738848568559e-07), ('0.bias', 2.0834398537234384e-06), ('2.weight', 2.6548909323588003e-05), ('2.bias', 7.812809201096933e-06)] 

GNN_Layer 4 gradients:
[('0.weight', 3.7951147594707874e-06), ('0.bias', 4.25809998817932e-05), ('2.weight', 0.0005620226337447271), ('2.bias', 0.00017133269742372197)] 

GNN_Layer 5 gradients:
[('0.weight', 3.4861584724027305e-07), ('0.bias', 9.067636091913993e-06), ('2.weight', 0.00011681415033085739), ('2.bias', 3.289474214524409e-05)] 

Evaluation on test dataset:
Step 25, mean loss 0.019888943387055012
Step 50, mean loss 0.010462992673753372
Step 75, mean loss 0.016625948697624515
Step 100, mean loss 0.021993377041030496
Step 125, mean loss 0.027645414827630947
Step 150, mean loss 0.036499065286958635
Step 175, mean loss 0.048564478806328235
Step 200, mean loss 0.06628249994708973
Step 225, mean loss 0.06755234061949947
Unrolled forward losses 1.2262252471479052
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 13
Starting epoch 13...
Training Loss (progress: 0.00), 0.10335749899605932, [0.4373793265275111, 0.3096563860989446, 0.001956360844261686, 0.3205438472301832, 0.349326997859605, 0.4269634194819292]
Training Loss (progress: 0.08), 0.10070524209906685, [0.4373119247113629, 0.3097310172643393, 0.0019404351599529917, 0.32062970551722564, 0.3494287240970281, 0.42705424068962716]
Training Loss (progress: 0.16), 0.10763997623587243, [0.43724101668846416, 0.3101034392418092, 0.0019439063565033186, 0.3209997432632266, 0.35012438418002345, 0.42770166140209764]
Training Loss (progress: 0.24), 0.10627004908394769, [0.4378273622333758, 0.31031290078722834, 0.001920448549821963, 0.3213617402587172, 0.3507907788403469, 0.4281376989384592]
Training Loss (progress: 0.32), 0.10225870788917889, [0.4381319132341075, 0.311286329585657, 0.0019416308457163153, 0.32204744214536124, 0.3512877913551543, 0.42870169880624254]
Training Loss (progress: 0.40), 0.10248143756436978, [0.4383373729048643, 0.3117850239781664, 0.001944445309893383, 0.3228475253532735, 0.35149794560251635, 0.42926281787090237]
Training Loss (progress: 0.48), 0.11166808628357519, [0.43883380916635834, 0.31201297213324247, 0.0019549129942219613, 0.32339007014541193, 0.3517815784355901, 0.43015749500824546]
Training Loss (progress: 0.56), 0.10037968720279969, [0.43927987412238506, 0.312489675894455, 0.0019388987840237744, 0.3237238438966122, 0.3520277117353568, 0.4305845654645388]
Training Loss (progress: 0.64), 0.1101074066350223, [0.4395432585807785, 0.3132808670651154, 0.0019397892254512806, 0.32436288241888894, 0.3520975050608174, 0.431366323823794]
Training Loss (progress: 0.72), 0.10703672562087724, [0.44008520316013666, 0.3142935786221633, 0.0019450997121455925, 0.32468730030267573, 0.35242790836227944, 0.43175053470750957]
Training Loss (progress: 0.80), 0.10365051865893159, [0.44094787720525785, 0.31469321197186323, 0.0019626160855021847, 0.3246418519490212, 0.3523691020795314, 0.4324649235068151]
Training Loss (progress: 0.88), 0.10982688212254257, [0.4414937170918071, 0.31535409520734164, 0.0019382356568521362, 0.3248724386222398, 0.35274162682183097, 0.4329797412846096]
Training Loss (progress: 0.96), 0.10485177576335473, [0.44216799885624175, 0.3155878720747329, 0.001942391137905203, 0.325448052219857, 0.3531827107636412, 0.433739054293755]
Evaluation on validation dataset:
Step 25, mean loss 0.02534338191948946
Step 50, mean loss 0.013961441280300036
Step 75, mean loss 0.025196430312660716
Step 100, mean loss 0.027943141499292095
Step 125, mean loss 0.0333472286434659
Step 150, mean loss 0.03268587409530261
Step 175, mean loss 0.055700955609953015
Step 200, mean loss 0.17745613487325537
Step 225, mean loss 0.1540464480569098
Unrolled forward losses 1.6202037440501251
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.11347e-05, 1.77358e-05, -7.96255e-02, 2.29578e-05, -5.26552e-05, -4.65195e-06
Node: 01 (pos: 0.010): 1.44144e-06, 2.26445e-05, -6.71798e-02, 2.87523e-05, -4.71118e-05, -1.14220e-08
Node: 02 (pos: 0.020): -8.34923e-06, 2.36392e-05, -5.42860e-02, 3.48283e-05, -4.20747e-05, 2.91631e-06
Node: 03 (pos: 0.030): -8.22757e-06, 2.07246e-05, -4.09411e-02, 4.11957e-05, -3.75737e-05, 4.13827e-06
Node: 04 (pos: 0.040): 1.81624e-06, 1.39058e-05, -2.71423e-02, 4.78640e-05, -3.36385e-05, 3.66150e-06
Node: 05 (pos: 0.051): 2.17920e-05, 3.18833e-06, -1.28872e-02, 5.48429e-05, -3.02987e-05, 1.49300e-06
-
Node: 07 (pos: 0.071): 2.17920e-05, 3.18833e-06, -1.28872e-02, 5.48429e-05, -3.02987e-05, 1.49300e-06
Node: 08 (pos: 0.081): 1.81624e-06, 1.39058e-05, -2.71423e-02, 4.78640e-05, -3.36385e-05, 3.66150e-06
Node: 09 (pos: 0.091): -8.22757e-06, 2.07246e-05, -4.09411e-02, 4.11957e-05, -3.75737e-05, 4.13827e-06
Node: 10 (pos: 0.101): -8.34923e-06, 2.36392e-05, -5.42860e-02, 3.48283e-05, -4.20747e-05, 2.91631e-06
Node: 11 (pos: 0.111): 1.44144e-06, 2.26445e-05, -6.71798e-02, 2.87523e-05, -4.71118e-05, -1.14220e-08
Node: 12 (pos: 0.121): 2.11347e-05, 1.77358e-05, -7.96255e-02, 2.29578e-05, -5.26552e-05, -4.65195e-06

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.00000e+00, 1.00000e+00, 3.74218e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 01 (pos: 0.010): 1.00000e+00, 1.00000e+00, 9.64530e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 02 (pos: 0.020): 1.00000e+00, 1.00000e+00, 2.17160e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 03 (pos: 0.030): 1.00000e+00, 1.00000e+00, 4.19542e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 04 (pos: 0.040): 1.00000e+00, 1.00000e+00, 6.82659e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 05 (pos: 0.051): 1.00000e+00, 1.00000e+00, 9.17536e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 07 (pos: 0.071): 1.00000e+00, 1.00000e+00, 9.17536e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 08 (pos: 0.081): 1.00000e+00, 1.00000e+00, 6.82659e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 09 (pos: 0.091): 1.00000e+00, 1.00000e+00, 4.19542e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 10 (pos: 0.101): 1.00000e+00, 1.00000e+00, 2.17160e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 11 (pos: 0.111): 1.00000e+00, 1.00000e+00, 9.64530e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 12 (pos: 0.121): 1.00000e+00, 1.00000e+00, 3.74218e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 2.17920e-05, 3.18833e-06, -1.28872e-02, 5.48429e-05, -3.02987e-05, 1.49300e-06
Node: 01 (pos: 0.010): 1.81624e-06, 1.39058e-05, -2.71423e-02, 4.78640e-05, -3.36385e-05, 3.66150e-06
Node: 02 (pos: 0.020): -8.22757e-06, 2.07246e-05, -4.09411e-02, 4.11957e-05, -3.75737e-05, 4.13827e-06
Node: 03 (pos: 0.030): -8.34923e-06, 2.36392e-05, -5.42860e-02, 3.48283e-05, -4.20747e-05, 2.91631e-06
Node: 04 (pos: 0.040): 1.44144e-06, 2.26445e-05, -6.71798e-02, 2.87523e-05, -4.71118e-05, -1.14220e-08
Node: 05 (pos: 0.051): 2.11347e-05, 1.77358e-05, -7.96255e-02, 2.29578e-05, -5.26552e-05, -4.65195e-06
-
Node: 07 (pos: 0.071): 1.44144e-06, 2.26445e-05, -6.71798e-02, 2.87523e-05, -4.71118e-05, -1.14220e-08
Node: 08 (pos: 0.081): -8.34923e-06, 2.36392e-05, -5.42860e-02, 3.48283e-05, -4.20747e-05, 2.91631e-06
Node: 09 (pos: 0.091): -8.22757e-06, 2.07246e-05, -4.09411e-02, 4.11957e-05, -3.75737e-05, 4.13827e-06
Node: 10 (pos: 0.101): 1.81624e-06, 1.39058e-05, -2.71423e-02, 4.78640e-05, -3.36385e-05, 3.66150e-06
Node: 11 (pos: 0.111): 2.17920e-05, 3.18833e-06, -1.28872e-02, 5.48429e-05, -3.02987e-05, 1.49300e-06
Node: 12 (pos: 0.121): 2.11347e-05, 1.77358e-05, -7.96255e-02, 2.29578e-05, -5.26552e-05, -4.65195e-06

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.00000e+00, 1.00000e+00, 9.17536e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 58 (pos: 0.586): 1.00000e+00, 1.00000e+00, 6.82659e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 59 (pos: 0.596): 1.00000e+00, 1.00000e+00, 4.19542e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 60 (pos: 0.606): 1.00000e+00, 1.00000e+00, 2.17160e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 61 (pos: 0.616): 1.00000e+00, 1.00000e+00, 9.64530e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 50 (pos: 0.505): 1.00000e+00, 1.00000e+00, 3.74218e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 51 (pos: 0.515): 1.00000e+00, 1.00000e+00, 9.64530e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 52 (pos: 0.525): 1.00000e+00, 1.00000e+00, 2.17160e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 53 (pos: 0.535): 1.00000e+00, 1.00000e+00, 4.19542e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 54 (pos: 0.545): 1.00000e+00, 1.00000e+00, 6.82659e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 55 (pos: 0.556): 1.00000e+00, 1.00000e+00, 9.17536e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 62 (pos: 0.626): 1.00000e+00, 1.00000e+00, 3.74218e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 9.769255173102642e-08), ('0.bias', 4.389485279217067e-07), ('2.weight', 5.04821384559227e-06), ('2.bias', 1.5542197096488701e-06)] 

GNN_Layer 1 gradients:
[('0.weight', 1.8418643768414997e-07), ('0.bias', 4.120600935748338e-06), ('2.weight', 5.2255981403292034e-05), ('2.bias', 1.6001332768184808e-05)] 

GNN_Layer 2 gradients:
[('0.weight', 0.025105788347237742), ('0.bias', 0.7259741451984704), ('2.weight', 4.245144371616957), ('2.bias', 1.3108945588031131)] 

GNN_Layer 3 gradients:
[('0.weight', 4.840221636665357e-07), ('0.bias', 8.854622953707652e-06), ('2.weight', 0.00011286034803623426), ('2.bias', 3.328546639001006e-05)] 

GNN_Layer 4 gradients:
[('0.weight', 5.184398576813285e-08), ('0.bias', 1.0702392276076689e-06), ('2.weight', 1.4489686067887171e-05), ('2.bias', 4.328035076232156e-06)] 

GNN_Layer 5 gradients:
[('0.weight', 7.207193268403349e-09), ('0.bias', 8.968043045518568e-07), ('2.weight', 1.1577586342108898e-05), ('2.bias', 3.2694289991048765e-06)] 

Evaluation on test dataset:
Step 25, mean loss 0.020560133076174762
Step 50, mean loss 0.01062625203617524
Step 75, mean loss 0.01688134641390291
Step 100, mean loss 0.021191031545118987
Step 125, mean loss 0.027277685027191648
Step 150, mean loss 0.035302634230132815
Step 175, mean loss 0.04767100938785042
Step 200, mean loss 0.06517779871393174
Step 225, mean loss 0.06491743090574939
Unrolled forward losses 1.2570436295143992
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 14
Starting epoch 14...
Training Loss (progress: 0.00), 0.09636758394667838, [0.4421309437831581, 0.3155645562899433, 0.0019214088743067202, 0.3254364330024697, 0.3532988770273121, 0.43413326383845485]
Training Loss (progress: 0.08), 0.10489906214725964, [0.4424097875381337, 0.3160104722448516, 0.0019442194011593129, 0.3260913438025198, 0.35361333348327856, 0.43441001294421633]
Training Loss (progress: 0.16), 0.09287829338924926, [0.44307919474015095, 0.31687383876679615, 0.0019439879380288153, 0.3268551893648259, 0.3538585681432566, 0.43485369680118463]
Training Loss (progress: 0.24), 0.1101467059379481, [0.44327810066125656, 0.3171988903906039, 0.0019382798675871525, 0.3271826522056609, 0.3545067139703227, 0.43569212675838015]
Training Loss (progress: 0.32), 0.10379797424661134, [0.44365454957464556, 0.3175311319527546, 0.0019451211383283062, 0.32713526446086005, 0.3548385353846464, 0.4361070473795179]
Training Loss (progress: 0.40), 0.10456513429055701, [0.4444445740605734, 0.31822791087477703, 0.0019305909659464039, 0.3274827804908603, 0.3553515629303751, 0.43673202003375583]
Training Loss (progress: 0.48), 0.10652805784215147, [0.4450072427976141, 0.3186567316024262, 0.0019406738206296757, 0.3274280112049765, 0.3553640573673121, 0.43727855463915966]
Training Loss (progress: 0.56), 0.11439006179704168, [0.44529022652368927, 0.31911085503225617, 0.0019470924340289578, 0.32788309538726496, 0.3556314583197901, 0.4375145528272383]
Training Loss (progress: 0.64), 0.10079570830751768, [0.4459555915193977, 0.31927222298868335, 0.0019342209576975315, 0.32817578380306944, 0.3555833393381761, 0.4376793715399985]
Training Loss (progress: 0.72), 0.10556287816330259, [0.44598054453640973, 0.319668722779878, 0.001949412960619287, 0.3287107324483296, 0.3555264467453905, 0.4383788567963259]
Training Loss (progress: 0.80), 0.10407034198412861, [0.4459381770967749, 0.31996115911184275, 0.0019524867414723384, 0.32867809549835264, 0.3558308757101829, 0.43884968493844595]
Training Loss (progress: 0.88), 0.10251218256518607, [0.44631219404678607, 0.3203404008009264, 0.0019256171223097876, 0.32903852646696025, 0.35624305898011466, 0.439255357768695]
Training Loss (progress: 0.96), 0.11175138461728759, [0.4471299708039357, 0.3205447159967721, 0.0019326203096754113, 0.3292913284259536, 0.35618422984537357, 0.43970584810092517]
Evaluation on validation dataset:
Step 25, mean loss 0.02379360583997587
Step 50, mean loss 0.014385101989402613
Step 75, mean loss 0.026083335155729838
Step 100, mean loss 0.028972823834083897
Step 125, mean loss 0.03706851281523678
Step 150, mean loss 0.03267351211095136
Step 175, mean loss 0.056080325789574545
Step 200, mean loss 0.17930451725975427
Step 225, mean loss 0.15882101161594175
Unrolled forward losses 1.7207173471307309
Unrolled forward base losses 2.565701273852575
Epoch 15
Starting epoch 15...
Training Loss (progress: 0.00), 0.10952743295081584, [0.44709508264336206, 0.32060100478183584, 0.0019344756778991385, 0.329668685305307, 0.35615618991297676, 0.4396717540879855]
Training Loss (progress: 0.08), 0.09568202148627462, [0.4471764858622708, 0.32066988369342014, 0.0019303610490892052, 0.3296787190680368, 0.3562461965033872, 0.4397377473454041]
Training Loss (progress: 0.16), 0.09614873809902492, [0.4472662207060094, 0.32079281570034235, 0.0019309612568980394, 0.3298641780393523, 0.3563018580793796, 0.4398337198030674]
Training Loss (progress: 0.24), 0.10162034618156102, [0.4474279684865162, 0.320914845538981, 0.0019236202568420435, 0.3298423013562837, 0.356444513855964, 0.44008584205369966]
Training Loss (progress: 0.32), 0.10435008050686165, [0.44754065108926055, 0.3210264368657938, 0.0019319492957094455, 0.3300141826674084, 0.3565783165278409, 0.440096088279853]
Training Loss (progress: 0.40), 0.09103108434833365, [0.44774509812360264, 0.321141218396999, 0.0019164285906477512, 0.3299898849933091, 0.35672421986549246, 0.44050184955691596]
Training Loss (progress: 0.48), 0.0977529496664935, [0.4478681210369773, 0.32144403752829476, 0.0019143371509371114, 0.33008177018319074, 0.35684783488617766, 0.44053952633875126]
Training Loss (progress: 0.56), 0.09842704397142649, [0.4479395065617937, 0.3214243657934846, 0.0019148055010389277, 0.3301572337819885, 0.3568309899245173, 0.4408360988786]
Training Loss (progress: 0.64), 0.09325122400127142, [0.44801371768637077, 0.32150891718844654, 0.0019106506308164508, 0.33023500578814596, 0.3569298903041019, 0.4410507901332937]
Training Loss (progress: 0.72), 0.09840626621340445, [0.44817681163298073, 0.3217812263608824, 0.001917219605614776, 0.330213064784397, 0.3571425549142146, 0.44123679178655706]
Training Loss (progress: 0.80), 0.09834145102234246, [0.44832038358282617, 0.32213976133301625, 0.0019182038289193566, 0.3303075928260727, 0.3573523237112739, 0.44136450174781194]
Training Loss (progress: 0.88), 0.10149097522468685, [0.44858020785406344, 0.32228733960351347, 0.0019190658037889728, 0.33040053981697076, 0.35741482535825414, 0.4415368323457904]
Training Loss (progress: 0.96), 0.09977084506055019, [0.44881199512567055, 0.32242447253807505, 0.0019330387625708628, 0.3304408123291578, 0.3576654906538902, 0.4416454221177678]
Evaluation on validation dataset:
Step 25, mean loss 0.02380014130427197
Step 50, mean loss 0.013479326228666242
Step 75, mean loss 0.02371017734272196
Step 100, mean loss 0.02585509887031298
Step 125, mean loss 0.03337207242206826
Step 150, mean loss 0.03197355590154211
Step 175, mean loss 0.05397630133277294
Step 200, mean loss 0.1783065820281381
Step 225, mean loss 0.15646747523156534
Unrolled forward losses 1.645633590759541
Unrolled forward base losses 2.565701273852575
Epoch 16
Starting epoch 16...
Training Loss (progress: 0.00), 0.10694189599530918, [0.4489123445203115, 0.32242233439483486, 0.0019289015212691897, 0.3304445916711613, 0.35766606221452824, 0.44177096416212536]
Training Loss (progress: 0.08), 0.10277073586475896, [0.44910818604957914, 0.32257088259753325, 0.0019138455202117384, 0.3305710315158919, 0.35788966003297207, 0.4417442221292797]
Training Loss (progress: 0.16), 0.09533758422859785, [0.4493025519200145, 0.3225495768879869, 0.0019099719834401144, 0.3307500476773621, 0.35809723685993683, 0.44186694483287686]
Training Loss (progress: 0.24), 0.09839071268770488, [0.4492736072578314, 0.32253444718953567, 0.0019161680781783037, 0.33093899555455636, 0.3584151679226561, 0.4420481596274226]
Training Loss (progress: 0.32), 0.09456824286959085, [0.4493270642362243, 0.3226594885196348, 0.0019190486882139201, 0.3311452145394681, 0.35840764058544455, 0.4421515674814442]
Training Loss (progress: 0.40), 0.10254591146664854, [0.4495126118371325, 0.32271342716609613, 0.001912602115417544, 0.3312455172963176, 0.358614425419434, 0.44263605276395424]
Training Loss (progress: 0.48), 0.10236849688168874, [0.4494832520894406, 0.32269249169301484, 0.0019095335301190484, 0.33152652282356176, 0.3588921081629193, 0.4427936352762583]
Training Loss (progress: 0.56), 0.09955840497051904, [0.4496596064920874, 0.32275021271614834, 0.0019034113997670602, 0.3316171226887482, 0.35889049944864876, 0.4429666063065168]
Training Loss (progress: 0.64), 0.09731632881031882, [0.4497176745486099, 0.32289992584583227, 0.0019022505138194192, 0.3317901478400407, 0.35898064254399786, 0.44334027015073696]
Training Loss (progress: 0.72), 0.10306504645481895, [0.4500125599224374, 0.32287833420178796, 0.0019089537698415706, 0.3318042481536123, 0.3591078913437343, 0.44331695771719726]
Training Loss (progress: 0.80), 0.10017829638070644, [0.45033671115084467, 0.32292459555374586, 0.001909432269818724, 0.331825140028099, 0.3593835523261953, 0.44344557408756086]
Training Loss (progress: 0.88), 0.09897700035249299, [0.4503172341981365, 0.32295737412850173, 0.0019146529856563562, 0.3318725862654731, 0.35955360612260057, 0.44372018284210546]
Training Loss (progress: 0.96), 0.11145565123353422, [0.4506155157831488, 0.32314561469865277, 0.0019036273529381654, 0.332051854837825, 0.35959649185805276, 0.44391981775749373]
Evaluation on validation dataset:
Step 25, mean loss 0.02262159284202813
Step 50, mean loss 0.013228364781216355
Step 75, mean loss 0.024308124801850104
Step 100, mean loss 0.025904225821827675
Step 125, mean loss 0.032503543455750794
Step 150, mean loss 0.03149577572532755
Step 175, mean loss 0.054879727037871744
Step 200, mean loss 0.1765384956404414
Step 225, mean loss 0.152574043042817
Unrolled forward losses 1.658137469406475
Unrolled forward base losses 2.565701273852575
Epoch 17
Starting epoch 17...
Training Loss (progress: 0.00), 0.09573237776497638, [0.4506669301307635, 0.32320783382190177, 0.0019140120361009017, 0.3320408005489322, 0.3595844988779006, 0.44415765261108053]
Training Loss (progress: 0.08), 0.10536160602175917, [0.45071655881550016, 0.32320616209000386, 0.0018990932649680808, 0.3321919835420966, 0.35962596530323815, 0.44432235970885103]
Training Loss (progress: 0.16), 0.1016205860776789, [0.450720040752538, 0.3233814595475983, 0.0019100899423681117, 0.33224572279732384, 0.35973881436199895, 0.44455033628891344]
Training Loss (progress: 0.24), 0.09873787394068753, [0.4509032955625377, 0.3234291491217725, 0.0019062604531377616, 0.3322864313291436, 0.3599086141945157, 0.4446462359827152]
Training Loss (progress: 0.32), 0.09269892487819718, [0.45095627840577024, 0.3234083473369085, 0.001892396400666605, 0.33231552209947013, 0.36013182707851193, 0.4449485114245599]
Training Loss (progress: 0.40), 0.09279057060398069, [0.4510550721379508, 0.32359310852970546, 0.0018837521372108632, 0.33229336013145166, 0.3601932316651127, 0.44503013529177543]
Training Loss (progress: 0.48), 0.10312070141420686, [0.45139001571190746, 0.3236409480073465, 0.0018984598728227307, 0.3322748271940179, 0.36036681710590823, 0.4453267168101945]
Training Loss (progress: 0.56), 0.10408403338199475, [0.45152648890309427, 0.32362260665680453, 0.0018906921445938807, 0.3324781057934082, 0.3604962994899692, 0.445374427690388]
Training Loss (progress: 0.64), 0.09912777669143077, [0.4517760524553547, 0.3236223639219257, 0.0019033584888593117, 0.3325810565354098, 0.3605660513874537, 0.4454737933212792]
Training Loss (progress: 0.72), 0.10474378918504454, [0.45187648644379436, 0.32370350727649305, 0.001901740696713461, 0.3325599542830727, 0.3607812561539137, 0.44566076702337476]
Training Loss (progress: 0.80), 0.09767226482785495, [0.451981271463499, 0.32397012207785364, 0.001895324875206639, 0.33283181549354846, 0.3608335815380551, 0.445871020719743]
Training Loss (progress: 0.88), 0.10753556751854293, [0.4521304622855645, 0.3241238965555266, 0.001897731846599672, 0.3330941880799616, 0.360809686752755, 0.445955369545304]
Training Loss (progress: 0.96), 0.08855691141733303, [0.4523258535527633, 0.32410623473133027, 0.0018753649710923288, 0.33313222015104976, 0.3608557931395604, 0.4461730334322421]
Evaluation on validation dataset:
Step 25, mean loss 0.022613425458944455
Step 50, mean loss 0.013261113892724781
Step 75, mean loss 0.02279780282891312
Step 100, mean loss 0.026490235400624947
Step 125, mean loss 0.03390501272622995
Step 150, mean loss 0.03238816520684582
Step 175, mean loss 0.05224201624166705
Step 200, mean loss 0.16821443458359386
Step 225, mean loss 0.1493693389440798
Unrolled forward losses 1.5423453434057675
Unrolled forward base losses 2.565701273852575
=========================================================================================================
Positions transformed for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 2.69482e-05, 1.89032e-05, -7.85644e-02, -6.20367e-06, -6.70409e-06, 3.89446e-05
Node: 01 (pos: 0.010): 6.16572e-06, 2.89807e-05, -6.61609e-02, -4.35667e-06, -4.93576e-06, 4.30080e-05
Node: 02 (pos: 0.020): -4.84981e-06, 3.51877e-05, -5.33148e-02, -2.22955e-06, -3.66390e-06, 4.53739e-05
Node: 03 (pos: 0.030): -6.08887e-06, 3.75288e-05, -4.00231e-02, 1.87257e-07, -2.91767e-06, 4.60491e-05
Node: 04 (pos: 0.040): 2.45808e-06, 3.60089e-05, -2.62830e-02, 2.90321e-06, -2.72617e-06, 4.50406e-05
Node: 05 (pos: 0.051): 2.08006e-05, 3.06333e-05, -1.20923e-02, 5.92764e-06, -3.11845e-06, 4.23552e-05
-
Node: 07 (pos: 0.071): 2.08006e-05, 3.06333e-05, -1.20923e-02, 5.92764e-06, -3.11845e-06, 4.23552e-05
Node: 08 (pos: 0.081): 2.45808e-06, 3.60089e-05, -2.62830e-02, 2.90321e-06, -2.72617e-06, 4.50406e-05
Node: 09 (pos: 0.091): -6.08887e-06, 3.75288e-05, -4.00231e-02, 1.87257e-07, -2.91767e-06, 4.60491e-05
Node: 10 (pos: 0.101): -4.84981e-06, 3.51877e-05, -5.33148e-02, -2.22955e-06, -3.66390e-06, 4.53739e-05
Node: 11 (pos: 0.111): 6.16572e-06, 2.89807e-05, -6.61609e-02, -4.35667e-06, -4.93576e-06, 4.30080e-05
Node: 12 (pos: 0.121): 2.69482e-05, 1.89032e-05, -7.85644e-02, -6.20367e-06, -6.70409e-06, 3.89446e-05

Kernel Weights for neighbours of Node 6 (for each GNN layer):

Node: 00 (pos: 0.000): 1.00000e+00, 1.00000e+00, 3.75677e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 01 (pos: 0.010): 1.00000e+00, 1.00000e+00, 9.75658e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 02 (pos: 0.020): 1.00000e+00, 1.00000e+00, 2.20637e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 03 (pos: 0.030): 1.00000e+00, 1.00000e+00, 4.26714e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 04 (pos: 0.040): 1.00000e+00, 1.00000e+00, 6.92623e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 05 (pos: 0.051): 1.00000e+00, 1.00000e+00, 9.25204e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 07 (pos: 0.071): 1.00000e+00, 1.00000e+00, 9.25204e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 08 (pos: 0.081): 1.00000e+00, 1.00000e+00, 6.92623e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 09 (pos: 0.091): 1.00000e+00, 1.00000e+00, 4.26714e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 10 (pos: 0.101): 1.00000e+00, 1.00000e+00, 2.20637e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 11 (pos: 0.111): 1.00000e+00, 1.00000e+00, 9.75658e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 12 (pos: 0.121): 1.00000e+00, 1.00000e+00, 3.75677e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
---------------------------------------------------------------------------------------------------------
Positions transformed for neighbours of Node 56 (for each GNN layer):

Node: 00 (pos: 0.000): 2.08006e-05, 3.06333e-05, -1.20923e-02, 5.92764e-06, -3.11845e-06, 4.23552e-05
Node: 01 (pos: 0.010): 2.45808e-06, 3.60089e-05, -2.62830e-02, 2.90321e-06, -2.72617e-06, 4.50406e-05
Node: 02 (pos: 0.020): -6.08887e-06, 3.75288e-05, -4.00231e-02, 1.87257e-07, -2.91767e-06, 4.60491e-05
Node: 03 (pos: 0.030): -4.84981e-06, 3.51877e-05, -5.33148e-02, -2.22955e-06, -3.66390e-06, 4.53739e-05
Node: 04 (pos: 0.040): 6.16572e-06, 2.89807e-05, -6.61609e-02, -4.35667e-06, -4.93576e-06, 4.30080e-05
Node: 05 (pos: 0.051): 2.69482e-05, 1.89032e-05, -7.85644e-02, -6.20367e-06, -6.70409e-06, 3.89446e-05
-
Node: 07 (pos: 0.071): 6.16572e-06, 2.89807e-05, -6.61609e-02, -4.35667e-06, -4.93576e-06, 4.30080e-05
Node: 08 (pos: 0.081): -4.84981e-06, 3.51877e-05, -5.33148e-02, -2.22955e-06, -3.66390e-06, 4.53739e-05
Node: 09 (pos: 0.091): -6.08887e-06, 3.75288e-05, -4.00231e-02, 1.87257e-07, -2.91767e-06, 4.60491e-05
Node: 10 (pos: 0.101): 2.45808e-06, 3.60089e-05, -2.62830e-02, 2.90321e-06, -2.72617e-06, 4.50406e-05
Node: 11 (pos: 0.111): 2.08006e-05, 3.06333e-05, -1.20923e-02, 5.92764e-06, -3.11845e-06, 4.23552e-05
Node: 12 (pos: 0.121): 2.69482e-05, 1.89032e-05, -7.85644e-02, -6.20367e-06, -6.70409e-06, 3.89446e-05

Kernel Weights for neighbours of Node 56 (for each GNN layer):

Node: 57 (pos: 0.576): 1.00000e+00, 1.00000e+00, 9.25204e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 58 (pos: 0.586): 1.00000e+00, 1.00000e+00, 6.92623e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 59 (pos: 0.596): 1.00000e+00, 1.00000e+00, 4.26714e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 60 (pos: 0.606): 1.00000e+00, 1.00000e+00, 2.20637e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 61 (pos: 0.616): 1.00000e+00, 1.00000e+00, 9.75658e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 50 (pos: 0.505): 1.00000e+00, 1.00000e+00, 3.75677e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
-
Node: 51 (pos: 0.515): 1.00000e+00, 1.00000e+00, 9.75658e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 52 (pos: 0.525): 1.00000e+00, 1.00000e+00, 2.20637e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 53 (pos: 0.535): 1.00000e+00, 1.00000e+00, 4.26714e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 54 (pos: 0.545): 1.00000e+00, 1.00000e+00, 6.92623e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 55 (pos: 0.556): 1.00000e+00, 1.00000e+00, 9.25204e-01, 1.00000e+00, 1.00000e+00, 1.00000e+00
Node: 62 (pos: 0.626): 1.00000e+00, 1.00000e+00, 3.75677e-02, 1.00000e+00, 1.00000e+00, 1.00000e+00
=========================================================================================================
GNN_Layer 0 gradients:
[('0.weight', 5.96617360606561e-09), ('0.bias', 8.092892956090415e-07), ('2.weight', 8.883484009869125e-06), ('2.bias', 2.89398213201662e-06)] 

GNN_Layer 1 gradients:
[('0.weight', 2.835308793026571e-07), ('0.bias', 6.621182802768065e-06), ('2.weight', 8.397876040877696e-05), ('2.bias', 2.5848065725097308e-05)] 

GNN_Layer 2 gradients:
[('0.weight', 0.032036279957888936), ('0.bias', 0.5924581136705639), ('2.weight', 3.4677946539623106), ('2.bias', 1.0766472117453447)] 

GNN_Layer 3 gradients:
[('0.weight', 1.6799659383305244e-08), ('0.bias', 3.2439529439543966e-07), ('2.weight', 4.136547003925159e-06), ('2.bias', 1.2260366692120843e-06)] 

GNN_Layer 4 gradients:
[('0.weight', 5.089065750708697e-08), ('0.bias', 1.0269237942021325e-06), ('2.weight', 1.3627239962191848e-05), ('2.bias', 4.168326562420146e-06)] 

GNN_Layer 5 gradients:
[('0.weight', 5.302259591058382e-07), ('0.bias', 1.227836872412104e-05), ('2.weight', 0.00015820950941404732), ('2.bias', 4.488626389166344e-05)] 

Evaluation on test dataset:
Step 25, mean loss 0.01831614147572836
Step 50, mean loss 0.010001481733396204
Step 75, mean loss 0.015659146241057718
Step 100, mean loss 0.020449727296601494
Step 125, mean loss 0.026461491170551698
Step 150, mean loss 0.03368308058940782
Step 175, mean loss 0.044366166825685
Step 200, mean loss 0.06525051284129368
Step 225, mean loss 0.06473125703340155
Unrolled forward losses 1.2275151891581904
Unrolled forward base losses 2.5892662621222584
Saved model at models/GNN_norm+mlp+product_CE_E1_xresolution100-200_lr0.0001_n6_s0.001_tw25_unrolling2_time514350.tar

Epoch 18
Starting epoch 18...
Training Loss (progress: 0.00), 0.09199800905350572, [0.4524514991557639, 0.3241794567807213, 0.0018891328694555416, 0.3331217556959348, 0.3609034859662214, 0.44631853511299807]
Training Loss (progress: 0.08), 0.09725027695947784, [0.4526338783573371, 0.324214360404295, 0.00188261628596267, 0.33310098772963365, 0.36104850685052625, 0.4467302792151593]
Training Loss (progress: 0.16), 0.09592597611700814, [0.4527648735622981, 0.3242865252599283, 0.0018769105514946547, 0.33322474456434586, 0.36102441764951143, 0.44675351685923886]
Training Loss (progress: 0.24), 0.09936355487059248, [0.4528864193415872, 0.3244700652916517, 0.0018791018186704892, 0.33346366226942664, 0.3611138517444754, 0.44681905908480246]
Training Loss (progress: 0.32), 0.09856738219556102, [0.4530078705971373, 0.3244487966385553, 0.0018799203623150946, 0.3335441195660098, 0.3613216932582984, 0.4470005422655603]
Training Loss (progress: 0.40), 0.10254260138983415, [0.45309373842767586, 0.324667764772236, 0.001883218396320026, 0.3337456079908173, 0.36148024104270243, 0.4472388816550148]
Training Loss (progress: 0.48), 0.09395682226432019, [0.4532662370392946, 0.32480019622767503, 0.0018766507046499544, 0.3339982057857038, 0.36160245955781034, 0.4473430075658094]
Training Loss (progress: 0.56), 0.09891331625567878, [0.45340308589695144, 0.3247795674530106, 0.0018821663826323642, 0.3342683094233625, 0.36159424840898124, 0.4475990695067427]
Training Loss (progress: 0.64), 0.10289230236893937, [0.4536227997580634, 0.32475895461173715, 0.0018887996967626812, 0.33441720140973635, 0.36184564001301106, 0.4476021199363879]
Training Loss (progress: 0.72), 0.09853112781401047, [0.4536787190211612, 0.32486234107595924, 0.0018886036690624922, 0.33457811087126255, 0.3618541015360685, 0.44778458155277484]
Training Loss (progress: 0.80), 0.0946605079270295, [0.45380645847880513, 0.32489613243309723, 0.0018707065952803161, 0.3348507651526995, 0.36206285285918866, 0.44793184582115086]
Training Loss (progress: 0.88), 0.09086163790732672, [0.4540482987620996, 0.3248921402579136, 0.0018792558721555874, 0.33489732213212847, 0.3623702772306944, 0.44801897209114827]
Training Loss (progress: 0.96), 0.10028397830375152, [0.45425807050868394, 0.3250179576550027, 0.0018569605970356995, 0.3350986135834315, 0.36235004221990424, 0.4480871978070085]
Evaluation on validation dataset:
Step 25, mean loss 0.022120671254913696
Step 50, mean loss 0.013051995840256618
Step 75, mean loss 0.02317231104055724
Step 100, mean loss 0.027269961535978972
Step 125, mean loss 0.03394230302993633
Step 150, mean loss 0.03186146998315645
Step 175, mean loss 0.05401601445379897
Step 200, mean loss 0.1651578492416904
Step 225, mean loss 0.15091293595993002
Unrolled forward losses 1.5618648174969665
Unrolled forward base losses 2.565701273852575
Epoch 19
Starting epoch 19...
Training Loss (progress: 0.00), 0.10413655319259561, [0.4544301877974405, 0.32500735044857515, 0.001878540558329731, 0.3351733259352701, 0.3625399989693942, 0.44829601471357305]
Training Loss (progress: 0.08), 0.10721035406790062, [0.4546456359718575, 0.32514482880859924, 0.0018752530151046967, 0.3352877355762317, 0.3627598469861079, 0.4487330120677244]
Training Loss (progress: 0.16), 0.0990808556853115, [0.45483440261267305, 0.32516353383761326, 0.0018937207777656477, 0.33535452120403403, 0.36285177602757207, 0.4489101828148129]
Training Loss (progress: 0.24), 0.09967034988386742, [0.4549558770812671, 0.32530495922487024, 0.0018768079379473408, 0.3354566095617584, 0.36291354117132824, 0.4492319146774643]
Training Loss (progress: 0.32), 0.09544680048985608, [0.45511407476422877, 0.32537941327231323, 0.0018634965343402737, 0.33565951110799896, 0.36320354033091, 0.44949692080285675]
Training Loss (progress: 0.40), 0.09429881287435515, [0.45517016909909586, 0.3254686003219834, 0.0018754082630245469, 0.33563959008893085, 0.3632760078142059, 0.44969695930644404]
Training Loss (progress: 0.48), 0.09493876321397364, [0.45555431364079185, 0.32550512937307746, 0.001870352263950149, 0.33577869876414085, 0.3635412528653853, 0.4500682991692391]
Training Loss (progress: 0.56), 0.10552036637074554, [0.455718614392629, 0.3254931677287076, 0.0018796129313759387, 0.3359496428266848, 0.3637154594222514, 0.45021780795223393]
Training Loss (progress: 0.64), 0.10161140566403659, [0.45587678070772786, 0.3256999385064531, 0.0018763382686665113, 0.3360238033612719, 0.3637338087144847, 0.4502671175780451]
Training Loss (progress: 0.72), 0.10567992769934709, [0.456015263099928, 0.32585683988847725, 0.0018704360065087502, 0.33604136609889423, 0.3637974130556124, 0.450438227948488]
Training Loss (progress: 0.80), 0.11121350077092955, [0.4562306418104459, 0.32617820851962903, 0.001864228641953851, 0.3361369529570233, 0.36396752888106176, 0.4505834991323216]
Training Loss (progress: 0.88), 0.10148652335990978, [0.45639900386906085, 0.32636838734127743, 0.0018606084817591579, 0.33624213985190476, 0.36401068614520155, 0.4509245832090237]
Training Loss (progress: 0.96), 0.10894977700031333, [0.45656699663396016, 0.3264212127749188, 0.0018688276590924629, 0.33621991413908014, 0.3640780696122037, 0.45097941852863777]
Evaluation on validation dataset:
Step 25, mean loss 0.021589125582562534
Step 50, mean loss 0.013313992666396216
Step 75, mean loss 0.023586299525717006
Step 100, mean loss 0.026893554553605988
Step 125, mean loss 0.034085283131118915
Step 150, mean loss 0.03208489810321314
Step 175, mean loss 0.053971534042540986
Step 200, mean loss 0.17236403945624706
Step 225, mean loss 0.1537443975323013
Unrolled forward losses 1.5640994962412869
Unrolled forward base losses 2.565701273852575
Test loss: 1.2275151891581904
